{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PersonaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization, Dropout, Dense, Concatenate, Input, Flatten, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Qualifiaction</th>\n",
       "      <th>A (Raw)</th>\n",
       "      <th>C(Raw)</th>\n",
       "      <th>E (Raw)</th>\n",
       "      <th>O (Raw)</th>\n",
       "      <th>N (Raw)</th>\n",
       "      <th>A (T score)</th>\n",
       "      <th>C(T score)</th>\n",
       "      <th>E(T score)</th>\n",
       "      <th>O (T score)</th>\n",
       "      <th>N (T score)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>Subhi Jain</td>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>Under Grad</td>\n",
       "      <td>26</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>Simran</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>Under Grad</td>\n",
       "      <td>40</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>Romy Kumari</td>\n",
       "      <td>19</td>\n",
       "      <td>F</td>\n",
       "      <td>Under Grad</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>47</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>59</td>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>19</td>\n",
       "      <td>M</td>\n",
       "      <td>Under Grad</td>\n",
       "      <td>39</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>64</td>\n",
       "      <td>49</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>Surmai</td>\n",
       "      <td>20</td>\n",
       "      <td>F</td>\n",
       "      <td>Under Grad</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>46</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number ID         Name   Age  Gender Qualifiaction  A (Raw)  C(Raw)  \\\n",
       "0        1000   Subhi Jain    19      F    Under Grad       26      45   \n",
       "1        1001       Simran    20      F    Under Grad       40      38   \n",
       "2        1002  Romy Kumari    19      F    Under Grad       38      40   \n",
       "3        1003       Aditya    19      M    Under Grad       39      33   \n",
       "4        1004       Surmai    20      F    Under Grad       42      34   \n",
       "\n",
       "   E (Raw)  O (Raw)  N (Raw)  A (T score)  C(T score)  E(T score)  \\\n",
       "0       45       40       28           34          67          74   \n",
       "1       38       36       39           63          55          67   \n",
       "2       47       39       42           59          58          74   \n",
       "3       32       44       35           64          49          57   \n",
       "4       44       42       46           67          48          74   \n",
       "\n",
       "   O (T score)  N (T score)  \n",
       "0           73           55  \n",
       "1           66           66  \n",
       "2           71           69  \n",
       "3           74           72  \n",
       "4           74           73  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_excel('Dataset/data_mini.xlsx')\n",
    "print(labels.shape)\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x00000206373F6780>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000206374360B8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000020637466668>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000020637498C18>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000206374D5208>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000206375057B8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x0000020637537D68>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000020637575390>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000206375753C8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x00000206375D6EB8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x00000206376144A8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x0000020637641A58>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = labels.copy()\n",
    "vis = df.drop('Number ID ', axis = 1)\n",
    "import matplotlib.pyplot as plt\n",
    "vis.boxplot()\n",
    "vis.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122 123\n"
     ]
    }
   ],
   "source": [
    "p_list = os.listdir('Dataset/para')\n",
    "t_list = os.listdir('Dataset/t')\n",
    "print(len(p_list), len(t_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_ls = []\n",
    "id_ls = labels['Number ID ']\n",
    "feat = []\n",
    "for image in p_list:\n",
    "    for ID in id_ls:\n",
    "        for t in t_list:\n",
    "            name = image.split('.')[0]\n",
    "            nt = t.split('.')[0]\n",
    "            if str(int(ID)) == name and str(int(ID)) == nt:\n",
    "                try:\n",
    "                    com_ls.append(name)\n",
    "                    imgt = cv2.imread('Dataset/t/' + t, 0)\n",
    "                    imgt = cv2.resize(imgt, (img_size, img_size))\n",
    "                    imgp = cv2.imread('Dataset/para/' + image, 0)\n",
    "                    imgp = cv2.resize(imgp, (img_size, img_size))\n",
    "                    feat.append(np.array([imgt, imgp]))\n",
    "                except:\n",
    "                    print('Dataset/t/' + image)\n",
    "                    print(imgt.shape, imgp.shape)\n",
    "feat = np.array(feat, dtype = np.float32)\n",
    "feat /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "lab = []\n",
    "for x in com_ls:\n",
    "    z = df.loc[df['Number ID '] == float(x)]\n",
    "    if z.values != []:\n",
    "        lab.append(np.array(z.values[0][5:]))\n",
    "lab = np.array(lab)\n",
    "print(lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = np.array(lab)\n",
    "lab = lab[..., 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((122, 2, 24, 24), (122, 5))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape, lab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Labels to Categorical Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACEON\n",
    "for i in range(len(lab)):\n",
    "    if(lab[i][4]>=26 and lab[i][4]<=34):\n",
    "        lab[i][4]=0\n",
    "        \n",
    "    elif(lab[i][4]>=35 and lab[i][4]<=44):\n",
    "        lab[i][4]=1\n",
    "        \n",
    "    elif(lab[i][4]>=45 and lab[i][4]<=55):\n",
    "        lab[i][4]=2\n",
    "        \n",
    "    elif(lab[i][4]>=56 and lab[i][4]<=65):\n",
    "        lab[i][4]=3\n",
    "     \n",
    "    elif(lab[i][4]>=66 and lab[i][4]<=74):\n",
    "        lab[i][4]=4\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    if(lab[i][2]>=26 and lab[i][2]<=34):\n",
    "        lab[i][2]=0\n",
    "        \n",
    "    elif(lab[i][2]>=35 and lab[i][2]<=44):\n",
    "        lab[i][2]=1\n",
    "        \n",
    "    elif(lab[i][2]>=45 and lab[i][2]<=55):\n",
    "        lab[i][2]=2\n",
    "        \n",
    "    elif(lab[i][2]>=56 and lab[i][2]<=65):\n",
    "        lab[i][2]=3\n",
    "        \n",
    "    elif(lab[i][2]>=66 and lab[i][2]<=74):\n",
    "        lab[i][2]=4\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(lab[i][3]>=26 and lab[i][3]<=34):\n",
    "        lab[i][3]=0\n",
    "        \n",
    "    elif(lab[i][3]>=35 and lab[i][3]<=44):\n",
    "        lab[i][3]=1\n",
    "        \n",
    "    elif(lab[i][3]>=45 and lab[i][3]<=55):\n",
    "        lab[i][3]=2\n",
    "        \n",
    "    elif(lab[i][3]>=56 and lab[i][3]<=65):\n",
    "        lab[i][3]=3\n",
    "        \n",
    "    elif(lab[i][3]>=66 and lab[i][3]<=74):\n",
    "        lab[i][3]=4\n",
    "    \n",
    "        \n",
    "    \n",
    "    if(lab[i][0]>=26 and lab[i][0]<=34):\n",
    "        lab[i][0]=0\n",
    "        \n",
    "    elif(lab[i][0]>=35 and lab[i][0]<=44):\n",
    "        lab[i][0]=1\n",
    "        \n",
    "    elif(lab[i][0]>=45 and lab[i][0]<=55):\n",
    "        lab[i][0]=2\n",
    "        \n",
    "    elif(lab[i][0]>=56 and lab[i][0]<=65):\n",
    "        lab[i][0]=3\n",
    "        \n",
    "    elif(lab[i][0]>=66 and lab[i][0]<=74):\n",
    "        lab[i][0]=4\n",
    "        \n",
    "   \n",
    " \n",
    "    if(lab[i][1]>=26 and lab[i][1]<=34):\n",
    "        lab[i][1]=0\n",
    "        \n",
    "    elif(lab[i][1]>=35 and lab[i][1]<=44):\n",
    "        lab[i][1]=1\n",
    "        \n",
    "    elif(lab[i][1]>=45 and lab[i][1]<=55):\n",
    "        lab[i][1]=2\n",
    "        \n",
    "    elif(lab[i][1]>=56 and lab[i][1]<=65):\n",
    "        lab[i][1]=3\n",
    "        \n",
    "    elif(lab[i][1]>=66 and lab[i][1]<=74):\n",
    "        lab[i][1]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 5)\n"
     ]
    }
   ],
   "source": [
    "print(lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 5, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Output Shape: [?, 5, 5]\n",
    "#One Hot Encode Labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "test = lab.copy()\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(test.reshape(-1, 1))\n",
    "op = ohe.transform(test.reshape(-1, 1))\n",
    "op = op.reshape((-1, 5, 5))\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_e = op.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.expand_dims(feat, axis = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 24, 24, 1)\n",
      "(122, 24, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "t = feat[:, 0, :, :]\n",
    "print(t.shape)\n",
    "p = feat[:, 1, :, :]\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_e = op.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training and Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = np.expand_dims(feat, axis = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "feat_train, feat_test, lab_train, lab_test = train_test_split(feat, lab_e, test_size = 0.4, shuffle = True) \n",
    "tr = feat_train[:, 0, :, :]\n",
    "pr = feat_train[:, 1, :, :]\n",
    "tt = feat_test[:, 0, :, :]\n",
    "pt = feat_test[:, 1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73, 2, 24, 24, 1, 1) (73, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(feat_train.shape, lab_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def my_acc(pred, lab_test):\n",
    "    ps = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        for j in range(pred.shape[1]):\n",
    "            ps.append(np.argmax(pred[i][j]))\n",
    "    ps = np.reshape(ps, (-1, 5))\n",
    "\n",
    "    ls = []\n",
    "    for i in range(lab_test.shape[0]):\n",
    "        ls.append(ohe.inverse_transform(lab_test[0]))\n",
    "    ls = np.reshape(ls, (-1, 5))\n",
    "    \n",
    "    ps = np.array(ps.flatten(), dtype = np.int64)\n",
    "    ls = np.array(ls.flatten(), dtype = np.int64)\n",
    "\n",
    "    ctr = 0\n",
    "    for i in range(len(ps)):\n",
    "        if ps[i] == ls[i]:\n",
    "            ctr += 1\n",
    "    return (ctr/float(len(ps)))\n",
    "\n",
    "def p_acc(pred, lab_test):\n",
    "    acc = tf.py_func(my_acc, [pred, lab_test], np.float64)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_t = Input(shape = (24, 24, 1, ))\n",
    "x = Conv2D(4, (3, 3), strides = 2, activation = 'relu')(inp_t)\n",
    "\n",
    "conv2 = Conv2D(16, (3, 3), strides = 2, activation = 'relu')(x)\n",
    "\n",
    "inp_p = Input(shape = (24, 24, 1, ))\n",
    "y = Conv2D(4, (3, 3), strides = 2, activation = 'relu')(inp_p)\n",
    "\n",
    "conv4 = Conv2D(16, (3, 3), strides = 2, activation = 'relu')(y)\n",
    "\n",
    "flat_x = Flatten()(conv2)\n",
    "flat_y = Flatten()(conv4)\n",
    "\n",
    "concat = Concatenate()([flat_x, flat_y])\n",
    "concat = ReLU()(concat)\n",
    "\n",
    "b_n5 = BatchNormalization(name = 'b5')(concat)\n",
    "d5 = Dropout(rate = 0.5)(b_n5)\n",
    "\n",
    "output = Dense(25, activation = 'relu')(d5)\n",
    "b_n6 = BatchNormalization(name = 'b6')(output)\n",
    "d6 = Dropout(rate = 0.5)(b_n6)\n",
    "\n",
    "output = Reshape((5, 5, ))(d6)\n",
    "output = ReLU()(output)\n",
    "output = Dropout(rate = 0.5)(output)\n",
    "\n",
    "b_n7 = BatchNormalization(name = 'b7')(output)\n",
    "output = sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 24, 24, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 24, 24, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 11, 11, 4)    40          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 11, 11, 4)    40          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 5, 5, 16)     592         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 5, 5, 16)     592         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 400)          0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 400)          0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 800)          0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 800)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "b5 (BatchNormalization)         (None, 800)          3200        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 800)          0           b5[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 25)           20025       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "b6 (BatchNormalization)         (None, 25)           100         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 25)           0           b6[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 5, 5)         0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 5, 5)         0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 5, 5)         0           re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sigmoid (TensorFlow [(None, 5, 5)]       0           dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 24,589\n",
      "Trainable params: 22,939\n",
      "Non-trainable params: 1,650\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = [inp_t, inp_p], outputs = output)\n",
    "prec = tf.keras.metrics.Precision()\n",
    "rec = tf.keras.metrics.Recall()\n",
    "model.compile(optimizer = Adam(lr = 0.0001), loss = 'categorical_crossentropy', metrics = ['acc', prec, rec])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85 samples, validate on 37 samples\n",
      "Epoch 1/2000\n",
      "85/85 [==============================] - 0s 6ms/sample - loss: 1.6288 - acc: 0.0541 - precision_3: 0.1848 - recall_3: 0.0800 - val_loss: 1.6147 - val_acc: 0.0541 - val_precision_3: 0.1875 - val_recall_3: 0.3081\n",
      "Epoch 2/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6310 - acc: 0.0541 - precision_3: 0.1620 - recall_3: 0.0682 - val_loss: 1.6139 - val_acc: 0.0378 - val_precision_3: 0.1780 - val_recall_3: 0.2270\n",
      "Epoch 3/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6149 - acc: 0.0847 - precision_3: 0.2251 - recall_3: 0.1012 - val_loss: 1.6129 - val_acc: 0.0378 - val_precision_3: 0.1459 - val_recall_3: 0.1459\n",
      "Epoch 4/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6253 - acc: 0.0659 - precision_3: 0.1882 - recall_3: 0.0824 - val_loss: 1.6118 - val_acc: 0.0324 - val_precision_3: 0.1206 - val_recall_3: 0.0919\n",
      "Epoch 5/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.6365 - acc: 0.0400 - precision_3: 0.1257 - recall_3: 0.0494 - val_loss: 1.6108 - val_acc: 0.0270 - val_precision_3: 0.1010 - val_recall_3: 0.0541\n",
      "Epoch 6/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6289 - acc: 0.0565 - precision_3: 0.1788 - recall_3: 0.0753 - val_loss: 1.6102 - val_acc: 0.0216 - val_precision_3: 0.1176 - val_recall_3: 0.0432\n",
      "Epoch 7/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6232 - acc: 0.0729 - precision_3: 0.1899 - recall_3: 0.0800 - val_loss: 1.6098 - val_acc: 0.0216 - val_precision_3: 0.1132 - val_recall_3: 0.0324\n",
      "Epoch 8/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6209 - acc: 0.0776 - precision_3: 0.2094 - recall_3: 0.0941 - val_loss: 1.6096 - val_acc: 0.0216 - val_precision_3: 0.1579 - val_recall_3: 0.0324\n",
      "Epoch 9/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.6171 - acc: 0.0706 - precision_3: 0.2047 - recall_3: 0.0824 - val_loss: 1.6095 - val_acc: 0.0162 - val_precision_3: 0.1600 - val_recall_3: 0.0216\n",
      "Epoch 10/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6209 - acc: 0.0682 - precision_3: 0.2011 - recall_3: 0.0847 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 0.1667 - val_recall_3: 0.0108\n",
      "Epoch 11/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6173 - acc: 0.0753 - precision_3: 0.2159 - recall_3: 0.0894 - val_loss: 1.6093 - val_acc: 0.0162 - val_precision_3: 0.4000 - val_recall_3: 0.0108\n",
      "Epoch 12/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6242 - acc: 0.0729 - precision_3: 0.2123 - recall_3: 0.0894 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 0.3333 - val_recall_3: 0.0054\n",
      "Epoch 13/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.6195 - acc: 0.0659 - precision_3: 0.2065 - recall_3: 0.0753 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 14/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6112 - acc: 0.0800 - precision_3: 0.2375 - recall_3: 0.0894 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 15/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.6197 - acc: 0.0682 - precision_3: 0.1899 - recall_3: 0.0800 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 16/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6204 - acc: 0.0871 - precision_3: 0.2151 - recall_3: 0.0941 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 17/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6246 - acc: 0.0635 - precision_3: 0.1864 - recall_3: 0.0776 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 18/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6236 - acc: 0.0635 - precision_3: 0.1927 - recall_3: 0.0871 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 19/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6072 - acc: 0.0918 - precision_3: 0.2457 - recall_3: 0.1012 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 20/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6323 - acc: 0.0635 - precision_3: 0.1868 - recall_3: 0.0800 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 21/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6195 - acc: 0.0659 - precision_3: 0.1966 - recall_3: 0.0824 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 22/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6180 - acc: 0.0871 - precision_3: 0.2184 - recall_3: 0.1059 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 23/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6207 - acc: 0.0800 - precision_3: 0.2011 - recall_3: 0.0871 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 24/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6225 - acc: 0.0729 - precision_3: 0.2077 - recall_3: 0.0894 - val_loss: 1.6094 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 25/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6249 - acc: 0.0682 - precision_3: 0.1813 - recall_3: 0.0776 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 26/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.6258 - acc: 0.0706 - precision_3: 0.1902 - recall_3: 0.0824 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 27/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6175 - acc: 0.0753 - precision_3: 0.2176 - recall_3: 0.0871 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 28/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6195 - acc: 0.0776 - precision_3: 0.2197 - recall_3: 0.0894 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 29/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6182 - acc: 0.0776 - precision_3: 0.2054 - recall_3: 0.0894 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 30/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.6268 - acc: 0.0612 - precision_3: 0.1742 - recall_3: 0.0729 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 31/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.6141 - acc: 0.0824 - precision_3: 0.2171 - recall_3: 0.0894 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 32/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.6210 - acc: 0.0753 - precision_3: 0.2147 - recall_3: 0.0894 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 33/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6078 - acc: 0.0847 - precision_3: 0.2454 - recall_3: 0.0941 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 34/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.6174 - acc: 0.0776 - precision_3: 0.2198 - recall_3: 0.0941 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 35/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.6294 - acc: 0.0588 - precision_3: 0.1656 - recall_3: 0.0635 - val_loss: 1.6093 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 36/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6220 - acc: 0.0753 - precision_3: 0.2043 - recall_3: 0.0894 - val_loss: 1.6092 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.6149 - acc: 0.0824 - precision_3: 0.2349 - recall_3: 0.0918 - val_loss: 1.6092 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 38/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6115 - acc: 0.0894 - precision_3: 0.2263 - recall_3: 0.1012 - val_loss: 1.6092 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 39/2000\n",
      "85/85 [==============================] - 0s 482us/sample - loss: 1.6323 - acc: 0.0588 - precision_3: 0.1780 - recall_3: 0.0800 - val_loss: 1.6091 - val_acc: 0.0108 - val_precision_3: 1.0000 - val_recall_3: 0.0054\n",
      "Epoch 40/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6231 - acc: 0.0682 - precision_3: 0.1946 - recall_3: 0.0847 - val_loss: 1.6091 - val_acc: 0.0108 - val_precision_3: 0.5000 - val_recall_3: 0.0054\n",
      "Epoch 41/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6307 - acc: 0.0659 - precision_3: 0.1643 - recall_3: 0.0800 - val_loss: 1.6091 - val_acc: 0.0108 - val_precision_3: 0.5000 - val_recall_3: 0.0054\n",
      "Epoch 42/2000\n",
      "85/85 [==============================] - 0s 492us/sample - loss: 1.6053 - acc: 0.1082 - precision_3: 0.2540 - recall_3: 0.1129 - val_loss: 1.6091 - val_acc: 0.0108 - val_precision_3: 0.5000 - val_recall_3: 0.0054\n",
      "Epoch 43/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6282 - acc: 0.0753 - precision_3: 0.1735 - recall_3: 0.0800 - val_loss: 1.6091 - val_acc: 0.0108 - val_precision_3: 0.5000 - val_recall_3: 0.0054\n",
      "Epoch 44/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6217 - acc: 0.0894 - precision_3: 0.2263 - recall_3: 0.1012 - val_loss: 1.6090 - val_acc: 0.0162 - val_precision_3: 0.5000 - val_recall_3: 0.0108\n",
      "Epoch 45/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.6216 - acc: 0.0682 - precision_3: 0.2073 - recall_3: 0.0941 - val_loss: 1.6089 - val_acc: 0.0162 - val_precision_3: 0.4000 - val_recall_3: 0.0108\n",
      "Epoch 46/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6068 - acc: 0.0871 - precision_3: 0.2486 - recall_3: 0.1035 - val_loss: 1.6089 - val_acc: 0.0162 - val_precision_3: 0.3333 - val_recall_3: 0.0108\n",
      "Epoch 47/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6230 - acc: 0.0729 - precision_3: 0.2000 - recall_3: 0.0871 - val_loss: 1.6088 - val_acc: 0.0270 - val_precision_3: 0.5000 - val_recall_3: 0.0216\n",
      "Epoch 48/2000\n",
      "85/85 [==============================] - 0s 533us/sample - loss: 1.6300 - acc: 0.0471 - precision_3: 0.1588 - recall_3: 0.0635 - val_loss: 1.6086 - val_acc: 0.0324 - val_precision_3: 0.5000 - val_recall_3: 0.0270\n",
      "Epoch 49/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6117 - acc: 0.0776 - precision_3: 0.2275 - recall_3: 0.0894 - val_loss: 1.6085 - val_acc: 0.0324 - val_precision_3: 0.4545 - val_recall_3: 0.0270\n",
      "Epoch 50/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6273 - acc: 0.0847 - precision_3: 0.2020 - recall_3: 0.0941 - val_loss: 1.6084 - val_acc: 0.0324 - val_precision_3: 0.4545 - val_recall_3: 0.0270\n",
      "Epoch 51/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6117 - acc: 0.0941 - precision_3: 0.2402 - recall_3: 0.1012 - val_loss: 1.6083 - val_acc: 0.0324 - val_precision_3: 0.4545 - val_recall_3: 0.0270\n",
      "Epoch 52/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6225 - acc: 0.0682 - precision_3: 0.1925 - recall_3: 0.0847 - val_loss: 1.6083 - val_acc: 0.0324 - val_precision_3: 0.3846 - val_recall_3: 0.0270\n",
      "Epoch 53/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6179 - acc: 0.0776 - precision_3: 0.2275 - recall_3: 0.1012 - val_loss: 1.6081 - val_acc: 0.0378 - val_precision_3: 0.4286 - val_recall_3: 0.0324\n",
      "Epoch 54/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6139 - acc: 0.0800 - precision_3: 0.2254 - recall_3: 0.0918 - val_loss: 1.6080 - val_acc: 0.0378 - val_precision_3: 0.3750 - val_recall_3: 0.0324\n",
      "Epoch 55/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6021 - acc: 0.0965 - precision_3: 0.2857 - recall_3: 0.1224 - val_loss: 1.6079 - val_acc: 0.0378 - val_precision_3: 0.3529 - val_recall_3: 0.0324\n",
      "Epoch 56/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6034 - acc: 0.1012 - precision_3: 0.2595 - recall_3: 0.1129 - val_loss: 1.6076 - val_acc: 0.0432 - val_precision_3: 0.3333 - val_recall_3: 0.0378\n",
      "Epoch 57/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6120 - acc: 0.0753 - precision_3: 0.2346 - recall_3: 0.0988 - val_loss: 1.6076 - val_acc: 0.0432 - val_precision_3: 0.3043 - val_recall_3: 0.0378\n",
      "Epoch 58/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6197 - acc: 0.0800 - precision_3: 0.2275 - recall_3: 0.1012 - val_loss: 1.6077 - val_acc: 0.0432 - val_precision_3: 0.2333 - val_recall_3: 0.0378\n",
      "Epoch 59/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6192 - acc: 0.0729 - precision_3: 0.2097 - recall_3: 0.0918 - val_loss: 1.6077 - val_acc: 0.0432 - val_precision_3: 0.2333 - val_recall_3: 0.0378\n",
      "Epoch 60/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6114 - acc: 0.0871 - precision_3: 0.2378 - recall_3: 0.1035 - val_loss: 1.6076 - val_acc: 0.0432 - val_precision_3: 0.2258 - val_recall_3: 0.0378\n",
      "Epoch 61/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6244 - acc: 0.0659 - precision_3: 0.1930 - recall_3: 0.0776 - val_loss: 1.6074 - val_acc: 0.0486 - val_precision_3: 0.2353 - val_recall_3: 0.0432\n",
      "Epoch 62/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6020 - acc: 0.0918 - precision_3: 0.2638 - recall_3: 0.1012 - val_loss: 1.6072 - val_acc: 0.0486 - val_precision_3: 0.2424 - val_recall_3: 0.0432\n",
      "Epoch 63/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6115 - acc: 0.0824 - precision_3: 0.2412 - recall_3: 0.0965 - val_loss: 1.6070 - val_acc: 0.0486 - val_precision_3: 0.2353 - val_recall_3: 0.0432\n",
      "Epoch 64/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6036 - acc: 0.0988 - precision_3: 0.2831 - recall_3: 0.1106 - val_loss: 1.6068 - val_acc: 0.0595 - val_precision_3: 0.2500 - val_recall_3: 0.0541\n",
      "Epoch 65/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6042 - acc: 0.1082 - precision_3: 0.2742 - recall_3: 0.1200 - val_loss: 1.6066 - val_acc: 0.0595 - val_precision_3: 0.2273 - val_recall_3: 0.0541\n",
      "Epoch 66/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.6197 - acc: 0.0753 - precision_3: 0.2074 - recall_3: 0.0918 - val_loss: 1.6063 - val_acc: 0.0757 - val_precision_3: 0.2653 - val_recall_3: 0.0703\n",
      "Epoch 67/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.6139 - acc: 0.0824 - precision_3: 0.2204 - recall_3: 0.0965 - val_loss: 1.6056 - val_acc: 0.0919 - val_precision_3: 0.3000 - val_recall_3: 0.0973\n",
      "Epoch 68/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6254 - acc: 0.0729 - precision_3: 0.1838 - recall_3: 0.0800 - val_loss: 1.6051 - val_acc: 0.0919 - val_precision_3: 0.3175 - val_recall_3: 0.1081\n",
      "Epoch 69/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6025 - acc: 0.1059 - precision_3: 0.2717 - recall_3: 0.1176 - val_loss: 1.6047 - val_acc: 0.1081 - val_precision_3: 0.3382 - val_recall_3: 0.1243\n",
      "Epoch 70/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6182 - acc: 0.0753 - precision_3: 0.2151 - recall_3: 0.0871 - val_loss: 1.6041 - val_acc: 0.1189 - val_precision_3: 0.3521 - val_recall_3: 0.1351\n",
      "Epoch 71/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5989 - acc: 0.1106 - precision_3: 0.3023 - recall_3: 0.1224 - val_loss: 1.6038 - val_acc: 0.1189 - val_precision_3: 0.3425 - val_recall_3: 0.1351\n",
      "Epoch 72/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6139 - acc: 0.0824 - precision_3: 0.2500 - recall_3: 0.1012 - val_loss: 1.6033 - val_acc: 0.1243 - val_precision_3: 0.3377 - val_recall_3: 0.1405\n",
      "Epoch 73/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6036 - acc: 0.0871 - precision_3: 0.2530 - recall_3: 0.0988 - val_loss: 1.6029 - val_acc: 0.1243 - val_precision_3: 0.3293 - val_recall_3: 0.1459\n",
      "Epoch 74/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6279 - acc: 0.0588 - precision_3: 0.1647 - recall_3: 0.0659 - val_loss: 1.6024 - val_acc: 0.1297 - val_precision_3: 0.3372 - val_recall_3: 0.1568\n",
      "Epoch 75/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6166 - acc: 0.0800 - precision_3: 0.2092 - recall_3: 0.0965 - val_loss: 1.6020 - val_acc: 0.1351 - val_precision_3: 0.3261 - val_recall_3: 0.1622\n",
      "Epoch 76/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6053 - acc: 0.1035 - precision_3: 0.2703 - recall_3: 0.1176 - val_loss: 1.6017 - val_acc: 0.1351 - val_precision_3: 0.3265 - val_recall_3: 0.1730\n",
      "Epoch 77/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5990 - acc: 0.1059 - precision_3: 0.2888 - recall_3: 0.1271 - val_loss: 1.6011 - val_acc: 0.1351 - val_precision_3: 0.3232 - val_recall_3: 0.1730\n",
      "Epoch 78/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6071 - acc: 0.0941 - precision_3: 0.2738 - recall_3: 0.1082 - val_loss: 1.6000 - val_acc: 0.1459 - val_precision_3: 0.3269 - val_recall_3: 0.1838\n",
      "Epoch 79/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6075 - acc: 0.1082 - precision_3: 0.2500 - recall_3: 0.1129 - val_loss: 1.5990 - val_acc: 0.1622 - val_precision_3: 0.3455 - val_recall_3: 0.2054\n",
      "Epoch 80/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6089 - acc: 0.0918 - precision_3: 0.2543 - recall_3: 0.1035 - val_loss: 1.5983 - val_acc: 0.1730 - val_precision_3: 0.3509 - val_recall_3: 0.2162\n",
      "Epoch 81/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6123 - acc: 0.0753 - precision_3: 0.2210 - recall_3: 0.0941 - val_loss: 1.5976 - val_acc: 0.1784 - val_precision_3: 0.3559 - val_recall_3: 0.2270\n",
      "Epoch 82/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6093 - acc: 0.0871 - precision_3: 0.2553 - recall_3: 0.1129 - val_loss: 1.5962 - val_acc: 0.1838 - val_precision_3: 0.3667 - val_recall_3: 0.2378\n",
      "Epoch 83/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.6165 - acc: 0.0847 - precision_3: 0.2147 - recall_3: 0.0965 - val_loss: 1.5954 - val_acc: 0.1946 - val_precision_3: 0.3538 - val_recall_3: 0.2486\n",
      "Epoch 84/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6116 - acc: 0.0824 - precision_3: 0.2324 - recall_3: 0.1012 - val_loss: 1.5944 - val_acc: 0.1946 - val_precision_3: 0.3382 - val_recall_3: 0.2486\n",
      "Epoch 85/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6085 - acc: 0.0847 - precision_3: 0.2414 - recall_3: 0.0988 - val_loss: 1.5936 - val_acc: 0.1946 - val_precision_3: 0.3310 - val_recall_3: 0.2541\n",
      "Epoch 86/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.6113 - acc: 0.0871 - precision_3: 0.2381 - recall_3: 0.0941 - val_loss: 1.5935 - val_acc: 0.1892 - val_precision_3: 0.3262 - val_recall_3: 0.2486\n",
      "Epoch 87/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6120 - acc: 0.0776 - precision_3: 0.2291 - recall_3: 0.0965 - val_loss: 1.5927 - val_acc: 0.2054 - val_precision_3: 0.3264 - val_recall_3: 0.2541\n",
      "Epoch 88/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6078 - acc: 0.0824 - precision_3: 0.2468 - recall_3: 0.0918 - val_loss: 1.5928 - val_acc: 0.1946 - val_precision_3: 0.3176 - val_recall_3: 0.2541\n",
      "Epoch 89/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6155 - acc: 0.0824 - precision_3: 0.2235 - recall_3: 0.0894 - val_loss: 1.5925 - val_acc: 0.1838 - val_precision_3: 0.3067 - val_recall_3: 0.2486\n",
      "Epoch 90/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6058 - acc: 0.0871 - precision_3: 0.2568 - recall_3: 0.1106 - val_loss: 1.5928 - val_acc: 0.1892 - val_precision_3: 0.3113 - val_recall_3: 0.2541\n",
      "Epoch 91/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6271 - acc: 0.0659 - precision_3: 0.1755 - recall_3: 0.0776 - val_loss: 1.5925 - val_acc: 0.1946 - val_precision_3: 0.3052 - val_recall_3: 0.2541\n",
      "Epoch 92/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6045 - acc: 0.0847 - precision_3: 0.2654 - recall_3: 0.1012 - val_loss: 1.5919 - val_acc: 0.1892 - val_precision_3: 0.3057 - val_recall_3: 0.2595\n",
      "Epoch 93/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6145 - acc: 0.0847 - precision_3: 0.2312 - recall_3: 0.0941 - val_loss: 1.5917 - val_acc: 0.1892 - val_precision_3: 0.3038 - val_recall_3: 0.2595\n",
      "Epoch 94/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6080 - acc: 0.0965 - precision_3: 0.2554 - recall_3: 0.1106 - val_loss: 1.5921 - val_acc: 0.1892 - val_precision_3: 0.2945 - val_recall_3: 0.2595\n",
      "Epoch 95/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6179 - acc: 0.0800 - precision_3: 0.2093 - recall_3: 0.0847 - val_loss: 1.5942 - val_acc: 0.1784 - val_precision_3: 0.2830 - val_recall_3: 0.2432\n",
      "Epoch 96/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6181 - acc: 0.0894 - precision_3: 0.2332 - recall_3: 0.1059 - val_loss: 1.5971 - val_acc: 0.1784 - val_precision_3: 0.2821 - val_recall_3: 0.2378\n",
      "Epoch 97/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.6226 - acc: 0.0635 - precision_3: 0.1818 - recall_3: 0.0753 - val_loss: 1.5976 - val_acc: 0.1730 - val_precision_3: 0.2803 - val_recall_3: 0.2378\n",
      "Epoch 98/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6045 - acc: 0.0988 - precision_3: 0.2649 - recall_3: 0.1153 - val_loss: 1.5978 - val_acc: 0.1730 - val_precision_3: 0.2733 - val_recall_3: 0.2378\n",
      "Epoch 99/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6203 - acc: 0.0659 - precision_3: 0.2050 - recall_3: 0.0776 - val_loss: 1.5978 - val_acc: 0.1730 - val_precision_3: 0.2814 - val_recall_3: 0.2541\n",
      "Epoch 100/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5986 - acc: 0.0918 - precision_3: 0.2934 - recall_3: 0.1153 - val_loss: 1.5967 - val_acc: 0.1676 - val_precision_3: 0.2754 - val_recall_3: 0.2486\n",
      "Epoch 101/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.6088 - acc: 0.0871 - precision_3: 0.2554 - recall_3: 0.1106 - val_loss: 1.5949 - val_acc: 0.1946 - val_precision_3: 0.2874 - val_recall_3: 0.2703\n",
      "Epoch 102/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.6004 - acc: 0.1059 - precision_3: 0.2982 - recall_3: 0.1200 - val_loss: 1.5946 - val_acc: 0.1946 - val_precision_3: 0.2857 - val_recall_3: 0.2811\n",
      "Epoch 103/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.6121 - acc: 0.0965 - precision_3: 0.2435 - recall_3: 0.1106 - val_loss: 1.5954 - val_acc: 0.1892 - val_precision_3: 0.2778 - val_recall_3: 0.2703\n",
      "Epoch 104/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6246 - acc: 0.0753 - precision_3: 0.1895 - recall_3: 0.0847 - val_loss: 1.5949 - val_acc: 0.1946 - val_precision_3: 0.2732 - val_recall_3: 0.2703\n",
      "Epoch 105/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6073 - acc: 0.0941 - precision_3: 0.2553 - recall_3: 0.1129 - val_loss: 1.5942 - val_acc: 0.2162 - val_precision_3: 0.2834 - val_recall_3: 0.2865\n",
      "Epoch 106/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.6047 - acc: 0.0965 - precision_3: 0.2674 - recall_3: 0.1082 - val_loss: 1.5948 - val_acc: 0.2000 - val_precision_3: 0.2674 - val_recall_3: 0.2703\n",
      "Epoch 107/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5991 - acc: 0.1106 - precision_3: 0.2750 - recall_3: 0.1294 - val_loss: 1.5952 - val_acc: 0.2054 - val_precision_3: 0.2781 - val_recall_3: 0.2811\n",
      "Epoch 108/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6064 - acc: 0.0988 - precision_3: 0.2581 - recall_3: 0.1129 - val_loss: 1.5948 - val_acc: 0.2054 - val_precision_3: 0.2713 - val_recall_3: 0.2757\n",
      "Epoch 109/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6114 - acc: 0.0729 - precision_3: 0.2372 - recall_3: 0.0871 - val_loss: 1.5940 - val_acc: 0.1946 - val_precision_3: 0.2674 - val_recall_3: 0.2703\n",
      "Epoch 110/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.6159 - acc: 0.0824 - precision_3: 0.2296 - recall_3: 0.1059 - val_loss: 1.5941 - val_acc: 0.1946 - val_precision_3: 0.2660 - val_recall_3: 0.2703\n",
      "Epoch 111/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.6129 - acc: 0.0894 - precision_3: 0.2458 - recall_3: 0.1035 - val_loss: 1.5935 - val_acc: 0.1946 - val_precision_3: 0.2646 - val_recall_3: 0.2703\n",
      "Epoch 112/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6088 - acc: 0.0871 - precision_3: 0.2638 - recall_3: 0.1012 - val_loss: 1.5935 - val_acc: 0.1946 - val_precision_3: 0.2646 - val_recall_3: 0.2703\n",
      "Epoch 113/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6082 - acc: 0.0847 - precision_3: 0.2515 - recall_3: 0.0988 - val_loss: 1.5930 - val_acc: 0.2054 - val_precision_3: 0.2615 - val_recall_3: 0.2757\n",
      "Epoch 114/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6150 - acc: 0.0824 - precision_3: 0.2154 - recall_3: 0.0988 - val_loss: 1.5932 - val_acc: 0.2054 - val_precision_3: 0.2576 - val_recall_3: 0.2757\n",
      "Epoch 115/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.6073 - acc: 0.0847 - precision_3: 0.2543 - recall_3: 0.1035 - val_loss: 1.5932 - val_acc: 0.2108 - val_precision_3: 0.2573 - val_recall_3: 0.2865\n",
      "Epoch 116/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6214 - acc: 0.0706 - precision_3: 0.2057 - recall_3: 0.0847 - val_loss: 1.5934 - val_acc: 0.2108 - val_precision_3: 0.2611 - val_recall_3: 0.2865\n",
      "Epoch 117/2000\n",
      "85/85 [==============================] - 0s 457us/sample - loss: 1.6064 - acc: 0.0918 - precision_3: 0.2513 - recall_3: 0.1153 - val_loss: 1.5943 - val_acc: 0.2000 - val_precision_3: 0.2587 - val_recall_3: 0.2811\n",
      "Epoch 118/2000\n",
      "85/85 [==============================] - 0s 470us/sample - loss: 1.6210 - acc: 0.0659 - precision_3: 0.1860 - recall_3: 0.0753 - val_loss: 1.5944 - val_acc: 0.2000 - val_precision_3: 0.2626 - val_recall_3: 0.2811\n",
      "Epoch 119/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.6177 - acc: 0.0941 - precision_3: 0.2261 - recall_3: 0.1059 - val_loss: 1.5925 - val_acc: 0.2054 - val_precision_3: 0.2626 - val_recall_3: 0.2811\n",
      "Epoch 120/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.6182 - acc: 0.0800 - precision_3: 0.2099 - recall_3: 0.0894 - val_loss: 1.5895 - val_acc: 0.2000 - val_precision_3: 0.2650 - val_recall_3: 0.2865\n",
      "Epoch 121/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.6164 - acc: 0.0871 - precision_3: 0.2211 - recall_3: 0.1035 - val_loss: 1.5870 - val_acc: 0.2162 - val_precision_3: 0.2843 - val_recall_3: 0.3135\n",
      "Epoch 122/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.6116 - acc: 0.0847 - precision_3: 0.2418 - recall_3: 0.1035 - val_loss: 1.5862 - val_acc: 0.2162 - val_precision_3: 0.2857 - val_recall_3: 0.3135\n",
      "Epoch 123/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.5979 - acc: 0.1059 - precision_3: 0.2826 - recall_3: 0.1224 - val_loss: 1.5854 - val_acc: 0.2216 - val_precision_3: 0.2816 - val_recall_3: 0.3135\n",
      "Epoch 124/2000\n",
      "85/85 [==============================] - 0s 482us/sample - loss: 1.6070 - acc: 0.1012 - precision_3: 0.2595 - recall_3: 0.1129 - val_loss: 1.5863 - val_acc: 0.2162 - val_precision_3: 0.2816 - val_recall_3: 0.3135\n",
      "Epoch 125/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6156 - acc: 0.0941 - precision_3: 0.2381 - recall_3: 0.1059 - val_loss: 1.5861 - val_acc: 0.2162 - val_precision_3: 0.2775 - val_recall_3: 0.3135\n",
      "Epoch 126/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.6162 - acc: 0.0847 - precision_3: 0.2275 - recall_3: 0.0894 - val_loss: 1.5858 - val_acc: 0.2162 - val_precision_3: 0.2857 - val_recall_3: 0.3243\n",
      "Epoch 127/2000\n",
      "85/85 [==============================] - 0s 458us/sample - loss: 1.6032 - acc: 0.1059 - precision_3: 0.2644 - recall_3: 0.1082 - val_loss: 1.5857 - val_acc: 0.2162 - val_precision_3: 0.2830 - val_recall_3: 0.3243\n",
      "Epoch 128/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.6063 - acc: 0.0965 - precision_3: 0.2473 - recall_3: 0.1082 - val_loss: 1.5861 - val_acc: 0.2270 - val_precision_3: 0.2824 - val_recall_3: 0.3297\n",
      "Epoch 129/2000\n",
      "85/85 [==============================] - 0s 470us/sample - loss: 1.6052 - acc: 0.0965 - precision_3: 0.2711 - recall_3: 0.1059 - val_loss: 1.5858 - val_acc: 0.2216 - val_precision_3: 0.2757 - val_recall_3: 0.3189\n",
      "Epoch 130/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.6209 - acc: 0.0635 - precision_3: 0.1902 - recall_3: 0.0729 - val_loss: 1.5857 - val_acc: 0.2108 - val_precision_3: 0.2765 - val_recall_3: 0.3243\n",
      "Epoch 131/2000\n",
      "85/85 [==============================] - 0s 457us/sample - loss: 1.5921 - acc: 0.1059 - precision_3: 0.3232 - recall_3: 0.1247 - val_loss: 1.5855 - val_acc: 0.2216 - val_precision_3: 0.2760 - val_recall_3: 0.3297\n",
      "Epoch 132/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.6135 - acc: 0.0659 - precision_3: 0.2244 - recall_3: 0.0824 - val_loss: 1.5837 - val_acc: 0.2324 - val_precision_3: 0.2760 - val_recall_3: 0.3297\n",
      "Epoch 133/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.6113 - acc: 0.0918 - precision_3: 0.2485 - recall_3: 0.0988 - val_loss: 1.5829 - val_acc: 0.2324 - val_precision_3: 0.2825 - val_recall_3: 0.3405\n",
      "Epoch 134/2000\n",
      "85/85 [==============================] - 0s 446us/sample - loss: 1.6146 - acc: 0.0847 - precision_3: 0.2320 - recall_3: 0.0988 - val_loss: 1.5818 - val_acc: 0.2432 - val_precision_3: 0.2788 - val_recall_3: 0.3405\n",
      "Epoch 135/2000\n",
      "85/85 [==============================] - 0s 458us/sample - loss: 1.6162 - acc: 0.0918 - precision_3: 0.2434 - recall_3: 0.1082 - val_loss: 1.5803 - val_acc: 0.2432 - val_precision_3: 0.2723 - val_recall_3: 0.3459\n",
      "Epoch 136/2000\n",
      "85/85 [==============================] - 0s 458us/sample - loss: 1.5997 - acc: 0.1129 - precision_3: 0.3077 - recall_3: 0.1318 - val_loss: 1.5793 - val_acc: 0.2541 - val_precision_3: 0.2785 - val_recall_3: 0.3568\n",
      "Epoch 137/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.6101 - acc: 0.0918 - precision_3: 0.2524 - recall_3: 0.1224 - val_loss: 1.5793 - val_acc: 0.2541 - val_precision_3: 0.2771 - val_recall_3: 0.3459\n",
      "Epoch 138/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.6041 - acc: 0.0894 - precision_3: 0.2683 - recall_3: 0.1035 - val_loss: 1.5787 - val_acc: 0.2649 - val_precision_3: 0.2747 - val_recall_3: 0.3459\n",
      "Epoch 139/2000\n",
      "85/85 [==============================] - 0s 470us/sample - loss: 1.6133 - acc: 0.0824 - precision_3: 0.2442 - recall_3: 0.0988 - val_loss: 1.5762 - val_acc: 0.2649 - val_precision_3: 0.2857 - val_recall_3: 0.3568\n",
      "Epoch 140/2000\n",
      "85/85 [==============================] - 0s 446us/sample - loss: 1.5975 - acc: 0.1082 - precision_3: 0.3140 - recall_3: 0.1271 - val_loss: 1.5745 - val_acc: 0.2649 - val_precision_3: 0.2888 - val_recall_3: 0.3622\n",
      "Epoch 141/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.5965 - acc: 0.1082 - precision_3: 0.3138 - recall_3: 0.1388 - val_loss: 1.5741 - val_acc: 0.2595 - val_precision_3: 0.2894 - val_recall_3: 0.3676\n",
      "Epoch 142/2000\n",
      "85/85 [==============================] - 0s 458us/sample - loss: 1.5972 - acc: 0.1012 - precision_3: 0.2914 - recall_3: 0.1200 - val_loss: 1.5739 - val_acc: 0.2703 - val_precision_3: 0.2966 - val_recall_3: 0.3784\n",
      "Epoch 143/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.6032 - acc: 0.0941 - precision_3: 0.2778 - recall_3: 0.1059 - val_loss: 1.5741 - val_acc: 0.2757 - val_precision_3: 0.2946 - val_recall_3: 0.3838\n",
      "Epoch 144/2000\n",
      "85/85 [==============================] - 0s 458us/sample - loss: 1.6015 - acc: 0.0988 - precision_3: 0.2703 - recall_3: 0.1176 - val_loss: 1.5747 - val_acc: 0.2757 - val_precision_3: 0.2874 - val_recall_3: 0.3838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.6041 - acc: 0.1059 - precision_3: 0.2686 - recall_3: 0.1106 - val_loss: 1.5743 - val_acc: 0.2757 - val_precision_3: 0.2927 - val_recall_3: 0.3892\n",
      "Epoch 146/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.5892 - acc: 0.1176 - precision_3: 0.3179 - recall_3: 0.1294 - val_loss: 1.5741 - val_acc: 0.2811 - val_precision_3: 0.2939 - val_recall_3: 0.3892\n",
      "Epoch 147/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5989 - acc: 0.0988 - precision_3: 0.2899 - recall_3: 0.1153 - val_loss: 1.5753 - val_acc: 0.2703 - val_precision_3: 0.2910 - val_recall_3: 0.3838\n",
      "Epoch 148/2000\n",
      "85/85 [==============================] - 0s 492us/sample - loss: 1.5961 - acc: 0.1129 - precision_3: 0.2898 - recall_3: 0.1200 - val_loss: 1.5773 - val_acc: 0.2595 - val_precision_3: 0.2922 - val_recall_3: 0.3838\n",
      "Epoch 149/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5972 - acc: 0.0965 - precision_3: 0.3011 - recall_3: 0.1247 - val_loss: 1.5787 - val_acc: 0.2486 - val_precision_3: 0.2869 - val_recall_3: 0.3784\n",
      "Epoch 150/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6033 - acc: 0.0894 - precision_3: 0.2568 - recall_3: 0.1106 - val_loss: 1.5801 - val_acc: 0.2324 - val_precision_3: 0.2851 - val_recall_3: 0.3730\n",
      "Epoch 151/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6119 - acc: 0.0753 - precision_3: 0.2457 - recall_3: 0.1012 - val_loss: 1.5812 - val_acc: 0.2378 - val_precision_3: 0.2833 - val_recall_3: 0.3676\n",
      "Epoch 152/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.6053 - acc: 0.0847 - precision_3: 0.2619 - recall_3: 0.1035 - val_loss: 1.5814 - val_acc: 0.2378 - val_precision_3: 0.2822 - val_recall_3: 0.3676\n",
      "Epoch 153/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.6007 - acc: 0.0941 - precision_3: 0.2865 - recall_3: 0.1200 - val_loss: 1.5809 - val_acc: 0.2378 - val_precision_3: 0.2851 - val_recall_3: 0.3730\n",
      "Epoch 154/2000\n",
      "85/85 [==============================] - 0s 446us/sample - loss: 1.6035 - acc: 0.0965 - precision_3: 0.2674 - recall_3: 0.1082 - val_loss: 1.5806 - val_acc: 0.2486 - val_precision_3: 0.2863 - val_recall_3: 0.3730\n",
      "Epoch 155/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.6048 - acc: 0.1082 - precision_3: 0.2798 - recall_3: 0.1271 - val_loss: 1.5800 - val_acc: 0.2432 - val_precision_3: 0.2803 - val_recall_3: 0.3622\n",
      "Epoch 156/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.5947 - acc: 0.1129 - precision_3: 0.3253 - recall_3: 0.1271 - val_loss: 1.5791 - val_acc: 0.2486 - val_precision_3: 0.2857 - val_recall_3: 0.3676\n",
      "Epoch 157/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5817 - acc: 0.1318 - precision_3: 0.3533 - recall_3: 0.1529 - val_loss: 1.5793 - val_acc: 0.2378 - val_precision_3: 0.2821 - val_recall_3: 0.3568\n",
      "Epoch 158/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5985 - acc: 0.1200 - precision_3: 0.3010 - recall_3: 0.1388 - val_loss: 1.5773 - val_acc: 0.2486 - val_precision_3: 0.2857 - val_recall_3: 0.3568\n",
      "Epoch 159/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.6062 - acc: 0.1035 - precision_3: 0.2597 - recall_3: 0.1106 - val_loss: 1.5761 - val_acc: 0.2541 - val_precision_3: 0.2894 - val_recall_3: 0.3676\n",
      "Epoch 160/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.6079 - acc: 0.0871 - precision_3: 0.2558 - recall_3: 0.1035 - val_loss: 1.5751 - val_acc: 0.2595 - val_precision_3: 0.2929 - val_recall_3: 0.3784\n",
      "Epoch 161/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.6032 - acc: 0.1035 - precision_3: 0.2609 - recall_3: 0.1129 - val_loss: 1.5750 - val_acc: 0.2649 - val_precision_3: 0.2875 - val_recall_3: 0.3730\n",
      "Epoch 162/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.6119 - acc: 0.0800 - precision_3: 0.2317 - recall_3: 0.0894 - val_loss: 1.5750 - val_acc: 0.2649 - val_precision_3: 0.2887 - val_recall_3: 0.3730\n",
      "Epoch 163/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.6066 - acc: 0.0894 - precision_3: 0.2614 - recall_3: 0.1082 - val_loss: 1.5741 - val_acc: 0.2649 - val_precision_3: 0.2911 - val_recall_3: 0.3730\n",
      "Epoch 164/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.6069 - acc: 0.0824 - precision_3: 0.2642 - recall_3: 0.0988 - val_loss: 1.5741 - val_acc: 0.2595 - val_precision_3: 0.2924 - val_recall_3: 0.3730\n",
      "Epoch 165/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6092 - acc: 0.0871 - precision_3: 0.2485 - recall_3: 0.0988 - val_loss: 1.5740 - val_acc: 0.2541 - val_precision_3: 0.2906 - val_recall_3: 0.3676\n",
      "Epoch 166/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6039 - acc: 0.0988 - precision_3: 0.2787 - recall_3: 0.1200 - val_loss: 1.5739 - val_acc: 0.2486 - val_precision_3: 0.2974 - val_recall_3: 0.3730\n",
      "Epoch 167/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6079 - acc: 0.0824 - precision_3: 0.2532 - recall_3: 0.0941 - val_loss: 1.5730 - val_acc: 0.2595 - val_precision_3: 0.3017 - val_recall_3: 0.3784\n",
      "Epoch 168/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5944 - acc: 0.1200 - precision_3: 0.3011 - recall_3: 0.1318 - val_loss: 1.5729 - val_acc: 0.2595 - val_precision_3: 0.3047 - val_recall_3: 0.3838\n",
      "Epoch 169/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5953 - acc: 0.1153 - precision_3: 0.2989 - recall_3: 0.1294 - val_loss: 1.5735 - val_acc: 0.2486 - val_precision_3: 0.2987 - val_recall_3: 0.3730\n",
      "Epoch 170/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6074 - acc: 0.0965 - precision_3: 0.2529 - recall_3: 0.1012 - val_loss: 1.5749 - val_acc: 0.2649 - val_precision_3: 0.3017 - val_recall_3: 0.3784\n",
      "Epoch 171/2000\n",
      "85/85 [==============================] - 0s 526us/sample - loss: 1.5967 - acc: 0.1035 - precision_3: 0.2967 - recall_3: 0.1271 - val_loss: 1.5760 - val_acc: 0.2649 - val_precision_3: 0.2952 - val_recall_3: 0.3622\n",
      "Epoch 172/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.6071 - acc: 0.1012 - precision_3: 0.2514 - recall_3: 0.1082 - val_loss: 1.5756 - val_acc: 0.2757 - val_precision_3: 0.3013 - val_recall_3: 0.3730\n",
      "Epoch 173/2000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 1.6087 - acc: 0.0847 - precision_3: 0.2579 - recall_3: 0.0965 - val_loss: 1.5759 - val_acc: 0.2703 - val_precision_3: 0.2895 - val_recall_3: 0.3568\n",
      "Epoch 174/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5989 - acc: 0.1106 - precision_3: 0.2818 - recall_3: 0.1200 - val_loss: 1.5764 - val_acc: 0.2703 - val_precision_3: 0.2933 - val_recall_3: 0.3568\n",
      "Epoch 175/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.6139 - acc: 0.0753 - precision_3: 0.2222 - recall_3: 0.0941 - val_loss: 1.5773 - val_acc: 0.2649 - val_precision_3: 0.2915 - val_recall_3: 0.3514\n",
      "Epoch 176/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5882 - acc: 0.1224 - precision_3: 0.3261 - recall_3: 0.1412 - val_loss: 1.5761 - val_acc: 0.2757 - val_precision_3: 0.2973 - val_recall_3: 0.3568\n",
      "Epoch 177/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5981 - acc: 0.1035 - precision_3: 0.2919 - recall_3: 0.1106 - val_loss: 1.5745 - val_acc: 0.2811 - val_precision_3: 0.2991 - val_recall_3: 0.3622\n",
      "Epoch 178/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.6009 - acc: 0.0918 - precision_3: 0.2810 - recall_3: 0.1012 - val_loss: 1.5744 - val_acc: 0.2811 - val_precision_3: 0.2933 - val_recall_3: 0.3568\n",
      "Epoch 179/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5920 - acc: 0.1247 - precision_3: 0.3061 - recall_3: 0.1412 - val_loss: 1.5742 - val_acc: 0.2811 - val_precision_3: 0.2926 - val_recall_3: 0.3622\n",
      "Epoch 180/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.6118 - acc: 0.0918 - precision_3: 0.2303 - recall_3: 0.0965 - val_loss: 1.5735 - val_acc: 0.2757 - val_precision_3: 0.2952 - val_recall_3: 0.3622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5971 - acc: 0.1106 - precision_3: 0.2971 - recall_3: 0.1224 - val_loss: 1.5725 - val_acc: 0.2811 - val_precision_3: 0.2982 - val_recall_3: 0.3676\n",
      "Epoch 182/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5935 - acc: 0.1129 - precision_3: 0.3091 - recall_3: 0.1200 - val_loss: 1.5712 - val_acc: 0.2811 - val_precision_3: 0.3043 - val_recall_3: 0.3784\n",
      "Epoch 183/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.6004 - acc: 0.1059 - precision_3: 0.2682 - recall_3: 0.1129 - val_loss: 1.5704 - val_acc: 0.2703 - val_precision_3: 0.3030 - val_recall_3: 0.3784\n",
      "Epoch 184/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6077 - acc: 0.0871 - precision_3: 0.2625 - recall_3: 0.0988 - val_loss: 1.5697 - val_acc: 0.2811 - val_precision_3: 0.3074 - val_recall_3: 0.3838\n",
      "Epoch 185/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5988 - acc: 0.1059 - precision_3: 0.2935 - recall_3: 0.1271 - val_loss: 1.5699 - val_acc: 0.2811 - val_precision_3: 0.3087 - val_recall_3: 0.3838\n",
      "Epoch 186/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5922 - acc: 0.1153 - precision_3: 0.3146 - recall_3: 0.1318 - val_loss: 1.5702 - val_acc: 0.2865 - val_precision_3: 0.3067 - val_recall_3: 0.3730\n",
      "Epoch 187/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5876 - acc: 0.1106 - precision_3: 0.3293 - recall_3: 0.1271 - val_loss: 1.5699 - val_acc: 0.2973 - val_precision_3: 0.3080 - val_recall_3: 0.3730\n",
      "Epoch 188/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5929 - acc: 0.1129 - precision_3: 0.3043 - recall_3: 0.1318 - val_loss: 1.5694 - val_acc: 0.3027 - val_precision_3: 0.3080 - val_recall_3: 0.3730\n",
      "Epoch 189/2000\n",
      "85/85 [==============================] - 0s 457us/sample - loss: 1.6018 - acc: 0.1012 - precision_3: 0.2743 - recall_3: 0.1129 - val_loss: 1.5685 - val_acc: 0.3027 - val_precision_3: 0.3080 - val_recall_3: 0.3730\n",
      "Epoch 190/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.6005 - acc: 0.1012 - precision_3: 0.2848 - recall_3: 0.1106 - val_loss: 1.5681 - val_acc: 0.3081 - val_precision_3: 0.3153 - val_recall_3: 0.3784\n",
      "Epoch 191/2000\n",
      "85/85 [==============================] - 0s 457us/sample - loss: 1.6156 - acc: 0.0753 - precision_3: 0.2235 - recall_3: 0.0894 - val_loss: 1.5684 - val_acc: 0.3081 - val_precision_3: 0.3125 - val_recall_3: 0.3784\n",
      "Epoch 192/2000\n",
      "85/85 [==============================] - 0s 458us/sample - loss: 1.5939 - acc: 0.0965 - precision_3: 0.3245 - recall_3: 0.1153 - val_loss: 1.5682 - val_acc: 0.3081 - val_precision_3: 0.3097 - val_recall_3: 0.3784\n",
      "Epoch 193/2000\n",
      "85/85 [==============================] - 0s 457us/sample - loss: 1.5854 - acc: 0.1271 - precision_3: 0.3373 - recall_3: 0.1341 - val_loss: 1.5691 - val_acc: 0.3081 - val_precision_3: 0.3084 - val_recall_3: 0.3784\n",
      "Epoch 194/2000\n",
      "85/85 [==============================] - 0s 434us/sample - loss: 1.5977 - acc: 0.1035 - precision_3: 0.2896 - recall_3: 0.1247 - val_loss: 1.5688 - val_acc: 0.3081 - val_precision_3: 0.3030 - val_recall_3: 0.3784\n",
      "Epoch 195/2000\n",
      "85/85 [==============================] - 0s 458us/sample - loss: 1.6063 - acc: 0.0871 - precision_3: 0.2530 - recall_3: 0.0988 - val_loss: 1.5686 - val_acc: 0.2919 - val_precision_3: 0.3077 - val_recall_3: 0.3676\n",
      "Epoch 196/2000\n",
      "85/85 [==============================] - 0s 492us/sample - loss: 1.5994 - acc: 0.1012 - precision_3: 0.2874 - recall_3: 0.1176 - val_loss: 1.5686 - val_acc: 0.3027 - val_precision_3: 0.3184 - val_recall_3: 0.3838\n",
      "Epoch 197/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.6071 - acc: 0.0894 - precision_3: 0.2470 - recall_3: 0.0965 - val_loss: 1.5702 - val_acc: 0.2919 - val_precision_3: 0.3186 - val_recall_3: 0.3892\n",
      "Epoch 198/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.6056 - acc: 0.0894 - precision_3: 0.2857 - recall_3: 0.1082 - val_loss: 1.5701 - val_acc: 0.2973 - val_precision_3: 0.3244 - val_recall_3: 0.3946\n",
      "Epoch 199/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5978 - acc: 0.1200 - precision_3: 0.3098 - recall_3: 0.1341 - val_loss: 1.5702 - val_acc: 0.2919 - val_precision_3: 0.3259 - val_recall_3: 0.3946\n",
      "Epoch 200/2000\n",
      "85/85 [==============================] - 0s 446us/sample - loss: 1.6042 - acc: 0.0941 - precision_3: 0.2541 - recall_3: 0.1106 - val_loss: 1.5702 - val_acc: 0.2973 - val_precision_3: 0.3319 - val_recall_3: 0.4054\n",
      "Epoch 201/2000\n",
      "85/85 [==============================] - 0s 458us/sample - loss: 1.6006 - acc: 0.0988 - precision_3: 0.2874 - recall_3: 0.1129 - val_loss: 1.5690 - val_acc: 0.2973 - val_precision_3: 0.3393 - val_recall_3: 0.4108\n",
      "Epoch 202/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6036 - acc: 0.0894 - precision_3: 0.2831 - recall_3: 0.1106 - val_loss: 1.5687 - val_acc: 0.2865 - val_precision_3: 0.3378 - val_recall_3: 0.4054\n",
      "Epoch 203/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5938 - acc: 0.0894 - precision_3: 0.3117 - recall_3: 0.1129 - val_loss: 1.5689 - val_acc: 0.2919 - val_precision_3: 0.3439 - val_recall_3: 0.4108\n",
      "Epoch 204/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.6142 - acc: 0.0894 - precision_3: 0.2366 - recall_3: 0.1035 - val_loss: 1.5687 - val_acc: 0.2919 - val_precision_3: 0.3380 - val_recall_3: 0.3946\n",
      "Epoch 205/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5942 - acc: 0.1176 - precision_3: 0.3110 - recall_3: 0.1200 - val_loss: 1.5682 - val_acc: 0.2865 - val_precision_3: 0.3379 - val_recall_3: 0.4000\n",
      "Epoch 206/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5999 - acc: 0.1012 - precision_3: 0.2893 - recall_3: 0.1082 - val_loss: 1.5693 - val_acc: 0.2865 - val_precision_3: 0.3394 - val_recall_3: 0.4000\n",
      "Epoch 207/2000\n",
      "85/85 [==============================] - 0s 492us/sample - loss: 1.6010 - acc: 0.1035 - precision_3: 0.2781 - recall_3: 0.1106 - val_loss: 1.5689 - val_acc: 0.2919 - val_precision_3: 0.3514 - val_recall_3: 0.4216\n",
      "Epoch 208/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5908 - acc: 0.1247 - precision_3: 0.3434 - recall_3: 0.1341 - val_loss: 1.5677 - val_acc: 0.2973 - val_precision_3: 0.3559 - val_recall_3: 0.4270\n",
      "Epoch 209/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.6074 - acc: 0.0894 - precision_3: 0.2590 - recall_3: 0.1012 - val_loss: 1.5672 - val_acc: 0.2973 - val_precision_3: 0.3628 - val_recall_3: 0.4216\n",
      "Epoch 210/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5803 - acc: 0.1294 - precision_3: 0.3616 - recall_3: 0.1506 - val_loss: 1.5675 - val_acc: 0.2919 - val_precision_3: 0.3645 - val_recall_3: 0.4216\n",
      "Epoch 211/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5758 - acc: 0.1341 - precision_3: 0.3832 - recall_3: 0.1506 - val_loss: 1.5679 - val_acc: 0.2919 - val_precision_3: 0.3598 - val_recall_3: 0.4162\n",
      "Epoch 212/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5915 - acc: 0.1106 - precision_3: 0.3312 - recall_3: 0.1200 - val_loss: 1.5674 - val_acc: 0.2973 - val_precision_3: 0.3538 - val_recall_3: 0.4054\n",
      "Epoch 213/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5987 - acc: 0.1129 - precision_3: 0.2896 - recall_3: 0.1247 - val_loss: 1.5687 - val_acc: 0.2919 - val_precision_3: 0.3571 - val_recall_3: 0.4054\n",
      "Epoch 214/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.6114 - acc: 0.0659 - precision_3: 0.2293 - recall_3: 0.0847 - val_loss: 1.5674 - val_acc: 0.2973 - val_precision_3: 0.3521 - val_recall_3: 0.4054\n",
      "Epoch 215/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6041 - acc: 0.0824 - precision_3: 0.2752 - recall_3: 0.0965 - val_loss: 1.5659 - val_acc: 0.3081 - val_precision_3: 0.3519 - val_recall_3: 0.4108\n",
      "Epoch 216/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6113 - acc: 0.0871 - precision_3: 0.2568 - recall_3: 0.1106 - val_loss: 1.5651 - val_acc: 0.3297 - val_precision_3: 0.3632 - val_recall_3: 0.4378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 217/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5906 - acc: 0.1176 - precision_3: 0.3293 - recall_3: 0.1294 - val_loss: 1.5645 - val_acc: 0.3297 - val_precision_3: 0.3649 - val_recall_3: 0.4378\n",
      "Epoch 218/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5768 - acc: 0.1247 - precision_3: 0.3663 - recall_3: 0.1482 - val_loss: 1.5642 - val_acc: 0.3351 - val_precision_3: 0.3620 - val_recall_3: 0.4324\n",
      "Epoch 219/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5934 - acc: 0.1106 - precision_3: 0.2970 - recall_3: 0.1153 - val_loss: 1.5645 - val_acc: 0.3405 - val_precision_3: 0.3616 - val_recall_3: 0.4378\n",
      "Epoch 220/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.6007 - acc: 0.0988 - precision_3: 0.2848 - recall_3: 0.1106 - val_loss: 1.5640 - val_acc: 0.3243 - val_precision_3: 0.3612 - val_recall_3: 0.4432\n",
      "Epoch 221/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6062 - acc: 0.0965 - precision_3: 0.2575 - recall_3: 0.1012 - val_loss: 1.5636 - val_acc: 0.3351 - val_precision_3: 0.3644 - val_recall_3: 0.4432\n",
      "Epoch 222/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5878 - acc: 0.1224 - precision_3: 0.3450 - recall_3: 0.1388 - val_loss: 1.5645 - val_acc: 0.3081 - val_precision_3: 0.3575 - val_recall_3: 0.4270\n",
      "Epoch 223/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5946 - acc: 0.1176 - precision_3: 0.3133 - recall_3: 0.1224 - val_loss: 1.5638 - val_acc: 0.3189 - val_precision_3: 0.3484 - val_recall_3: 0.4162\n",
      "Epoch 224/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5957 - acc: 0.1059 - precision_3: 0.3041 - recall_3: 0.1224 - val_loss: 1.5629 - val_acc: 0.3243 - val_precision_3: 0.3482 - val_recall_3: 0.4216\n",
      "Epoch 225/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6001 - acc: 0.0965 - precision_3: 0.2874 - recall_3: 0.1129 - val_loss: 1.5626 - val_acc: 0.3135 - val_precision_3: 0.3482 - val_recall_3: 0.4216\n",
      "Epoch 226/2000\n",
      "85/85 [==============================] - 0s 527us/sample - loss: 1.6045 - acc: 0.0918 - precision_3: 0.2667 - recall_3: 0.1035 - val_loss: 1.5622 - val_acc: 0.3135 - val_precision_3: 0.3514 - val_recall_3: 0.4216\n",
      "Epoch 227/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5924 - acc: 0.1153 - precision_3: 0.3152 - recall_3: 0.1365 - val_loss: 1.5626 - val_acc: 0.3189 - val_precision_3: 0.3467 - val_recall_3: 0.4216\n",
      "Epoch 228/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5875 - acc: 0.1129 - precision_3: 0.3649 - recall_3: 0.1271 - val_loss: 1.5634 - val_acc: 0.3135 - val_precision_3: 0.3451 - val_recall_3: 0.4216\n",
      "Epoch 229/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5976 - acc: 0.1059 - precision_3: 0.3059 - recall_3: 0.1224 - val_loss: 1.5643 - val_acc: 0.3135 - val_precision_3: 0.3498 - val_recall_3: 0.4216\n",
      "Epoch 230/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5894 - acc: 0.1129 - precision_3: 0.3291 - recall_3: 0.1224 - val_loss: 1.5647 - val_acc: 0.3135 - val_precision_3: 0.3543 - val_recall_3: 0.4270\n",
      "Epoch 231/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.6143 - acc: 0.0894 - precision_3: 0.2457 - recall_3: 0.1012 - val_loss: 1.5644 - val_acc: 0.3081 - val_precision_3: 0.3451 - val_recall_3: 0.4216\n",
      "Epoch 232/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5867 - acc: 0.1250 - precision_3: 0.3235 - recall_3: 0.13 - 0s 575us/sample - loss: 1.5974 - acc: 0.1059 - precision_3: 0.2961 - recall_3: 0.1247 - val_loss: 1.5639 - val_acc: 0.3027 - val_precision_3: 0.3393 - val_recall_3: 0.4108\n",
      "Epoch 233/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5917 - acc: 0.1082 - precision_3: 0.3292 - recall_3: 0.1247 - val_loss: 1.5647 - val_acc: 0.3135 - val_precision_3: 0.3451 - val_recall_3: 0.4216\n",
      "Epoch 234/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5948 - acc: 0.1200 - precision_3: 0.3017 - recall_3: 0.1271 - val_loss: 1.5645 - val_acc: 0.3135 - val_precision_3: 0.3451 - val_recall_3: 0.4216\n",
      "Epoch 235/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5934 - acc: 0.1129 - precision_3: 0.3086 - recall_3: 0.1271 - val_loss: 1.5636 - val_acc: 0.3135 - val_precision_3: 0.3496 - val_recall_3: 0.4270\n",
      "Epoch 236/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5936 - acc: 0.1200 - precision_3: 0.3333 - recall_3: 0.1318 - val_loss: 1.5625 - val_acc: 0.3189 - val_precision_3: 0.3453 - val_recall_3: 0.4162\n",
      "Epoch 237/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5892 - acc: 0.1176 - precision_3: 0.3671 - recall_3: 0.1365 - val_loss: 1.5617 - val_acc: 0.3081 - val_precision_3: 0.3514 - val_recall_3: 0.4216\n",
      "Epoch 238/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6007 - acc: 0.0753 - precision_3: 0.2670 - recall_3: 0.1106 - val_loss: 1.5614 - val_acc: 0.3297 - val_precision_3: 0.3575 - val_recall_3: 0.4270\n",
      "Epoch 239/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5872 - acc: 0.1200 - precision_3: 0.3373 - recall_3: 0.1318 - val_loss: 1.5606 - val_acc: 0.3297 - val_precision_3: 0.3559 - val_recall_3: 0.4270\n",
      "Epoch 240/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5920 - acc: 0.1200 - precision_3: 0.3258 - recall_3: 0.1365 - val_loss: 1.5583 - val_acc: 0.3297 - val_precision_3: 0.3556 - val_recall_3: 0.4324\n",
      "Epoch 241/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5964 - acc: 0.1059 - precision_3: 0.3025 - recall_3: 0.1153 - val_loss: 1.5563 - val_acc: 0.3351 - val_precision_3: 0.3556 - val_recall_3: 0.4324\n",
      "Epoch 242/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5961 - acc: 0.1106 - precision_3: 0.2872 - recall_3: 0.1271 - val_loss: 1.5551 - val_acc: 0.3568 - val_precision_3: 0.3616 - val_recall_3: 0.4378\n",
      "Epoch 243/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5883 - acc: 0.1200 - precision_3: 0.3158 - recall_3: 0.1271 - val_loss: 1.5539 - val_acc: 0.3676 - val_precision_3: 0.3628 - val_recall_3: 0.4432\n",
      "Epoch 244/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5863 - acc: 0.1435 - precision_3: 0.3232 - recall_3: 0.1506 - val_loss: 1.5535 - val_acc: 0.3568 - val_precision_3: 0.3616 - val_recall_3: 0.4378\n",
      "Epoch 245/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.6017 - acc: 0.0965 - precision_3: 0.2814 - recall_3: 0.1106 - val_loss: 1.5534 - val_acc: 0.3459 - val_precision_3: 0.3632 - val_recall_3: 0.4378\n",
      "Epoch 246/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5785 - acc: 0.1341 - precision_3: 0.3765 - recall_3: 0.1506 - val_loss: 1.5534 - val_acc: 0.3459 - val_precision_3: 0.3710 - val_recall_3: 0.4432\n",
      "Epoch 247/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5952 - acc: 0.1059 - precision_3: 0.3025 - recall_3: 0.1153 - val_loss: 1.5534 - val_acc: 0.3459 - val_precision_3: 0.3727 - val_recall_3: 0.4432\n",
      "Epoch 248/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5970 - acc: 0.1012 - precision_3: 0.3019 - recall_3: 0.1129 - val_loss: 1.5546 - val_acc: 0.3405 - val_precision_3: 0.3779 - val_recall_3: 0.4432\n",
      "Epoch 249/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5883 - acc: 0.1153 - precision_3: 0.3254 - recall_3: 0.1294 - val_loss: 1.5544 - val_acc: 0.3351 - val_precision_3: 0.3779 - val_recall_3: 0.4432\n",
      "Epoch 250/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5762 - acc: 0.1341 - precision_3: 0.3787 - recall_3: 0.1506 - val_loss: 1.5534 - val_acc: 0.3351 - val_precision_3: 0.3727 - val_recall_3: 0.4432\n",
      "Epoch 251/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5976 - acc: 0.1059 - precision_3: 0.3043 - recall_3: 0.1153 - val_loss: 1.5541 - val_acc: 0.3405 - val_precision_3: 0.3694 - val_recall_3: 0.4432\n",
      "Epoch 252/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5830 - acc: 0.1294 - precision_3: 0.3600 - recall_3: 0.1482 - val_loss: 1.5546 - val_acc: 0.3243 - val_precision_3: 0.3607 - val_recall_3: 0.4270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5913 - acc: 0.1176 - precision_3: 0.3216 - recall_3: 0.1294 - val_loss: 1.5541 - val_acc: 0.3405 - val_precision_3: 0.3710 - val_recall_3: 0.4432\n",
      "Epoch 254/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5763 - acc: 0.1412 - precision_3: 0.3815 - recall_3: 0.1553 - val_loss: 1.5528 - val_acc: 0.3459 - val_precision_3: 0.3710 - val_recall_3: 0.4432\n",
      "Epoch 255/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5812 - acc: 0.1294 - precision_3: 0.3352 - recall_3: 0.1412 - val_loss: 1.5519 - val_acc: 0.3459 - val_precision_3: 0.3710 - val_recall_3: 0.4432\n",
      "Epoch 256/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5816 - acc: 0.1318 - precision_3: 0.3464 - recall_3: 0.1459 - val_loss: 1.5511 - val_acc: 0.3405 - val_precision_3: 0.3670 - val_recall_3: 0.4324\n",
      "Epoch 257/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5935 - acc: 0.1106 - precision_3: 0.3152 - recall_3: 0.1224 - val_loss: 1.5505 - val_acc: 0.3405 - val_precision_3: 0.3636 - val_recall_3: 0.4324\n",
      "Epoch 258/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5890 - acc: 0.1129 - precision_3: 0.3220 - recall_3: 0.1341 - val_loss: 1.5505 - val_acc: 0.3459 - val_precision_3: 0.3670 - val_recall_3: 0.4324\n",
      "Epoch 259/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5930 - acc: 0.1106 - precision_3: 0.3232 - recall_3: 0.1247 - val_loss: 1.5508 - val_acc: 0.3459 - val_precision_3: 0.3653 - val_recall_3: 0.4324\n",
      "Epoch 260/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5890 - acc: 0.1200 - precision_3: 0.3436 - recall_3: 0.1318 - val_loss: 1.5513 - val_acc: 0.3405 - val_precision_3: 0.3670 - val_recall_3: 0.4324\n",
      "Epoch 261/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5879 - acc: 0.1247 - precision_3: 0.3294 - recall_3: 0.1318 - val_loss: 1.5537 - val_acc: 0.3351 - val_precision_3: 0.3657 - val_recall_3: 0.4270\n",
      "Epoch 262/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5826 - acc: 0.1176 - precision_3: 0.3515 - recall_3: 0.1365 - val_loss: 1.5560 - val_acc: 0.3297 - val_precision_3: 0.3662 - val_recall_3: 0.4216\n",
      "Epoch 263/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5893 - acc: 0.1224 - precision_3: 0.3410 - recall_3: 0.1388 - val_loss: 1.5574 - val_acc: 0.3297 - val_precision_3: 0.3714 - val_recall_3: 0.4216\n",
      "Epoch 264/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5931 - acc: 0.1059 - precision_3: 0.3171 - recall_3: 0.1224 - val_loss: 1.5581 - val_acc: 0.3351 - val_precision_3: 0.3645 - val_recall_3: 0.4216\n",
      "Epoch 265/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5905 - acc: 0.0988 - precision_3: 0.3497 - recall_3: 0.1176 - val_loss: 1.5596 - val_acc: 0.3351 - val_precision_3: 0.3632 - val_recall_3: 0.4162\n",
      "Epoch 266/2000\n",
      "85/85 [==============================] - 0s 503us/sample - loss: 1.5852 - acc: 0.1271 - precision_3: 0.3558 - recall_3: 0.1365 - val_loss: 1.5607 - val_acc: 0.3297 - val_precision_3: 0.3636 - val_recall_3: 0.4108\n",
      "Epoch 267/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5897 - acc: 0.1129 - precision_3: 0.3432 - recall_3: 0.1365 - val_loss: 1.5609 - val_acc: 0.3243 - val_precision_3: 0.3623 - val_recall_3: 0.4054\n",
      "Epoch 268/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5824 - acc: 0.1247 - precision_3: 0.3466 - recall_3: 0.1435 - val_loss: 1.5603 - val_acc: 0.3189 - val_precision_3: 0.3527 - val_recall_3: 0.3946\n",
      "Epoch 269/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5846 - acc: 0.1224 - precision_3: 0.3673 - recall_3: 0.1271 - val_loss: 1.5609 - val_acc: 0.3189 - val_precision_3: 0.3544 - val_recall_3: 0.3946\n",
      "Epoch 270/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5876 - acc: 0.1059 - precision_3: 0.3529 - recall_3: 0.1129 - val_loss: 1.5615 - val_acc: 0.3189 - val_precision_3: 0.3480 - val_recall_3: 0.3838\n",
      "Epoch 271/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5955 - acc: 0.1082 - precision_3: 0.3133 - recall_3: 0.1224 - val_loss: 1.5623 - val_acc: 0.3189 - val_precision_3: 0.3447 - val_recall_3: 0.3838\n",
      "Epoch 272/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5849 - acc: 0.1200 - precision_3: 0.3430 - recall_3: 0.1388 - val_loss: 1.5627 - val_acc: 0.3243 - val_precision_3: 0.3529 - val_recall_3: 0.3892\n",
      "Epoch 273/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5876 - acc: 0.1224 - precision_3: 0.3462 - recall_3: 0.1271 - val_loss: 1.5624 - val_acc: 0.3189 - val_precision_3: 0.3498 - val_recall_3: 0.3838\n",
      "Epoch 274/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5878 - acc: 0.1106 - precision_3: 0.3585 - recall_3: 0.1341 - val_loss: 1.5627 - val_acc: 0.3027 - val_precision_3: 0.3465 - val_recall_3: 0.3784\n",
      "Epoch 275/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5856 - acc: 0.1129 - precision_3: 0.3393 - recall_3: 0.1341 - val_loss: 1.5636 - val_acc: 0.2919 - val_precision_3: 0.3317 - val_recall_3: 0.3676\n",
      "Epoch 276/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5895 - acc: 0.1176 - precision_3: 0.3314 - recall_3: 0.1365 - val_loss: 1.5652 - val_acc: 0.3027 - val_precision_3: 0.3333 - val_recall_3: 0.3676\n",
      "Epoch 277/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5735 - acc: 0.1388 - precision_3: 0.3824 - recall_3: 0.1529 - val_loss: 1.5663 - val_acc: 0.3081 - val_precision_3: 0.3382 - val_recall_3: 0.3730\n",
      "Epoch 278/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5893 - acc: 0.1176 - precision_3: 0.3254 - recall_3: 0.1294 - val_loss: 1.5650 - val_acc: 0.3135 - val_precision_3: 0.3431 - val_recall_3: 0.3784\n",
      "Epoch 279/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5895 - acc: 0.1318 - precision_3: 0.3261 - recall_3: 0.1412 - val_loss: 1.5627 - val_acc: 0.3189 - val_precision_3: 0.3445 - val_recall_3: 0.3892\n",
      "Epoch 280/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5892 - acc: 0.1129 - precision_3: 0.3434 - recall_3: 0.1341 - val_loss: 1.5616 - val_acc: 0.3081 - val_precision_3: 0.3462 - val_recall_3: 0.3892\n",
      "Epoch 281/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5873 - acc: 0.1247 - precision_3: 0.3372 - recall_3: 0.1365 - val_loss: 1.5616 - val_acc: 0.3135 - val_precision_3: 0.3541 - val_recall_3: 0.4000\n",
      "Epoch 282/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5916 - acc: 0.1129 - precision_3: 0.3128 - recall_3: 0.1318 - val_loss: 1.5625 - val_acc: 0.3189 - val_precision_3: 0.3558 - val_recall_3: 0.4000\n",
      "Epoch 283/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5945 - acc: 0.1059 - precision_3: 0.3179 - recall_3: 0.1129 - val_loss: 1.5637 - val_acc: 0.3027 - val_precision_3: 0.3463 - val_recall_3: 0.3838\n",
      "Epoch 284/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.6017 - acc: 0.1012 - precision_3: 0.3020 - recall_3: 0.1059 - val_loss: 1.5640 - val_acc: 0.3135 - val_precision_3: 0.3510 - val_recall_3: 0.3946\n",
      "Epoch 285/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5894 - acc: 0.1082 - precision_3: 0.3442 - recall_3: 0.1247 - val_loss: 1.5638 - val_acc: 0.3081 - val_precision_3: 0.3561 - val_recall_3: 0.3946\n",
      "Epoch 286/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5816 - acc: 0.1294 - precision_3: 0.3593 - recall_3: 0.1412 - val_loss: 1.5648 - val_acc: 0.3027 - val_precision_3: 0.3544 - val_recall_3: 0.3946\n",
      "Epoch 287/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5824 - acc: 0.1176 - precision_3: 0.3559 - recall_3: 0.1482 - val_loss: 1.5647 - val_acc: 0.3027 - val_precision_3: 0.3544 - val_recall_3: 0.3946\n",
      "Epoch 288/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5828 - acc: 0.1341 - precision_3: 0.3795 - recall_3: 0.1482 - val_loss: 1.5644 - val_acc: 0.3135 - val_precision_3: 0.3623 - val_recall_3: 0.4054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5998 - acc: 0.0941 - precision_3: 0.2814 - recall_3: 0.1106 - val_loss: 1.5641 - val_acc: 0.3243 - val_precision_3: 0.3671 - val_recall_3: 0.4108\n",
      "Epoch 290/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5806 - acc: 0.1200 - precision_3: 0.3642 - recall_3: 0.1294 - val_loss: 1.5645 - val_acc: 0.3351 - val_precision_3: 0.3750 - val_recall_3: 0.4216\n",
      "Epoch 291/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5926 - acc: 0.1176 - precision_3: 0.2989 - recall_3: 0.1294 - val_loss: 1.5648 - val_acc: 0.3351 - val_precision_3: 0.3768 - val_recall_3: 0.4216\n",
      "Epoch 292/2000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.5890 - acc: 0.1129 - precision_3: 0.3714 - recall_3: 0.1224 - val_loss: 1.5650 - val_acc: 0.3351 - val_precision_3: 0.3835 - val_recall_3: 0.4270\n",
      "Epoch 293/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5825 - acc: 0.1176 - precision_3: 0.3810 - recall_3: 0.1318 - val_loss: 1.5629 - val_acc: 0.3297 - val_precision_3: 0.3824 - val_recall_3: 0.4216\n",
      "Epoch 294/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5930 - acc: 0.0941 - precision_3: 0.3289 - recall_3: 0.1153 - val_loss: 1.5640 - val_acc: 0.3351 - val_precision_3: 0.3854 - val_recall_3: 0.4270\n",
      "Epoch 295/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5954 - acc: 0.1059 - precision_3: 0.3152 - recall_3: 0.1224 - val_loss: 1.5642 - val_acc: 0.3297 - val_precision_3: 0.3812 - val_recall_3: 0.4162\n",
      "Epoch 296/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5910 - acc: 0.1129 - precision_3: 0.3269 - recall_3: 0.1200 - val_loss: 1.5662 - val_acc: 0.3351 - val_precision_3: 0.3769 - val_recall_3: 0.4054\n",
      "Epoch 297/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.5681 - acc: 0.1412 - precision_3: 0.4107 - recall_3: 0.1624 - val_loss: 1.5684 - val_acc: 0.3243 - val_precision_3: 0.3756 - val_recall_3: 0.4000\n",
      "Epoch 298/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5992 - acc: 0.0988 - precision_3: 0.2848 - recall_3: 0.1106 - val_loss: 1.5692 - val_acc: 0.3243 - val_precision_3: 0.3724 - val_recall_3: 0.3946\n",
      "Epoch 299/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5929 - acc: 0.1106 - precision_3: 0.3155 - recall_3: 0.1247 - val_loss: 1.5689 - val_acc: 0.3243 - val_precision_3: 0.3687 - val_recall_3: 0.3946\n",
      "Epoch 300/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5855 - acc: 0.1271 - precision_3: 0.3613 - recall_3: 0.1318 - val_loss: 1.5677 - val_acc: 0.3297 - val_precision_3: 0.3776 - val_recall_3: 0.4000\n",
      "Epoch 301/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5709 - acc: 0.1435 - precision_3: 0.4379 - recall_3: 0.1576 - val_loss: 1.5674 - val_acc: 0.3459 - val_precision_3: 0.3819 - val_recall_3: 0.4108\n",
      "Epoch 302/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5918 - acc: 0.1035 - precision_3: 0.3571 - recall_3: 0.1176 - val_loss: 1.5658 - val_acc: 0.3405 - val_precision_3: 0.3750 - val_recall_3: 0.4054\n",
      "Epoch 303/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5787 - acc: 0.1200 - precision_3: 0.3904 - recall_3: 0.1341 - val_loss: 1.5649 - val_acc: 0.3405 - val_precision_3: 0.3731 - val_recall_3: 0.4054\n",
      "Epoch 304/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5784 - acc: 0.1200 - precision_3: 0.4044 - recall_3: 0.1294 - val_loss: 1.5631 - val_acc: 0.3459 - val_precision_3: 0.3689 - val_recall_3: 0.4108\n",
      "Epoch 305/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5837 - acc: 0.1200 - precision_3: 0.3649 - recall_3: 0.1271 - val_loss: 1.5616 - val_acc: 0.3459 - val_precision_3: 0.3720 - val_recall_3: 0.4162\n",
      "Epoch 306/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5871 - acc: 0.1294 - precision_3: 0.3636 - recall_3: 0.1412 - val_loss: 1.5591 - val_acc: 0.3405 - val_precision_3: 0.3720 - val_recall_3: 0.4162\n",
      "Epoch 307/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5763 - acc: 0.1294 - precision_3: 0.3973 - recall_3: 0.1365 - val_loss: 1.5590 - val_acc: 0.3405 - val_precision_3: 0.3714 - val_recall_3: 0.4216\n",
      "Epoch 308/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5809 - acc: 0.1294 - precision_3: 0.3642 - recall_3: 0.1482 - val_loss: 1.5617 - val_acc: 0.3243 - val_precision_3: 0.3654 - val_recall_3: 0.4108\n",
      "Epoch 309/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5898 - acc: 0.1129 - precision_3: 0.3312 - recall_3: 0.1200 - val_loss: 1.5634 - val_acc: 0.3297 - val_precision_3: 0.3720 - val_recall_3: 0.4162\n",
      "Epoch 310/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5848 - acc: 0.1224 - precision_3: 0.3681 - recall_3: 0.1412 - val_loss: 1.5639 - val_acc: 0.3243 - val_precision_3: 0.3725 - val_recall_3: 0.4108\n",
      "Epoch 311/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5872 - acc: 0.1153 - precision_3: 0.3354 - recall_3: 0.1294 - val_loss: 1.5647 - val_acc: 0.3243 - val_precision_3: 0.3800 - val_recall_3: 0.4108\n",
      "Epoch 312/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5826 - acc: 0.1247 - precision_3: 0.3497 - recall_3: 0.1341 - val_loss: 1.5657 - val_acc: 0.3189 - val_precision_3: 0.3793 - val_recall_3: 0.4162\n",
      "Epoch 313/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5900 - acc: 0.1153 - precision_3: 0.3377 - recall_3: 0.1224 - val_loss: 1.5665 - val_acc: 0.3243 - val_precision_3: 0.3831 - val_recall_3: 0.4162\n",
      "Epoch 314/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5852 - acc: 0.1129 - precision_3: 0.3557 - recall_3: 0.1247 - val_loss: 1.5662 - val_acc: 0.3297 - val_precision_3: 0.3824 - val_recall_3: 0.4216\n",
      "Epoch 315/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5743 - acc: 0.1388 - precision_3: 0.3855 - recall_3: 0.1506 - val_loss: 1.5656 - val_acc: 0.3405 - val_precision_3: 0.3894 - val_recall_3: 0.4378\n",
      "Epoch 316/2000\n",
      "85/85 [==============================] - 0s 492us/sample - loss: 1.5740 - acc: 0.1388 - precision_3: 0.4000 - recall_3: 0.1553 - val_loss: 1.5642 - val_acc: 0.3405 - val_precision_3: 0.3923 - val_recall_3: 0.4432\n",
      "Epoch 317/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5763 - acc: 0.1247 - precision_3: 0.3861 - recall_3: 0.1435 - val_loss: 1.5626 - val_acc: 0.3622 - val_precision_3: 0.4000 - val_recall_3: 0.4649\n",
      "Epoch 318/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5910 - acc: 0.1106 - precision_3: 0.3438 - recall_3: 0.1294 - val_loss: 1.5594 - val_acc: 0.3730 - val_precision_3: 0.4085 - val_recall_3: 0.4703\n",
      "Epoch 319/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5796 - acc: 0.1271 - precision_3: 0.3791 - recall_3: 0.1365 - val_loss: 1.5581 - val_acc: 0.3784 - val_precision_3: 0.4093 - val_recall_3: 0.4757\n",
      "Epoch 320/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5766 - acc: 0.1294 - precision_3: 0.3986 - recall_3: 0.1388 - val_loss: 1.5565 - val_acc: 0.3730 - val_precision_3: 0.4019 - val_recall_3: 0.4649\n",
      "Epoch 321/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5763 - acc: 0.1271 - precision_3: 0.3910 - recall_3: 0.1435 - val_loss: 1.5545 - val_acc: 0.3730 - val_precision_3: 0.3981 - val_recall_3: 0.4649\n",
      "Epoch 322/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5873 - acc: 0.1035 - precision_3: 0.3521 - recall_3: 0.1176 - val_loss: 1.5537 - val_acc: 0.3676 - val_precision_3: 0.4000 - val_recall_3: 0.4649\n",
      "Epoch 323/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5947 - acc: 0.1035 - precision_3: 0.3117 - recall_3: 0.1129 - val_loss: 1.5537 - val_acc: 0.3676 - val_precision_3: 0.4065 - val_recall_3: 0.4703\n",
      "Epoch 324/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5949 - acc: 0.1082 - precision_3: 0.3376 - recall_3: 0.1247 - val_loss: 1.5542 - val_acc: 0.3676 - val_precision_3: 0.4112 - val_recall_3: 0.4757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/2000\n",
      "85/85 [==============================] - 0s 469us/sample - loss: 1.5869 - acc: 0.1082 - precision_3: 0.3517 - recall_3: 0.1200 - val_loss: 1.5555 - val_acc: 0.3514 - val_precision_3: 0.4057 - val_recall_3: 0.4649\n",
      "Epoch 326/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5879 - acc: 0.1035 - precision_3: 0.3618 - recall_3: 0.1294 - val_loss: 1.5561 - val_acc: 0.3514 - val_precision_3: 0.4038 - val_recall_3: 0.4649\n",
      "Epoch 327/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5906 - acc: 0.1106 - precision_3: 0.3427 - recall_3: 0.1153 - val_loss: 1.5563 - val_acc: 0.3405 - val_precision_3: 0.4028 - val_recall_3: 0.4595\n",
      "Epoch 328/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5835 - acc: 0.1082 - precision_3: 0.3836 - recall_3: 0.1318 - val_loss: 1.5548 - val_acc: 0.3351 - val_precision_3: 0.4058 - val_recall_3: 0.4541\n",
      "Epoch 329/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5833 - acc: 0.1200 - precision_3: 0.3602 - recall_3: 0.1365 - val_loss: 1.5544 - val_acc: 0.3405 - val_precision_3: 0.4126 - val_recall_3: 0.4595\n",
      "Epoch 330/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5758 - acc: 0.1318 - precision_3: 0.3933 - recall_3: 0.1388 - val_loss: 1.5542 - val_acc: 0.3514 - val_precision_3: 0.4223 - val_recall_3: 0.4703\n",
      "Epoch 331/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5717 - acc: 0.1529 - precision_3: 0.4207 - recall_3: 0.1624 - val_loss: 1.5519 - val_acc: 0.3676 - val_precision_3: 0.4272 - val_recall_3: 0.4757\n",
      "Epoch 332/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5725 - acc: 0.1341 - precision_3: 0.4306 - recall_3: 0.1459 - val_loss: 1.5502 - val_acc: 0.3676 - val_precision_3: 0.4231 - val_recall_3: 0.4757\n",
      "Epoch 333/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5802 - acc: 0.1224 - precision_3: 0.3766 - recall_3: 0.1365 - val_loss: 1.5502 - val_acc: 0.3676 - val_precision_3: 0.4203 - val_recall_3: 0.4703\n",
      "Epoch 334/2000\n",
      "85/85 [==============================] - 0s 492us/sample - loss: 1.5807 - acc: 0.1318 - precision_3: 0.3885 - recall_3: 0.1435 - val_loss: 1.5506 - val_acc: 0.3676 - val_precision_3: 0.4183 - val_recall_3: 0.4703\n",
      "Epoch 335/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5725 - acc: 0.1294 - precision_3: 0.4106 - recall_3: 0.1459 - val_loss: 1.5505 - val_acc: 0.3676 - val_precision_3: 0.4087 - val_recall_3: 0.4595\n",
      "Epoch 336/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.6029 - acc: 0.0776 - precision_3: 0.2740 - recall_3: 0.0941 - val_loss: 1.5524 - val_acc: 0.3730 - val_precision_3: 0.4106 - val_recall_3: 0.4595\n",
      "Epoch 337/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5834 - acc: 0.1200 - precision_3: 0.3871 - recall_3: 0.1412 - val_loss: 1.5522 - val_acc: 0.3676 - val_precision_3: 0.4089 - val_recall_3: 0.4486\n",
      "Epoch 338/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5760 - acc: 0.1318 - precision_3: 0.3795 - recall_3: 0.1482 - val_loss: 1.5526 - val_acc: 0.3730 - val_precision_3: 0.4146 - val_recall_3: 0.4595\n",
      "Epoch 339/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5705 - acc: 0.1529 - precision_3: 0.4182 - recall_3: 0.1624 - val_loss: 1.5534 - val_acc: 0.3676 - val_precision_3: 0.4126 - val_recall_3: 0.4595\n",
      "Epoch 340/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5809 - acc: 0.1224 - precision_3: 0.3916 - recall_3: 0.1318 - val_loss: 1.5542 - val_acc: 0.3784 - val_precision_3: 0.4095 - val_recall_3: 0.4649\n",
      "Epoch 341/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5825 - acc: 0.1200 - precision_3: 0.3733 - recall_3: 0.1318 - val_loss: 1.5549 - val_acc: 0.3892 - val_precision_3: 0.4123 - val_recall_3: 0.4703\n",
      "Epoch 342/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5741 - acc: 0.1200 - precision_3: 0.4135 - recall_3: 0.1294 - val_loss: 1.5552 - val_acc: 0.3838 - val_precision_3: 0.4112 - val_recall_3: 0.4757\n",
      "Epoch 343/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5820 - acc: 0.1375 - precision_3: 0.3667 - recall_3: 0.13 - 0s 505us/sample - loss: 1.5809 - acc: 0.1224 - precision_3: 0.3944 - recall_3: 0.1318 - val_loss: 1.5556 - val_acc: 0.3730 - val_precision_3: 0.4085 - val_recall_3: 0.4703\n",
      "Epoch 344/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5822 - acc: 0.1247 - precision_3: 0.3654 - recall_3: 0.1341 - val_loss: 1.5545 - val_acc: 0.3730 - val_precision_3: 0.4038 - val_recall_3: 0.4649\n",
      "Epoch 345/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5879 - acc: 0.1224 - precision_3: 0.3392 - recall_3: 0.1365 - val_loss: 1.5517 - val_acc: 0.3784 - val_precision_3: 0.4055 - val_recall_3: 0.4757\n",
      "Epoch 346/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5750 - acc: 0.1294 - precision_3: 0.3867 - recall_3: 0.1365 - val_loss: 1.5500 - val_acc: 0.3784 - val_precision_3: 0.4147 - val_recall_3: 0.4865\n",
      "Epoch 347/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5726 - acc: 0.1341 - precision_3: 0.4026 - recall_3: 0.1459 - val_loss: 1.5510 - val_acc: 0.3784 - val_precision_3: 0.4131 - val_recall_3: 0.4757\n",
      "Epoch 348/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5868 - acc: 0.1059 - precision_3: 0.3692 - recall_3: 0.1129 - val_loss: 1.5526 - val_acc: 0.3784 - val_precision_3: 0.4143 - val_recall_3: 0.4703\n",
      "Epoch 349/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5791 - acc: 0.1059 - precision_3: 0.3923 - recall_3: 0.1200 - val_loss: 1.5543 - val_acc: 0.3784 - val_precision_3: 0.4135 - val_recall_3: 0.4649\n",
      "Epoch 350/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5896 - acc: 0.1012 - precision_3: 0.3520 - recall_3: 0.1035 - val_loss: 1.5549 - val_acc: 0.3676 - val_precision_3: 0.4089 - val_recall_3: 0.4486\n",
      "Epoch 351/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5855 - acc: 0.1129 - precision_3: 0.3464 - recall_3: 0.1247 - val_loss: 1.5551 - val_acc: 0.3676 - val_precision_3: 0.4109 - val_recall_3: 0.4486\n",
      "Epoch 352/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5925 - acc: 0.1059 - precision_3: 0.3478 - recall_3: 0.1129 - val_loss: 1.5545 - val_acc: 0.3784 - val_precision_3: 0.4109 - val_recall_3: 0.4486\n",
      "Epoch 353/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5867 - acc: 0.1153 - precision_3: 0.3636 - recall_3: 0.1224 - val_loss: 1.5528 - val_acc: 0.3784 - val_precision_3: 0.4150 - val_recall_3: 0.4486\n",
      "Epoch 354/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5788 - acc: 0.1247 - precision_3: 0.3782 - recall_3: 0.1388 - val_loss: 1.5512 - val_acc: 0.3730 - val_precision_3: 0.4200 - val_recall_3: 0.4541\n",
      "Epoch 355/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5913 - acc: 0.1153 - precision_3: 0.3421 - recall_3: 0.1224 - val_loss: 1.5509 - val_acc: 0.3730 - val_precision_3: 0.4138 - val_recall_3: 0.4541\n",
      "Epoch 356/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5779 - acc: 0.1365 - precision_3: 0.3913 - recall_3: 0.1482 - val_loss: 1.5493 - val_acc: 0.3838 - val_precision_3: 0.4203 - val_recall_3: 0.4703\n",
      "Epoch 357/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5915 - acc: 0.1176 - precision_3: 0.3399 - recall_3: 0.1224 - val_loss: 1.5488 - val_acc: 0.3784 - val_precision_3: 0.4126 - val_recall_3: 0.4595\n",
      "Epoch 358/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5807 - acc: 0.1224 - precision_3: 0.3709 - recall_3: 0.1318 - val_loss: 1.5484 - val_acc: 0.3784 - val_precision_3: 0.4048 - val_recall_3: 0.4595\n",
      "Epoch 359/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5776 - acc: 0.1247 - precision_3: 0.3665 - recall_3: 0.1388 - val_loss: 1.5473 - val_acc: 0.3784 - val_precision_3: 0.4009 - val_recall_3: 0.4595\n",
      "Epoch 360/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5886 - acc: 0.0918 - precision_3: 0.3571 - recall_3: 0.1059 - val_loss: 1.5480 - val_acc: 0.3838 - val_precision_3: 0.4057 - val_recall_3: 0.4649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5877 - acc: 0.1129 - precision_3: 0.3514 - recall_3: 0.1224 - val_loss: 1.5475 - val_acc: 0.3838 - val_precision_3: 0.4095 - val_recall_3: 0.4649\n",
      "Epoch 362/2000\n",
      "85/85 [==============================] - 0s 492us/sample - loss: 1.5606 - acc: 0.1600 - precision_3: 0.4684 - recall_3: 0.1741 - val_loss: 1.5487 - val_acc: 0.3784 - val_precision_3: 0.4190 - val_recall_3: 0.4757\n",
      "Epoch 363/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5658 - acc: 0.1506 - precision_3: 0.4277 - recall_3: 0.1600 - val_loss: 1.5486 - val_acc: 0.3838 - val_precision_3: 0.4206 - val_recall_3: 0.4865\n",
      "Epoch 364/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5665 - acc: 0.1506 - precision_3: 0.4416 - recall_3: 0.1600 - val_loss: 1.5494 - val_acc: 0.3892 - val_precision_3: 0.4167 - val_recall_3: 0.4865\n",
      "Epoch 365/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5778 - acc: 0.1318 - precision_3: 0.4245 - recall_3: 0.1388 - val_loss: 1.5485 - val_acc: 0.3946 - val_precision_3: 0.4093 - val_recall_3: 0.4757\n",
      "Epoch 366/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5853 - acc: 0.1176 - precision_3: 0.3630 - recall_3: 0.1247 - val_loss: 1.5484 - val_acc: 0.3892 - val_precision_3: 0.4131 - val_recall_3: 0.4757\n",
      "Epoch 367/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5555 - acc: 0.1718 - precision_3: 0.4777 - recall_3: 0.1765 - val_loss: 1.5489 - val_acc: 0.3838 - val_precision_3: 0.4095 - val_recall_3: 0.4649\n",
      "Epoch 368/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5740 - acc: 0.1247 - precision_3: 0.4189 - recall_3: 0.1459 - val_loss: 1.5503 - val_acc: 0.3838 - val_precision_3: 0.4058 - val_recall_3: 0.4541\n",
      "Epoch 369/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5679 - acc: 0.1365 - precision_3: 0.4194 - recall_3: 0.1529 - val_loss: 1.5530 - val_acc: 0.3784 - val_precision_3: 0.4000 - val_recall_3: 0.4432\n",
      "Epoch 370/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5889 - acc: 0.0988 - precision_3: 0.3404 - recall_3: 0.1129 - val_loss: 1.5559 - val_acc: 0.3676 - val_precision_3: 0.4100 - val_recall_3: 0.4432\n",
      "Epoch 371/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5848 - acc: 0.1082 - precision_3: 0.3694 - recall_3: 0.1365 - val_loss: 1.5578 - val_acc: 0.3568 - val_precision_3: 0.4205 - val_recall_3: 0.4432\n",
      "Epoch 372/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5743 - acc: 0.1341 - precision_3: 0.4000 - recall_3: 0.1459 - val_loss: 1.5573 - val_acc: 0.3622 - val_precision_3: 0.4213 - val_recall_3: 0.4486\n",
      "Epoch 373/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5645 - acc: 0.1506 - precision_3: 0.4671 - recall_3: 0.1671 - val_loss: 1.5571 - val_acc: 0.3676 - val_precision_3: 0.4129 - val_recall_3: 0.4486\n",
      "Epoch 374/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5784 - acc: 0.1200 - precision_3: 0.4044 - recall_3: 0.1294 - val_loss: 1.5571 - val_acc: 0.3622 - val_precision_3: 0.4162 - val_recall_3: 0.4432\n",
      "Epoch 375/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5707 - acc: 0.1506 - precision_3: 0.4387 - recall_3: 0.1600 - val_loss: 1.5550 - val_acc: 0.3676 - val_precision_3: 0.4070 - val_recall_3: 0.4378\n",
      "Epoch 376/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5583 - acc: 0.1482 - precision_3: 0.5109 - recall_3: 0.1647 - val_loss: 1.5503 - val_acc: 0.3676 - val_precision_3: 0.4020 - val_recall_3: 0.4432\n",
      "Epoch 377/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5915 - acc: 0.1082 - precision_3: 0.3423 - recall_3: 0.1200 - val_loss: 1.5481 - val_acc: 0.3676 - val_precision_3: 0.4049 - val_recall_3: 0.4486\n",
      "Epoch 378/2000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.5747 - acc: 0.1106 - precision_3: 0.4211 - recall_3: 0.1318 - val_loss: 1.5476 - val_acc: 0.3784 - val_precision_3: 0.4039 - val_recall_3: 0.4432\n",
      "Epoch 379/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5895 - acc: 0.1129 - precision_3: 0.3592 - recall_3: 0.1200 - val_loss: 1.5487 - val_acc: 0.3838 - val_precision_3: 0.4010 - val_recall_3: 0.4378\n",
      "Epoch 380/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5694 - acc: 0.1412 - precision_3: 0.4514 - recall_3: 0.1529 - val_loss: 1.5502 - val_acc: 0.3676 - val_precision_3: 0.3922 - val_recall_3: 0.4324\n",
      "Epoch 381/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5717 - acc: 0.1341 - precision_3: 0.4196 - recall_3: 0.1412 - val_loss: 1.5517 - val_acc: 0.3568 - val_precision_3: 0.3932 - val_recall_3: 0.4378\n",
      "Epoch 382/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5702 - acc: 0.1388 - precision_3: 0.4231 - recall_3: 0.1553 - val_loss: 1.5529 - val_acc: 0.3568 - val_precision_3: 0.3942 - val_recall_3: 0.4432\n",
      "Epoch 383/2000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.5765 - acc: 0.1247 - precision_3: 0.3750 - recall_3: 0.1341 - val_loss: 1.5533 - val_acc: 0.3568 - val_precision_3: 0.3922 - val_recall_3: 0.4324\n",
      "Epoch 384/2000\n",
      "85/85 [==============================] - 0s 658us/sample - loss: 1.5699 - acc: 0.1435 - precision_3: 0.4351 - recall_3: 0.1576 - val_loss: 1.5543 - val_acc: 0.3676 - val_precision_3: 0.3922 - val_recall_3: 0.4324\n",
      "Epoch 385/2000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.5757 - acc: 0.1318 - precision_3: 0.4094 - recall_3: 0.1435 - val_loss: 1.5556 - val_acc: 0.3622 - val_precision_3: 0.3990 - val_recall_3: 0.4378\n",
      "Epoch 386/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5730 - acc: 0.1365 - precision_3: 0.3860 - recall_3: 0.1553 - val_loss: 1.5578 - val_acc: 0.3568 - val_precision_3: 0.3950 - val_recall_3: 0.4270\n",
      "Epoch 387/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5656 - acc: 0.1553 - precision_3: 0.4768 - recall_3: 0.1694 - val_loss: 1.5593 - val_acc: 0.3676 - val_precision_3: 0.4020 - val_recall_3: 0.4324\n",
      "Epoch 388/2000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.5664 - acc: 0.1435 - precision_3: 0.4437 - recall_3: 0.1482 - val_loss: 1.5586 - val_acc: 0.3568 - val_precision_3: 0.4051 - val_recall_3: 0.4270\n",
      "Epoch 389/2000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.5813 - acc: 0.1224 - precision_3: 0.4030 - recall_3: 0.1271 - val_loss: 1.5574 - val_acc: 0.3622 - val_precision_3: 0.4082 - val_recall_3: 0.4324\n",
      "Epoch 390/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5731 - acc: 0.1200 - precision_3: 0.4500 - recall_3: 0.1271 - val_loss: 1.5562 - val_acc: 0.3622 - val_precision_3: 0.4124 - val_recall_3: 0.4324\n",
      "Epoch 391/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5813 - acc: 0.1129 - precision_3: 0.4032 - recall_3: 0.1176 - val_loss: 1.5551 - val_acc: 0.3784 - val_precision_3: 0.4221 - val_recall_3: 0.4541\n",
      "Epoch 392/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5676 - acc: 0.1459 - precision_3: 0.4648 - recall_3: 0.1553 - val_loss: 1.5538 - val_acc: 0.3784 - val_precision_3: 0.4264 - val_recall_3: 0.4541\n",
      "Epoch 393/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5845 - acc: 0.1106 - precision_3: 0.3566 - recall_3: 0.1200 - val_loss: 1.5530 - val_acc: 0.3784 - val_precision_3: 0.4264 - val_recall_3: 0.4541\n",
      "Epoch 394/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5837 - acc: 0.1082 - precision_3: 0.3676 - recall_3: 0.1176 - val_loss: 1.5525 - val_acc: 0.3784 - val_precision_3: 0.4330 - val_recall_3: 0.4541\n",
      "Epoch 395/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5772 - acc: 0.1200 - precision_3: 0.3946 - recall_3: 0.1365 - val_loss: 1.5525 - val_acc: 0.3730 - val_precision_3: 0.4375 - val_recall_3: 0.4541\n",
      "Epoch 396/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5633 - acc: 0.1482 - precision_3: 0.4371 - recall_3: 0.1718 - val_loss: 1.5531 - val_acc: 0.3784 - val_precision_3: 0.4368 - val_recall_3: 0.4486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5664 - acc: 0.1412 - precision_3: 0.4648 - recall_3: 0.1553 - val_loss: 1.5526 - val_acc: 0.3784 - val_precision_3: 0.4439 - val_recall_3: 0.4486\n",
      "Epoch 398/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5837 - acc: 0.1176 - precision_3: 0.3830 - recall_3: 0.1271 - val_loss: 1.5506 - val_acc: 0.3892 - val_precision_3: 0.4497 - val_recall_3: 0.4595\n",
      "Epoch 399/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5688 - acc: 0.1271 - precision_3: 0.4370 - recall_3: 0.1388 - val_loss: 1.5503 - val_acc: 0.3838 - val_precision_3: 0.4415 - val_recall_3: 0.4486\n",
      "Epoch 400/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5644 - acc: 0.1482 - precision_3: 0.4323 - recall_3: 0.1576 - val_loss: 1.5515 - val_acc: 0.3784 - val_precision_3: 0.4362 - val_recall_3: 0.4432\n",
      "Epoch 401/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5743 - acc: 0.1294 - precision_3: 0.4236 - recall_3: 0.1435 - val_loss: 1.5541 - val_acc: 0.3784 - val_precision_3: 0.4392 - val_recall_3: 0.4486\n",
      "Epoch 402/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5637 - acc: 0.1553 - precision_3: 0.4730 - recall_3: 0.1647 - val_loss: 1.5552 - val_acc: 0.3784 - val_precision_3: 0.4392 - val_recall_3: 0.4486\n",
      "Epoch 403/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5772 - acc: 0.1271 - precision_3: 0.3947 - recall_3: 0.1412 - val_loss: 1.5578 - val_acc: 0.3622 - val_precision_3: 0.4432 - val_recall_3: 0.4432\n",
      "Epoch 404/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5750 - acc: 0.1294 - precision_3: 0.4286 - recall_3: 0.1482 - val_loss: 1.5577 - val_acc: 0.3676 - val_precision_3: 0.4323 - val_recall_3: 0.4486\n",
      "Epoch 405/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5707 - acc: 0.1365 - precision_3: 0.4182 - recall_3: 0.1624 - val_loss: 1.5574 - val_acc: 0.3568 - val_precision_3: 0.4330 - val_recall_3: 0.4541\n",
      "Epoch 406/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5763 - acc: 0.1200 - precision_3: 0.4014 - recall_3: 0.1341 - val_loss: 1.5564 - val_acc: 0.3622 - val_precision_3: 0.4330 - val_recall_3: 0.4541\n",
      "Epoch 407/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5661 - acc: 0.1482 - precision_3: 0.4286 - recall_3: 0.1553 - val_loss: 1.5552 - val_acc: 0.3568 - val_precision_3: 0.4286 - val_recall_3: 0.4541\n",
      "Epoch 408/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5692 - acc: 0.1294 - precision_3: 0.4519 - recall_3: 0.1435 - val_loss: 1.5540 - val_acc: 0.3838 - val_precision_3: 0.4359 - val_recall_3: 0.4595\n",
      "Epoch 409/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5845 - acc: 0.1082 - precision_3: 0.3788 - recall_3: 0.1176 - val_loss: 1.5529 - val_acc: 0.3892 - val_precision_3: 0.4365 - val_recall_3: 0.4649\n",
      "Epoch 410/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5547 - acc: 0.1529 - precision_3: 0.5180 - recall_3: 0.1694 - val_loss: 1.5539 - val_acc: 0.3892 - val_precision_3: 0.4490 - val_recall_3: 0.4757\n",
      "Epoch 411/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5587 - acc: 0.1506 - precision_3: 0.4581 - recall_3: 0.1671 - val_loss: 1.5541 - val_acc: 0.3784 - val_precision_3: 0.4439 - val_recall_3: 0.4703\n",
      "Epoch 412/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5806 - acc: 0.1200 - precision_3: 0.4031 - recall_3: 0.1224 - val_loss: 1.5539 - val_acc: 0.3838 - val_precision_3: 0.4410 - val_recall_3: 0.4649\n",
      "Epoch 413/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5700 - acc: 0.1271 - precision_3: 0.4196 - recall_3: 0.1412 - val_loss: 1.5546 - val_acc: 0.3784 - val_precision_3: 0.4375 - val_recall_3: 0.4541\n",
      "Epoch 414/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5669 - acc: 0.1318 - precision_3: 0.4521 - recall_3: 0.1553 - val_loss: 1.5557 - val_acc: 0.3676 - val_precision_3: 0.4381 - val_recall_3: 0.4595\n",
      "Epoch 415/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5570 - acc: 0.1600 - precision_3: 0.5106 - recall_3: 0.1694 - val_loss: 1.5557 - val_acc: 0.3676 - val_precision_3: 0.4381 - val_recall_3: 0.4595\n",
      "Epoch 416/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5745 - acc: 0.1365 - precision_3: 0.4207 - recall_3: 0.1435 - val_loss: 1.5560 - val_acc: 0.3676 - val_precision_3: 0.4392 - val_recall_3: 0.4486\n",
      "Epoch 417/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5727 - acc: 0.1459 - precision_3: 0.4099 - recall_3: 0.1553 - val_loss: 1.5556 - val_acc: 0.3784 - val_precision_3: 0.4368 - val_recall_3: 0.4486\n",
      "Epoch 418/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5443 - acc: 0.1765 - precision_3: 0.5524 - recall_3: 0.1859 - val_loss: 1.5540 - val_acc: 0.3946 - val_precision_3: 0.4330 - val_recall_3: 0.4541\n",
      "Epoch 419/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5827 - acc: 0.1059 - precision_3: 0.3881 - recall_3: 0.1224 - val_loss: 1.5532 - val_acc: 0.4000 - val_precision_3: 0.4410 - val_recall_3: 0.4649\n",
      "Epoch 420/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5681 - acc: 0.1435 - precision_3: 0.4483 - recall_3: 0.1529 - val_loss: 1.5522 - val_acc: 0.4000 - val_precision_3: 0.4416 - val_recall_3: 0.4703\n",
      "Epoch 421/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5735 - acc: 0.1412 - precision_3: 0.4200 - recall_3: 0.1482 - val_loss: 1.5516 - val_acc: 0.3838 - val_precision_3: 0.4474 - val_recall_3: 0.4595\n",
      "Epoch 422/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5657 - acc: 0.1365 - precision_3: 0.4452 - recall_3: 0.1529 - val_loss: 1.5514 - val_acc: 0.3838 - val_precision_3: 0.4474 - val_recall_3: 0.4595\n",
      "Epoch 423/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5765 - acc: 0.1271 - precision_3: 0.4236 - recall_3: 0.1435 - val_loss: 1.5527 - val_acc: 0.3838 - val_precision_3: 0.4439 - val_recall_3: 0.4703\n",
      "Epoch 424/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5694 - acc: 0.1459 - precision_3: 0.4331 - recall_3: 0.1600 - val_loss: 1.5529 - val_acc: 0.3784 - val_precision_3: 0.4433 - val_recall_3: 0.4649\n",
      "Epoch 425/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5715 - acc: 0.1247 - precision_3: 0.4597 - recall_3: 0.1341 - val_loss: 1.5531 - val_acc: 0.3784 - val_precision_3: 0.4462 - val_recall_3: 0.4703\n",
      "Epoch 426/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5687 - acc: 0.1412 - precision_3: 0.4493 - recall_3: 0.1459 - val_loss: 1.5525 - val_acc: 0.3892 - val_precision_3: 0.4513 - val_recall_3: 0.4757\n",
      "Epoch 427/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5557 - acc: 0.1482 - precision_3: 0.5303 - recall_3: 0.1647 - val_loss: 1.5518 - val_acc: 0.3892 - val_precision_3: 0.4485 - val_recall_3: 0.4703\n",
      "Epoch 428/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5720 - acc: 0.1294 - precision_3: 0.4079 - recall_3: 0.1459 - val_loss: 1.5509 - val_acc: 0.3892 - val_precision_3: 0.4531 - val_recall_3: 0.4703\n",
      "Epoch 429/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5606 - acc: 0.1506 - precision_3: 0.4752 - recall_3: 0.1576 - val_loss: 1.5496 - val_acc: 0.3892 - val_precision_3: 0.4485 - val_recall_3: 0.4703\n",
      "Epoch 430/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5714 - acc: 0.1341 - precision_3: 0.4406 - recall_3: 0.1482 - val_loss: 1.5494 - val_acc: 0.3892 - val_precision_3: 0.4508 - val_recall_3: 0.4703\n",
      "Epoch 431/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5703 - acc: 0.1365 - precision_3: 0.4599 - recall_3: 0.1482 - val_loss: 1.5495 - val_acc: 0.3838 - val_precision_3: 0.4427 - val_recall_3: 0.4595\n",
      "Epoch 432/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5616 - acc: 0.1341 - precision_3: 0.5217 - recall_3: 0.1412 - val_loss: 1.5496 - val_acc: 0.3838 - val_precision_3: 0.4427 - val_recall_3: 0.4595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5549 - acc: 0.1694 - precision_3: 0.4512 - recall_3: 0.1741 - val_loss: 1.5505 - val_acc: 0.3946 - val_precision_3: 0.4485 - val_recall_3: 0.4703\n",
      "Epoch 434/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5635 - acc: 0.1482 - precision_3: 0.4755 - recall_3: 0.1600 - val_loss: 1.5505 - val_acc: 0.3946 - val_precision_3: 0.4508 - val_recall_3: 0.4703\n",
      "Epoch 435/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5477 - acc: 0.1812 - precision_3: 0.5122 - recall_3: 0.1976 - val_loss: 1.5506 - val_acc: 0.3946 - val_precision_3: 0.4555 - val_recall_3: 0.4703\n",
      "Epoch 436/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5576 - acc: 0.1576 - precision_3: 0.5182 - recall_3: 0.1671 - val_loss: 1.5503 - val_acc: 0.3838 - val_precision_3: 0.4579 - val_recall_3: 0.4703\n",
      "Epoch 437/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5698 - acc: 0.1365 - precision_3: 0.4762 - recall_3: 0.1412 - val_loss: 1.5503 - val_acc: 0.3838 - val_precision_3: 0.4531 - val_recall_3: 0.4703\n",
      "Epoch 438/2000\n",
      "85/85 [==============================] - 0s 529us/sample - loss: 1.5706 - acc: 0.1247 - precision_3: 0.4462 - recall_3: 0.1365 - val_loss: 1.5497 - val_acc: 0.3838 - val_precision_3: 0.4416 - val_recall_3: 0.4703\n",
      "Epoch 439/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5635 - acc: 0.1341 - precision_3: 0.5000 - recall_3: 0.1482 - val_loss: 1.5496 - val_acc: 0.3838 - val_precision_3: 0.4472 - val_recall_3: 0.4811\n",
      "Epoch 440/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5693 - acc: 0.1341 - precision_3: 0.4366 - recall_3: 0.1459 - val_loss: 1.5490 - val_acc: 0.3784 - val_precision_3: 0.4450 - val_recall_3: 0.4811\n",
      "Epoch 441/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5715 - acc: 0.1341 - precision_3: 0.4720 - recall_3: 0.1388 - val_loss: 1.5485 - val_acc: 0.3784 - val_precision_3: 0.4478 - val_recall_3: 0.4865\n",
      "Epoch 442/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5497 - acc: 0.1765 - precision_3: 0.5238 - recall_3: 0.1812 - val_loss: 1.5480 - val_acc: 0.3784 - val_precision_3: 0.4505 - val_recall_3: 0.4919\n",
      "Epoch 443/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5652 - acc: 0.1435 - precision_3: 0.4337 - recall_3: 0.1694 - val_loss: 1.5498 - val_acc: 0.3784 - val_precision_3: 0.4400 - val_recall_3: 0.4757\n",
      "Epoch 444/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5731 - acc: 0.1365 - precision_3: 0.4651 - recall_3: 0.1412 - val_loss: 1.5500 - val_acc: 0.3892 - val_precision_3: 0.4356 - val_recall_3: 0.4757\n",
      "Epoch 445/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5668 - acc: 0.1341 - precision_3: 0.4882 - recall_3: 0.1459 - val_loss: 1.5497 - val_acc: 0.3730 - val_precision_3: 0.4300 - val_recall_3: 0.4649\n",
      "Epoch 446/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5667 - acc: 0.1341 - precision_3: 0.4646 - recall_3: 0.1388 - val_loss: 1.5497 - val_acc: 0.3730 - val_precision_3: 0.4378 - val_recall_3: 0.4757\n",
      "Epoch 447/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5613 - acc: 0.1529 - precision_3: 0.5149 - recall_3: 0.1624 - val_loss: 1.5501 - val_acc: 0.3676 - val_precision_3: 0.4350 - val_recall_3: 0.4703\n",
      "Epoch 448/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5618 - acc: 0.1365 - precision_3: 0.4841 - recall_3: 0.1435 - val_loss: 1.5483 - val_acc: 0.3838 - val_precision_3: 0.4433 - val_recall_3: 0.4865\n",
      "Epoch 449/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5588 - acc: 0.1553 - precision_3: 0.4861 - recall_3: 0.1647 - val_loss: 1.5484 - val_acc: 0.3892 - val_precision_3: 0.4455 - val_recall_3: 0.4865\n",
      "Epoch 450/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5780 - acc: 0.1153 - precision_3: 0.3942 - recall_3: 0.1271 - val_loss: 1.5469 - val_acc: 0.3946 - val_precision_3: 0.4505 - val_recall_3: 0.4919\n",
      "Epoch 451/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5722 - acc: 0.1341 - precision_3: 0.3974 - recall_3: 0.1459 - val_loss: 1.5456 - val_acc: 0.4000 - val_precision_3: 0.4592 - val_recall_3: 0.4865\n",
      "Epoch 452/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5524 - acc: 0.1624 - precision_3: 0.5000 - recall_3: 0.1741 - val_loss: 1.5451 - val_acc: 0.4054 - val_precision_3: 0.4569 - val_recall_3: 0.4865\n",
      "Epoch 453/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5645 - acc: 0.1341 - precision_3: 0.4651 - recall_3: 0.1412 - val_loss: 1.5442 - val_acc: 0.4000 - val_precision_3: 0.4596 - val_recall_3: 0.4919\n",
      "Epoch 454/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5626 - acc: 0.1459 - precision_3: 0.5159 - recall_3: 0.1529 - val_loss: 1.5442 - val_acc: 0.3946 - val_precision_3: 0.4560 - val_recall_3: 0.4757\n",
      "Epoch 455/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5639 - acc: 0.1482 - precision_3: 0.5077 - recall_3: 0.1553 - val_loss: 1.5441 - val_acc: 0.4000 - val_precision_3: 0.4588 - val_recall_3: 0.4811\n",
      "Epoch 456/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5524 - acc: 0.1647 - precision_3: 0.5481 - recall_3: 0.1741 - val_loss: 1.5431 - val_acc: 0.4108 - val_precision_3: 0.4541 - val_recall_3: 0.4811\n",
      "Epoch 457/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5740 - acc: 0.1318 - precision_3: 0.4122 - recall_3: 0.1435 - val_loss: 1.5428 - val_acc: 0.4216 - val_precision_3: 0.4596 - val_recall_3: 0.4919\n",
      "Epoch 458/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5546 - acc: 0.1553 - precision_3: 0.5259 - recall_3: 0.1671 - val_loss: 1.5430 - val_acc: 0.4162 - val_precision_3: 0.4564 - val_recall_3: 0.4811\n",
      "Epoch 459/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5682 - acc: 0.1224 - precision_3: 0.4715 - recall_3: 0.1365 - val_loss: 1.5441 - val_acc: 0.4054 - val_precision_3: 0.4536 - val_recall_3: 0.4757\n",
      "Epoch 460/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5775 - acc: 0.1125 - precision_3: 0.3929 - recall_3: 0.13 - 0s 528us/sample - loss: 1.5670 - acc: 0.1318 - precision_3: 0.4766 - recall_3: 0.1435 - val_loss: 1.5448 - val_acc: 0.4054 - val_precision_3: 0.4536 - val_recall_3: 0.4757\n",
      "Epoch 461/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5509 - acc: 0.1600 - precision_3: 0.5414 - recall_3: 0.1694 - val_loss: 1.5435 - val_acc: 0.4216 - val_precision_3: 0.4573 - val_recall_3: 0.4919\n",
      "Epoch 462/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5649 - acc: 0.1412 - precision_3: 0.4846 - recall_3: 0.1482 - val_loss: 1.5411 - val_acc: 0.4162 - val_precision_3: 0.4523 - val_recall_3: 0.4865\n",
      "Epoch 463/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5738 - acc: 0.1200 - precision_3: 0.4385 - recall_3: 0.1341 - val_loss: 1.5374 - val_acc: 0.4216 - val_precision_3: 0.4406 - val_recall_3: 0.4811\n",
      "Epoch 464/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5660 - acc: 0.1459 - precision_3: 0.4342 - recall_3: 0.1553 - val_loss: 1.5354 - val_acc: 0.4270 - val_precision_3: 0.4505 - val_recall_3: 0.4919\n",
      "Epoch 465/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5559 - acc: 0.1750 - precision_3: 0.4242 - recall_3: 0.17 - 0s 528us/sample - loss: 1.5611 - acc: 0.1506 - precision_3: 0.4848 - recall_3: 0.1506 - val_loss: 1.5332 - val_acc: 0.4270 - val_precision_3: 0.4554 - val_recall_3: 0.4973\n",
      "Epoch 466/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5521 - acc: 0.1718 - precision_3: 0.5333 - recall_3: 0.1882 - val_loss: 1.5321 - val_acc: 0.4162 - val_precision_3: 0.4596 - val_recall_3: 0.4919\n",
      "Epoch 467/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5507 - acc: 0.1741 - precision_3: 0.5200 - recall_3: 0.1835 - val_loss: 1.5322 - val_acc: 0.4216 - val_precision_3: 0.4596 - val_recall_3: 0.4919\n",
      "Epoch 468/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5625 - acc: 0.1482 - precision_3: 0.4823 - recall_3: 0.1600 - val_loss: 1.5321 - val_acc: 0.4270 - val_precision_3: 0.4596 - val_recall_3: 0.4919\n",
      "Epoch 469/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5527 - acc: 0.1600 - precision_3: 0.5255 - recall_3: 0.1694 - val_loss: 1.5291 - val_acc: 0.4162 - val_precision_3: 0.4673 - val_recall_3: 0.5027\n",
      "Epoch 470/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5648 - acc: 0.1365 - precision_3: 0.5000 - recall_3: 0.1459 - val_loss: 1.5302 - val_acc: 0.4216 - val_precision_3: 0.4619 - val_recall_3: 0.4919\n",
      "Epoch 471/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5643 - acc: 0.1341 - precision_3: 0.4959 - recall_3: 0.1412 - val_loss: 1.5348 - val_acc: 0.4162 - val_precision_3: 0.4588 - val_recall_3: 0.4811\n",
      "Epoch 472/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5607 - acc: 0.1624 - precision_3: 0.4966 - recall_3: 0.1718 - val_loss: 1.5391 - val_acc: 0.4000 - val_precision_3: 0.4603 - val_recall_3: 0.4703\n",
      "Epoch 473/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5664 - acc: 0.1341 - precision_3: 0.5083 - recall_3: 0.1435 - val_loss: 1.5405 - val_acc: 0.3946 - val_precision_3: 0.4570 - val_recall_3: 0.4595\n",
      "Epoch 474/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5757 - acc: 0.1294 - precision_3: 0.4677 - recall_3: 0.1365 - val_loss: 1.5410 - val_acc: 0.4000 - val_precision_3: 0.4620 - val_recall_3: 0.4595\n",
      "Epoch 475/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5596 - acc: 0.1647 - precision_3: 0.4897 - recall_3: 0.1671 - val_loss: 1.5437 - val_acc: 0.3946 - val_precision_3: 0.4556 - val_recall_3: 0.4432\n",
      "Epoch 476/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5581 - acc: 0.1506 - precision_3: 0.5113 - recall_3: 0.1600 - val_loss: 1.5417 - val_acc: 0.4000 - val_precision_3: 0.4565 - val_recall_3: 0.4541\n",
      "Epoch 477/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5651 - acc: 0.1482 - precision_3: 0.5000 - recall_3: 0.1624 - val_loss: 1.5405 - val_acc: 0.4162 - val_precision_3: 0.4652 - val_recall_3: 0.4703\n",
      "Epoch 478/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5755 - acc: 0.1318 - precision_3: 0.4296 - recall_3: 0.1435 - val_loss: 1.5390 - val_acc: 0.4162 - val_precision_3: 0.4681 - val_recall_3: 0.4757\n",
      "Epoch 479/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5536 - acc: 0.1624 - precision_3: 0.5659 - recall_3: 0.1718 - val_loss: 1.5394 - val_acc: 0.4216 - val_precision_3: 0.4681 - val_recall_3: 0.4757\n",
      "Epoch 480/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5592 - acc: 0.1435 - precision_3: 0.5077 - recall_3: 0.1553 - val_loss: 1.5395 - val_acc: 0.4216 - val_precision_3: 0.4706 - val_recall_3: 0.4757\n",
      "Epoch 481/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5510 - acc: 0.1506 - precision_3: 0.5635 - recall_3: 0.1671 - val_loss: 1.5389 - val_acc: 0.4270 - val_precision_3: 0.4734 - val_recall_3: 0.4811\n",
      "Epoch 482/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5484 - acc: 0.1741 - precision_3: 0.5270 - recall_3: 0.1835 - val_loss: 1.5379 - val_acc: 0.4270 - val_precision_3: 0.4787 - val_recall_3: 0.4865\n",
      "Epoch 483/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5568 - acc: 0.1671 - precision_3: 0.4713 - recall_3: 0.1741 - val_loss: 1.5398 - val_acc: 0.4216 - val_precision_3: 0.4681 - val_recall_3: 0.4757\n",
      "Epoch 484/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5630 - acc: 0.1459 - precision_3: 0.5039 - recall_3: 0.1529 - val_loss: 1.5423 - val_acc: 0.4162 - val_precision_3: 0.4734 - val_recall_3: 0.4811\n",
      "Epoch 485/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5569 - acc: 0.1600 - precision_3: 0.5036 - recall_3: 0.1647 - val_loss: 1.5441 - val_acc: 0.4162 - val_precision_3: 0.4789 - val_recall_3: 0.4919\n",
      "Epoch 486/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5448 - acc: 0.1788 - precision_3: 0.5467 - recall_3: 0.1929 - val_loss: 1.5453 - val_acc: 0.4054 - val_precision_3: 0.4706 - val_recall_3: 0.4757\n",
      "Epoch 487/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5478 - acc: 0.1624 - precision_3: 0.5401 - recall_3: 0.1741 - val_loss: 1.5466 - val_acc: 0.4108 - val_precision_3: 0.4731 - val_recall_3: 0.4757\n",
      "Epoch 488/2000\n",
      "85/85 [==============================] - 0s 529us/sample - loss: 1.5699 - acc: 0.1412 - precision_3: 0.4615 - recall_3: 0.1412 - val_loss: 1.5461 - val_acc: 0.4162 - val_precision_3: 0.4759 - val_recall_3: 0.4811\n",
      "Epoch 489/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5720 - acc: 0.1271 - precision_3: 0.4715 - recall_3: 0.1365 - val_loss: 1.5458 - val_acc: 0.4216 - val_precision_3: 0.4762 - val_recall_3: 0.4865\n",
      "Epoch 490/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5640 - acc: 0.1459 - precision_3: 0.4667 - recall_3: 0.1647 - val_loss: 1.5462 - val_acc: 0.4216 - val_precision_3: 0.4789 - val_recall_3: 0.4919\n",
      "Epoch 491/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5504 - acc: 0.1600 - precision_3: 0.5328 - recall_3: 0.1718 - val_loss: 1.5457 - val_acc: 0.4324 - val_precision_3: 0.4844 - val_recall_3: 0.5027\n",
      "Epoch 492/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5812 - acc: 0.1375 - precision_3: 0.4286 - recall_3: 0.15 - 0s 505us/sample - loss: 1.5599 - acc: 0.1529 - precision_3: 0.5000 - recall_3: 0.1647 - val_loss: 1.5470 - val_acc: 0.4108 - val_precision_3: 0.4785 - val_recall_3: 0.4811\n",
      "Epoch 493/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5648 - acc: 0.1365 - precision_3: 0.5041 - recall_3: 0.1459 - val_loss: 1.5483 - val_acc: 0.4000 - val_precision_3: 0.4757 - val_recall_3: 0.4757\n",
      "Epoch 494/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5614 - acc: 0.1459 - precision_3: 0.5410 - recall_3: 0.1553 - val_loss: 1.5484 - val_acc: 0.4108 - val_precision_3: 0.4787 - val_recall_3: 0.4865\n",
      "Epoch 495/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5711 - acc: 0.1153 - precision_3: 0.5094 - recall_3: 0.1271 - val_loss: 1.5469 - val_acc: 0.4108 - val_precision_3: 0.4709 - val_recall_3: 0.4811\n",
      "Epoch 496/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5620 - acc: 0.1459 - precision_3: 0.5188 - recall_3: 0.1624 - val_loss: 1.5470 - val_acc: 0.3946 - val_precision_3: 0.4681 - val_recall_3: 0.4757\n",
      "Epoch 497/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5696 - acc: 0.1365 - precision_3: 0.4733 - recall_3: 0.1459 - val_loss: 1.5529 - val_acc: 0.3892 - val_precision_3: 0.4645 - val_recall_3: 0.4595\n",
      "Epoch 498/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5691 - acc: 0.1224 - precision_3: 0.4667 - recall_3: 0.1318 - val_loss: 1.5543 - val_acc: 0.3838 - val_precision_3: 0.4560 - val_recall_3: 0.4486\n",
      "Epoch 499/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5547 - acc: 0.1576 - precision_3: 0.5000 - recall_3: 0.1647 - val_loss: 1.5553 - val_acc: 0.3838 - val_precision_3: 0.4556 - val_recall_3: 0.4432\n",
      "Epoch 500/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5527 - acc: 0.1459 - precision_3: 0.6000 - recall_3: 0.1553 - val_loss: 1.5565 - val_acc: 0.3730 - val_precision_3: 0.4475 - val_recall_3: 0.4378\n",
      "Epoch 501/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5585 - acc: 0.1506 - precision_3: 0.5426 - recall_3: 0.1647 - val_loss: 1.5569 - val_acc: 0.3784 - val_precision_3: 0.4595 - val_recall_3: 0.4595\n",
      "Epoch 502/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5498 - acc: 0.1624 - precision_3: 0.5248 - recall_3: 0.1741 - val_loss: 1.5542 - val_acc: 0.3838 - val_precision_3: 0.4620 - val_recall_3: 0.4595\n",
      "Epoch 503/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5661 - acc: 0.1247 - precision_3: 0.5377 - recall_3: 0.1341 - val_loss: 1.5500 - val_acc: 0.3892 - val_precision_3: 0.4681 - val_recall_3: 0.4757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5607 - acc: 0.1482 - precision_3: 0.4752 - recall_3: 0.1576 - val_loss: 1.5463 - val_acc: 0.3676 - val_precision_3: 0.4385 - val_recall_3: 0.4432\n",
      "Epoch 505/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5557 - acc: 0.1459 - precision_3: 0.5462 - recall_3: 0.1529 - val_loss: 1.5450 - val_acc: 0.3730 - val_precision_3: 0.4392 - val_recall_3: 0.4486\n",
      "Epoch 506/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5639 - acc: 0.1388 - precision_3: 0.5000 - recall_3: 0.1412 - val_loss: 1.5443 - val_acc: 0.4000 - val_precision_3: 0.4536 - val_recall_3: 0.4757\n",
      "Epoch 507/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5641 - acc: 0.1375 - precision_3: 0.5714 - recall_3: 0.15 - 0s 516us/sample - loss: 1.5484 - acc: 0.1576 - precision_3: 0.5748 - recall_3: 0.1718 - val_loss: 1.5447 - val_acc: 0.4108 - val_precision_3: 0.4639 - val_recall_3: 0.4865\n",
      "Epoch 508/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5564 - acc: 0.1553 - precision_3: 0.5476 - recall_3: 0.1624 - val_loss: 1.5434 - val_acc: 0.4162 - val_precision_3: 0.4600 - val_recall_3: 0.4973\n",
      "Epoch 509/2000\n",
      "85/85 [==============================] - 0s 492us/sample - loss: 1.5659 - acc: 0.1365 - precision_3: 0.5172 - recall_3: 0.1412 - val_loss: 1.5405 - val_acc: 0.4270 - val_precision_3: 0.4627 - val_recall_3: 0.5027\n",
      "Epoch 510/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5698 - acc: 0.1412 - precision_3: 0.4599 - recall_3: 0.1482 - val_loss: 1.5389 - val_acc: 0.4216 - val_precision_3: 0.4581 - val_recall_3: 0.5027\n",
      "Epoch 511/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5671 - acc: 0.1176 - precision_3: 0.5000 - recall_3: 0.1318 - val_loss: 1.5379 - val_acc: 0.4324 - val_precision_3: 0.4634 - val_recall_3: 0.5135\n",
      "Epoch 512/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5624 - acc: 0.1412 - precision_3: 0.5227 - recall_3: 0.1624 - val_loss: 1.5368 - val_acc: 0.4378 - val_precision_3: 0.4581 - val_recall_3: 0.5027\n",
      "Epoch 513/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5557 - acc: 0.1718 - precision_3: 0.4934 - recall_3: 0.1765 - val_loss: 1.5332 - val_acc: 0.4324 - val_precision_3: 0.4706 - val_recall_3: 0.5189\n",
      "Epoch 514/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5541 - acc: 0.1576 - precision_3: 0.5217 - recall_3: 0.1694 - val_loss: 1.5298 - val_acc: 0.4270 - val_precision_3: 0.4634 - val_recall_3: 0.5135\n",
      "Epoch 515/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5612 - acc: 0.1412 - precision_3: 0.5124 - recall_3: 0.1459 - val_loss: 1.5256 - val_acc: 0.4432 - val_precision_3: 0.4615 - val_recall_3: 0.5189\n",
      "Epoch 516/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5642 - acc: 0.1318 - precision_3: 0.5130 - recall_3: 0.1388 - val_loss: 1.5245 - val_acc: 0.4432 - val_precision_3: 0.4660 - val_recall_3: 0.5189\n",
      "Epoch 517/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5677 - acc: 0.1294 - precision_3: 0.5000 - recall_3: 0.1412 - val_loss: 1.5249 - val_acc: 0.4432 - val_precision_3: 0.4608 - val_recall_3: 0.5081\n",
      "Epoch 518/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5639 - acc: 0.1482 - precision_3: 0.5000 - recall_3: 0.1529 - val_loss: 1.5259 - val_acc: 0.4486 - val_precision_3: 0.4581 - val_recall_3: 0.5027\n",
      "Epoch 519/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5687 - acc: 0.1318 - precision_3: 0.4790 - recall_3: 0.1341 - val_loss: 1.5271 - val_acc: 0.4486 - val_precision_3: 0.4581 - val_recall_3: 0.5027\n",
      "Epoch 520/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5518 - acc: 0.1624 - precision_3: 0.5278 - recall_3: 0.1788 - val_loss: 1.5275 - val_acc: 0.4432 - val_precision_3: 0.4577 - val_recall_3: 0.4973\n",
      "Epoch 521/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5625 - acc: 0.1341 - precision_3: 0.4815 - recall_3: 0.1529 - val_loss: 1.5273 - val_acc: 0.4432 - val_precision_3: 0.4612 - val_recall_3: 0.5135\n",
      "Epoch 522/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5499 - acc: 0.1600 - precision_3: 0.5917 - recall_3: 0.1671 - val_loss: 1.5294 - val_acc: 0.4432 - val_precision_3: 0.4657 - val_recall_3: 0.5135\n",
      "Epoch 523/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5669 - acc: 0.1318 - precision_3: 0.5225 - recall_3: 0.1365 - val_loss: 1.5305 - val_acc: 0.4541 - val_precision_3: 0.4734 - val_recall_3: 0.5297\n",
      "Epoch 524/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5605 - acc: 0.1412 - precision_3: 0.5526 - recall_3: 0.1482 - val_loss: 1.5314 - val_acc: 0.4541 - val_precision_3: 0.4804 - val_recall_3: 0.5297\n",
      "Epoch 525/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5527 - acc: 0.1506 - precision_3: 0.5461 - recall_3: 0.1812 - val_loss: 1.5338 - val_acc: 0.4595 - val_precision_3: 0.4712 - val_recall_3: 0.5297\n",
      "Epoch 526/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5476 - acc: 0.1765 - precision_3: 0.5612 - recall_3: 0.1835 - val_loss: 1.5354 - val_acc: 0.4541 - val_precision_3: 0.4783 - val_recall_3: 0.5351\n",
      "Epoch 527/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5561 - acc: 0.1506 - precision_3: 0.5391 - recall_3: 0.1624 - val_loss: 1.5372 - val_acc: 0.4486 - val_precision_3: 0.4878 - val_recall_3: 0.5405\n",
      "Epoch 528/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5475 - acc: 0.1624 - precision_3: 0.5564 - recall_3: 0.1741 - val_loss: 1.5380 - val_acc: 0.4486 - val_precision_3: 0.4856 - val_recall_3: 0.5459\n",
      "Epoch 529/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5637 - acc: 0.1318 - precision_3: 0.5000 - recall_3: 0.1435 - val_loss: 1.5380 - val_acc: 0.4541 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 530/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5657 - acc: 0.1341 - precision_3: 0.4880 - recall_3: 0.1435 - val_loss: 1.5354 - val_acc: 0.4541 - val_precision_3: 0.4857 - val_recall_3: 0.5514\n",
      "Epoch 531/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5684 - acc: 0.1247 - precision_3: 0.4956 - recall_3: 0.1318 - val_loss: 1.5312 - val_acc: 0.4649 - val_precision_3: 0.4785 - val_recall_3: 0.5405\n",
      "Epoch 532/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5293 - acc: 0.2024 - precision_3: 0.6475 - recall_3: 0.2118 - val_loss: 1.5307 - val_acc: 0.4486 - val_precision_3: 0.4760 - val_recall_3: 0.5351\n",
      "Epoch 533/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5585 - acc: 0.1388 - precision_3: 0.5203 - recall_3: 0.1506 - val_loss: 1.5303 - val_acc: 0.4541 - val_precision_3: 0.4734 - val_recall_3: 0.5297\n",
      "Epoch 534/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5762 - acc: 0.1200 - precision_3: 0.4583 - recall_3: 0.1294 - val_loss: 1.5303 - val_acc: 0.4541 - val_precision_3: 0.4734 - val_recall_3: 0.5297\n",
      "Epoch 535/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5685 - acc: 0.1247 - precision_3: 0.5000 - recall_3: 0.1318 - val_loss: 1.5314 - val_acc: 0.4432 - val_precision_3: 0.4709 - val_recall_3: 0.5243\n",
      "Epoch 536/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5506 - acc: 0.1600 - precision_3: 0.5481 - recall_3: 0.1741 - val_loss: 1.5343 - val_acc: 0.4486 - val_precision_3: 0.4755 - val_recall_3: 0.5243\n",
      "Epoch 537/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5530 - acc: 0.1576 - precision_3: 0.5308 - recall_3: 0.1624 - val_loss: 1.5365 - val_acc: 0.4378 - val_precision_3: 0.4752 - val_recall_3: 0.5189\n",
      "Epoch 538/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5611 - acc: 0.1341 - precision_3: 0.5040 - recall_3: 0.1482 - val_loss: 1.5363 - val_acc: 0.4324 - val_precision_3: 0.4700 - val_recall_3: 0.5081\n",
      "Epoch 539/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5525 - acc: 0.1624 - precision_3: 0.5760 - recall_3: 0.1694 - val_loss: 1.5348 - val_acc: 0.4324 - val_precision_3: 0.4673 - val_recall_3: 0.5027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5518 - acc: 0.1600 - precision_3: 0.5645 - recall_3: 0.1647 - val_loss: 1.5341 - val_acc: 0.4324 - val_precision_3: 0.4697 - val_recall_3: 0.5027\n",
      "Epoch 541/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5446 - acc: 0.1741 - precision_3: 0.5704 - recall_3: 0.1906 - val_loss: 1.5341 - val_acc: 0.4324 - val_precision_3: 0.4694 - val_recall_3: 0.4973\n",
      "Epoch 542/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5529 - acc: 0.1600 - precision_3: 0.5299 - recall_3: 0.1671 - val_loss: 1.5344 - val_acc: 0.4378 - val_precision_3: 0.4769 - val_recall_3: 0.5027\n",
      "Epoch 543/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5468 - acc: 0.1741 - precision_3: 0.5486 - recall_3: 0.1859 - val_loss: 1.5353 - val_acc: 0.4486 - val_precision_3: 0.4794 - val_recall_3: 0.5027\n",
      "Epoch 544/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5572 - acc: 0.1506 - precision_3: 0.5323 - recall_3: 0.1553 - val_loss: 1.5361 - val_acc: 0.4378 - val_precision_3: 0.4794 - val_recall_3: 0.5027\n",
      "Epoch 545/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5618 - acc: 0.1529 - precision_3: 0.5111 - recall_3: 0.1624 - val_loss: 1.5358 - val_acc: 0.4541 - val_precision_3: 0.4848 - val_recall_3: 0.5189\n",
      "Epoch 546/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5531 - acc: 0.1576 - precision_3: 0.5528 - recall_3: 0.1600 - val_loss: 1.5370 - val_acc: 0.4541 - val_precision_3: 0.4848 - val_recall_3: 0.5189\n",
      "Epoch 547/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5600 - acc: 0.1459 - precision_3: 0.5267 - recall_3: 0.1624 - val_loss: 1.5392 - val_acc: 0.4541 - val_precision_3: 0.4925 - val_recall_3: 0.5351\n",
      "Epoch 548/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5650 - acc: 0.1224 - precision_3: 0.4701 - recall_3: 0.1482 - val_loss: 1.5404 - val_acc: 0.4432 - val_precision_3: 0.4822 - val_recall_3: 0.5135\n",
      "Epoch 549/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5549 - acc: 0.1625 - precision_3: 0.5200 - recall_3: 0.16 - 0s 517us/sample - loss: 1.5582 - acc: 0.1435 - precision_3: 0.5385 - recall_3: 0.1482 - val_loss: 1.5414 - val_acc: 0.4324 - val_precision_3: 0.4872 - val_recall_3: 0.5135\n",
      "Epoch 550/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5683 - acc: 0.1294 - precision_3: 0.4797 - recall_3: 0.1388 - val_loss: 1.5417 - val_acc: 0.4324 - val_precision_3: 0.4847 - val_recall_3: 0.5135\n",
      "Epoch 551/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5457 - acc: 0.1765 - precision_3: 0.5493 - recall_3: 0.1835 - val_loss: 1.5418 - val_acc: 0.4270 - val_precision_3: 0.4721 - val_recall_3: 0.5027\n",
      "Epoch 552/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5498 - acc: 0.1647 - precision_3: 0.6218 - recall_3: 0.1741 - val_loss: 1.5407 - val_acc: 0.4216 - val_precision_3: 0.4691 - val_recall_3: 0.4919\n",
      "Epoch 553/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5664 - acc: 0.1375 - precision_3: 0.5000 - recall_3: 0.16 - 0s 516us/sample - loss: 1.5720 - acc: 0.1153 - precision_3: 0.4599 - recall_3: 0.1482 - val_loss: 1.5399 - val_acc: 0.4162 - val_precision_3: 0.4688 - val_recall_3: 0.4865\n",
      "Epoch 554/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5642 - acc: 0.1412 - precision_3: 0.5079 - recall_3: 0.1506 - val_loss: 1.5409 - val_acc: 0.4108 - val_precision_3: 0.4694 - val_recall_3: 0.4973\n",
      "Epoch 555/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5508 - acc: 0.1718 - precision_3: 0.5170 - recall_3: 0.1788 - val_loss: 1.5423 - val_acc: 0.4216 - val_precision_3: 0.4715 - val_recall_3: 0.4919\n",
      "Epoch 556/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5673 - acc: 0.1388 - precision_3: 0.4776 - recall_3: 0.1506 - val_loss: 1.5444 - val_acc: 0.4108 - val_precision_3: 0.4737 - val_recall_3: 0.4865\n",
      "Epoch 557/2000\n",
      "85/85 [==============================] - 0s 633us/sample - loss: 1.5477 - acc: 0.1624 - precision_3: 0.6034 - recall_3: 0.1647 - val_loss: 1.5470 - val_acc: 0.4216 - val_precision_3: 0.4817 - val_recall_3: 0.4973\n",
      "Epoch 558/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5488 - acc: 0.1694 - precision_3: 0.5522 - recall_3: 0.1741 - val_loss: 1.5483 - val_acc: 0.4000 - val_precision_3: 0.4734 - val_recall_3: 0.4811\n",
      "Epoch 559/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5557 - acc: 0.1600 - precision_3: 0.5862 - recall_3: 0.1600 - val_loss: 1.5497 - val_acc: 0.4000 - val_precision_3: 0.4817 - val_recall_3: 0.4973\n",
      "Epoch 560/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5567 - acc: 0.1459 - precision_3: 0.5455 - recall_3: 0.1553 - val_loss: 1.5492 - val_acc: 0.3838 - val_precision_3: 0.4706 - val_recall_3: 0.4757\n",
      "Epoch 561/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5656 - acc: 0.1435 - precision_3: 0.4851 - recall_3: 0.1529 - val_loss: 1.5487 - val_acc: 0.3838 - val_precision_3: 0.4706 - val_recall_3: 0.4757\n",
      "Epoch 562/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5529 - acc: 0.1529 - precision_3: 0.5308 - recall_3: 0.1624 - val_loss: 1.5484 - val_acc: 0.3892 - val_precision_3: 0.4709 - val_recall_3: 0.4811\n",
      "Epoch 563/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5626 - acc: 0.1459 - precision_3: 0.5000 - recall_3: 0.1529 - val_loss: 1.5479 - val_acc: 0.3838 - val_precision_3: 0.4628 - val_recall_3: 0.4703\n",
      "Epoch 564/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5519 - acc: 0.1624 - precision_3: 0.5738 - recall_3: 0.1647 - val_loss: 1.5473 - val_acc: 0.3892 - val_precision_3: 0.4656 - val_recall_3: 0.4757\n",
      "Epoch 565/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5503 - acc: 0.1647 - precision_3: 0.5748 - recall_3: 0.1718 - val_loss: 1.5468 - val_acc: 0.4054 - val_precision_3: 0.4656 - val_recall_3: 0.4757\n",
      "Epoch 566/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5559 - acc: 0.1529 - precision_3: 0.5583 - recall_3: 0.1576 - val_loss: 1.5450 - val_acc: 0.4000 - val_precision_3: 0.4652 - val_recall_3: 0.4703\n",
      "Epoch 567/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5469 - acc: 0.1647 - precision_3: 0.5540 - recall_3: 0.1812 - val_loss: 1.5431 - val_acc: 0.4108 - val_precision_3: 0.4712 - val_recall_3: 0.4865\n",
      "Epoch 568/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5494 - acc: 0.1600 - precision_3: 0.5600 - recall_3: 0.1647 - val_loss: 1.5409 - val_acc: 0.4108 - val_precision_3: 0.4670 - val_recall_3: 0.4973\n",
      "Epoch 569/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5405 - acc: 0.1765 - precision_3: 0.5970 - recall_3: 0.1882 - val_loss: 1.5384 - val_acc: 0.4000 - val_precision_3: 0.4573 - val_recall_3: 0.4919\n",
      "Epoch 570/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5496 - acc: 0.1624 - precision_3: 0.5278 - recall_3: 0.1788 - val_loss: 1.5348 - val_acc: 0.4324 - val_precision_3: 0.4573 - val_recall_3: 0.4919\n",
      "Epoch 571/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5543 - acc: 0.1600 - precision_3: 0.5625 - recall_3: 0.1694 - val_loss: 1.5329 - val_acc: 0.4162 - val_precision_3: 0.4523 - val_recall_3: 0.4865\n",
      "Epoch 572/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5610 - acc: 0.1294 - precision_3: 0.5263 - recall_3: 0.1412 - val_loss: 1.5338 - val_acc: 0.4216 - val_precision_3: 0.4523 - val_recall_3: 0.4865\n",
      "Epoch 573/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5598 - acc: 0.1459 - precision_3: 0.5508 - recall_3: 0.1529 - val_loss: 1.5351 - val_acc: 0.4270 - val_precision_3: 0.4569 - val_recall_3: 0.4865\n",
      "Epoch 574/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5525 - acc: 0.1624 - precision_3: 0.5591 - recall_3: 0.1671 - val_loss: 1.5354 - val_acc: 0.4270 - val_precision_3: 0.4596 - val_recall_3: 0.4919\n",
      "Epoch 575/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5476 - acc: 0.1694 - precision_3: 0.5794 - recall_3: 0.1718 - val_loss: 1.5353 - val_acc: 0.4216 - val_precision_3: 0.4643 - val_recall_3: 0.4919\n",
      "Epoch 576/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5341 - acc: 0.1859 - precision_3: 0.6343 - recall_3: 0.2000 - val_loss: 1.5367 - val_acc: 0.4378 - val_precision_3: 0.4677 - val_recall_3: 0.5081\n",
      "Epoch 577/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5609 - acc: 0.1318 - precision_3: 0.5041 - recall_3: 0.1435 - val_loss: 1.5363 - val_acc: 0.4378 - val_precision_3: 0.4680 - val_recall_3: 0.5135\n",
      "Epoch 578/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5546 - acc: 0.1435 - precision_3: 0.5508 - recall_3: 0.1529 - val_loss: 1.5368 - val_acc: 0.4378 - val_precision_3: 0.4650 - val_recall_3: 0.5027\n",
      "Epoch 579/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5580 - acc: 0.1459 - precision_3: 0.5508 - recall_3: 0.1529 - val_loss: 1.5364 - val_acc: 0.4432 - val_precision_3: 0.4604 - val_recall_3: 0.5027\n",
      "Epoch 580/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5489 - acc: 0.1647 - precision_3: 0.6032 - recall_3: 0.1788 - val_loss: 1.5358 - val_acc: 0.4324 - val_precision_3: 0.4604 - val_recall_3: 0.5027\n",
      "Epoch 581/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5480 - acc: 0.1600 - precision_3: 0.5984 - recall_3: 0.1788 - val_loss: 1.5359 - val_acc: 0.4162 - val_precision_3: 0.4646 - val_recall_3: 0.4973\n",
      "Epoch 582/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5544 - acc: 0.1529 - precision_3: 0.5426 - recall_3: 0.1647 - val_loss: 1.5332 - val_acc: 0.4054 - val_precision_3: 0.4569 - val_recall_3: 0.4865\n",
      "Epoch 583/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5446 - acc: 0.1741 - precision_3: 0.5417 - recall_3: 0.1835 - val_loss: 1.5291 - val_acc: 0.4162 - val_precision_3: 0.4673 - val_recall_3: 0.5027\n",
      "Epoch 584/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5604 - acc: 0.1365 - precision_3: 0.5122 - recall_3: 0.1482 - val_loss: 1.5270 - val_acc: 0.4108 - val_precision_3: 0.4680 - val_recall_3: 0.5135\n",
      "Epoch 585/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5534 - acc: 0.1624 - precision_3: 0.5564 - recall_3: 0.1741 - val_loss: 1.5253 - val_acc: 0.4324 - val_precision_3: 0.4680 - val_recall_3: 0.5135\n",
      "Epoch 586/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5711 - acc: 0.1294 - precision_3: 0.4615 - recall_3: 0.1412 - val_loss: 1.5228 - val_acc: 0.4324 - val_precision_3: 0.4505 - val_recall_3: 0.4919\n",
      "Epoch 587/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5404 - acc: 0.1835 - precision_3: 0.5985 - recall_3: 0.1929 - val_loss: 1.5235 - val_acc: 0.4270 - val_precision_3: 0.4573 - val_recall_3: 0.4919\n",
      "Epoch 588/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5485 - acc: 0.1624 - precision_3: 0.5703 - recall_3: 0.1718 - val_loss: 1.5213 - val_acc: 0.4486 - val_precision_3: 0.4703 - val_recall_3: 0.5135\n",
      "Epoch 589/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5383 - acc: 0.1859 - precision_3: 0.6364 - recall_3: 0.1976 - val_loss: 1.5185 - val_acc: 0.4541 - val_precision_3: 0.4734 - val_recall_3: 0.5297\n",
      "Epoch 590/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5542 - acc: 0.1529 - precision_3: 0.5217 - recall_3: 0.1694 - val_loss: 1.5162 - val_acc: 0.4432 - val_precision_3: 0.4670 - val_recall_3: 0.5351\n",
      "Epoch 591/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5581 - acc: 0.1435 - precision_3: 0.5455 - recall_3: 0.1553 - val_loss: 1.5129 - val_acc: 0.4486 - val_precision_3: 0.4541 - val_recall_3: 0.5351\n",
      "Epoch 592/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5592 - acc: 0.1529 - precision_3: 0.4929 - recall_3: 0.1624 - val_loss: 1.5124 - val_acc: 0.4432 - val_precision_3: 0.4521 - val_recall_3: 0.5351\n",
      "Epoch 593/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5424 - acc: 0.1788 - precision_3: 0.5926 - recall_3: 0.1882 - val_loss: 1.5116 - val_acc: 0.4432 - val_precision_3: 0.4550 - val_recall_3: 0.5459\n",
      "Epoch 594/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5390 - acc: 0.1859 - precision_3: 0.6220 - recall_3: 0.1859 - val_loss: 1.5116 - val_acc: 0.4432 - val_precision_3: 0.4566 - val_recall_3: 0.5405\n",
      "Epoch 595/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5535 - acc: 0.1529 - precision_3: 0.5750 - recall_3: 0.1624 - val_loss: 1.5136 - val_acc: 0.4486 - val_precision_3: 0.4633 - val_recall_3: 0.5459\n",
      "Epoch 596/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5370 - acc: 0.1835 - precision_3: 0.6723 - recall_3: 0.1882 - val_loss: 1.5157 - val_acc: 0.4541 - val_precision_3: 0.4633 - val_recall_3: 0.5459\n",
      "Epoch 597/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5643 - acc: 0.1482 - precision_3: 0.5120 - recall_3: 0.1506 - val_loss: 1.5175 - val_acc: 0.4432 - val_precision_3: 0.4651 - val_recall_3: 0.5405\n",
      "Epoch 598/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5553 - acc: 0.1506 - precision_3: 0.5630 - recall_3: 0.1576 - val_loss: 1.5183 - val_acc: 0.4486 - val_precision_3: 0.4695 - val_recall_3: 0.5405\n",
      "Epoch 599/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5254 - acc: 0.2094 - precision_3: 0.6104 - recall_3: 0.2212 - val_loss: 1.5242 - val_acc: 0.4324 - val_precision_3: 0.4667 - val_recall_3: 0.5297\n",
      "Epoch 600/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5450 - acc: 0.1788 - precision_3: 0.6016 - recall_3: 0.1812 - val_loss: 1.5289 - val_acc: 0.4486 - val_precision_3: 0.4737 - val_recall_3: 0.5351\n",
      "Epoch 601/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5500 - acc: 0.1553 - precision_3: 0.6126 - recall_3: 0.1600 - val_loss: 1.5311 - val_acc: 0.4486 - val_precision_3: 0.4709 - val_recall_3: 0.5243\n",
      "Epoch 602/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5421 - acc: 0.1741 - precision_3: 0.5929 - recall_3: 0.1953 - val_loss: 1.5333 - val_acc: 0.4432 - val_precision_3: 0.4703 - val_recall_3: 0.5135\n",
      "Epoch 603/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5613 - acc: 0.1459 - precision_3: 0.5000 - recall_3: 0.1529 - val_loss: 1.5348 - val_acc: 0.4541 - val_precision_3: 0.4850 - val_recall_3: 0.5243\n",
      "Epoch 604/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5465 - acc: 0.1600 - precision_3: 0.5984 - recall_3: 0.1718 - val_loss: 1.5366 - val_acc: 0.4378 - val_precision_3: 0.4824 - val_recall_3: 0.5189\n",
      "Epoch 605/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5469 - acc: 0.1718 - precision_3: 0.5682 - recall_3: 0.1765 - val_loss: 1.5373 - val_acc: 0.4270 - val_precision_3: 0.4721 - val_recall_3: 0.5027\n",
      "Epoch 606/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5397 - acc: 0.1718 - precision_3: 0.6124 - recall_3: 0.1859 - val_loss: 1.5381 - val_acc: 0.4162 - val_precision_3: 0.4767 - val_recall_3: 0.4973\n",
      "Epoch 607/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5480 - acc: 0.1553 - precision_3: 0.5983 - recall_3: 0.1647 - val_loss: 1.5386 - val_acc: 0.4162 - val_precision_3: 0.4688 - val_recall_3: 0.4865\n",
      "Epoch 608/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5599 - acc: 0.1412 - precision_3: 0.5339 - recall_3: 0.1482 - val_loss: 1.5385 - val_acc: 0.4270 - val_precision_3: 0.4868 - val_recall_3: 0.4973\n",
      "Epoch 609/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5588 - acc: 0.1412 - precision_3: 0.5299 - recall_3: 0.1459 - val_loss: 1.5373 - val_acc: 0.4486 - val_precision_3: 0.4921 - val_recall_3: 0.5027\n",
      "Epoch 610/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5551 - acc: 0.1506 - precision_3: 0.5354 - recall_3: 0.1600 - val_loss: 1.5351 - val_acc: 0.4378 - val_precision_3: 0.4845 - val_recall_3: 0.5081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5464 - acc: 0.1647 - precision_3: 0.5950 - recall_3: 0.1694 - val_loss: 1.5346 - val_acc: 0.4378 - val_precision_3: 0.4870 - val_recall_3: 0.5081\n",
      "Epoch 612/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5472 - acc: 0.1482 - precision_3: 0.6535 - recall_3: 0.1553 - val_loss: 1.5346 - val_acc: 0.4432 - val_precision_3: 0.4794 - val_recall_3: 0.5027\n",
      "Epoch 613/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.5635 - acc: 0.1294 - precision_3: 0.5577 - recall_3: 0.1365 - val_loss: 1.5347 - val_acc: 0.4432 - val_precision_3: 0.4821 - val_recall_3: 0.5081\n",
      "Epoch 614/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5454 - acc: 0.1671 - precision_3: 0.5649 - recall_3: 0.1741 - val_loss: 1.5326 - val_acc: 0.4486 - val_precision_3: 0.4819 - val_recall_3: 0.5027\n",
      "Epoch 615/2000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.5417 - acc: 0.1835 - precision_3: 0.6074 - recall_3: 0.1929 - val_loss: 1.5310 - val_acc: 0.4595 - val_precision_3: 0.4897 - val_recall_3: 0.5135\n",
      "Epoch 616/2000\n",
      "85/85 [==============================] - 0s 633us/sample - loss: 1.5759 - acc: 0.1059 - precision_3: 0.4717 - recall_3: 0.1176 - val_loss: 1.5306 - val_acc: 0.4595 - val_precision_3: 0.4873 - val_recall_3: 0.5189\n",
      "Epoch 617/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5572 - acc: 0.1435 - precision_3: 0.5417 - recall_3: 0.1529 - val_loss: 1.5298 - val_acc: 0.4541 - val_precision_3: 0.4949 - val_recall_3: 0.5297\n",
      "Epoch 618/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5456 - acc: 0.1647 - precision_3: 0.5868 - recall_3: 0.1671 - val_loss: 1.5313 - val_acc: 0.4649 - val_precision_3: 0.5051 - val_recall_3: 0.5351\n",
      "Epoch 619/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5288 - acc: 0.2000 - precision_3: 0.6567 - recall_3: 0.2071 - val_loss: 1.5325 - val_acc: 0.4595 - val_precision_3: 0.5000 - val_recall_3: 0.5297\n",
      "Epoch 620/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5403 - acc: 0.1765 - precision_3: 0.5797 - recall_3: 0.1882 - val_loss: 1.5335 - val_acc: 0.4649 - val_precision_3: 0.5052 - val_recall_3: 0.5297\n",
      "Epoch 621/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5437 - acc: 0.1741 - precision_3: 0.6111 - recall_3: 0.1812 - val_loss: 1.5332 - val_acc: 0.4595 - val_precision_3: 0.5026 - val_recall_3: 0.5243\n",
      "Epoch 622/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5477 - acc: 0.1647 - precision_3: 0.5966 - recall_3: 0.1671 - val_loss: 1.5332 - val_acc: 0.4541 - val_precision_3: 0.5000 - val_recall_3: 0.5189\n",
      "Epoch 623/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5540 - acc: 0.1435 - precision_3: 0.5591 - recall_3: 0.1671 - val_loss: 1.5330 - val_acc: 0.4649 - val_precision_3: 0.5105 - val_recall_3: 0.5243\n",
      "Epoch 624/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5577 - acc: 0.1576 - precision_3: 0.5074 - recall_3: 0.1624 - val_loss: 1.5323 - val_acc: 0.4703 - val_precision_3: 0.5185 - val_recall_3: 0.5297\n",
      "Epoch 625/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5506 - acc: 0.1576 - precision_3: 0.5645 - recall_3: 0.1647 - val_loss: 1.5312 - val_acc: 0.4541 - val_precision_3: 0.5134 - val_recall_3: 0.5189\n",
      "Epoch 626/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5650 - acc: 0.1388 - precision_3: 0.5085 - recall_3: 0.1412 - val_loss: 1.5323 - val_acc: 0.4649 - val_precision_3: 0.5105 - val_recall_3: 0.5243\n",
      "Epoch 627/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5528 - acc: 0.1459 - precision_3: 0.6055 - recall_3: 0.1553 - val_loss: 1.5326 - val_acc: 0.4595 - val_precision_3: 0.5105 - val_recall_3: 0.5243\n",
      "Epoch 628/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5568 - acc: 0.1341 - precision_3: 0.5825 - recall_3: 0.1412 - val_loss: 1.5310 - val_acc: 0.4541 - val_precision_3: 0.5000 - val_recall_3: 0.5081\n",
      "Epoch 629/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5459 - acc: 0.1647 - precision_3: 0.5794 - recall_3: 0.1718 - val_loss: 1.5299 - val_acc: 0.4541 - val_precision_3: 0.5026 - val_recall_3: 0.5243\n",
      "Epoch 630/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5513 - acc: 0.1576 - precision_3: 0.5785 - recall_3: 0.1647 - val_loss: 1.5285 - val_acc: 0.4486 - val_precision_3: 0.4922 - val_recall_3: 0.5135\n",
      "Epoch 631/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5476 - acc: 0.1624 - precision_3: 0.6016 - recall_3: 0.1741 - val_loss: 1.5280 - val_acc: 0.4541 - val_precision_3: 0.4974 - val_recall_3: 0.5189\n",
      "Epoch 632/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5530 - acc: 0.1553 - precision_3: 0.5748 - recall_3: 0.1718 - val_loss: 1.5283 - val_acc: 0.4541 - val_precision_3: 0.5026 - val_recall_3: 0.5189\n",
      "Epoch 633/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5445 - acc: 0.1671 - precision_3: 0.6577 - recall_3: 0.1718 - val_loss: 1.5292 - val_acc: 0.4541 - val_precision_3: 0.5026 - val_recall_3: 0.5189\n",
      "Epoch 634/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5327 - acc: 0.1906 - precision_3: 0.6222 - recall_3: 0.1976 - val_loss: 1.5294 - val_acc: 0.4595 - val_precision_3: 0.4974 - val_recall_3: 0.5189\n",
      "Epoch 635/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5352 - acc: 0.1906 - precision_3: 0.6535 - recall_3: 0.1953 - val_loss: 1.5302 - val_acc: 0.4649 - val_precision_3: 0.5026 - val_recall_3: 0.5189\n",
      "Epoch 636/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5499 - acc: 0.1671 - precision_3: 0.5649 - recall_3: 0.1741 - val_loss: 1.5310 - val_acc: 0.4486 - val_precision_3: 0.4974 - val_recall_3: 0.5081\n",
      "Epoch 637/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5398 - acc: 0.1882 - precision_3: 0.5705 - recall_3: 0.2000 - val_loss: 1.5318 - val_acc: 0.4541 - val_precision_3: 0.5000 - val_recall_3: 0.5135\n",
      "Epoch 638/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5434 - acc: 0.1741 - precision_3: 0.6250 - recall_3: 0.1765 - val_loss: 1.5307 - val_acc: 0.4649 - val_precision_3: 0.4974 - val_recall_3: 0.5189\n",
      "Epoch 639/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5437 - acc: 0.1765 - precision_3: 0.5985 - recall_3: 0.1859 - val_loss: 1.5263 - val_acc: 0.4595 - val_precision_3: 0.4847 - val_recall_3: 0.5135\n",
      "Epoch 640/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5423 - acc: 0.1765 - precision_3: 0.5969 - recall_3: 0.1812 - val_loss: 1.5228 - val_acc: 0.4541 - val_precision_3: 0.4900 - val_recall_3: 0.5297\n",
      "Epoch 641/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5468 - acc: 0.1694 - precision_3: 0.6218 - recall_3: 0.1741 - val_loss: 1.5213 - val_acc: 0.4486 - val_precision_3: 0.4850 - val_recall_3: 0.5243\n",
      "Epoch 642/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5542 - acc: 0.1459 - precision_3: 0.5630 - recall_3: 0.1576 - val_loss: 1.5194 - val_acc: 0.4432 - val_precision_3: 0.4828 - val_recall_3: 0.5297\n",
      "Epoch 643/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5552 - acc: 0.1412 - precision_3: 0.6154 - recall_3: 0.1506 - val_loss: 1.5182 - val_acc: 0.4432 - val_precision_3: 0.4876 - val_recall_3: 0.5297\n",
      "Epoch 644/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5681 - acc: 0.1200 - precision_3: 0.5048 - recall_3: 0.1247 - val_loss: 1.5189 - val_acc: 0.4541 - val_precision_3: 0.4950 - val_recall_3: 0.5351\n",
      "Epoch 645/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5611 - acc: 0.1294 - precision_3: 0.5545 - recall_3: 0.1435 - val_loss: 1.5185 - val_acc: 0.4541 - val_precision_3: 0.5000 - val_recall_3: 0.5459\n",
      "Epoch 646/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5576 - acc: 0.1459 - precision_3: 0.5194 - recall_3: 0.1576 - val_loss: 1.5168 - val_acc: 0.4541 - val_precision_3: 0.5000 - val_recall_3: 0.5459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 647/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5641 - acc: 0.1247 - precision_3: 0.5081 - recall_3: 0.1482 - val_loss: 1.5160 - val_acc: 0.4757 - val_precision_3: 0.5074 - val_recall_3: 0.5568\n",
      "Epoch 648/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5534 - acc: 0.1624 - precision_3: 0.5854 - recall_3: 0.1694 - val_loss: 1.5151 - val_acc: 0.4703 - val_precision_3: 0.5024 - val_recall_3: 0.5568\n",
      "Epoch 649/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5398 - acc: 0.1859 - precision_3: 0.5870 - recall_3: 0.1906 - val_loss: 1.5141 - val_acc: 0.4757 - val_precision_3: 0.4976 - val_recall_3: 0.5514\n",
      "Epoch 650/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5605 - acc: 0.1365 - precision_3: 0.5478 - recall_3: 0.1482 - val_loss: 1.5139 - val_acc: 0.4757 - val_precision_3: 0.4928 - val_recall_3: 0.5514\n",
      "Epoch 651/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5572 - acc: 0.1506 - precision_3: 0.5537 - recall_3: 0.1576 - val_loss: 1.5160 - val_acc: 0.4649 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 652/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5425 - acc: 0.1741 - precision_3: 0.6311 - recall_3: 0.1812 - val_loss: 1.5169 - val_acc: 0.4541 - val_precision_3: 0.4950 - val_recall_3: 0.5405\n",
      "Epoch 653/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5573 - acc: 0.1341 - precision_3: 0.5741 - recall_3: 0.1459 - val_loss: 1.5181 - val_acc: 0.4595 - val_precision_3: 0.4951 - val_recall_3: 0.5459\n",
      "Epoch 654/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5676 - acc: 0.1200 - precision_3: 0.5347 - recall_3: 0.1271 - val_loss: 1.5172 - val_acc: 0.4595 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 655/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5591 - acc: 0.1435 - precision_3: 0.5345 - recall_3: 0.1459 - val_loss: 1.5187 - val_acc: 0.4541 - val_precision_3: 0.4831 - val_recall_3: 0.5405\n",
      "Epoch 656/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5475 - acc: 0.1765 - precision_3: 0.6160 - recall_3: 0.1812 - val_loss: 1.5191 - val_acc: 0.4541 - val_precision_3: 0.4902 - val_recall_3: 0.5405\n",
      "Epoch 657/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5473 - acc: 0.1576 - precision_3: 0.5760 - recall_3: 0.1694 - val_loss: 1.5185 - val_acc: 0.4486 - val_precision_3: 0.4975 - val_recall_3: 0.5405\n",
      "Epoch 658/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5498 - acc: 0.1576 - precision_3: 0.6018 - recall_3: 0.1600 - val_loss: 1.5183 - val_acc: 0.4486 - val_precision_3: 0.5051 - val_recall_3: 0.5405\n",
      "Epoch 659/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5480 - acc: 0.1553 - precision_3: 0.6126 - recall_3: 0.1600 - val_loss: 1.5197 - val_acc: 0.4541 - val_precision_3: 0.5075 - val_recall_3: 0.5459\n",
      "Epoch 660/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5556 - acc: 0.1482 - precision_3: 0.5447 - recall_3: 0.1576 - val_loss: 1.5201 - val_acc: 0.4595 - val_precision_3: 0.5050 - val_recall_3: 0.5459\n",
      "Epoch 661/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5550 - acc: 0.1506 - precision_3: 0.5500 - recall_3: 0.1553 - val_loss: 1.5224 - val_acc: 0.4541 - val_precision_3: 0.5076 - val_recall_3: 0.5405\n",
      "Epoch 662/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5379 - acc: 0.1765 - precision_3: 0.6417 - recall_3: 0.1812 - val_loss: 1.5245 - val_acc: 0.4541 - val_precision_3: 0.5102 - val_recall_3: 0.5405\n",
      "Epoch 663/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5636 - acc: 0.1365 - precision_3: 0.5351 - recall_3: 0.1435 - val_loss: 1.5278 - val_acc: 0.4486 - val_precision_3: 0.5053 - val_recall_3: 0.5135\n",
      "Epoch 664/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5541 - acc: 0.1435 - precision_3: 0.6117 - recall_3: 0.1482 - val_loss: 1.5288 - val_acc: 0.4378 - val_precision_3: 0.5000 - val_recall_3: 0.5027\n",
      "Epoch 665/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5496 - acc: 0.1576 - precision_3: 0.6106 - recall_3: 0.1624 - val_loss: 1.5285 - val_acc: 0.4486 - val_precision_3: 0.5109 - val_recall_3: 0.5081\n",
      "Epoch 666/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5465 - acc: 0.1576 - precision_3: 0.5714 - recall_3: 0.1694 - val_loss: 1.5289 - val_acc: 0.4649 - val_precision_3: 0.5189 - val_recall_3: 0.5189\n",
      "Epoch 667/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5453 - acc: 0.1600 - precision_3: 0.5966 - recall_3: 0.1671 - val_loss: 1.5299 - val_acc: 0.4649 - val_precision_3: 0.5243 - val_recall_3: 0.5243\n",
      "Epoch 668/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5485 - acc: 0.1600 - precision_3: 0.5726 - recall_3: 0.1671 - val_loss: 1.5328 - val_acc: 0.4541 - val_precision_3: 0.5243 - val_recall_3: 0.5243\n",
      "Epoch 669/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5363 - acc: 0.1882 - precision_3: 0.6045 - recall_3: 0.1906 - val_loss: 1.5317 - val_acc: 0.4595 - val_precision_3: 0.5269 - val_recall_3: 0.5297\n",
      "Epoch 670/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5422 - acc: 0.1741 - precision_3: 0.6333 - recall_3: 0.1788 - val_loss: 1.5301 - val_acc: 0.4649 - val_precision_3: 0.5238 - val_recall_3: 0.5351\n",
      "Epoch 671/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5361 - acc: 0.1835 - precision_3: 0.6585 - recall_3: 0.1906 - val_loss: 1.5278 - val_acc: 0.4649 - val_precision_3: 0.5238 - val_recall_3: 0.5351\n",
      "Epoch 672/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5462 - acc: 0.1529 - precision_3: 0.6121 - recall_3: 0.1671 - val_loss: 1.5254 - val_acc: 0.4811 - val_precision_3: 0.5260 - val_recall_3: 0.5459\n",
      "Epoch 673/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5368 - acc: 0.1812 - precision_3: 0.6560 - recall_3: 0.1929 - val_loss: 1.5258 - val_acc: 0.4649 - val_precision_3: 0.5263 - val_recall_3: 0.5405\n",
      "Epoch 674/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5492 - acc: 0.1529 - precision_3: 0.5868 - recall_3: 0.1671 - val_loss: 1.5325 - val_acc: 0.4378 - val_precision_3: 0.5211 - val_recall_3: 0.5351\n",
      "Epoch 675/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5453 - acc: 0.1718 - precision_3: 0.6198 - recall_3: 0.1765 - val_loss: 1.5361 - val_acc: 0.4216 - val_precision_3: 0.5078 - val_recall_3: 0.5297\n",
      "Epoch 676/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5371 - acc: 0.1788 - precision_3: 0.6250 - recall_3: 0.1882 - val_loss: 1.5384 - val_acc: 0.4054 - val_precision_3: 0.4896 - val_recall_3: 0.5081\n",
      "Epoch 677/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5499 - acc: 0.1375 - precision_3: 0.6667 - recall_3: 0.15 - 0s 575us/sample - loss: 1.5375 - acc: 0.1788 - precision_3: 0.6290 - recall_3: 0.1835 - val_loss: 1.5388 - val_acc: 0.4000 - val_precision_3: 0.4869 - val_recall_3: 0.5027\n",
      "Epoch 678/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5471 - acc: 0.1624 - precision_3: 0.5669 - recall_3: 0.1694 - val_loss: 1.5384 - val_acc: 0.4054 - val_precision_3: 0.4921 - val_recall_3: 0.5081\n",
      "Epoch 679/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5499 - acc: 0.1671 - precision_3: 0.5736 - recall_3: 0.1741 - val_loss: 1.5368 - val_acc: 0.4270 - val_precision_3: 0.4974 - val_recall_3: 0.5243\n",
      "Epoch 680/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5437 - acc: 0.1694 - precision_3: 0.6167 - recall_3: 0.1741 - val_loss: 1.5358 - val_acc: 0.4216 - val_precision_3: 0.5026 - val_recall_3: 0.5189\n",
      "Epoch 681/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5379 - acc: 0.1812 - precision_3: 0.6838 - recall_3: 0.1882 - val_loss: 1.5341 - val_acc: 0.4270 - val_precision_3: 0.5052 - val_recall_3: 0.5243\n",
      "Epoch 682/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5458 - acc: 0.1812 - precision_3: 0.5896 - recall_3: 0.1859 - val_loss: 1.5341 - val_acc: 0.4216 - val_precision_3: 0.5000 - val_recall_3: 0.5243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5567 - acc: 0.1459 - precision_3: 0.5789 - recall_3: 0.1553 - val_loss: 1.5342 - val_acc: 0.4324 - val_precision_3: 0.5026 - val_recall_3: 0.5297\n",
      "Epoch 684/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5240 - acc: 0.2165 - precision_3: 0.7045 - recall_3: 0.2188 - val_loss: 1.5338 - val_acc: 0.4324 - val_precision_3: 0.5104 - val_recall_3: 0.5297\n",
      "Epoch 685/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5483 - acc: 0.1671 - precision_3: 0.5564 - recall_3: 0.1741 - val_loss: 1.5347 - val_acc: 0.4378 - val_precision_3: 0.5130 - val_recall_3: 0.5351\n",
      "Epoch 686/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5548 - acc: 0.1435 - precision_3: 0.5752 - recall_3: 0.1529 - val_loss: 1.5334 - val_acc: 0.4432 - val_precision_3: 0.5294 - val_recall_3: 0.5351\n",
      "Epoch 687/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5324 - acc: 0.1906 - precision_3: 0.7034 - recall_3: 0.1953 - val_loss: 1.5320 - val_acc: 0.4324 - val_precision_3: 0.5246 - val_recall_3: 0.5189\n",
      "Epoch 688/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5378 - acc: 0.1859 - precision_3: 0.6148 - recall_3: 0.1953 - val_loss: 1.5332 - val_acc: 0.4324 - val_precision_3: 0.5246 - val_recall_3: 0.5189\n",
      "Epoch 689/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5393 - acc: 0.1859 - precision_3: 0.5887 - recall_3: 0.1953 - val_loss: 1.5343 - val_acc: 0.4324 - val_precision_3: 0.5249 - val_recall_3: 0.5135\n",
      "Epoch 690/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5455 - acc: 0.1671 - precision_3: 0.6404 - recall_3: 0.1718 - val_loss: 1.5351 - val_acc: 0.4324 - val_precision_3: 0.5251 - val_recall_3: 0.5081\n",
      "Epoch 691/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5231 - acc: 0.2000 - precision_3: 0.6899 - recall_3: 0.2094 - val_loss: 1.5347 - val_acc: 0.4378 - val_precision_3: 0.5220 - val_recall_3: 0.5135\n",
      "Epoch 692/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5594 - acc: 0.1318 - precision_3: 0.6170 - recall_3: 0.1365 - val_loss: 1.5330 - val_acc: 0.4432 - val_precision_3: 0.5081 - val_recall_3: 0.5081\n",
      "Epoch 693/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5505 - acc: 0.1529 - precision_3: 0.5798 - recall_3: 0.1624 - val_loss: 1.5315 - val_acc: 0.4270 - val_precision_3: 0.5000 - val_recall_3: 0.5027\n",
      "Epoch 694/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5557 - acc: 0.1435 - precision_3: 0.5980 - recall_3: 0.1435 - val_loss: 1.5304 - val_acc: 0.4270 - val_precision_3: 0.5000 - val_recall_3: 0.5081\n",
      "Epoch 695/2000\n",
      "85/85 [==============================] - 0s 562us/sample - loss: 1.5450 - acc: 0.1647 - precision_3: 0.5736 - recall_3: 0.1741 - val_loss: 1.5338 - val_acc: 0.4270 - val_precision_3: 0.5054 - val_recall_3: 0.5081\n",
      "Epoch 696/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5554 - acc: 0.1482 - precision_3: 0.6038 - recall_3: 0.1506 - val_loss: 1.5352 - val_acc: 0.4216 - val_precision_3: 0.5081 - val_recall_3: 0.5081\n",
      "Epoch 697/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5529 - acc: 0.1529 - precision_3: 0.6000 - recall_3: 0.1553 - val_loss: 1.5348 - val_acc: 0.4270 - val_precision_3: 0.5000 - val_recall_3: 0.5081\n",
      "Epoch 698/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5380 - acc: 0.1788 - precision_3: 0.6417 - recall_3: 0.1812 - val_loss: 1.5334 - val_acc: 0.4324 - val_precision_3: 0.5000 - val_recall_3: 0.5027\n",
      "Epoch 699/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5485 - acc: 0.1600 - precision_3: 0.6250 - recall_3: 0.1647 - val_loss: 1.5305 - val_acc: 0.4378 - val_precision_3: 0.5053 - val_recall_3: 0.5135\n",
      "Epoch 700/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5390 - acc: 0.1765 - precision_3: 0.6667 - recall_3: 0.1835 - val_loss: 1.5261 - val_acc: 0.4378 - val_precision_3: 0.5053 - val_recall_3: 0.5189\n",
      "Epoch 701/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5476 - acc: 0.1600 - precision_3: 0.6216 - recall_3: 0.1624 - val_loss: 1.5239 - val_acc: 0.4486 - val_precision_3: 0.5103 - val_recall_3: 0.5351\n",
      "Epoch 702/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5480 - acc: 0.1506 - precision_3: 0.5913 - recall_3: 0.1600 - val_loss: 1.5268 - val_acc: 0.4541 - val_precision_3: 0.5131 - val_recall_3: 0.5297\n",
      "Epoch 703/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5492 - acc: 0.1600 - precision_3: 0.5950 - recall_3: 0.1694 - val_loss: 1.5283 - val_acc: 0.4432 - val_precision_3: 0.5026 - val_recall_3: 0.5243\n",
      "Epoch 704/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5497 - acc: 0.1576 - precision_3: 0.5738 - recall_3: 0.1647 - val_loss: 1.5291 - val_acc: 0.4486 - val_precision_3: 0.5026 - val_recall_3: 0.5189\n",
      "Epoch 705/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5523 - acc: 0.1624 - precision_3: 0.5932 - recall_3: 0.1647 - val_loss: 1.5290 - val_acc: 0.4486 - val_precision_3: 0.5053 - val_recall_3: 0.5189\n",
      "Epoch 706/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5524 - acc: 0.1506 - precision_3: 0.5948 - recall_3: 0.1624 - val_loss: 1.5275 - val_acc: 0.4541 - val_precision_3: 0.5105 - val_recall_3: 0.5243\n",
      "Epoch 707/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5547 - acc: 0.1529 - precision_3: 0.5354 - recall_3: 0.1600 - val_loss: 1.5271 - val_acc: 0.4541 - val_precision_3: 0.5079 - val_recall_3: 0.5243\n",
      "Epoch 708/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5494 - acc: 0.1624 - precision_3: 0.6106 - recall_3: 0.1624 - val_loss: 1.5259 - val_acc: 0.4541 - val_precision_3: 0.5077 - val_recall_3: 0.5351\n",
      "Epoch 709/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5341 - acc: 0.1976 - precision_3: 0.6343 - recall_3: 0.2000 - val_loss: 1.5241 - val_acc: 0.4541 - val_precision_3: 0.5051 - val_recall_3: 0.5405\n",
      "Epoch 710/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5560 - acc: 0.1506 - precision_3: 0.5862 - recall_3: 0.1600 - val_loss: 1.5220 - val_acc: 0.4649 - val_precision_3: 0.5050 - val_recall_3: 0.5514\n",
      "Epoch 711/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5475 - acc: 0.1718 - precision_3: 0.5873 - recall_3: 0.1741 - val_loss: 1.5261 - val_acc: 0.4541 - val_precision_3: 0.5183 - val_recall_3: 0.5351\n",
      "Epoch 712/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5309 - acc: 0.2071 - precision_3: 0.6338 - recall_3: 0.2118 - val_loss: 1.5276 - val_acc: 0.4486 - val_precision_3: 0.5158 - val_recall_3: 0.5297\n",
      "Epoch 713/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5337 - acc: 0.1788 - precision_3: 0.6429 - recall_3: 0.1906 - val_loss: 1.5270 - val_acc: 0.4486 - val_precision_3: 0.5105 - val_recall_3: 0.5243\n",
      "Epoch 714/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5485 - acc: 0.1576 - precision_3: 0.5680 - recall_3: 0.1671 - val_loss: 1.5255 - val_acc: 0.4541 - val_precision_3: 0.5051 - val_recall_3: 0.5351\n",
      "Epoch 715/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5214 - acc: 0.2212 - precision_3: 0.6713 - recall_3: 0.2259 - val_loss: 1.5250 - val_acc: 0.4595 - val_precision_3: 0.5153 - val_recall_3: 0.5459\n",
      "Epoch 716/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5397 - acc: 0.1718 - precision_3: 0.6260 - recall_3: 0.1812 - val_loss: 1.5250 - val_acc: 0.4595 - val_precision_3: 0.5153 - val_recall_3: 0.5459\n",
      "Epoch 717/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5297 - acc: 0.2000 - precision_3: 0.6154 - recall_3: 0.2071 - val_loss: 1.5246 - val_acc: 0.4595 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 718/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5355 - acc: 0.1953 - precision_3: 0.6222 - recall_3: 0.1976 - val_loss: 1.5240 - val_acc: 0.4541 - val_precision_3: 0.5179 - val_recall_3: 0.5459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 719/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5539 - acc: 0.1435 - precision_3: 0.5366 - recall_3: 0.1553 - val_loss: 1.5249 - val_acc: 0.4541 - val_precision_3: 0.5233 - val_recall_3: 0.5459\n",
      "Epoch 720/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5467 - acc: 0.1624 - precision_3: 0.6134 - recall_3: 0.1718 - val_loss: 1.5246 - val_acc: 0.4595 - val_precision_3: 0.5155 - val_recall_3: 0.5405\n",
      "Epoch 721/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5443 - acc: 0.1671 - precision_3: 0.6239 - recall_3: 0.1718 - val_loss: 1.5242 - val_acc: 0.4595 - val_precision_3: 0.5102 - val_recall_3: 0.5405\n",
      "Epoch 722/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5495 - acc: 0.1624 - precision_3: 0.6216 - recall_3: 0.1624 - val_loss: 1.5232 - val_acc: 0.4595 - val_precision_3: 0.5127 - val_recall_3: 0.5459\n",
      "Epoch 723/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5434 - acc: 0.1718 - precision_3: 0.5814 - recall_3: 0.1765 - val_loss: 1.5242 - val_acc: 0.4432 - val_precision_3: 0.5103 - val_recall_3: 0.5351\n",
      "Epoch 724/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5573 - acc: 0.1576 - precision_3: 0.5433 - recall_3: 0.1624 - val_loss: 1.5245 - val_acc: 0.4486 - val_precision_3: 0.5103 - val_recall_3: 0.5351\n",
      "Epoch 725/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5450 - acc: 0.1553 - precision_3: 0.6195 - recall_3: 0.1647 - val_loss: 1.5238 - val_acc: 0.4486 - val_precision_3: 0.5078 - val_recall_3: 0.5297\n",
      "Epoch 726/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5478 - acc: 0.1553 - precision_3: 0.6195 - recall_3: 0.1647 - val_loss: 1.5234 - val_acc: 0.4486 - val_precision_3: 0.5103 - val_recall_3: 0.5351\n",
      "Epoch 727/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5404 - acc: 0.1671 - precision_3: 0.6293 - recall_3: 0.1718 - val_loss: 1.5227 - val_acc: 0.4432 - val_precision_3: 0.5103 - val_recall_3: 0.5351\n",
      "Epoch 728/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5371 - acc: 0.1765 - precision_3: 0.6525 - recall_3: 0.1812 - val_loss: 1.5237 - val_acc: 0.4541 - val_precision_3: 0.5103 - val_recall_3: 0.5351\n",
      "Epoch 729/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5547 - acc: 0.1435 - precision_3: 0.5678 - recall_3: 0.1576 - val_loss: 1.5238 - val_acc: 0.4486 - val_precision_3: 0.5052 - val_recall_3: 0.5297\n",
      "Epoch 730/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5502 - acc: 0.1506 - precision_3: 0.6091 - recall_3: 0.1576 - val_loss: 1.5210 - val_acc: 0.4595 - val_precision_3: 0.5153 - val_recall_3: 0.5459\n",
      "Epoch 731/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5301 - acc: 0.1953 - precision_3: 0.6397 - recall_3: 0.2047 - val_loss: 1.5183 - val_acc: 0.4703 - val_precision_3: 0.5255 - val_recall_3: 0.5568\n",
      "Epoch 732/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5517 - acc: 0.1459 - precision_3: 0.6263 - recall_3: 0.1459 - val_loss: 1.5151 - val_acc: 0.4919 - val_precision_3: 0.5178 - val_recall_3: 0.5514\n",
      "Epoch 733/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5510 - acc: 0.1553 - precision_3: 0.5877 - recall_3: 0.1576 - val_loss: 1.5152 - val_acc: 0.4919 - val_precision_3: 0.5231 - val_recall_3: 0.5514\n",
      "Epoch 734/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5687 - acc: 0.1224 - precision_3: 0.5189 - recall_3: 0.1294 - val_loss: 1.5119 - val_acc: 0.4757 - val_precision_3: 0.5076 - val_recall_3: 0.5405\n",
      "Epoch 735/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5385 - acc: 0.1875 - precision_3: 0.5926 - recall_3: 0.20 - 0s 539us/sample - loss: 1.5409 - acc: 0.1835 - precision_3: 0.5926 - recall_3: 0.1882 - val_loss: 1.5094 - val_acc: 0.4703 - val_precision_3: 0.5075 - val_recall_3: 0.5459\n",
      "Epoch 736/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5485 - acc: 0.1576 - precision_3: 0.6140 - recall_3: 0.1647 - val_loss: 1.5074 - val_acc: 0.4649 - val_precision_3: 0.4925 - val_recall_3: 0.5297\n",
      "Epoch 737/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5380 - acc: 0.1859 - precision_3: 0.6165 - recall_3: 0.1929 - val_loss: 1.5070 - val_acc: 0.4649 - val_precision_3: 0.4949 - val_recall_3: 0.5297\n",
      "Epoch 738/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5384 - acc: 0.1812 - precision_3: 0.6172 - recall_3: 0.1859 - val_loss: 1.5083 - val_acc: 0.4649 - val_precision_3: 0.4950 - val_recall_3: 0.5405\n",
      "Epoch 739/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5484 - acc: 0.1482 - precision_3: 0.6275 - recall_3: 0.1506 - val_loss: 1.5091 - val_acc: 0.4595 - val_precision_3: 0.4951 - val_recall_3: 0.5459\n",
      "Epoch 740/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5369 - acc: 0.1812 - precision_3: 0.5970 - recall_3: 0.1882 - val_loss: 1.5114 - val_acc: 0.4595 - val_precision_3: 0.5051 - val_recall_3: 0.5405\n",
      "Epoch 741/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5437 - acc: 0.1741 - precision_3: 0.6098 - recall_3: 0.1765 - val_loss: 1.5141 - val_acc: 0.4595 - val_precision_3: 0.5050 - val_recall_3: 0.5459\n",
      "Epoch 742/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5459 - acc: 0.1576 - precision_3: 0.6228 - recall_3: 0.1671 - val_loss: 1.5145 - val_acc: 0.4703 - val_precision_3: 0.5100 - val_recall_3: 0.5514\n",
      "Epoch 743/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5594 - acc: 0.1412 - precision_3: 0.5391 - recall_3: 0.1459 - val_loss: 1.5158 - val_acc: 0.4919 - val_precision_3: 0.5100 - val_recall_3: 0.5514\n",
      "Epoch 744/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5407 - acc: 0.1718 - precision_3: 0.6441 - recall_3: 0.1788 - val_loss: 1.5163 - val_acc: 0.4919 - val_precision_3: 0.5100 - val_recall_3: 0.5514\n",
      "Epoch 745/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5370 - acc: 0.1882 - precision_3: 0.6000 - recall_3: 0.1906 - val_loss: 1.5163 - val_acc: 0.4865 - val_precision_3: 0.5101 - val_recall_3: 0.5459\n",
      "Epoch 746/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5457 - acc: 0.1529 - precision_3: 0.6106 - recall_3: 0.1624 - val_loss: 1.5158 - val_acc: 0.4865 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 747/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5340 - acc: 0.1929 - precision_3: 0.6028 - recall_3: 0.2000 - val_loss: 1.5190 - val_acc: 0.4919 - val_precision_3: 0.5231 - val_recall_3: 0.5514\n",
      "Epoch 748/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5360 - acc: 0.1788 - precision_3: 0.6814 - recall_3: 0.1812 - val_loss: 1.5213 - val_acc: 0.4703 - val_precision_3: 0.5208 - val_recall_3: 0.5405\n",
      "Epoch 749/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5391 - acc: 0.1859 - precision_3: 0.6585 - recall_3: 0.1906 - val_loss: 1.5213 - val_acc: 0.4703 - val_precision_3: 0.5208 - val_recall_3: 0.5405\n",
      "Epoch 750/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5520 - acc: 0.1506 - precision_3: 0.6168 - recall_3: 0.1553 - val_loss: 1.5178 - val_acc: 0.4919 - val_precision_3: 0.5365 - val_recall_3: 0.5568\n",
      "Epoch 751/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5363 - acc: 0.1859 - precision_3: 0.7080 - recall_3: 0.1882 - val_loss: 1.5172 - val_acc: 0.4865 - val_precision_3: 0.5365 - val_recall_3: 0.5568\n",
      "Epoch 752/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5406 - acc: 0.1835 - precision_3: 0.6077 - recall_3: 0.1859 - val_loss: 1.5203 - val_acc: 0.4757 - val_precision_3: 0.5316 - val_recall_3: 0.5459\n",
      "Epoch 753/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5476 - acc: 0.1624 - precision_3: 0.6364 - recall_3: 0.1647 - val_loss: 1.5217 - val_acc: 0.4649 - val_precision_3: 0.5294 - val_recall_3: 0.5351\n",
      "Epoch 754/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5503 - acc: 0.1482 - precision_3: 0.6373 - recall_3: 0.1529 - val_loss: 1.5227 - val_acc: 0.4649 - val_precision_3: 0.5211 - val_recall_3: 0.5351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 755/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5496 - acc: 0.1576 - precision_3: 0.6034 - recall_3: 0.1647 - val_loss: 1.5229 - val_acc: 0.4595 - val_precision_3: 0.5158 - val_recall_3: 0.5297\n",
      "Epoch 756/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5303 - acc: 0.1835 - precision_3: 0.6838 - recall_3: 0.1882 - val_loss: 1.5237 - val_acc: 0.4595 - val_precision_3: 0.5185 - val_recall_3: 0.5297\n",
      "Epoch 757/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5402 - acc: 0.1788 - precision_3: 0.6031 - recall_3: 0.1859 - val_loss: 1.5232 - val_acc: 0.4595 - val_precision_3: 0.5158 - val_recall_3: 0.5297\n",
      "Epoch 758/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5526 - acc: 0.1529 - precision_3: 0.5965 - recall_3: 0.1600 - val_loss: 1.5216 - val_acc: 0.4595 - val_precision_3: 0.5130 - val_recall_3: 0.5351\n",
      "Epoch 759/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5364 - acc: 0.1859 - precision_3: 0.6250 - recall_3: 0.1882 - val_loss: 1.5211 - val_acc: 0.4649 - val_precision_3: 0.5158 - val_recall_3: 0.5297\n",
      "Epoch 760/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5391 - acc: 0.1788 - precision_3: 0.6210 - recall_3: 0.1812 - val_loss: 1.5211 - val_acc: 0.4595 - val_precision_3: 0.5160 - val_recall_3: 0.5243\n",
      "Epoch 761/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5579 - acc: 0.1341 - precision_3: 0.5900 - recall_3: 0.1388 - val_loss: 1.5206 - val_acc: 0.4649 - val_precision_3: 0.5158 - val_recall_3: 0.5297\n",
      "Epoch 762/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5361 - acc: 0.1788 - precision_3: 0.6107 - recall_3: 0.1882 - val_loss: 1.5199 - val_acc: 0.4757 - val_precision_3: 0.5211 - val_recall_3: 0.5351\n",
      "Epoch 763/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5412 - acc: 0.1765 - precision_3: 0.6500 - recall_3: 0.1835 - val_loss: 1.5202 - val_acc: 0.4595 - val_precision_3: 0.5183 - val_recall_3: 0.5351\n",
      "Epoch 764/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5470 - acc: 0.1600 - precision_3: 0.6087 - recall_3: 0.1647 - val_loss: 1.5174 - val_acc: 0.4649 - val_precision_3: 0.5156 - val_recall_3: 0.5351\n",
      "Epoch 765/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5229 - acc: 0.2071 - precision_3: 0.6619 - recall_3: 0.2165 - val_loss: 1.5159 - val_acc: 0.4703 - val_precision_3: 0.5155 - val_recall_3: 0.5405\n",
      "Epoch 766/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5536 - acc: 0.1412 - precision_3: 0.5575 - recall_3: 0.1482 - val_loss: 1.5147 - val_acc: 0.4865 - val_precision_3: 0.5204 - val_recall_3: 0.5514\n",
      "Epoch 767/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5466 - acc: 0.1576 - precision_3: 0.6121 - recall_3: 0.1671 - val_loss: 1.5161 - val_acc: 0.4757 - val_precision_3: 0.5178 - val_recall_3: 0.5514\n",
      "Epoch 768/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5432 - acc: 0.1694 - precision_3: 0.6466 - recall_3: 0.1765 - val_loss: 1.5154 - val_acc: 0.4919 - val_precision_3: 0.5231 - val_recall_3: 0.5514\n",
      "Epoch 769/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5249 - acc: 0.1929 - precision_3: 0.7097 - recall_3: 0.2071 - val_loss: 1.5151 - val_acc: 0.4919 - val_precision_3: 0.5231 - val_recall_3: 0.5514\n",
      "Epoch 770/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5312 - acc: 0.1859 - precision_3: 0.6043 - recall_3: 0.1976 - val_loss: 1.5136 - val_acc: 0.4919 - val_precision_3: 0.5255 - val_recall_3: 0.5568\n",
      "Epoch 771/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5377 - acc: 0.1788 - precision_3: 0.5852 - recall_3: 0.1859 - val_loss: 1.5139 - val_acc: 0.4919 - val_precision_3: 0.5282 - val_recall_3: 0.5568\n",
      "Epoch 772/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5497 - acc: 0.1459 - precision_3: 0.6364 - recall_3: 0.1482 - val_loss: 1.5132 - val_acc: 0.4919 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 773/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5205 - acc: 0.2212 - precision_3: 0.6809 - recall_3: 0.2259 - val_loss: 1.5139 - val_acc: 0.4919 - val_precision_3: 0.5279 - val_recall_3: 0.5622\n",
      "Epoch 774/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5485 - acc: 0.1624 - precision_3: 0.5785 - recall_3: 0.1647 - val_loss: 1.5130 - val_acc: 0.4919 - val_precision_3: 0.5306 - val_recall_3: 0.5622\n",
      "Epoch 775/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5376 - acc: 0.1788 - precision_3: 0.6111 - recall_3: 0.1812 - val_loss: 1.5118 - val_acc: 0.4865 - val_precision_3: 0.5255 - val_recall_3: 0.5568\n",
      "Epoch 776/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5387 - acc: 0.1812 - precision_3: 0.6371 - recall_3: 0.1859 - val_loss: 1.5111 - val_acc: 0.4865 - val_precision_3: 0.5306 - val_recall_3: 0.5622\n",
      "Epoch 777/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5362 - acc: 0.1718 - precision_3: 0.6881 - recall_3: 0.1765 - val_loss: 1.5111 - val_acc: 0.4865 - val_precision_3: 0.5389 - val_recall_3: 0.5622\n",
      "Epoch 778/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5308 - acc: 0.1906 - precision_3: 0.6439 - recall_3: 0.2000 - val_loss: 1.5098 - val_acc: 0.4865 - val_precision_3: 0.5389 - val_recall_3: 0.5622\n",
      "Epoch 779/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5380 - acc: 0.1718 - precision_3: 0.6944 - recall_3: 0.1765 - val_loss: 1.5108 - val_acc: 0.4919 - val_precision_3: 0.5333 - val_recall_3: 0.5622\n",
      "Epoch 780/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5372 - acc: 0.1765 - precision_3: 0.6154 - recall_3: 0.1882 - val_loss: 1.5093 - val_acc: 0.4919 - val_precision_3: 0.5306 - val_recall_3: 0.5622\n",
      "Epoch 781/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5418 - acc: 0.1694 - precision_3: 0.5968 - recall_3: 0.1741 - val_loss: 1.5086 - val_acc: 0.4919 - val_precision_3: 0.5306 - val_recall_3: 0.5622\n",
      "Epoch 782/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5376 - acc: 0.1835 - precision_3: 0.6212 - recall_3: 0.1929 - val_loss: 1.5067 - val_acc: 0.4865 - val_precision_3: 0.5258 - val_recall_3: 0.5514\n",
      "Epoch 783/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5458 - acc: 0.1600 - precision_3: 0.5820 - recall_3: 0.1671 - val_loss: 1.5060 - val_acc: 0.4865 - val_precision_3: 0.5258 - val_recall_3: 0.5514\n",
      "Epoch 784/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5265 - acc: 0.1953 - precision_3: 0.6800 - recall_3: 0.2000 - val_loss: 1.5071 - val_acc: 0.4919 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 785/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5319 - acc: 0.1859 - precision_3: 0.6462 - recall_3: 0.1976 - val_loss: 1.5084 - val_acc: 0.4865 - val_precision_3: 0.5255 - val_recall_3: 0.5568\n",
      "Epoch 786/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5428 - acc: 0.1624 - precision_3: 0.6404 - recall_3: 0.1718 - val_loss: 1.5111 - val_acc: 0.4865 - val_precision_3: 0.5255 - val_recall_3: 0.5568\n",
      "Epoch 787/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5497 - acc: 0.1482 - precision_3: 0.5963 - recall_3: 0.1529 - val_loss: 1.5108 - val_acc: 0.4811 - val_precision_3: 0.5309 - val_recall_3: 0.5568\n",
      "Epoch 788/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5314 - acc: 0.1812 - precision_3: 0.6842 - recall_3: 0.1835 - val_loss: 1.5124 - val_acc: 0.4811 - val_precision_3: 0.5285 - val_recall_3: 0.5514\n",
      "Epoch 789/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5371 - acc: 0.1788 - precision_3: 0.6612 - recall_3: 0.1882 - val_loss: 1.5131 - val_acc: 0.4811 - val_precision_3: 0.5285 - val_recall_3: 0.5514\n",
      "Epoch 790/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5449 - acc: 0.1875 - precision_3: 0.5484 - recall_3: 0.21 - 0s 551us/sample - loss: 1.5461 - acc: 0.1624 - precision_3: 0.6167 - recall_3: 0.1741 - val_loss: 1.5129 - val_acc: 0.4811 - val_precision_3: 0.5333 - val_recall_3: 0.5622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 791/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5462 - acc: 0.1600 - precision_3: 0.6449 - recall_3: 0.1624 - val_loss: 1.5140 - val_acc: 0.4811 - val_precision_3: 0.5337 - val_recall_3: 0.5568\n",
      "Epoch 792/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5436 - acc: 0.1600 - precision_3: 0.6604 - recall_3: 0.1647 - val_loss: 1.5138 - val_acc: 0.4811 - val_precision_3: 0.5337 - val_recall_3: 0.5568\n",
      "Epoch 793/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5468 - acc: 0.1624 - precision_3: 0.6034 - recall_3: 0.1647 - val_loss: 1.5122 - val_acc: 0.4811 - val_precision_3: 0.5361 - val_recall_3: 0.5622\n",
      "Epoch 794/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5280 - acc: 0.2024 - precision_3: 0.6953 - recall_3: 0.2094 - val_loss: 1.5109 - val_acc: 0.4811 - val_precision_3: 0.5361 - val_recall_3: 0.5622\n",
      "Epoch 795/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5319 - acc: 0.1953 - precision_3: 0.6855 - recall_3: 0.2000 - val_loss: 1.5086 - val_acc: 0.4919 - val_precision_3: 0.5282 - val_recall_3: 0.5568\n",
      "Epoch 796/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5459 - acc: 0.1529 - precision_3: 0.6768 - recall_3: 0.1576 - val_loss: 1.5090 - val_acc: 0.4919 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 797/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5328 - acc: 0.1859 - precision_3: 0.6723 - recall_3: 0.1882 - val_loss: 1.5100 - val_acc: 0.4919 - val_precision_3: 0.5285 - val_recall_3: 0.5514\n",
      "Epoch 798/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5329 - acc: 0.1835 - precision_3: 0.6583 - recall_3: 0.1859 - val_loss: 1.5096 - val_acc: 0.4811 - val_precision_3: 0.5258 - val_recall_3: 0.5514\n",
      "Epoch 799/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5456 - acc: 0.1576 - precision_3: 0.6415 - recall_3: 0.1600 - val_loss: 1.5086 - val_acc: 0.4865 - val_precision_3: 0.5231 - val_recall_3: 0.5514\n",
      "Epoch 800/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5361 - acc: 0.1882 - precision_3: 0.6639 - recall_3: 0.1906 - val_loss: 1.5091 - val_acc: 0.4811 - val_precision_3: 0.5337 - val_recall_3: 0.5568\n",
      "Epoch 801/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5305 - acc: 0.1882 - precision_3: 0.7000 - recall_3: 0.1976 - val_loss: 1.5099 - val_acc: 0.4865 - val_precision_3: 0.5421 - val_recall_3: 0.5568\n",
      "Epoch 802/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5393 - acc: 0.1718 - precision_3: 0.6080 - recall_3: 0.1788 - val_loss: 1.5112 - val_acc: 0.4865 - val_precision_3: 0.5426 - val_recall_3: 0.5514\n",
      "Epoch 803/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5417 - acc: 0.1812 - precision_3: 0.5985 - recall_3: 0.1859 - val_loss: 1.5125 - val_acc: 0.4865 - val_precision_3: 0.5426 - val_recall_3: 0.5514\n",
      "Epoch 804/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5366 - acc: 0.1741 - precision_3: 0.6333 - recall_3: 0.1788 - val_loss: 1.5134 - val_acc: 0.4865 - val_precision_3: 0.5426 - val_recall_3: 0.5514\n",
      "Epoch 805/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5442 - acc: 0.1671 - precision_3: 0.6017 - recall_3: 0.1671 - val_loss: 1.5137 - val_acc: 0.4865 - val_precision_3: 0.5426 - val_recall_3: 0.5514\n",
      "Epoch 806/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5460 - acc: 0.1576 - precision_3: 0.6733 - recall_3: 0.1600 - val_loss: 1.5148 - val_acc: 0.4811 - val_precision_3: 0.5397 - val_recall_3: 0.5514\n",
      "Epoch 807/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5563 - acc: 0.1341 - precision_3: 0.6170 - recall_3: 0.1365 - val_loss: 1.5165 - val_acc: 0.4811 - val_precision_3: 0.5368 - val_recall_3: 0.5514\n",
      "Epoch 808/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5430 - acc: 0.1812 - precision_3: 0.6260 - recall_3: 0.1812 - val_loss: 1.5204 - val_acc: 0.4811 - val_precision_3: 0.5316 - val_recall_3: 0.5459\n",
      "Epoch 809/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5411 - acc: 0.1647 - precision_3: 0.6542 - recall_3: 0.1647 - val_loss: 1.5249 - val_acc: 0.4703 - val_precision_3: 0.5297 - val_recall_3: 0.5297\n",
      "Epoch 810/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5423 - acc: 0.1812 - precision_3: 0.6260 - recall_3: 0.1812 - val_loss: 1.5255 - val_acc: 0.4757 - val_precision_3: 0.5326 - val_recall_3: 0.5297\n",
      "Epoch 811/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5279 - acc: 0.1929 - precision_3: 0.7130 - recall_3: 0.1929 - val_loss: 1.5245 - val_acc: 0.4703 - val_precision_3: 0.5301 - val_recall_3: 0.5243\n",
      "Epoch 812/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5511 - acc: 0.1553 - precision_3: 0.6476 - recall_3: 0.1600 - val_loss: 1.5253 - val_acc: 0.4649 - val_precision_3: 0.5269 - val_recall_3: 0.5297\n",
      "Epoch 813/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5384 - acc: 0.1882 - precision_3: 0.6400 - recall_3: 0.1882 - val_loss: 1.5271 - val_acc: 0.4595 - val_precision_3: 0.5294 - val_recall_3: 0.5351\n",
      "Epoch 814/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5388 - acc: 0.1765 - precision_3: 0.5833 - recall_3: 0.1812 - val_loss: 1.5276 - val_acc: 0.4595 - val_precision_3: 0.5294 - val_recall_3: 0.5351\n",
      "Epoch 815/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5298 - acc: 0.1929 - precision_3: 0.6797 - recall_3: 0.2047 - val_loss: 1.5281 - val_acc: 0.4595 - val_precision_3: 0.5243 - val_recall_3: 0.5243\n",
      "Epoch 816/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5221 - acc: 0.2071 - precision_3: 0.7236 - recall_3: 0.2094 - val_loss: 1.5311 - val_acc: 0.4595 - val_precision_3: 0.5246 - val_recall_3: 0.5189\n",
      "Epoch 817/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5299 - acc: 0.2047 - precision_3: 0.6642 - recall_3: 0.2141 - val_loss: 1.5331 - val_acc: 0.4541 - val_precision_3: 0.5080 - val_recall_3: 0.5135\n",
      "Epoch 818/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5303 - acc: 0.1882 - precision_3: 0.6222 - recall_3: 0.1976 - val_loss: 1.5331 - val_acc: 0.4486 - val_precision_3: 0.5110 - val_recall_3: 0.5027\n",
      "Epoch 819/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5254 - acc: 0.2024 - precision_3: 0.7049 - recall_3: 0.2024 - val_loss: 1.5333 - val_acc: 0.4432 - val_precision_3: 0.5054 - val_recall_3: 0.5027\n",
      "Epoch 820/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5478 - acc: 0.1600 - precision_3: 0.6306 - recall_3: 0.1647 - val_loss: 1.5330 - val_acc: 0.4432 - val_precision_3: 0.5054 - val_recall_3: 0.5081\n",
      "Epoch 821/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5394 - acc: 0.1647 - precision_3: 0.6549 - recall_3: 0.1741 - val_loss: 1.5334 - val_acc: 0.4432 - val_precision_3: 0.5079 - val_recall_3: 0.5243\n",
      "Epoch 822/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5254 - acc: 0.2094 - precision_3: 0.6571 - recall_3: 0.2165 - val_loss: 1.5329 - val_acc: 0.4432 - val_precision_3: 0.5026 - val_recall_3: 0.5243\n",
      "Epoch 823/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5485 - acc: 0.1576 - precision_3: 0.6053 - recall_3: 0.1624 - val_loss: 1.5337 - val_acc: 0.4378 - val_precision_3: 0.4948 - val_recall_3: 0.5135\n",
      "Epoch 824/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5431 - acc: 0.1624 - precision_3: 0.6449 - recall_3: 0.1624 - val_loss: 1.5329 - val_acc: 0.4432 - val_precision_3: 0.5052 - val_recall_3: 0.5243\n",
      "Epoch 825/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5468 - acc: 0.1671 - precision_3: 0.5873 - recall_3: 0.1741 - val_loss: 1.5321 - val_acc: 0.4486 - val_precision_3: 0.5078 - val_recall_3: 0.5297\n",
      "Epoch 826/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5423 - acc: 0.1624 - precision_3: 0.6379 - recall_3: 0.1741 - val_loss: 1.5313 - val_acc: 0.4486 - val_precision_3: 0.5158 - val_recall_3: 0.5297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 827/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5545 - acc: 0.1412 - precision_3: 0.6139 - recall_3: 0.1459 - val_loss: 1.5295 - val_acc: 0.4486 - val_precision_3: 0.5156 - val_recall_3: 0.5351\n",
      "Epoch 828/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5308 - acc: 0.1929 - precision_3: 0.6855 - recall_3: 0.2000 - val_loss: 1.5297 - val_acc: 0.4432 - val_precision_3: 0.5131 - val_recall_3: 0.5297\n",
      "Epoch 829/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5450 - acc: 0.1624 - precision_3: 0.6486 - recall_3: 0.1694 - val_loss: 1.5297 - val_acc: 0.4432 - val_precision_3: 0.5130 - val_recall_3: 0.5351\n",
      "Epoch 830/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5388 - acc: 0.1741 - precision_3: 0.6667 - recall_3: 0.1788 - val_loss: 1.5290 - val_acc: 0.4378 - val_precision_3: 0.5104 - val_recall_3: 0.5297\n",
      "Epoch 831/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5430 - acc: 0.1718 - precision_3: 0.6016 - recall_3: 0.1741 - val_loss: 1.5282 - val_acc: 0.4432 - val_precision_3: 0.5103 - val_recall_3: 0.5351\n",
      "Epoch 832/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5326 - acc: 0.1929 - precision_3: 0.7009 - recall_3: 0.1929 - val_loss: 1.5283 - val_acc: 0.4486 - val_precision_3: 0.5208 - val_recall_3: 0.5405\n",
      "Epoch 833/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5383 - acc: 0.1859 - precision_3: 0.6991 - recall_3: 0.1859 - val_loss: 1.5265 - val_acc: 0.4486 - val_precision_3: 0.5181 - val_recall_3: 0.5405\n",
      "Epoch 834/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5390 - acc: 0.1765 - precision_3: 0.6696 - recall_3: 0.1812 - val_loss: 1.5225 - val_acc: 0.4649 - val_precision_3: 0.5253 - val_recall_3: 0.5622\n",
      "Epoch 835/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5475 - acc: 0.1553 - precision_3: 0.6147 - recall_3: 0.1576 - val_loss: 1.5172 - val_acc: 0.4703 - val_precision_3: 0.5176 - val_recall_3: 0.5568\n",
      "Epoch 836/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5449 - acc: 0.1576 - precision_3: 0.6250 - recall_3: 0.1647 - val_loss: 1.5128 - val_acc: 0.4649 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 837/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5345 - acc: 0.1953 - precision_3: 0.7025 - recall_3: 0.2000 - val_loss: 1.5084 - val_acc: 0.4595 - val_precision_3: 0.5204 - val_recall_3: 0.5514\n",
      "Epoch 838/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5462 - acc: 0.1647 - precision_3: 0.5983 - recall_3: 0.1647 - val_loss: 1.5063 - val_acc: 0.4757 - val_precision_3: 0.5100 - val_recall_3: 0.5514\n",
      "Epoch 839/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5273 - acc: 0.1976 - precision_3: 0.6992 - recall_3: 0.2024 - val_loss: 1.5052 - val_acc: 0.4703 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 840/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5401 - acc: 0.1741 - precision_3: 0.6333 - recall_3: 0.1788 - val_loss: 1.5049 - val_acc: 0.4757 - val_precision_3: 0.5050 - val_recall_3: 0.5459\n",
      "Epoch 841/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5473 - acc: 0.1694 - precision_3: 0.6033 - recall_3: 0.1718 - val_loss: 1.5058 - val_acc: 0.4703 - val_precision_3: 0.5100 - val_recall_3: 0.5514\n",
      "Epoch 842/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5420 - acc: 0.1671 - precision_3: 0.6514 - recall_3: 0.1671 - val_loss: 1.5072 - val_acc: 0.4703 - val_precision_3: 0.5075 - val_recall_3: 0.5459\n",
      "Epoch 843/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5514 - acc: 0.1553 - precision_3: 0.5948 - recall_3: 0.1624 - val_loss: 1.5093 - val_acc: 0.4703 - val_precision_3: 0.5179 - val_recall_3: 0.5459\n",
      "Epoch 844/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5256 - acc: 0.1976 - precision_3: 0.6935 - recall_3: 0.2024 - val_loss: 1.5122 - val_acc: 0.4649 - val_precision_3: 0.5158 - val_recall_3: 0.5297\n",
      "Epoch 845/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5358 - acc: 0.1929 - precision_3: 0.6385 - recall_3: 0.1953 - val_loss: 1.5125 - val_acc: 0.4757 - val_precision_3: 0.5319 - val_recall_3: 0.5405\n",
      "Epoch 846/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5325 - acc: 0.1882 - precision_3: 0.7257 - recall_3: 0.1929 - val_loss: 1.5125 - val_acc: 0.4757 - val_precision_3: 0.5266 - val_recall_3: 0.5351\n",
      "Epoch 847/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5290 - acc: 0.1953 - precision_3: 0.6418 - recall_3: 0.2024 - val_loss: 1.5109 - val_acc: 0.4757 - val_precision_3: 0.5319 - val_recall_3: 0.5405\n",
      "Epoch 848/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5443 - acc: 0.1694 - precision_3: 0.6348 - recall_3: 0.1718 - val_loss: 1.5110 - val_acc: 0.4811 - val_precision_3: 0.5319 - val_recall_3: 0.5405\n",
      "Epoch 849/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5269 - acc: 0.1953 - precision_3: 0.6905 - recall_3: 0.2047 - val_loss: 1.5111 - val_acc: 0.4703 - val_precision_3: 0.5376 - val_recall_3: 0.5405\n",
      "Epoch 850/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5488 - acc: 0.1506 - precision_3: 0.6701 - recall_3: 0.1529 - val_loss: 1.5097 - val_acc: 0.4703 - val_precision_3: 0.5401 - val_recall_3: 0.5459\n",
      "Epoch 851/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5505 - acc: 0.1529 - precision_3: 0.6000 - recall_3: 0.1624 - val_loss: 1.5084 - val_acc: 0.4541 - val_precision_3: 0.5263 - val_recall_3: 0.5405\n",
      "Epoch 852/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5384 - acc: 0.1812 - precision_3: 0.6638 - recall_3: 0.1812 - val_loss: 1.5071 - val_acc: 0.4649 - val_precision_3: 0.5316 - val_recall_3: 0.5459\n",
      "Epoch 853/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5424 - acc: 0.1671 - precision_3: 0.6549 - recall_3: 0.1741 - val_loss: 1.5050 - val_acc: 0.4703 - val_precision_3: 0.5294 - val_recall_3: 0.5351\n",
      "Epoch 854/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5408 - acc: 0.1671 - precision_3: 0.6762 - recall_3: 0.1671 - val_loss: 1.5053 - val_acc: 0.4649 - val_precision_3: 0.5266 - val_recall_3: 0.5351\n",
      "Epoch 855/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5161 - acc: 0.2282 - precision_3: 0.6577 - recall_3: 0.2306 - val_loss: 1.5067 - val_acc: 0.4595 - val_precision_3: 0.5294 - val_recall_3: 0.5351\n",
      "Epoch 856/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5352 - acc: 0.1859 - precision_3: 0.7018 - recall_3: 0.1882 - val_loss: 1.5068 - val_acc: 0.4649 - val_precision_3: 0.5263 - val_recall_3: 0.5405\n",
      "Epoch 857/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5267 - acc: 0.2071 - precision_3: 0.6715 - recall_3: 0.2165 - val_loss: 1.5066 - val_acc: 0.4811 - val_precision_3: 0.5260 - val_recall_3: 0.5459\n",
      "Epoch 858/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5406 - acc: 0.1718 - precision_3: 0.6549 - recall_3: 0.1741 - val_loss: 1.5061 - val_acc: 0.4703 - val_precision_3: 0.5208 - val_recall_3: 0.5405\n",
      "Epoch 859/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5238 - acc: 0.2071 - precision_3: 0.6767 - recall_3: 0.2118 - val_loss: 1.5071 - val_acc: 0.4649 - val_precision_3: 0.5208 - val_recall_3: 0.5405\n",
      "Epoch 860/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.5430 - acc: 0.1624 - precision_3: 0.6509 - recall_3: 0.1624 - val_loss: 1.5079 - val_acc: 0.4649 - val_precision_3: 0.5156 - val_recall_3: 0.5351\n",
      "Epoch 861/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5407 - acc: 0.1835 - precision_3: 0.6393 - recall_3: 0.1835 - val_loss: 1.5112 - val_acc: 0.4649 - val_precision_3: 0.5185 - val_recall_3: 0.5297\n",
      "Epoch 862/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5471 - acc: 0.1482 - precision_3: 0.6147 - recall_3: 0.1576 - val_loss: 1.5129 - val_acc: 0.4757 - val_precision_3: 0.5156 - val_recall_3: 0.5351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 863/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5403 - acc: 0.1718 - precision_3: 0.6496 - recall_3: 0.1788 - val_loss: 1.5112 - val_acc: 0.4757 - val_precision_3: 0.5181 - val_recall_3: 0.5405\n",
      "Epoch 864/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5441 - acc: 0.1694 - precision_3: 0.6066 - recall_3: 0.1741 - val_loss: 1.5077 - val_acc: 0.4757 - val_precision_3: 0.5231 - val_recall_3: 0.5514\n",
      "Epoch 865/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5365 - acc: 0.1812 - precision_3: 0.6581 - recall_3: 0.1812 - val_loss: 1.5050 - val_acc: 0.4811 - val_precision_3: 0.5202 - val_recall_3: 0.5568\n",
      "Epoch 866/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5364 - acc: 0.1788 - precision_3: 0.6429 - recall_3: 0.1906 - val_loss: 1.5039 - val_acc: 0.4811 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 867/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5529 - acc: 0.1435 - precision_3: 0.6019 - recall_3: 0.1529 - val_loss: 1.5026 - val_acc: 0.4865 - val_precision_3: 0.5176 - val_recall_3: 0.5568\n",
      "Epoch 868/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5264 - acc: 0.2000 - precision_3: 0.6617 - recall_3: 0.2071 - val_loss: 1.5036 - val_acc: 0.4865 - val_precision_3: 0.5150 - val_recall_3: 0.5568\n",
      "Epoch 869/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5486 - acc: 0.1506 - precision_3: 0.6036 - recall_3: 0.1576 - val_loss: 1.5053 - val_acc: 0.4811 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 870/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5270 - acc: 0.2094 - precision_3: 0.6741 - recall_3: 0.2141 - val_loss: 1.5066 - val_acc: 0.4811 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 871/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5338 - acc: 0.1765 - precision_3: 0.6610 - recall_3: 0.1835 - val_loss: 1.5065 - val_acc: 0.4865 - val_precision_3: 0.5226 - val_recall_3: 0.5622\n",
      "Epoch 872/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5363 - acc: 0.1835 - precision_3: 0.5985 - recall_3: 0.1859 - val_loss: 1.5063 - val_acc: 0.4919 - val_precision_3: 0.5200 - val_recall_3: 0.5622\n",
      "Epoch 873/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5492 - acc: 0.1576 - precision_3: 0.5645 - recall_3: 0.1647 - val_loss: 1.5055 - val_acc: 0.4973 - val_precision_3: 0.5174 - val_recall_3: 0.5622\n",
      "Epoch 874/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5174 - acc: 0.2165 - precision_3: 0.7176 - recall_3: 0.2212 - val_loss: 1.5054 - val_acc: 0.4919 - val_precision_3: 0.5124 - val_recall_3: 0.5568\n",
      "Epoch 875/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5235 - acc: 0.2000 - precision_3: 0.6875 - recall_3: 0.2071 - val_loss: 1.5045 - val_acc: 0.4973 - val_precision_3: 0.5122 - val_recall_3: 0.5676\n",
      "Epoch 876/2000\n",
      "85/85 [==============================] - 0s 529us/sample - loss: 1.5341 - acc: 0.1812 - precision_3: 0.6610 - recall_3: 0.1835 - val_loss: 1.5046 - val_acc: 0.4973 - val_precision_3: 0.5122 - val_recall_3: 0.5676\n",
      "Epoch 877/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5315 - acc: 0.1906 - precision_3: 0.6891 - recall_3: 0.1929 - val_loss: 1.5026 - val_acc: 0.4919 - val_precision_3: 0.5146 - val_recall_3: 0.5730\n",
      "Epoch 878/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5393 - acc: 0.1647 - precision_3: 0.6496 - recall_3: 0.1788 - val_loss: 1.5014 - val_acc: 0.4865 - val_precision_3: 0.5121 - val_recall_3: 0.5730\n",
      "Epoch 879/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5358 - acc: 0.1765 - precision_3: 0.6667 - recall_3: 0.1788 - val_loss: 1.5010 - val_acc: 0.4865 - val_precision_3: 0.5144 - val_recall_3: 0.5784\n",
      "Epoch 880/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5251 - acc: 0.2024 - precision_3: 0.6929 - recall_3: 0.2071 - val_loss: 1.5017 - val_acc: 0.4865 - val_precision_3: 0.5194 - val_recall_3: 0.5784\n",
      "Epoch 881/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5518 - acc: 0.1482 - precision_3: 0.6632 - recall_3: 0.1482 - val_loss: 1.5034 - val_acc: 0.4811 - val_precision_3: 0.5147 - val_recall_3: 0.5676\n",
      "Epoch 882/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5253 - acc: 0.2000 - precision_3: 0.6967 - recall_3: 0.2000 - val_loss: 1.5047 - val_acc: 0.4757 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 883/2000\n",
      "85/85 [==============================] - 0s 633us/sample - loss: 1.5346 - acc: 0.1835 - precision_3: 0.6838 - recall_3: 0.1882 - val_loss: 1.5078 - val_acc: 0.4811 - val_precision_3: 0.5075 - val_recall_3: 0.5459\n",
      "Epoch 884/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5404 - acc: 0.1741 - precision_3: 0.6607 - recall_3: 0.1741 - val_loss: 1.5107 - val_acc: 0.4865 - val_precision_3: 0.5076 - val_recall_3: 0.5405\n",
      "Epoch 885/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5368 - acc: 0.1765 - precision_3: 0.7103 - recall_3: 0.1788 - val_loss: 1.5128 - val_acc: 0.4865 - val_precision_3: 0.5076 - val_recall_3: 0.5405\n",
      "Epoch 886/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5455 - acc: 0.1694 - precision_3: 0.5814 - recall_3: 0.1765 - val_loss: 1.5144 - val_acc: 0.4811 - val_precision_3: 0.5127 - val_recall_3: 0.5459\n",
      "Epoch 887/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5356 - acc: 0.1741 - precision_3: 0.6637 - recall_3: 0.1765 - val_loss: 1.5148 - val_acc: 0.4703 - val_precision_3: 0.5103 - val_recall_3: 0.5351\n",
      "Epoch 888/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5233 - acc: 0.1976 - precision_3: 0.6692 - recall_3: 0.2047 - val_loss: 1.5142 - val_acc: 0.4757 - val_precision_3: 0.5103 - val_recall_3: 0.5351\n",
      "Epoch 889/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5420 - acc: 0.1812 - precision_3: 0.5778 - recall_3: 0.1835 - val_loss: 1.5138 - val_acc: 0.4757 - val_precision_3: 0.5078 - val_recall_3: 0.5297\n",
      "Epoch 890/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5412 - acc: 0.1788 - precision_3: 0.6667 - recall_3: 0.1835 - val_loss: 1.5143 - val_acc: 0.4811 - val_precision_3: 0.5155 - val_recall_3: 0.5405\n",
      "Epoch 891/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5453 - acc: 0.1600 - precision_3: 0.6306 - recall_3: 0.1647 - val_loss: 1.5160 - val_acc: 0.4811 - val_precision_3: 0.5258 - val_recall_3: 0.5514\n",
      "Epoch 892/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5440 - acc: 0.1624 - precision_3: 0.5902 - recall_3: 0.1694 - val_loss: 1.5161 - val_acc: 0.4757 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 893/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5419 - acc: 0.1671 - precision_3: 0.6174 - recall_3: 0.1671 - val_loss: 1.5160 - val_acc: 0.4757 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 894/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5174 - acc: 0.2141 - precision_3: 0.6912 - recall_3: 0.2212 - val_loss: 1.5166 - val_acc: 0.4811 - val_precision_3: 0.5279 - val_recall_3: 0.5622\n",
      "Epoch 895/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5391 - acc: 0.1718 - precision_3: 0.6916 - recall_3: 0.1741 - val_loss: 1.5173 - val_acc: 0.4811 - val_precision_3: 0.5309 - val_recall_3: 0.5568\n",
      "Epoch 896/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5454 - acc: 0.1671 - precision_3: 0.6455 - recall_3: 0.1671 - val_loss: 1.5171 - val_acc: 0.4811 - val_precision_3: 0.5309 - val_recall_3: 0.5568\n",
      "Epoch 897/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5132 - acc: 0.2188 - precision_3: 0.7405 - recall_3: 0.2282 - val_loss: 1.5158 - val_acc: 0.4649 - val_precision_3: 0.5181 - val_recall_3: 0.5405\n",
      "Epoch 898/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5318 - acc: 0.1765 - precision_3: 0.6814 - recall_3: 0.1812 - val_loss: 1.5149 - val_acc: 0.4757 - val_precision_3: 0.5178 - val_recall_3: 0.5514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5563 - acc: 0.1388 - precision_3: 0.5701 - recall_3: 0.1435 - val_loss: 1.5146 - val_acc: 0.4703 - val_precision_3: 0.5153 - val_recall_3: 0.5459\n",
      "Epoch 900/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5353 - acc: 0.1765 - precision_3: 0.6446 - recall_3: 0.1835 - val_loss: 1.5134 - val_acc: 0.4757 - val_precision_3: 0.5179 - val_recall_3: 0.5459\n",
      "Epoch 901/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5343 - acc: 0.1812 - precision_3: 0.6724 - recall_3: 0.1835 - val_loss: 1.5132 - val_acc: 0.4757 - val_precision_3: 0.5179 - val_recall_3: 0.5459\n",
      "Epoch 902/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5425 - acc: 0.1718 - precision_3: 0.6757 - recall_3: 0.1765 - val_loss: 1.5140 - val_acc: 0.4703 - val_precision_3: 0.5179 - val_recall_3: 0.5459\n",
      "Epoch 903/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5383 - acc: 0.1765 - precision_3: 0.6311 - recall_3: 0.1812 - val_loss: 1.5150 - val_acc: 0.4703 - val_precision_3: 0.5231 - val_recall_3: 0.5514\n",
      "Epoch 904/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5469 - acc: 0.1576 - precision_3: 0.6321 - recall_3: 0.1576 - val_loss: 1.5154 - val_acc: 0.4703 - val_precision_3: 0.5233 - val_recall_3: 0.5459\n",
      "Epoch 905/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5320 - acc: 0.1859 - precision_3: 0.7168 - recall_3: 0.1906 - val_loss: 1.5152 - val_acc: 0.4757 - val_precision_3: 0.5255 - val_recall_3: 0.5568\n",
      "Epoch 906/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5400 - acc: 0.1812 - precision_3: 0.6364 - recall_3: 0.1812 - val_loss: 1.5149 - val_acc: 0.4811 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 907/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5269 - acc: 0.2047 - precision_3: 0.6642 - recall_3: 0.2141 - val_loss: 1.5155 - val_acc: 0.4486 - val_precision_3: 0.5132 - val_recall_3: 0.5243\n",
      "Epoch 908/2000\n",
      "85/85 [==============================] - 0s 527us/sample - loss: 1.5401 - acc: 0.1671 - precision_3: 0.6545 - recall_3: 0.1694 - val_loss: 1.5148 - val_acc: 0.4541 - val_precision_3: 0.5160 - val_recall_3: 0.5243\n",
      "Epoch 909/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5508 - acc: 0.1553 - precision_3: 0.5763 - recall_3: 0.1600 - val_loss: 1.5139 - val_acc: 0.4649 - val_precision_3: 0.5269 - val_recall_3: 0.5297\n",
      "Epoch 910/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5208 - acc: 0.2024 - precision_3: 0.6929 - recall_3: 0.2071 - val_loss: 1.5134 - val_acc: 0.4649 - val_precision_3: 0.5297 - val_recall_3: 0.5297\n",
      "Epoch 911/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5331 - acc: 0.1788 - precision_3: 0.7000 - recall_3: 0.1812 - val_loss: 1.5125 - val_acc: 0.4649 - val_precision_3: 0.5297 - val_recall_3: 0.5297\n",
      "Epoch 912/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5411 - acc: 0.1788 - precision_3: 0.6667 - recall_3: 0.1788 - val_loss: 1.5123 - val_acc: 0.4649 - val_precision_3: 0.5241 - val_recall_3: 0.5297\n",
      "Epoch 913/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5282 - acc: 0.1929 - precision_3: 0.6667 - recall_3: 0.1976 - val_loss: 1.5117 - val_acc: 0.4649 - val_precision_3: 0.5213 - val_recall_3: 0.5297\n",
      "Epoch 914/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5474 - acc: 0.1553 - precision_3: 0.6731 - recall_3: 0.1647 - val_loss: 1.5111 - val_acc: 0.4649 - val_precision_3: 0.5185 - val_recall_3: 0.5297\n",
      "Epoch 915/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5517 - acc: 0.1388 - precision_3: 0.5905 - recall_3: 0.1459 - val_loss: 1.5106 - val_acc: 0.4649 - val_precision_3: 0.5213 - val_recall_3: 0.5297\n",
      "Epoch 916/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5290 - acc: 0.1882 - precision_3: 0.6957 - recall_3: 0.1882 - val_loss: 1.5114 - val_acc: 0.4703 - val_precision_3: 0.5156 - val_recall_3: 0.5351\n",
      "Epoch 917/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5223 - acc: 0.2024 - precision_3: 0.7097 - recall_3: 0.2071 - val_loss: 1.5130 - val_acc: 0.4703 - val_precision_3: 0.5156 - val_recall_3: 0.5351\n",
      "Epoch 918/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5267 - acc: 0.1976 - precision_3: 0.6992 - recall_3: 0.2024 - val_loss: 1.5142 - val_acc: 0.4703 - val_precision_3: 0.5104 - val_recall_3: 0.5297\n",
      "Epoch 919/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5272 - acc: 0.2000 - precision_3: 0.6769 - recall_3: 0.2071 - val_loss: 1.5149 - val_acc: 0.4649 - val_precision_3: 0.5103 - val_recall_3: 0.5351\n",
      "Epoch 920/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5295 - acc: 0.1976 - precision_3: 0.6746 - recall_3: 0.2000 - val_loss: 1.5147 - val_acc: 0.4703 - val_precision_3: 0.5155 - val_recall_3: 0.5405\n",
      "Epoch 921/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5453 - acc: 0.1741 - precision_3: 0.6325 - recall_3: 0.1741 - val_loss: 1.5140 - val_acc: 0.4649 - val_precision_3: 0.5155 - val_recall_3: 0.5405\n",
      "Epoch 922/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5132 - acc: 0.2306 - precision_3: 0.7463 - recall_3: 0.2353 - val_loss: 1.5127 - val_acc: 0.4757 - val_precision_3: 0.5202 - val_recall_3: 0.5568\n",
      "Epoch 923/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5319 - acc: 0.1812 - precision_3: 0.6897 - recall_3: 0.1882 - val_loss: 1.5137 - val_acc: 0.4811 - val_precision_3: 0.5285 - val_recall_3: 0.5514\n",
      "Epoch 924/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5425 - acc: 0.1624 - precision_3: 0.6486 - recall_3: 0.1694 - val_loss: 1.5143 - val_acc: 0.4865 - val_precision_3: 0.5340 - val_recall_3: 0.5514\n",
      "Epoch 925/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5318 - acc: 0.1882 - precision_3: 0.6639 - recall_3: 0.1906 - val_loss: 1.5131 - val_acc: 0.4865 - val_precision_3: 0.5316 - val_recall_3: 0.5459\n",
      "Epoch 926/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5315 - acc: 0.1859 - precision_3: 0.6803 - recall_3: 0.1953 - val_loss: 1.5143 - val_acc: 0.4865 - val_precision_3: 0.5368 - val_recall_3: 0.5514\n",
      "Epoch 927/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5304 - acc: 0.1859 - precision_3: 0.6667 - recall_3: 0.1929 - val_loss: 1.5158 - val_acc: 0.4811 - val_precision_3: 0.5238 - val_recall_3: 0.5351\n",
      "Epoch 928/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5282 - acc: 0.2000 - precision_3: 0.6967 - recall_3: 0.2000 - val_loss: 1.5155 - val_acc: 0.4811 - val_precision_3: 0.5208 - val_recall_3: 0.5405\n",
      "Epoch 929/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5287 - acc: 0.1929 - precision_3: 0.7094 - recall_3: 0.1953 - val_loss: 1.5143 - val_acc: 0.4811 - val_precision_3: 0.5128 - val_recall_3: 0.5405\n",
      "Epoch 930/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5384 - acc: 0.1812 - precision_3: 0.6270 - recall_3: 0.1859 - val_loss: 1.5145 - val_acc: 0.4757 - val_precision_3: 0.5178 - val_recall_3: 0.5514\n",
      "Epoch 931/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5440 - acc: 0.1600 - precision_3: 0.6316 - recall_3: 0.1694 - val_loss: 1.5148 - val_acc: 0.4811 - val_precision_3: 0.5152 - val_recall_3: 0.5514\n",
      "Epoch 932/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5439 - acc: 0.1741 - precision_3: 0.5984 - recall_3: 0.1788 - val_loss: 1.5148 - val_acc: 0.4757 - val_precision_3: 0.5202 - val_recall_3: 0.5568\n",
      "Epoch 933/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5274 - acc: 0.1906 - precision_3: 0.6350 - recall_3: 0.2047 - val_loss: 1.5147 - val_acc: 0.4811 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 934/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5350 - acc: 0.1906 - precision_3: 0.6585 - recall_3: 0.1906 - val_loss: 1.5146 - val_acc: 0.4757 - val_precision_3: 0.5155 - val_recall_3: 0.5405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 935/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5326 - acc: 0.1882 - precision_3: 0.7297 - recall_3: 0.1906 - val_loss: 1.5159 - val_acc: 0.4595 - val_precision_3: 0.5158 - val_recall_3: 0.5297\n",
      "Epoch 936/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5446 - acc: 0.1482 - precision_3: 0.6804 - recall_3: 0.1553 - val_loss: 1.5156 - val_acc: 0.4649 - val_precision_3: 0.5158 - val_recall_3: 0.5297\n",
      "Epoch 937/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5301 - acc: 0.1882 - precision_3: 0.6587 - recall_3: 0.1953 - val_loss: 1.5150 - val_acc: 0.4703 - val_precision_3: 0.5211 - val_recall_3: 0.5351\n",
      "Epoch 938/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.5398 - acc: 0.1765 - precision_3: 0.6410 - recall_3: 0.1765 - val_loss: 1.5158 - val_acc: 0.4649 - val_precision_3: 0.5156 - val_recall_3: 0.5351\n",
      "Epoch 939/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5264 - acc: 0.1882 - precision_3: 0.7094 - recall_3: 0.1953 - val_loss: 1.5161 - val_acc: 0.4595 - val_precision_3: 0.5185 - val_recall_3: 0.5297\n",
      "Epoch 940/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5413 - acc: 0.1600 - precision_3: 0.6981 - recall_3: 0.1741 - val_loss: 1.5157 - val_acc: 0.4649 - val_precision_3: 0.5132 - val_recall_3: 0.5243\n",
      "Epoch 941/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5265 - acc: 0.1953 - precision_3: 0.7143 - recall_3: 0.2000 - val_loss: 1.5159 - val_acc: 0.4703 - val_precision_3: 0.5160 - val_recall_3: 0.5243\n",
      "Epoch 942/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5369 - acc: 0.1812 - precision_3: 0.6423 - recall_3: 0.1859 - val_loss: 1.5156 - val_acc: 0.4703 - val_precision_3: 0.5132 - val_recall_3: 0.5243\n",
      "Epoch 943/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5356 - acc: 0.1812 - precision_3: 0.7091 - recall_3: 0.1835 - val_loss: 1.5157 - val_acc: 0.4757 - val_precision_3: 0.5131 - val_recall_3: 0.5297\n",
      "Epoch 944/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5271 - acc: 0.1835 - precision_3: 0.7407 - recall_3: 0.1882 - val_loss: 1.5168 - val_acc: 0.4757 - val_precision_3: 0.5131 - val_recall_3: 0.5297\n",
      "Epoch 945/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5296 - acc: 0.1929 - precision_3: 0.7193 - recall_3: 0.1929 - val_loss: 1.5172 - val_acc: 0.4757 - val_precision_3: 0.5130 - val_recall_3: 0.5351\n",
      "Epoch 946/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5368 - acc: 0.1859 - precision_3: 0.6480 - recall_3: 0.1906 - val_loss: 1.5177 - val_acc: 0.4811 - val_precision_3: 0.5181 - val_recall_3: 0.5405\n",
      "Epoch 947/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5279 - acc: 0.1906 - precision_3: 0.6693 - recall_3: 0.2000 - val_loss: 1.5180 - val_acc: 0.4757 - val_precision_3: 0.5181 - val_recall_3: 0.5405\n",
      "Epoch 948/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5383 - acc: 0.1835 - precision_3: 0.6299 - recall_3: 0.1882 - val_loss: 1.5156 - val_acc: 0.4811 - val_precision_3: 0.5208 - val_recall_3: 0.5405\n",
      "Epoch 949/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5277 - acc: 0.1976 - precision_3: 0.6911 - recall_3: 0.2000 - val_loss: 1.5130 - val_acc: 0.4811 - val_precision_3: 0.5208 - val_recall_3: 0.5405\n",
      "Epoch 950/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5231 - acc: 0.2118 - precision_3: 0.6619 - recall_3: 0.2165 - val_loss: 1.5129 - val_acc: 0.4811 - val_precision_3: 0.5208 - val_recall_3: 0.5405\n",
      "Epoch 951/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5380 - acc: 0.1788 - precision_3: 0.6496 - recall_3: 0.1788 - val_loss: 1.5131 - val_acc: 0.4811 - val_precision_3: 0.5181 - val_recall_3: 0.5405\n",
      "Epoch 952/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5249 - acc: 0.1976 - precision_3: 0.7016 - recall_3: 0.2047 - val_loss: 1.5134 - val_acc: 0.4811 - val_precision_3: 0.5155 - val_recall_3: 0.5405\n",
      "Epoch 953/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5240 - acc: 0.2047 - precision_3: 0.6923 - recall_3: 0.2118 - val_loss: 1.5137 - val_acc: 0.4811 - val_precision_3: 0.5236 - val_recall_3: 0.5405\n",
      "Epoch 954/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5373 - acc: 0.1765 - precision_3: 0.6610 - recall_3: 0.1835 - val_loss: 1.5144 - val_acc: 0.4865 - val_precision_3: 0.5288 - val_recall_3: 0.5459\n",
      "Epoch 955/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5295 - acc: 0.1859 - precision_3: 0.7257 - recall_3: 0.1929 - val_loss: 1.5134 - val_acc: 0.4919 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 956/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5360 - acc: 0.1765 - precision_3: 0.6847 - recall_3: 0.1788 - val_loss: 1.5119 - val_acc: 0.4919 - val_precision_3: 0.5231 - val_recall_3: 0.5514\n",
      "Epoch 957/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5301 - acc: 0.1882 - precision_3: 0.6891 - recall_3: 0.1929 - val_loss: 1.5107 - val_acc: 0.4865 - val_precision_3: 0.5153 - val_recall_3: 0.5459\n",
      "Epoch 958/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5283 - acc: 0.1906 - precision_3: 0.6891 - recall_3: 0.1929 - val_loss: 1.5091 - val_acc: 0.4919 - val_precision_3: 0.5153 - val_recall_3: 0.5459\n",
      "Epoch 959/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5387 - acc: 0.1671 - precision_3: 0.6923 - recall_3: 0.1694 - val_loss: 1.5049 - val_acc: 0.4919 - val_precision_3: 0.5204 - val_recall_3: 0.5514\n",
      "Epoch 960/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5387 - acc: 0.1788 - precision_3: 0.6754 - recall_3: 0.1812 - val_loss: 1.5025 - val_acc: 0.5081 - val_precision_3: 0.5274 - val_recall_3: 0.5730\n",
      "Epoch 961/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5314 - acc: 0.1953 - precision_3: 0.6562 - recall_3: 0.1976 - val_loss: 1.5003 - val_acc: 0.5081 - val_precision_3: 0.5327 - val_recall_3: 0.5730\n",
      "Epoch 962/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5327 - acc: 0.1882 - precision_3: 0.6504 - recall_3: 0.1882 - val_loss: 1.5003 - val_acc: 0.5027 - val_precision_3: 0.5330 - val_recall_3: 0.5676\n",
      "Epoch 963/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5277 - acc: 0.1953 - precision_3: 0.7265 - recall_3: 0.2000 - val_loss: 1.5003 - val_acc: 0.5027 - val_precision_3: 0.5330 - val_recall_3: 0.5676\n",
      "Epoch 964/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5310 - acc: 0.1859 - precision_3: 0.7339 - recall_3: 0.1882 - val_loss: 1.5010 - val_acc: 0.5081 - val_precision_3: 0.5327 - val_recall_3: 0.5730\n",
      "Epoch 965/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5445 - acc: 0.1576 - precision_3: 0.6699 - recall_3: 0.1624 - val_loss: 1.5019 - val_acc: 0.5081 - val_precision_3: 0.5327 - val_recall_3: 0.5730\n",
      "Epoch 966/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5256 - acc: 0.1953 - precision_3: 0.6992 - recall_3: 0.2024 - val_loss: 1.5041 - val_acc: 0.5081 - val_precision_3: 0.5354 - val_recall_3: 0.5730\n",
      "Epoch 967/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5450 - acc: 0.1694 - precision_3: 0.6261 - recall_3: 0.1694 - val_loss: 1.5047 - val_acc: 0.5081 - val_precision_3: 0.5303 - val_recall_3: 0.5676\n",
      "Epoch 968/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5135 - acc: 0.2188 - precision_3: 0.7328 - recall_3: 0.2259 - val_loss: 1.5074 - val_acc: 0.4865 - val_precision_3: 0.5361 - val_recall_3: 0.5622\n",
      "Epoch 969/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5351 - acc: 0.1718 - precision_3: 0.6696 - recall_3: 0.1812 - val_loss: 1.5103 - val_acc: 0.4811 - val_precision_3: 0.5260 - val_recall_3: 0.5459\n",
      "Epoch 970/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5190 - acc: 0.2282 - precision_3: 0.6783 - recall_3: 0.2282 - val_loss: 1.5104 - val_acc: 0.4811 - val_precision_3: 0.5233 - val_recall_3: 0.5459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 971/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5327 - acc: 0.1953 - precision_3: 0.6364 - recall_3: 0.1976 - val_loss: 1.5111 - val_acc: 0.4811 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 972/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5375 - acc: 0.1718 - precision_3: 0.6387 - recall_3: 0.1788 - val_loss: 1.5113 - val_acc: 0.4811 - val_precision_3: 0.5179 - val_recall_3: 0.5459\n",
      "Epoch 973/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5333 - acc: 0.1882 - precision_3: 0.6807 - recall_3: 0.1906 - val_loss: 1.5110 - val_acc: 0.4811 - val_precision_3: 0.5179 - val_recall_3: 0.5459\n",
      "Epoch 974/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5156 - acc: 0.2188 - precision_3: 0.7344 - recall_3: 0.2212 - val_loss: 1.5096 - val_acc: 0.4811 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 975/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5283 - acc: 0.1976 - precision_3: 0.6591 - recall_3: 0.2047 - val_loss: 1.5091 - val_acc: 0.4811 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 976/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5404 - acc: 0.1694 - precision_3: 0.6637 - recall_3: 0.1765 - val_loss: 1.5090 - val_acc: 0.4865 - val_precision_3: 0.5127 - val_recall_3: 0.5459\n",
      "Epoch 977/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5407 - acc: 0.1718 - precision_3: 0.6466 - recall_3: 0.1765 - val_loss: 1.5093 - val_acc: 0.4865 - val_precision_3: 0.5179 - val_recall_3: 0.5459\n",
      "Epoch 978/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5402 - acc: 0.1647 - precision_3: 0.7100 - recall_3: 0.1671 - val_loss: 1.5080 - val_acc: 0.4865 - val_precision_3: 0.5231 - val_recall_3: 0.5514\n",
      "Epoch 979/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5399 - acc: 0.1624 - precision_3: 0.7172 - recall_3: 0.1671 - val_loss: 1.5069 - val_acc: 0.4919 - val_precision_3: 0.5176 - val_recall_3: 0.5568\n",
      "Epoch 980/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5289 - acc: 0.1929 - precision_3: 0.6336 - recall_3: 0.1953 - val_loss: 1.5061 - val_acc: 0.4919 - val_precision_3: 0.5124 - val_recall_3: 0.5568\n",
      "Epoch 981/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5409 - acc: 0.1647 - precision_3: 0.6549 - recall_3: 0.1741 - val_loss: 1.5074 - val_acc: 0.4919 - val_precision_3: 0.5126 - val_recall_3: 0.5514\n",
      "Epoch 982/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5272 - acc: 0.2024 - precision_3: 0.7016 - recall_3: 0.2047 - val_loss: 1.5086 - val_acc: 0.4865 - val_precision_3: 0.5100 - val_recall_3: 0.5514\n",
      "Epoch 983/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5273 - acc: 0.1882 - precision_3: 0.7069 - recall_3: 0.1929 - val_loss: 1.5108 - val_acc: 0.4865 - val_precision_3: 0.5075 - val_recall_3: 0.5459\n",
      "Epoch 984/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5323 - acc: 0.1765 - precision_3: 0.7308 - recall_3: 0.1788 - val_loss: 1.5124 - val_acc: 0.4757 - val_precision_3: 0.5100 - val_recall_3: 0.5514\n",
      "Epoch 985/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5454 - acc: 0.1647 - precision_3: 0.6140 - recall_3: 0.1647 - val_loss: 1.5153 - val_acc: 0.4703 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 986/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5283 - acc: 0.1882 - precision_3: 0.7155 - recall_3: 0.1953 - val_loss: 1.5200 - val_acc: 0.4378 - val_precision_3: 0.5102 - val_recall_3: 0.5405\n",
      "Epoch 987/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5259 - acc: 0.1953 - precision_3: 0.7434 - recall_3: 0.1976 - val_loss: 1.5232 - val_acc: 0.4378 - val_precision_3: 0.5211 - val_recall_3: 0.5351\n",
      "Epoch 988/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5230 - acc: 0.2000 - precision_3: 0.7373 - recall_3: 0.2047 - val_loss: 1.5240 - val_acc: 0.4432 - val_precision_3: 0.5288 - val_recall_3: 0.5459\n",
      "Epoch 989/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5230 - acc: 0.2118 - precision_3: 0.7339 - recall_3: 0.2141 - val_loss: 1.5225 - val_acc: 0.4486 - val_precision_3: 0.5260 - val_recall_3: 0.5459\n",
      "Epoch 990/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5353 - acc: 0.1788 - precision_3: 0.7308 - recall_3: 0.1788 - val_loss: 1.5208 - val_acc: 0.4378 - val_precision_3: 0.5128 - val_recall_3: 0.5405\n",
      "Epoch 991/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5112 - acc: 0.2188 - precision_3: 0.7214 - recall_3: 0.2376 - val_loss: 1.5182 - val_acc: 0.4432 - val_precision_3: 0.5101 - val_recall_3: 0.5459\n",
      "Epoch 992/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5327 - acc: 0.1765 - precision_3: 0.7027 - recall_3: 0.1835 - val_loss: 1.5172 - val_acc: 0.4486 - val_precision_3: 0.5202 - val_recall_3: 0.5568\n",
      "Epoch 993/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5369 - acc: 0.1718 - precision_3: 0.6333 - recall_3: 0.1788 - val_loss: 1.5171 - val_acc: 0.4486 - val_precision_3: 0.5202 - val_recall_3: 0.5568\n",
      "Epoch 994/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5345 - acc: 0.1882 - precision_3: 0.6560 - recall_3: 0.1929 - val_loss: 1.5147 - val_acc: 0.4703 - val_precision_3: 0.5200 - val_recall_3: 0.5622\n",
      "Epoch 995/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5318 - acc: 0.1859 - precision_3: 0.7193 - recall_3: 0.1929 - val_loss: 1.5091 - val_acc: 0.4865 - val_precision_3: 0.5150 - val_recall_3: 0.5568\n",
      "Epoch 996/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5393 - acc: 0.1647 - precision_3: 0.6923 - recall_3: 0.1694 - val_loss: 1.5062 - val_acc: 0.4865 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 997/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5438 - acc: 0.1576 - precision_3: 0.7283 - recall_3: 0.1576 - val_loss: 1.5041 - val_acc: 0.4865 - val_precision_3: 0.5073 - val_recall_3: 0.5622\n",
      "Epoch 998/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5354 - acc: 0.1671 - precision_3: 0.7048 - recall_3: 0.1741 - val_loss: 1.5032 - val_acc: 0.4865 - val_precision_3: 0.5072 - val_recall_3: 0.5676\n",
      "Epoch 999/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5287 - acc: 0.1929 - precision_3: 0.6214 - recall_3: 0.2047 - val_loss: 1.5028 - val_acc: 0.4919 - val_precision_3: 0.4976 - val_recall_3: 0.5676\n",
      "Epoch 1000/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5170 - acc: 0.2212 - precision_3: 0.7029 - recall_3: 0.2282 - val_loss: 1.5035 - val_acc: 0.4919 - val_precision_3: 0.4976 - val_recall_3: 0.5676\n",
      "Epoch 1001/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5365 - acc: 0.1718 - precision_3: 0.6822 - recall_3: 0.1718 - val_loss: 1.5045 - val_acc: 0.4919 - val_precision_3: 0.5048 - val_recall_3: 0.5676\n",
      "Epoch 1002/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5333 - acc: 0.1812 - precision_3: 0.6750 - recall_3: 0.1906 - val_loss: 1.5048 - val_acc: 0.4919 - val_precision_3: 0.5000 - val_recall_3: 0.5622\n",
      "Epoch 1003/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5342 - acc: 0.1741 - precision_3: 0.6726 - recall_3: 0.1788 - val_loss: 1.5052 - val_acc: 0.4919 - val_precision_3: 0.5024 - val_recall_3: 0.5568\n",
      "Epoch 1004/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5384 - acc: 0.1671 - precision_3: 0.7660 - recall_3: 0.1694 - val_loss: 1.5055 - val_acc: 0.4919 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1005/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5483 - acc: 0.1529 - precision_3: 0.7222 - recall_3: 0.1529 - val_loss: 1.5056 - val_acc: 0.4919 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1006/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5373 - acc: 0.1718 - precision_3: 0.7009 - recall_3: 0.1765 - val_loss: 1.5034 - val_acc: 0.4919 - val_precision_3: 0.5000 - val_recall_3: 0.5622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1007/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5189 - acc: 0.2094 - precision_3: 0.7000 - recall_3: 0.2141 - val_loss: 1.5034 - val_acc: 0.4919 - val_precision_3: 0.5048 - val_recall_3: 0.5730\n",
      "Epoch 1008/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5446 - acc: 0.1647 - precision_3: 0.6186 - recall_3: 0.1718 - val_loss: 1.5010 - val_acc: 0.4973 - val_precision_3: 0.5023 - val_recall_3: 0.5784\n",
      "Epoch 1009/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5170 - acc: 0.2165 - precision_3: 0.7266 - recall_3: 0.2188 - val_loss: 1.4999 - val_acc: 0.4973 - val_precision_3: 0.5047 - val_recall_3: 0.5784\n",
      "Epoch 1010/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5399 - acc: 0.1671 - precision_3: 0.6460 - recall_3: 0.1718 - val_loss: 1.4995 - val_acc: 0.4973 - val_precision_3: 0.5024 - val_recall_3: 0.5730\n",
      "Epoch 1011/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5267 - acc: 0.2071 - precision_3: 0.6953 - recall_3: 0.2094 - val_loss: 1.4985 - val_acc: 0.4973 - val_precision_3: 0.5071 - val_recall_3: 0.5784\n",
      "Epoch 1012/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5411 - acc: 0.1671 - precision_3: 0.6429 - recall_3: 0.1694 - val_loss: 1.4986 - val_acc: 0.5027 - val_precision_3: 0.5118 - val_recall_3: 0.5838\n",
      "Epoch 1013/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5271 - acc: 0.1976 - precision_3: 0.6667 - recall_3: 0.2071 - val_loss: 1.4987 - val_acc: 0.5081 - val_precision_3: 0.5023 - val_recall_3: 0.5784\n",
      "Epoch 1014/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5278 - acc: 0.2024 - precision_3: 0.7131 - recall_3: 0.2047 - val_loss: 1.4990 - val_acc: 0.5027 - val_precision_3: 0.4977 - val_recall_3: 0.5784\n",
      "Epoch 1015/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5312 - acc: 0.1906 - precision_3: 0.6613 - recall_3: 0.1929 - val_loss: 1.5025 - val_acc: 0.5027 - val_precision_3: 0.5096 - val_recall_3: 0.5730\n",
      "Epoch 1016/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5178 - acc: 0.2188 - precision_3: 0.7099 - recall_3: 0.2188 - val_loss: 1.5032 - val_acc: 0.5081 - val_precision_3: 0.5094 - val_recall_3: 0.5838\n",
      "Epoch 1017/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5250 - acc: 0.1859 - precision_3: 0.7257 - recall_3: 0.1929 - val_loss: 1.5022 - val_acc: 0.5135 - val_precision_3: 0.5094 - val_recall_3: 0.5838\n",
      "Epoch 1018/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5272 - acc: 0.2024 - precision_3: 0.6641 - recall_3: 0.2047 - val_loss: 1.5028 - val_acc: 0.5081 - val_precision_3: 0.5047 - val_recall_3: 0.5838\n",
      "Epoch 1019/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5382 - acc: 0.1788 - precision_3: 0.6111 - recall_3: 0.1812 - val_loss: 1.5041 - val_acc: 0.5081 - val_precision_3: 0.5023 - val_recall_3: 0.5838\n",
      "Epoch 1020/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5334 - acc: 0.1882 - precision_3: 0.7043 - recall_3: 0.1906 - val_loss: 1.5042 - val_acc: 0.5081 - val_precision_3: 0.5070 - val_recall_3: 0.5892\n",
      "Epoch 1021/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5283 - acc: 0.1882 - precision_3: 0.7130 - recall_3: 0.1929 - val_loss: 1.5051 - val_acc: 0.4973 - val_precision_3: 0.5047 - val_recall_3: 0.5838\n",
      "Epoch 1022/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5307 - acc: 0.1835 - precision_3: 0.7069 - recall_3: 0.1929 - val_loss: 1.5075 - val_acc: 0.4973 - val_precision_3: 0.5070 - val_recall_3: 0.5838\n",
      "Epoch 1023/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5195 - acc: 0.2141 - precision_3: 0.6970 - recall_3: 0.2165 - val_loss: 1.5094 - val_acc: 0.4973 - val_precision_3: 0.5071 - val_recall_3: 0.5784\n",
      "Epoch 1024/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5367 - acc: 0.1765 - precision_3: 0.6696 - recall_3: 0.1812 - val_loss: 1.5107 - val_acc: 0.4865 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1025/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5503 - acc: 0.1600 - precision_3: 0.5854 - recall_3: 0.1694 - val_loss: 1.5102 - val_acc: 0.4919 - val_precision_3: 0.5000 - val_recall_3: 0.5622\n",
      "Epoch 1026/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5208 - acc: 0.2047 - precision_3: 0.7586 - recall_3: 0.2071 - val_loss: 1.5105 - val_acc: 0.4919 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1027/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5355 - acc: 0.1694 - precision_3: 0.6852 - recall_3: 0.1741 - val_loss: 1.5162 - val_acc: 0.4757 - val_precision_3: 0.5000 - val_recall_3: 0.5459\n",
      "Epoch 1028/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5347 - acc: 0.1718 - precision_3: 0.7184 - recall_3: 0.1741 - val_loss: 1.5162 - val_acc: 0.4541 - val_precision_3: 0.4900 - val_recall_3: 0.5297\n",
      "Epoch 1029/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5311 - acc: 0.1906 - precision_3: 0.6589 - recall_3: 0.2000 - val_loss: 1.5149 - val_acc: 0.4595 - val_precision_3: 0.4925 - val_recall_3: 0.5351\n",
      "Epoch 1030/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5256 - acc: 0.1929 - precision_3: 0.6642 - recall_3: 0.2094 - val_loss: 1.5129 - val_acc: 0.4811 - val_precision_3: 0.4927 - val_recall_3: 0.5459\n",
      "Epoch 1031/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5272 - acc: 0.1906 - precision_3: 0.6885 - recall_3: 0.1976 - val_loss: 1.5127 - val_acc: 0.4865 - val_precision_3: 0.4927 - val_recall_3: 0.5459\n",
      "Epoch 1032/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5271 - acc: 0.1953 - precision_3: 0.6797 - recall_3: 0.2047 - val_loss: 1.5109 - val_acc: 0.4703 - val_precision_3: 0.4902 - val_recall_3: 0.5405\n",
      "Epoch 1033/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5331 - acc: 0.1718 - precision_3: 0.7170 - recall_3: 0.1788 - val_loss: 1.5100 - val_acc: 0.4595 - val_precision_3: 0.4877 - val_recall_3: 0.5351\n",
      "Epoch 1034/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5346 - acc: 0.1741 - precision_3: 0.6814 - recall_3: 0.1812 - val_loss: 1.5116 - val_acc: 0.4757 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 1035/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5395 - acc: 0.1671 - precision_3: 0.6387 - recall_3: 0.1788 - val_loss: 1.5151 - val_acc: 0.4757 - val_precision_3: 0.4926 - val_recall_3: 0.5405\n",
      "Epoch 1036/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5380 - acc: 0.1647 - precision_3: 0.6518 - recall_3: 0.1718 - val_loss: 1.5174 - val_acc: 0.4757 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 1037/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5268 - acc: 0.1859 - precision_3: 0.7523 - recall_3: 0.1929 - val_loss: 1.5165 - val_acc: 0.4757 - val_precision_3: 0.5049 - val_recall_3: 0.5568\n",
      "Epoch 1038/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5362 - acc: 0.1741 - precision_3: 0.7143 - recall_3: 0.1765 - val_loss: 1.5163 - val_acc: 0.4919 - val_precision_3: 0.5049 - val_recall_3: 0.5568\n",
      "Epoch 1039/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5178 - acc: 0.2165 - precision_3: 0.7231 - recall_3: 0.2212 - val_loss: 1.5176 - val_acc: 0.4811 - val_precision_3: 0.5000 - val_recall_3: 0.5514\n",
      "Epoch 1040/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5269 - acc: 0.2000 - precision_3: 0.7143 - recall_3: 0.2000 - val_loss: 1.5176 - val_acc: 0.4811 - val_precision_3: 0.5000 - val_recall_3: 0.5405\n",
      "Epoch 1041/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5392 - acc: 0.1741 - precision_3: 0.6303 - recall_3: 0.1765 - val_loss: 1.5168 - val_acc: 0.4811 - val_precision_3: 0.5101 - val_recall_3: 0.5459\n",
      "Epoch 1042/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5432 - acc: 0.1624 - precision_3: 0.6698 - recall_3: 0.1671 - val_loss: 1.5170 - val_acc: 0.4757 - val_precision_3: 0.5128 - val_recall_3: 0.5405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1043/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5386 - acc: 0.1718 - precision_3: 0.6696 - recall_3: 0.1765 - val_loss: 1.5168 - val_acc: 0.4757 - val_precision_3: 0.5101 - val_recall_3: 0.5459\n",
      "Epoch 1044/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5367 - acc: 0.1694 - precision_3: 0.6518 - recall_3: 0.1718 - val_loss: 1.5155 - val_acc: 0.4757 - val_precision_3: 0.5101 - val_recall_3: 0.5459\n",
      "Epoch 1045/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5232 - acc: 0.2000 - precision_3: 0.6797 - recall_3: 0.2047 - val_loss: 1.5143 - val_acc: 0.4757 - val_precision_3: 0.5126 - val_recall_3: 0.5514\n",
      "Epoch 1046/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5266 - acc: 0.1835 - precision_3: 0.7642 - recall_3: 0.1906 - val_loss: 1.5148 - val_acc: 0.4703 - val_precision_3: 0.5102 - val_recall_3: 0.5405\n",
      "Epoch 1047/2000\n",
      "85/85 [==============================] - 0s 529us/sample - loss: 1.5460 - acc: 0.1647 - precision_3: 0.6154 - recall_3: 0.1694 - val_loss: 1.5159 - val_acc: 0.4703 - val_precision_3: 0.5052 - val_recall_3: 0.5297\n",
      "Epoch 1048/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5228 - acc: 0.2071 - precision_3: 0.6667 - recall_3: 0.2118 - val_loss: 1.5170 - val_acc: 0.4595 - val_precision_3: 0.5052 - val_recall_3: 0.5243\n",
      "Epoch 1049/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5101 - acc: 0.2282 - precision_3: 0.7206 - recall_3: 0.2306 - val_loss: 1.5170 - val_acc: 0.4649 - val_precision_3: 0.5104 - val_recall_3: 0.5297\n",
      "Epoch 1050/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5130 - acc: 0.2094 - precision_3: 0.7561 - recall_3: 0.2188 - val_loss: 1.5157 - val_acc: 0.4703 - val_precision_3: 0.5153 - val_recall_3: 0.5459\n",
      "Epoch 1051/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5456 - acc: 0.1576 - precision_3: 0.6442 - recall_3: 0.1576 - val_loss: 1.5145 - val_acc: 0.4865 - val_precision_3: 0.5176 - val_recall_3: 0.5568\n",
      "Epoch 1052/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5288 - acc: 0.2024 - precision_3: 0.7748 - recall_3: 0.2024 - val_loss: 1.5152 - val_acc: 0.4865 - val_precision_3: 0.5258 - val_recall_3: 0.5514\n",
      "Epoch 1053/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5219 - acc: 0.2024 - precision_3: 0.7438 - recall_3: 0.2118 - val_loss: 1.5178 - val_acc: 0.4595 - val_precision_3: 0.5233 - val_recall_3: 0.5459\n",
      "Epoch 1054/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5355 - acc: 0.1741 - precision_3: 0.6754 - recall_3: 0.1812 - val_loss: 1.5176 - val_acc: 0.4703 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 1055/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5132 - acc: 0.2141 - precision_3: 0.7252 - recall_3: 0.2235 - val_loss: 1.5169 - val_acc: 0.4811 - val_precision_3: 0.5204 - val_recall_3: 0.5514\n",
      "Epoch 1056/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5147 - acc: 0.2141 - precision_3: 0.7323 - recall_3: 0.2188 - val_loss: 1.5155 - val_acc: 0.4811 - val_precision_3: 0.5204 - val_recall_3: 0.5514\n",
      "Epoch 1057/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5158 - acc: 0.2141 - precision_3: 0.7287 - recall_3: 0.2212 - val_loss: 1.5136 - val_acc: 0.4811 - val_precision_3: 0.5255 - val_recall_3: 0.5568\n",
      "Epoch 1058/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5135 - acc: 0.2259 - precision_3: 0.7101 - recall_3: 0.2306 - val_loss: 1.5143 - val_acc: 0.4703 - val_precision_3: 0.5179 - val_recall_3: 0.5459\n",
      "Epoch 1059/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5148 - acc: 0.2141 - precision_3: 0.7623 - recall_3: 0.2188 - val_loss: 1.5142 - val_acc: 0.4703 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 1060/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5163 - acc: 0.2141 - precision_3: 0.7209 - recall_3: 0.2188 - val_loss: 1.5159 - val_acc: 0.4703 - val_precision_3: 0.5181 - val_recall_3: 0.5405\n",
      "Epoch 1061/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5369 - acc: 0.1788 - precision_3: 0.6695 - recall_3: 0.1859 - val_loss: 1.5177 - val_acc: 0.4757 - val_precision_3: 0.5178 - val_recall_3: 0.5514\n",
      "Epoch 1062/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5215 - acc: 0.2118 - precision_3: 0.6992 - recall_3: 0.2188 - val_loss: 1.5171 - val_acc: 0.4757 - val_precision_3: 0.5178 - val_recall_3: 0.5514\n",
      "Epoch 1063/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5343 - acc: 0.1835 - precision_3: 0.6723 - recall_3: 0.1882 - val_loss: 1.5137 - val_acc: 0.4811 - val_precision_3: 0.5206 - val_recall_3: 0.5459\n",
      "Epoch 1064/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5265 - acc: 0.1906 - precision_3: 0.6975 - recall_3: 0.1953 - val_loss: 1.5119 - val_acc: 0.4811 - val_precision_3: 0.5204 - val_recall_3: 0.5514\n",
      "Epoch 1065/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5204 - acc: 0.2071 - precision_3: 0.7398 - recall_3: 0.2141 - val_loss: 1.5097 - val_acc: 0.4865 - val_precision_3: 0.5202 - val_recall_3: 0.5568\n",
      "Epoch 1066/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5306 - acc: 0.1788 - precision_3: 0.7222 - recall_3: 0.1835 - val_loss: 1.5083 - val_acc: 0.4865 - val_precision_3: 0.5255 - val_recall_3: 0.5568\n",
      "Epoch 1067/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5355 - acc: 0.1835 - precision_3: 0.6930 - recall_3: 0.1859 - val_loss: 1.5061 - val_acc: 0.4919 - val_precision_3: 0.5226 - val_recall_3: 0.5622\n",
      "Epoch 1068/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5232 - acc: 0.2047 - precision_3: 0.7273 - recall_3: 0.2071 - val_loss: 1.5022 - val_acc: 0.4973 - val_precision_3: 0.5124 - val_recall_3: 0.5568\n",
      "Epoch 1069/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5239 - acc: 0.2118 - precision_3: 0.7165 - recall_3: 0.2141 - val_loss: 1.5003 - val_acc: 0.5027 - val_precision_3: 0.5122 - val_recall_3: 0.5676\n",
      "Epoch 1070/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5247 - acc: 0.1953 - precision_3: 0.7059 - recall_3: 0.1976 - val_loss: 1.5000 - val_acc: 0.4973 - val_precision_3: 0.5095 - val_recall_3: 0.5784\n",
      "Epoch 1071/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5471 - acc: 0.1506 - precision_3: 0.6600 - recall_3: 0.1553 - val_loss: 1.5001 - val_acc: 0.4973 - val_precision_3: 0.5121 - val_recall_3: 0.5730\n",
      "Epoch 1072/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5262 - acc: 0.1976 - precision_3: 0.7049 - recall_3: 0.2024 - val_loss: 1.5018 - val_acc: 0.4919 - val_precision_3: 0.5096 - val_recall_3: 0.5730\n",
      "Epoch 1073/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5415 - acc: 0.1694 - precision_3: 0.6606 - recall_3: 0.1694 - val_loss: 1.5034 - val_acc: 0.4865 - val_precision_3: 0.5144 - val_recall_3: 0.5784\n",
      "Epoch 1074/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5201 - acc: 0.2047 - precision_3: 0.7295 - recall_3: 0.2094 - val_loss: 1.5048 - val_acc: 0.4865 - val_precision_3: 0.5121 - val_recall_3: 0.5730\n",
      "Epoch 1075/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5218 - acc: 0.2024 - precision_3: 0.7395 - recall_3: 0.2071 - val_loss: 1.5039 - val_acc: 0.4973 - val_precision_3: 0.5096 - val_recall_3: 0.5730\n",
      "Epoch 1076/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5336 - acc: 0.1788 - precision_3: 0.7196 - recall_3: 0.1812 - val_loss: 1.5035 - val_acc: 0.5027 - val_precision_3: 0.5120 - val_recall_3: 0.5784\n",
      "Epoch 1077/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5356 - acc: 0.1812 - precision_3: 0.6452 - recall_3: 0.1882 - val_loss: 1.5017 - val_acc: 0.4973 - val_precision_3: 0.5047 - val_recall_3: 0.5784\n",
      "Epoch 1078/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5345 - acc: 0.1859 - precision_3: 0.6107 - recall_3: 0.1882 - val_loss: 1.5002 - val_acc: 0.5027 - val_precision_3: 0.5071 - val_recall_3: 0.5784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1079/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5463 - acc: 0.1435 - precision_3: 0.7033 - recall_3: 0.1506 - val_loss: 1.4992 - val_acc: 0.5027 - val_precision_3: 0.5047 - val_recall_3: 0.5784\n",
      "Epoch 1080/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5273 - acc: 0.1976 - precision_3: 0.6615 - recall_3: 0.2024 - val_loss: 1.4988 - val_acc: 0.5081 - val_precision_3: 0.5023 - val_recall_3: 0.5784\n",
      "Epoch 1081/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5190 - acc: 0.2000 - precision_3: 0.7087 - recall_3: 0.2118 - val_loss: 1.5004 - val_acc: 0.5081 - val_precision_3: 0.5047 - val_recall_3: 0.5784\n",
      "Epoch 1082/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5184 - acc: 0.2212 - precision_3: 0.7007 - recall_3: 0.2259 - val_loss: 1.5039 - val_acc: 0.4919 - val_precision_3: 0.5024 - val_recall_3: 0.5622\n",
      "Epoch 1083/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5310 - acc: 0.1859 - precision_3: 0.6807 - recall_3: 0.1906 - val_loss: 1.5084 - val_acc: 0.4865 - val_precision_3: 0.5000 - val_recall_3: 0.5514\n",
      "Epoch 1084/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5296 - acc: 0.1882 - precision_3: 0.6639 - recall_3: 0.1906 - val_loss: 1.5129 - val_acc: 0.4811 - val_precision_3: 0.5025 - val_recall_3: 0.5351\n",
      "Epoch 1085/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5192 - acc: 0.2000 - precision_3: 0.7459 - recall_3: 0.2141 - val_loss: 1.5147 - val_acc: 0.4703 - val_precision_3: 0.5025 - val_recall_3: 0.5351\n",
      "Epoch 1086/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5344 - acc: 0.1741 - precision_3: 0.6696 - recall_3: 0.1765 - val_loss: 1.5153 - val_acc: 0.4703 - val_precision_3: 0.5051 - val_recall_3: 0.5351\n",
      "Epoch 1087/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5443 - acc: 0.1553 - precision_3: 0.6355 - recall_3: 0.1600 - val_loss: 1.5159 - val_acc: 0.4595 - val_precision_3: 0.5051 - val_recall_3: 0.5351\n",
      "Epoch 1088/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5302 - acc: 0.1812 - precision_3: 0.7117 - recall_3: 0.1859 - val_loss: 1.5151 - val_acc: 0.4649 - val_precision_3: 0.5077 - val_recall_3: 0.5351\n",
      "Epoch 1089/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5278 - acc: 0.1906 - precision_3: 0.7179 - recall_3: 0.1976 - val_loss: 1.5125 - val_acc: 0.4649 - val_precision_3: 0.5051 - val_recall_3: 0.5351\n",
      "Epoch 1090/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5158 - acc: 0.2141 - precision_3: 0.7323 - recall_3: 0.2188 - val_loss: 1.5120 - val_acc: 0.4649 - val_precision_3: 0.5025 - val_recall_3: 0.5351\n",
      "Epoch 1091/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5405 - acc: 0.1624 - precision_3: 0.6961 - recall_3: 0.1671 - val_loss: 1.5117 - val_acc: 0.4649 - val_precision_3: 0.5076 - val_recall_3: 0.5405\n",
      "Epoch 1092/2000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.5350 - acc: 0.1765 - precision_3: 0.6786 - recall_3: 0.1788 - val_loss: 1.5111 - val_acc: 0.4703 - val_precision_3: 0.4950 - val_recall_3: 0.5405\n",
      "Epoch 1093/2000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.5193 - acc: 0.2047 - precision_3: 0.7500 - recall_3: 0.2118 - val_loss: 1.5124 - val_acc: 0.4703 - val_precision_3: 0.4950 - val_recall_3: 0.5405\n",
      "Epoch 1094/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5175 - acc: 0.2141 - precision_3: 0.7339 - recall_3: 0.2141 - val_loss: 1.5135 - val_acc: 0.4703 - val_precision_3: 0.5025 - val_recall_3: 0.5405\n",
      "Epoch 1095/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5408 - acc: 0.1647 - precision_3: 0.6549 - recall_3: 0.1741 - val_loss: 1.5130 - val_acc: 0.4703 - val_precision_3: 0.5000 - val_recall_3: 0.5351\n",
      "Epoch 1096/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5202 - acc: 0.2094 - precision_3: 0.6791 - recall_3: 0.2141 - val_loss: 1.5115 - val_acc: 0.4757 - val_precision_3: 0.5050 - val_recall_3: 0.5459\n",
      "Epoch 1097/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5254 - acc: 0.2024 - precision_3: 0.6692 - recall_3: 0.2094 - val_loss: 1.5094 - val_acc: 0.4865 - val_precision_3: 0.5000 - val_recall_3: 0.5459\n",
      "Epoch 1098/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5304 - acc: 0.2000 - precision_3: 0.7167 - recall_3: 0.2024 - val_loss: 1.5093 - val_acc: 0.4919 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 1099/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5334 - acc: 0.1765 - precision_3: 0.6786 - recall_3: 0.1788 - val_loss: 1.5139 - val_acc: 0.4865 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 1100/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5464 - acc: 0.1412 - precision_3: 0.6923 - recall_3: 0.1482 - val_loss: 1.5155 - val_acc: 0.4865 - val_precision_3: 0.4976 - val_recall_3: 0.5514\n",
      "Epoch 1101/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5424 - acc: 0.1624 - precision_3: 0.6542 - recall_3: 0.1647 - val_loss: 1.5142 - val_acc: 0.4865 - val_precision_3: 0.5000 - val_recall_3: 0.5568\n",
      "Epoch 1102/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5142 - acc: 0.2141 - precision_3: 0.7176 - recall_3: 0.2212 - val_loss: 1.5129 - val_acc: 0.4919 - val_precision_3: 0.4976 - val_recall_3: 0.5568\n",
      "Epoch 1103/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5297 - acc: 0.1835 - precision_3: 0.7248 - recall_3: 0.1859 - val_loss: 1.5128 - val_acc: 0.4973 - val_precision_3: 0.5000 - val_recall_3: 0.5568\n",
      "Epoch 1104/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5302 - acc: 0.1929 - precision_3: 0.6484 - recall_3: 0.1953 - val_loss: 1.5131 - val_acc: 0.4919 - val_precision_3: 0.4976 - val_recall_3: 0.5514\n",
      "Epoch 1105/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5354 - acc: 0.1835 - precision_3: 0.6991 - recall_3: 0.1859 - val_loss: 1.5132 - val_acc: 0.4919 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 1106/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5167 - acc: 0.2047 - precision_3: 0.7807 - recall_3: 0.2094 - val_loss: 1.5132 - val_acc: 0.4865 - val_precision_3: 0.5075 - val_recall_3: 0.5459\n",
      "Epoch 1107/2000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.5234 - acc: 0.2024 - precision_3: 0.7227 - recall_3: 0.2024 - val_loss: 1.5154 - val_acc: 0.4757 - val_precision_3: 0.5026 - val_recall_3: 0.5297\n",
      "Epoch 1108/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5275 - acc: 0.1929 - precision_3: 0.6774 - recall_3: 0.1976 - val_loss: 1.5171 - val_acc: 0.4811 - val_precision_3: 0.5155 - val_recall_3: 0.5405\n",
      "Epoch 1109/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5417 - acc: 0.1741 - precision_3: 0.6607 - recall_3: 0.1741 - val_loss: 1.5182 - val_acc: 0.4757 - val_precision_3: 0.5051 - val_recall_3: 0.5351\n",
      "Epoch 1110/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5207 - acc: 0.2000 - precision_3: 0.7414 - recall_3: 0.2024 - val_loss: 1.5197 - val_acc: 0.4811 - val_precision_3: 0.5025 - val_recall_3: 0.5405\n",
      "Epoch 1111/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5319 - acc: 0.1812 - precision_3: 0.7117 - recall_3: 0.1859 - val_loss: 1.5198 - val_acc: 0.4811 - val_precision_3: 0.5051 - val_recall_3: 0.5405\n",
      "Epoch 1112/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5210 - acc: 0.2047 - precision_3: 0.7395 - recall_3: 0.2071 - val_loss: 1.5202 - val_acc: 0.4703 - val_precision_3: 0.5077 - val_recall_3: 0.5351\n",
      "Epoch 1113/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5120 - acc: 0.2353 - precision_3: 0.6986 - recall_3: 0.2400 - val_loss: 1.5193 - val_acc: 0.4703 - val_precision_3: 0.5077 - val_recall_3: 0.5351\n",
      "Epoch 1114/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5314 - acc: 0.1788 - precision_3: 0.7027 - recall_3: 0.1835 - val_loss: 1.5160 - val_acc: 0.4703 - val_precision_3: 0.5102 - val_recall_3: 0.5405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1115/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5095 - acc: 0.2353 - precision_3: 0.7214 - recall_3: 0.2376 - val_loss: 1.5140 - val_acc: 0.4703 - val_precision_3: 0.5126 - val_recall_3: 0.5514\n",
      "Epoch 1116/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5197 - acc: 0.2094 - precision_3: 0.7132 - recall_3: 0.2165 - val_loss: 1.5129 - val_acc: 0.4703 - val_precision_3: 0.5126 - val_recall_3: 0.5514\n",
      "Epoch 1117/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5148 - acc: 0.2188 - precision_3: 0.7111 - recall_3: 0.2259 - val_loss: 1.5125 - val_acc: 0.4703 - val_precision_3: 0.5124 - val_recall_3: 0.5568\n",
      "Epoch 1118/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5289 - acc: 0.1953 - precision_3: 0.6515 - recall_3: 0.2024 - val_loss: 1.5114 - val_acc: 0.4649 - val_precision_3: 0.5176 - val_recall_3: 0.5568\n",
      "Epoch 1119/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5232 - acc: 0.2000 - precision_3: 0.7456 - recall_3: 0.2000 - val_loss: 1.5085 - val_acc: 0.4703 - val_precision_3: 0.5202 - val_recall_3: 0.5568\n",
      "Epoch 1120/2000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.5395 - acc: 0.1718 - precision_3: 0.6333 - recall_3: 0.1788 - val_loss: 1.5064 - val_acc: 0.4811 - val_precision_3: 0.5176 - val_recall_3: 0.5568\n",
      "Epoch 1121/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5196 - acc: 0.2094 - precision_3: 0.7377 - recall_3: 0.2118 - val_loss: 1.5063 - val_acc: 0.4757 - val_precision_3: 0.5178 - val_recall_3: 0.5514\n",
      "Epoch 1122/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5345 - acc: 0.1741 - precision_3: 0.6754 - recall_3: 0.1812 - val_loss: 1.5060 - val_acc: 0.4703 - val_precision_3: 0.5179 - val_recall_3: 0.5459\n",
      "Epoch 1123/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5199 - acc: 0.1976 - precision_3: 0.7788 - recall_3: 0.2071 - val_loss: 1.5061 - val_acc: 0.4703 - val_precision_3: 0.5153 - val_recall_3: 0.5459\n",
      "Epoch 1124/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5174 - acc: 0.2118 - precision_3: 0.7266 - recall_3: 0.2188 - val_loss: 1.5068 - val_acc: 0.4649 - val_precision_3: 0.5050 - val_recall_3: 0.5459\n",
      "Epoch 1125/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5390 - acc: 0.1694 - precision_3: 0.6881 - recall_3: 0.1765 - val_loss: 1.5075 - val_acc: 0.4703 - val_precision_3: 0.5150 - val_recall_3: 0.5568\n",
      "Epoch 1126/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5370 - acc: 0.1788 - precision_3: 0.6937 - recall_3: 0.1812 - val_loss: 1.5056 - val_acc: 0.4703 - val_precision_3: 0.5000 - val_recall_3: 0.5459\n",
      "Epoch 1127/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5283 - acc: 0.1859 - precision_3: 0.6535 - recall_3: 0.1953 - val_loss: 1.5057 - val_acc: 0.4811 - val_precision_3: 0.5050 - val_recall_3: 0.5459\n",
      "Epoch 1128/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5483 - acc: 0.1529 - precision_3: 0.6415 - recall_3: 0.1600 - val_loss: 1.5061 - val_acc: 0.4811 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 1129/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5213 - acc: 0.2165 - precision_3: 0.6714 - recall_3: 0.2212 - val_loss: 1.5076 - val_acc: 0.4865 - val_precision_3: 0.5075 - val_recall_3: 0.5514\n",
      "Epoch 1130/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5225 - acc: 0.2000 - precision_3: 0.7236 - recall_3: 0.2094 - val_loss: 1.5091 - val_acc: 0.4865 - val_precision_3: 0.5126 - val_recall_3: 0.5514\n",
      "Epoch 1131/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5180 - acc: 0.2071 - precision_3: 0.7258 - recall_3: 0.2118 - val_loss: 1.5103 - val_acc: 0.4811 - val_precision_3: 0.5126 - val_recall_3: 0.5514\n",
      "Epoch 1132/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5312 - acc: 0.1835 - precision_3: 0.7018 - recall_3: 0.1882 - val_loss: 1.5092 - val_acc: 0.4757 - val_precision_3: 0.5076 - val_recall_3: 0.5405\n",
      "Epoch 1133/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5324 - acc: 0.1788 - precision_3: 0.7315 - recall_3: 0.1859 - val_loss: 1.5095 - val_acc: 0.4757 - val_precision_3: 0.5049 - val_recall_3: 0.5568\n",
      "Epoch 1134/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5250 - acc: 0.1953 - precision_3: 0.7094 - recall_3: 0.1953 - val_loss: 1.5087 - val_acc: 0.4703 - val_precision_3: 0.5075 - val_recall_3: 0.5514\n",
      "Epoch 1135/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5353 - acc: 0.1812 - precision_3: 0.6423 - recall_3: 0.1859 - val_loss: 1.5067 - val_acc: 0.4811 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 1136/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5209 - acc: 0.2024 - precision_3: 0.7333 - recall_3: 0.2071 - val_loss: 1.5065 - val_acc: 0.4757 - val_precision_3: 0.5000 - val_recall_3: 0.5405\n",
      "Epoch 1137/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5362 - acc: 0.1765 - precision_3: 0.7037 - recall_3: 0.1788 - val_loss: 1.5061 - val_acc: 0.4703 - val_precision_3: 0.5000 - val_recall_3: 0.5459\n",
      "Epoch 1138/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5140 - acc: 0.2235 - precision_3: 0.6978 - recall_3: 0.2282 - val_loss: 1.5061 - val_acc: 0.4757 - val_precision_3: 0.4951 - val_recall_3: 0.5459\n",
      "Epoch 1139/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5261 - acc: 0.1953 - precision_3: 0.7131 - recall_3: 0.2047 - val_loss: 1.5059 - val_acc: 0.4757 - val_precision_3: 0.4976 - val_recall_3: 0.5514\n",
      "Epoch 1140/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5214 - acc: 0.2094 - precision_3: 0.7031 - recall_3: 0.2118 - val_loss: 1.5081 - val_acc: 0.4703 - val_precision_3: 0.5024 - val_recall_3: 0.5568\n",
      "Epoch 1141/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5259 - acc: 0.1906 - precision_3: 0.7179 - recall_3: 0.1976 - val_loss: 1.5105 - val_acc: 0.4757 - val_precision_3: 0.5072 - val_recall_3: 0.5676\n",
      "Epoch 1142/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5277 - acc: 0.1906 - precision_3: 0.7155 - recall_3: 0.1953 - val_loss: 1.5134 - val_acc: 0.4703 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1143/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5257 - acc: 0.1976 - precision_3: 0.7414 - recall_3: 0.2024 - val_loss: 1.5135 - val_acc: 0.4757 - val_precision_3: 0.5024 - val_recall_3: 0.5622\n",
      "Epoch 1144/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5204 - acc: 0.2094 - precision_3: 0.7500 - recall_3: 0.2118 - val_loss: 1.5112 - val_acc: 0.4703 - val_precision_3: 0.5000 - val_recall_3: 0.5622\n",
      "Epoch 1145/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5328 - acc: 0.1765 - precision_3: 0.7027 - recall_3: 0.1835 - val_loss: 1.5109 - val_acc: 0.4703 - val_precision_3: 0.4952 - val_recall_3: 0.5622\n",
      "Epoch 1146/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5415 - acc: 0.1671 - precision_3: 0.6283 - recall_3: 0.1671 - val_loss: 1.5118 - val_acc: 0.4757 - val_precision_3: 0.5000 - val_recall_3: 0.5676\n",
      "Epoch 1147/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5351 - acc: 0.1812 - precision_3: 0.6555 - recall_3: 0.1835 - val_loss: 1.5121 - val_acc: 0.4811 - val_precision_3: 0.4953 - val_recall_3: 0.5676\n",
      "Epoch 1148/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5303 - acc: 0.1835 - precision_3: 0.7156 - recall_3: 0.1835 - val_loss: 1.5131 - val_acc: 0.4757 - val_precision_3: 0.4976 - val_recall_3: 0.5568\n",
      "Epoch 1149/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5461 - acc: 0.1600 - precision_3: 0.6330 - recall_3: 0.1624 - val_loss: 1.5118 - val_acc: 0.4811 - val_precision_3: 0.4952 - val_recall_3: 0.5568\n",
      "Epoch 1150/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5229 - acc: 0.1953 - precision_3: 0.7350 - recall_3: 0.2024 - val_loss: 1.5104 - val_acc: 0.4757 - val_precision_3: 0.5000 - val_recall_3: 0.5514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1151/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.4970 - acc: 0.2471 - precision_3: 0.7535 - recall_3: 0.2518 - val_loss: 1.5095 - val_acc: 0.4757 - val_precision_3: 0.5024 - val_recall_3: 0.5568\n",
      "Epoch 1152/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5350 - acc: 0.1859 - precision_3: 0.6585 - recall_3: 0.1906 - val_loss: 1.5082 - val_acc: 0.4811 - val_precision_3: 0.4976 - val_recall_3: 0.5568\n",
      "Epoch 1153/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5205 - acc: 0.2024 - precision_3: 0.7350 - recall_3: 0.2024 - val_loss: 1.5070 - val_acc: 0.4919 - val_precision_3: 0.5048 - val_recall_3: 0.5676\n",
      "Epoch 1154/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5342 - acc: 0.1765 - precision_3: 0.6754 - recall_3: 0.1812 - val_loss: 1.5059 - val_acc: 0.5027 - val_precision_3: 0.5072 - val_recall_3: 0.5730\n",
      "Epoch 1155/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5382 - acc: 0.1647 - precision_3: 0.6952 - recall_3: 0.1718 - val_loss: 1.5059 - val_acc: 0.5027 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1156/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5303 - acc: 0.1906 - precision_3: 0.6508 - recall_3: 0.1929 - val_loss: 1.5076 - val_acc: 0.5027 - val_precision_3: 0.5024 - val_recall_3: 0.5622\n",
      "Epoch 1157/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5299 - acc: 0.1929 - precision_3: 0.6296 - recall_3: 0.2000 - val_loss: 1.5100 - val_acc: 0.4973 - val_precision_3: 0.5024 - val_recall_3: 0.5568\n",
      "Epoch 1158/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5312 - acc: 0.1835 - precision_3: 0.6864 - recall_3: 0.1906 - val_loss: 1.5089 - val_acc: 0.4919 - val_precision_3: 0.5096 - val_recall_3: 0.5730\n",
      "Epoch 1159/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5349 - acc: 0.1718 - precision_3: 0.7212 - recall_3: 0.1765 - val_loss: 1.5074 - val_acc: 0.4919 - val_precision_3: 0.5048 - val_recall_3: 0.5676\n",
      "Epoch 1160/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5275 - acc: 0.1976 - precision_3: 0.6719 - recall_3: 0.2024 - val_loss: 1.5054 - val_acc: 0.4865 - val_precision_3: 0.4976 - val_recall_3: 0.5622\n",
      "Epoch 1161/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5234 - acc: 0.1976 - precision_3: 0.7391 - recall_3: 0.2000 - val_loss: 1.5052 - val_acc: 0.4865 - val_precision_3: 0.5072 - val_recall_3: 0.5676\n",
      "Epoch 1162/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5187 - acc: 0.2118 - precision_3: 0.6985 - recall_3: 0.2235 - val_loss: 1.5052 - val_acc: 0.4919 - val_precision_3: 0.5097 - val_recall_3: 0.5676\n",
      "Epoch 1163/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5316 - acc: 0.1835 - precision_3: 0.6810 - recall_3: 0.1859 - val_loss: 1.5037 - val_acc: 0.4919 - val_precision_3: 0.5072 - val_recall_3: 0.5676\n",
      "Epoch 1164/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5217 - acc: 0.2141 - precision_3: 0.7109 - recall_3: 0.2141 - val_loss: 1.5024 - val_acc: 0.4973 - val_precision_3: 0.5072 - val_recall_3: 0.5676\n",
      "Epoch 1165/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5385 - acc: 0.1875 - precision_3: 0.6250 - recall_3: 0.18 - 0s 528us/sample - loss: 1.5127 - acc: 0.2212 - precision_3: 0.7252 - recall_3: 0.2235 - val_loss: 1.4999 - val_acc: 0.4919 - val_precision_3: 0.5048 - val_recall_3: 0.5676\n",
      "Epoch 1166/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5326 - acc: 0.1812 - precision_3: 0.6724 - recall_3: 0.1835 - val_loss: 1.4997 - val_acc: 0.4973 - val_precision_3: 0.5071 - val_recall_3: 0.5784\n",
      "Epoch 1167/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5159 - acc: 0.2094 - precision_3: 0.7541 - recall_3: 0.2165 - val_loss: 1.5003 - val_acc: 0.5027 - val_precision_3: 0.5071 - val_recall_3: 0.5784\n",
      "Epoch 1168/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5307 - acc: 0.1929 - precision_3: 0.6800 - recall_3: 0.2000 - val_loss: 1.4999 - val_acc: 0.5027 - val_precision_3: 0.5070 - val_recall_3: 0.5838\n",
      "Epoch 1169/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5317 - acc: 0.1859 - precision_3: 0.7207 - recall_3: 0.1882 - val_loss: 1.4995 - val_acc: 0.5081 - val_precision_3: 0.5143 - val_recall_3: 0.5838\n",
      "Epoch 1170/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5245 - acc: 0.2000 - precision_3: 0.7265 - recall_3: 0.2000 - val_loss: 1.4989 - val_acc: 0.5081 - val_precision_3: 0.5071 - val_recall_3: 0.5784\n",
      "Epoch 1171/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5037 - acc: 0.2400 - precision_3: 0.7907 - recall_3: 0.2400 - val_loss: 1.4985 - val_acc: 0.5027 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1172/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5139 - acc: 0.2235 - precision_3: 0.6985 - recall_3: 0.2235 - val_loss: 1.4973 - val_acc: 0.5027 - val_precision_3: 0.5072 - val_recall_3: 0.5676\n",
      "Epoch 1173/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.4979 - acc: 0.2400 - precision_3: 0.8000 - recall_3: 0.2447 - val_loss: 1.4961 - val_acc: 0.4973 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 1174/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5317 - acc: 0.1859 - precision_3: 0.6810 - recall_3: 0.1859 - val_loss: 1.4963 - val_acc: 0.5027 - val_precision_3: 0.5024 - val_recall_3: 0.5568\n",
      "Epoch 1175/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5303 - acc: 0.1812 - precision_3: 0.6897 - recall_3: 0.1882 - val_loss: 1.4978 - val_acc: 0.4973 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1176/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5472 - acc: 0.1529 - precision_3: 0.6569 - recall_3: 0.1576 - val_loss: 1.4982 - val_acc: 0.4973 - val_precision_3: 0.5122 - val_recall_3: 0.5676\n",
      "Epoch 1177/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5228 - acc: 0.1929 - precision_3: 0.6885 - recall_3: 0.1976 - val_loss: 1.4995 - val_acc: 0.4973 - val_precision_3: 0.5147 - val_recall_3: 0.5676\n",
      "Epoch 1178/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5142 - acc: 0.2141 - precision_3: 0.7561 - recall_3: 0.2188 - val_loss: 1.5013 - val_acc: 0.5081 - val_precision_3: 0.5171 - val_recall_3: 0.5730\n",
      "Epoch 1179/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5327 - acc: 0.1835 - precision_3: 0.6500 - recall_3: 0.1835 - val_loss: 1.5034 - val_acc: 0.5189 - val_precision_3: 0.5121 - val_recall_3: 0.5730\n",
      "Epoch 1180/2000\n",
      "85/85 [==============================] - 0s 562us/sample - loss: 1.5106 - acc: 0.2165 - precision_3: 0.7705 - recall_3: 0.2212 - val_loss: 1.5061 - val_acc: 0.4973 - val_precision_3: 0.5196 - val_recall_3: 0.5730\n",
      "Epoch 1181/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5135 - acc: 0.2188 - precision_3: 0.7460 - recall_3: 0.2212 - val_loss: 1.5079 - val_acc: 0.4973 - val_precision_3: 0.5224 - val_recall_3: 0.5676\n",
      "Epoch 1182/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5206 - acc: 0.2047 - precision_3: 0.7120 - recall_3: 0.2094 - val_loss: 1.5076 - val_acc: 0.4919 - val_precision_3: 0.5174 - val_recall_3: 0.5622\n",
      "Epoch 1183/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5218 - acc: 0.2000 - precision_3: 0.7355 - recall_3: 0.2094 - val_loss: 1.5082 - val_acc: 0.4865 - val_precision_3: 0.5149 - val_recall_3: 0.5622\n",
      "Epoch 1184/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5365 - acc: 0.1835 - precision_3: 0.6529 - recall_3: 0.1859 - val_loss: 1.5092 - val_acc: 0.4865 - val_precision_3: 0.5098 - val_recall_3: 0.5622\n",
      "Epoch 1185/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5290 - acc: 0.1906 - precision_3: 0.6949 - recall_3: 0.1929 - val_loss: 1.5103 - val_acc: 0.4865 - val_precision_3: 0.5198 - val_recall_3: 0.5676\n",
      "Epoch 1186/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5310 - acc: 0.1859 - precision_3: 0.7297 - recall_3: 0.1906 - val_loss: 1.5130 - val_acc: 0.4757 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 1187/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5261 - acc: 0.1953 - precision_3: 0.7304 - recall_3: 0.1976 - val_loss: 1.5151 - val_acc: 0.4703 - val_precision_3: 0.5204 - val_recall_3: 0.5514\n",
      "Epoch 1188/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5255 - acc: 0.1882 - precision_3: 0.7009 - recall_3: 0.1929 - val_loss: 1.5171 - val_acc: 0.4865 - val_precision_3: 0.5333 - val_recall_3: 0.5622\n",
      "Epoch 1189/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5240 - acc: 0.1882 - precision_3: 0.7368 - recall_3: 0.1976 - val_loss: 1.5170 - val_acc: 0.4757 - val_precision_3: 0.5228 - val_recall_3: 0.5568\n",
      "Epoch 1190/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5309 - acc: 0.1875 - precision_3: 0.7143 - recall_3: 0.18 - 0s 517us/sample - loss: 1.5429 - acc: 0.1624 - precision_3: 0.6832 - recall_3: 0.1624 - val_loss: 1.5159 - val_acc: 0.4973 - val_precision_3: 0.5250 - val_recall_3: 0.5676\n",
      "Epoch 1191/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5153 - acc: 0.2250 - precision_3: 0.6923 - recall_3: 0.22 - 0s 505us/sample - loss: 1.5096 - acc: 0.2188 - precision_3: 0.7698 - recall_3: 0.2282 - val_loss: 1.5161 - val_acc: 0.4919 - val_precision_3: 0.5224 - val_recall_3: 0.5676\n",
      "Epoch 1192/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5166 - acc: 0.2165 - precision_3: 0.7603 - recall_3: 0.2165 - val_loss: 1.5161 - val_acc: 0.4919 - val_precision_3: 0.5224 - val_recall_3: 0.5676\n",
      "Epoch 1193/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5130 - acc: 0.2165 - precision_3: 0.7323 - recall_3: 0.2188 - val_loss: 1.5157 - val_acc: 0.4919 - val_precision_3: 0.5176 - val_recall_3: 0.5568\n",
      "Epoch 1194/2000\n",
      "85/85 [==============================] - 0s 529us/sample - loss: 1.5031 - acc: 0.2400 - precision_3: 0.7357 - recall_3: 0.2424 - val_loss: 1.5143 - val_acc: 0.4919 - val_precision_3: 0.5198 - val_recall_3: 0.5676\n",
      "Epoch 1195/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5194 - acc: 0.2047 - precision_3: 0.7077 - recall_3: 0.2165 - val_loss: 1.5135 - val_acc: 0.4919 - val_precision_3: 0.5172 - val_recall_3: 0.5676\n",
      "Epoch 1196/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5163 - acc: 0.2024 - precision_3: 0.7360 - recall_3: 0.2165 - val_loss: 1.5113 - val_acc: 0.4865 - val_precision_3: 0.5122 - val_recall_3: 0.5676\n",
      "Epoch 1197/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5204 - acc: 0.2000 - precision_3: 0.6967 - recall_3: 0.2000 - val_loss: 1.5099 - val_acc: 0.4919 - val_precision_3: 0.5245 - val_recall_3: 0.5784\n",
      "Epoch 1198/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5304 - acc: 0.1882 - precision_3: 0.6723 - recall_3: 0.1882 - val_loss: 1.5102 - val_acc: 0.4865 - val_precision_3: 0.5169 - val_recall_3: 0.5784\n",
      "Epoch 1199/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5238 - acc: 0.1906 - precision_3: 0.7016 - recall_3: 0.2047 - val_loss: 1.5105 - val_acc: 0.4811 - val_precision_3: 0.5146 - val_recall_3: 0.5730\n",
      "Epoch 1200/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5042 - acc: 0.2518 - precision_3: 0.7347 - recall_3: 0.2541 - val_loss: 1.5111 - val_acc: 0.4811 - val_precision_3: 0.5171 - val_recall_3: 0.5730\n",
      "Epoch 1201/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5329 - acc: 0.1765 - precision_3: 0.6723 - recall_3: 0.1882 - val_loss: 1.5126 - val_acc: 0.4811 - val_precision_3: 0.5122 - val_recall_3: 0.5676\n",
      "Epoch 1202/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5169 - acc: 0.2094 - precision_3: 0.7603 - recall_3: 0.2165 - val_loss: 1.5164 - val_acc: 0.4811 - val_precision_3: 0.5000 - val_recall_3: 0.5514\n",
      "Epoch 1203/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5129 - acc: 0.2118 - precision_3: 0.7797 - recall_3: 0.2165 - val_loss: 1.5186 - val_acc: 0.4595 - val_precision_3: 0.4851 - val_recall_3: 0.5297\n",
      "Epoch 1204/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5367 - acc: 0.1671 - precision_3: 0.7143 - recall_3: 0.1765 - val_loss: 1.5188 - val_acc: 0.4595 - val_precision_3: 0.4877 - val_recall_3: 0.5351\n",
      "Epoch 1205/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5154 - acc: 0.2118 - precision_3: 0.7459 - recall_3: 0.2141 - val_loss: 1.5173 - val_acc: 0.4757 - val_precision_3: 0.4878 - val_recall_3: 0.5405\n",
      "Epoch 1206/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5279 - acc: 0.1976 - precision_3: 0.6641 - recall_3: 0.2000 - val_loss: 1.5161 - val_acc: 0.4757 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1207/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5320 - acc: 0.1835 - precision_3: 0.6695 - recall_3: 0.1859 - val_loss: 1.5154 - val_acc: 0.4757 - val_precision_3: 0.4879 - val_recall_3: 0.5459\n",
      "Epoch 1208/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5283 - acc: 0.1953 - precision_3: 0.6917 - recall_3: 0.1953 - val_loss: 1.5154 - val_acc: 0.4757 - val_precision_3: 0.4928 - val_recall_3: 0.5514\n",
      "Epoch 1209/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5129 - acc: 0.2118 - precision_3: 0.7541 - recall_3: 0.2165 - val_loss: 1.5143 - val_acc: 0.4757 - val_precision_3: 0.5000 - val_recall_3: 0.5514\n",
      "Epoch 1210/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5222 - acc: 0.2024 - precision_3: 0.6767 - recall_3: 0.2118 - val_loss: 1.5125 - val_acc: 0.4865 - val_precision_3: 0.4976 - val_recall_3: 0.5622\n",
      "Epoch 1211/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5304 - acc: 0.1929 - precision_3: 0.6942 - recall_3: 0.1976 - val_loss: 1.5141 - val_acc: 0.4811 - val_precision_3: 0.4904 - val_recall_3: 0.5514\n",
      "Epoch 1212/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5244 - acc: 0.2024 - precision_3: 0.6960 - recall_3: 0.2047 - val_loss: 1.5130 - val_acc: 0.4703 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1213/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5193 - acc: 0.2047 - precision_3: 0.7377 - recall_3: 0.2118 - val_loss: 1.5131 - val_acc: 0.4757 - val_precision_3: 0.4860 - val_recall_3: 0.5622\n",
      "Epoch 1214/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5275 - acc: 0.1882 - precision_3: 0.7232 - recall_3: 0.1906 - val_loss: 1.5135 - val_acc: 0.4757 - val_precision_3: 0.4793 - val_recall_3: 0.5622\n",
      "Epoch 1215/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5336 - acc: 0.1835 - precision_3: 0.6752 - recall_3: 0.1859 - val_loss: 1.5160 - val_acc: 0.4811 - val_precision_3: 0.4861 - val_recall_3: 0.5676\n",
      "Epoch 1216/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5256 - acc: 0.2000 - precision_3: 0.6875 - recall_3: 0.2071 - val_loss: 1.5183 - val_acc: 0.4703 - val_precision_3: 0.4811 - val_recall_3: 0.5514\n",
      "Epoch 1217/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5194 - acc: 0.2071 - precision_3: 0.7154 - recall_3: 0.2071 - val_loss: 1.5192 - val_acc: 0.4649 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1218/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5337 - acc: 0.1741 - precision_3: 0.7196 - recall_3: 0.1812 - val_loss: 1.5198 - val_acc: 0.4703 - val_precision_3: 0.4882 - val_recall_3: 0.5568\n",
      "Epoch 1219/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5208 - acc: 0.1976 - precision_3: 0.7273 - recall_3: 0.2071 - val_loss: 1.5178 - val_acc: 0.4649 - val_precision_3: 0.4905 - val_recall_3: 0.5568\n",
      "Epoch 1220/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5246 - acc: 0.1929 - precision_3: 0.6803 - recall_3: 0.1953 - val_loss: 1.5159 - val_acc: 0.4811 - val_precision_3: 0.4929 - val_recall_3: 0.5622\n",
      "Epoch 1221/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5164 - acc: 0.2118 - precision_3: 0.7845 - recall_3: 0.2141 - val_loss: 1.5138 - val_acc: 0.4811 - val_precision_3: 0.5000 - val_recall_3: 0.5622\n",
      "Epoch 1222/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5362 - acc: 0.1718 - precision_3: 0.6981 - recall_3: 0.1741 - val_loss: 1.5121 - val_acc: 0.4811 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1223/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5266 - acc: 0.1953 - precision_3: 0.7190 - recall_3: 0.2047 - val_loss: 1.5114 - val_acc: 0.4811 - val_precision_3: 0.5024 - val_recall_3: 0.5622\n",
      "Epoch 1224/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5485 - acc: 0.1625 - precision_3: 0.6842 - recall_3: 0.16 - 0s 540us/sample - loss: 1.5329 - acc: 0.1741 - precision_3: 0.6875 - recall_3: 0.1812 - val_loss: 1.5121 - val_acc: 0.4811 - val_precision_3: 0.5024 - val_recall_3: 0.5622\n",
      "Epoch 1225/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5173 - acc: 0.2141 - precision_3: 0.7583 - recall_3: 0.2141 - val_loss: 1.5135 - val_acc: 0.4703 - val_precision_3: 0.5000 - val_recall_3: 0.5568\n",
      "Epoch 1226/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5270 - acc: 0.1859 - precision_3: 0.7193 - recall_3: 0.1929 - val_loss: 1.5152 - val_acc: 0.4703 - val_precision_3: 0.5000 - val_recall_3: 0.5568\n",
      "Epoch 1227/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5482 - acc: 0.1529 - precision_3: 0.6471 - recall_3: 0.1553 - val_loss: 1.5152 - val_acc: 0.4649 - val_precision_3: 0.5000 - val_recall_3: 0.5514\n",
      "Epoch 1228/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5143 - acc: 0.2165 - precision_3: 0.7231 - recall_3: 0.2212 - val_loss: 1.5133 - val_acc: 0.4757 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 1229/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5279 - acc: 0.1929 - precision_3: 0.7094 - recall_3: 0.1953 - val_loss: 1.5128 - val_acc: 0.4811 - val_precision_3: 0.4856 - val_recall_3: 0.5459\n",
      "Epoch 1230/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5161 - acc: 0.2071 - precision_3: 0.7542 - recall_3: 0.2094 - val_loss: 1.5115 - val_acc: 0.4811 - val_precision_3: 0.4856 - val_recall_3: 0.5459\n",
      "Epoch 1231/2000\n",
      "85/85 [==============================] - 0s 517us/sample - loss: 1.5307 - acc: 0.1788 - precision_3: 0.6964 - recall_3: 0.1835 - val_loss: 1.5101 - val_acc: 0.4811 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 1232/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5322 - acc: 0.1882 - precision_3: 0.6639 - recall_3: 0.1906 - val_loss: 1.5098 - val_acc: 0.4811 - val_precision_3: 0.4976 - val_recall_3: 0.5514\n",
      "Epoch 1233/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5312 - acc: 0.1882 - precision_3: 0.6640 - recall_3: 0.1953 - val_loss: 1.5093 - val_acc: 0.4865 - val_precision_3: 0.4976 - val_recall_3: 0.5514\n",
      "Epoch 1234/2000\n",
      "85/85 [==============================] - 0s 481us/sample - loss: 1.5274 - acc: 0.1882 - precision_3: 0.7500 - recall_3: 0.1906 - val_loss: 1.5091 - val_acc: 0.4919 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 1235/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5191 - acc: 0.1976 - precision_3: 0.7963 - recall_3: 0.2024 - val_loss: 1.5103 - val_acc: 0.4703 - val_precision_3: 0.4925 - val_recall_3: 0.5297\n",
      "Epoch 1236/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5268 - acc: 0.1976 - precision_3: 0.6992 - recall_3: 0.2024 - val_loss: 1.5125 - val_acc: 0.4703 - val_precision_3: 0.4901 - val_recall_3: 0.5351\n",
      "Epoch 1237/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5221 - acc: 0.2024 - precision_3: 0.7288 - recall_3: 0.2024 - val_loss: 1.5145 - val_acc: 0.4541 - val_precision_3: 0.4975 - val_recall_3: 0.5297\n",
      "Epoch 1238/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5606 - acc: 0.1250 - precision_3: 0.6471 - recall_3: 0.13 - 0s 505us/sample - loss: 1.5317 - acc: 0.1906 - precision_3: 0.6917 - recall_3: 0.1953 - val_loss: 1.5155 - val_acc: 0.4703 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 1239/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5293 - acc: 0.1859 - precision_3: 0.6864 - recall_3: 0.1906 - val_loss: 1.5164 - val_acc: 0.4595 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 1240/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5226 - acc: 0.2024 - precision_3: 0.7008 - recall_3: 0.2094 - val_loss: 1.5152 - val_acc: 0.4649 - val_precision_3: 0.5000 - val_recall_3: 0.5568\n",
      "Epoch 1241/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.4656 - acc: 0.3125 - precision_3: 0.7879 - recall_3: 0.32 - 0s 528us/sample - loss: 1.5253 - acc: 0.1929 - precision_3: 0.7119 - recall_3: 0.1976 - val_loss: 1.5138 - val_acc: 0.4649 - val_precision_3: 0.4952 - val_recall_3: 0.5568\n",
      "Epoch 1242/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5275 - acc: 0.1859 - precision_3: 0.7080 - recall_3: 0.1882 - val_loss: 1.5109 - val_acc: 0.4595 - val_precision_3: 0.4906 - val_recall_3: 0.5622\n",
      "Epoch 1243/2000\n",
      "85/85 [==============================] - 0s 529us/sample - loss: 1.5272 - acc: 0.2024 - precision_3: 0.6822 - recall_3: 0.2071 - val_loss: 1.5087 - val_acc: 0.4811 - val_precision_3: 0.4882 - val_recall_3: 0.5568\n",
      "Epoch 1244/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5113 - acc: 0.2212 - precision_3: 0.7520 - recall_3: 0.2212 - val_loss: 1.5054 - val_acc: 0.4703 - val_precision_3: 0.4883 - val_recall_3: 0.5622\n",
      "Epoch 1245/2000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.5337 - acc: 0.1625 - precision_3: 0.7647 - recall_3: 0.16 - 0s 505us/sample - loss: 1.5326 - acc: 0.1741 - precision_3: 0.6724 - recall_3: 0.1835 - val_loss: 1.5028 - val_acc: 0.4703 - val_precision_3: 0.4883 - val_recall_3: 0.5622\n",
      "Epoch 1246/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5477 - acc: 0.1553 - precision_3: 0.6389 - recall_3: 0.1624 - val_loss: 1.4996 - val_acc: 0.4757 - val_precision_3: 0.4883 - val_recall_3: 0.5622\n",
      "Epoch 1247/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5256 - acc: 0.1953 - precision_3: 0.7265 - recall_3: 0.2000 - val_loss: 1.4972 - val_acc: 0.4919 - val_precision_3: 0.4907 - val_recall_3: 0.5676\n",
      "Epoch 1248/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5067 - acc: 0.2282 - precision_3: 0.7615 - recall_3: 0.2329 - val_loss: 1.4954 - val_acc: 0.5027 - val_precision_3: 0.4907 - val_recall_3: 0.5676\n",
      "Epoch 1249/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5252 - acc: 0.2047 - precision_3: 0.7097 - recall_3: 0.2071 - val_loss: 1.4947 - val_acc: 0.5027 - val_precision_3: 0.4930 - val_recall_3: 0.5676\n",
      "Epoch 1250/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5247 - acc: 0.1976 - precision_3: 0.7434 - recall_3: 0.1976 - val_loss: 1.4956 - val_acc: 0.5027 - val_precision_3: 0.4907 - val_recall_3: 0.5676\n",
      "Epoch 1251/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5185 - acc: 0.2071 - precision_3: 0.7031 - recall_3: 0.2118 - val_loss: 1.4956 - val_acc: 0.4919 - val_precision_3: 0.4884 - val_recall_3: 0.5676\n",
      "Epoch 1252/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5285 - acc: 0.1953 - precision_3: 0.6800 - recall_3: 0.2000 - val_loss: 1.4969 - val_acc: 0.4757 - val_precision_3: 0.4884 - val_recall_3: 0.5676\n",
      "Epoch 1253/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5132 - acc: 0.2165 - precision_3: 0.7422 - recall_3: 0.2235 - val_loss: 1.4988 - val_acc: 0.4703 - val_precision_3: 0.4930 - val_recall_3: 0.5730\n",
      "Epoch 1254/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5079 - acc: 0.2259 - precision_3: 0.7538 - recall_3: 0.2306 - val_loss: 1.4996 - val_acc: 0.4865 - val_precision_3: 0.4955 - val_recall_3: 0.5892\n",
      "Epoch 1255/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5281 - acc: 0.1835 - precision_3: 0.7168 - recall_3: 0.1906 - val_loss: 1.5008 - val_acc: 0.4811 - val_precision_3: 0.5000 - val_recall_3: 0.5892\n",
      "Epoch 1256/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5273 - acc: 0.1976 - precision_3: 0.6935 - recall_3: 0.2024 - val_loss: 1.5017 - val_acc: 0.4757 - val_precision_3: 0.4977 - val_recall_3: 0.5892\n",
      "Epoch 1257/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5230 - acc: 0.2047 - precision_3: 0.6718 - recall_3: 0.2071 - val_loss: 1.5010 - val_acc: 0.4811 - val_precision_3: 0.4910 - val_recall_3: 0.5892\n",
      "Epoch 1258/2000\n",
      "85/85 [==============================] - 0s 493us/sample - loss: 1.5112 - acc: 0.2235 - precision_3: 0.7385 - recall_3: 0.2259 - val_loss: 1.5007 - val_acc: 0.4811 - val_precision_3: 0.4932 - val_recall_3: 0.5892\n",
      "Epoch 1259/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5380 - acc: 0.1694 - precision_3: 0.7115 - recall_3: 0.1741 - val_loss: 1.5010 - val_acc: 0.4865 - val_precision_3: 0.5000 - val_recall_3: 0.5892\n",
      "Epoch 1260/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5277 - acc: 0.1929 - precision_3: 0.7321 - recall_3: 0.1929 - val_loss: 1.5015 - val_acc: 0.4811 - val_precision_3: 0.4977 - val_recall_3: 0.5838\n",
      "Epoch 1261/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5265 - acc: 0.1859 - precision_3: 0.7080 - recall_3: 0.1882 - val_loss: 1.5021 - val_acc: 0.4865 - val_precision_3: 0.4977 - val_recall_3: 0.5838\n",
      "Epoch 1262/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5456 - acc: 0.1553 - precision_3: 0.6355 - recall_3: 0.1600 - val_loss: 1.5024 - val_acc: 0.4865 - val_precision_3: 0.4931 - val_recall_3: 0.5784\n",
      "Epoch 1263/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5233 - acc: 0.1882 - precision_3: 0.8020 - recall_3: 0.1906 - val_loss: 1.5035 - val_acc: 0.4811 - val_precision_3: 0.4977 - val_recall_3: 0.5838\n",
      "Epoch 1264/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5403 - acc: 0.1718 - precision_3: 0.6460 - recall_3: 0.1718 - val_loss: 1.5079 - val_acc: 0.4757 - val_precision_3: 0.5000 - val_recall_3: 0.5622\n",
      "Epoch 1265/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5130 - acc: 0.2071 - precision_3: 0.7480 - recall_3: 0.2235 - val_loss: 1.5111 - val_acc: 0.4595 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 1266/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5239 - acc: 0.2000 - precision_3: 0.7107 - recall_3: 0.2024 - val_loss: 1.5114 - val_acc: 0.4595 - val_precision_3: 0.5075 - val_recall_3: 0.5514\n",
      "Epoch 1267/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5366 - acc: 0.1671 - precision_3: 0.7087 - recall_3: 0.1718 - val_loss: 1.5088 - val_acc: 0.4703 - val_precision_3: 0.5098 - val_recall_3: 0.5622\n",
      "Epoch 1268/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5264 - acc: 0.1906 - precision_3: 0.7257 - recall_3: 0.1929 - val_loss: 1.5086 - val_acc: 0.4757 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1269/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5261 - acc: 0.1953 - precision_3: 0.7658 - recall_3: 0.2000 - val_loss: 1.5101 - val_acc: 0.4649 - val_precision_3: 0.5050 - val_recall_3: 0.5514\n",
      "Epoch 1270/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5282 - acc: 0.1859 - precision_3: 0.7407 - recall_3: 0.1882 - val_loss: 1.5112 - val_acc: 0.4757 - val_precision_3: 0.5050 - val_recall_3: 0.5514\n",
      "Epoch 1271/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5318 - acc: 0.1788 - precision_3: 0.7091 - recall_3: 0.1835 - val_loss: 1.5133 - val_acc: 0.4757 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 1272/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5181 - acc: 0.2094 - precision_3: 0.7731 - recall_3: 0.2165 - val_loss: 1.5138 - val_acc: 0.4757 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 1273/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5101 - acc: 0.2235 - precision_3: 0.7442 - recall_3: 0.2259 - val_loss: 1.5136 - val_acc: 0.4757 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 1274/2000\n",
      "85/85 [==============================] - 0s 516us/sample - loss: 1.5257 - acc: 0.1882 - precision_3: 0.7547 - recall_3: 0.1882 - val_loss: 1.5067 - val_acc: 0.4757 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1275/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5323 - acc: 0.1835 - precision_3: 0.6723 - recall_3: 0.1882 - val_loss: 1.5036 - val_acc: 0.4811 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1276/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5193 - acc: 0.2024 - precision_3: 0.7928 - recall_3: 0.2071 - val_loss: 1.5026 - val_acc: 0.4811 - val_precision_3: 0.4766 - val_recall_3: 0.5514\n",
      "Epoch 1277/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5357 - acc: 0.1812 - precision_3: 0.6270 - recall_3: 0.1859 - val_loss: 1.5022 - val_acc: 0.4811 - val_precision_3: 0.4744 - val_recall_3: 0.5514\n",
      "Epoch 1278/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5371 - acc: 0.1694 - precision_3: 0.6727 - recall_3: 0.1741 - val_loss: 1.5013 - val_acc: 0.4811 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1279/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5167 - acc: 0.2188 - precision_3: 0.7500 - recall_3: 0.2188 - val_loss: 1.5000 - val_acc: 0.4811 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1280/2000\n",
      "85/85 [==============================] - 0s 505us/sample - loss: 1.5252 - acc: 0.1906 - precision_3: 0.7615 - recall_3: 0.1953 - val_loss: 1.4991 - val_acc: 0.4703 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1281/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5278 - acc: 0.1929 - precision_3: 0.7281 - recall_3: 0.1953 - val_loss: 1.4996 - val_acc: 0.4757 - val_precision_3: 0.4747 - val_recall_3: 0.5568\n",
      "Epoch 1282/2000\n",
      "85/85 [==============================] - 0s 504us/sample - loss: 1.5337 - acc: 0.1788 - precision_3: 0.7723 - recall_3: 0.1835 - val_loss: 1.5016 - val_acc: 0.4757 - val_precision_3: 0.4793 - val_recall_3: 0.5622\n",
      "Epoch 1283/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5120 - acc: 0.2282 - precision_3: 0.7823 - recall_3: 0.2282 - val_loss: 1.4997 - val_acc: 0.4973 - val_precision_3: 0.4931 - val_recall_3: 0.5784\n",
      "Epoch 1284/2000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.5157 - acc: 0.2141 - precision_3: 0.7287 - recall_3: 0.2212 - val_loss: 1.4988 - val_acc: 0.4919 - val_precision_3: 0.5023 - val_recall_3: 0.5892\n",
      "Epoch 1285/2000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.5185 - acc: 0.2047 - precision_3: 0.7542 - recall_3: 0.2094 - val_loss: 1.4984 - val_acc: 0.4973 - val_precision_3: 0.5000 - val_recall_3: 0.5946\n",
      "Epoch 1286/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5301 - acc: 0.1953 - precision_3: 0.6343 - recall_3: 0.2000 - val_loss: 1.4997 - val_acc: 0.4973 - val_precision_3: 0.5046 - val_recall_3: 0.5946\n",
      "Epoch 1287/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5236 - acc: 0.2000 - precision_3: 0.7265 - recall_3: 0.2000 - val_loss: 1.5012 - val_acc: 0.4973 - val_precision_3: 0.4977 - val_recall_3: 0.5838\n",
      "Epoch 1288/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5248 - acc: 0.1906 - precision_3: 0.7179 - recall_3: 0.1976 - val_loss: 1.5022 - val_acc: 0.4973 - val_precision_3: 0.4909 - val_recall_3: 0.5838\n",
      "Epoch 1289/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5192 - acc: 0.2118 - precision_3: 0.6818 - recall_3: 0.2118 - val_loss: 1.5026 - val_acc: 0.4973 - val_precision_3: 0.4886 - val_recall_3: 0.5784\n",
      "Epoch 1290/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5115 - acc: 0.2165 - precision_3: 0.7600 - recall_3: 0.2235 - val_loss: 1.5027 - val_acc: 0.4973 - val_precision_3: 0.4864 - val_recall_3: 0.5784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1291/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5141 - acc: 0.2212 - precision_3: 0.7090 - recall_3: 0.2235 - val_loss: 1.5005 - val_acc: 0.5081 - val_precision_3: 0.4977 - val_recall_3: 0.5946\n",
      "Epoch 1292/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5437 - acc: 0.1647 - precision_3: 0.6460 - recall_3: 0.1718 - val_loss: 1.4977 - val_acc: 0.5135 - val_precision_3: 0.4889 - val_recall_3: 0.5946\n",
      "Epoch 1293/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5268 - acc: 0.1929 - precision_3: 0.7615 - recall_3: 0.1953 - val_loss: 1.4983 - val_acc: 0.5027 - val_precision_3: 0.4820 - val_recall_3: 0.5784\n",
      "Epoch 1294/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5284 - acc: 0.1835 - precision_3: 0.7054 - recall_3: 0.1859 - val_loss: 1.4989 - val_acc: 0.5027 - val_precision_3: 0.4798 - val_recall_3: 0.5784\n",
      "Epoch 1295/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5241 - acc: 0.1929 - precision_3: 0.6720 - recall_3: 0.1976 - val_loss: 1.5002 - val_acc: 0.4919 - val_precision_3: 0.4818 - val_recall_3: 0.5730\n",
      "Epoch 1296/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5260 - acc: 0.1906 - precision_3: 0.7168 - recall_3: 0.1906 - val_loss: 1.5022 - val_acc: 0.4919 - val_precision_3: 0.4862 - val_recall_3: 0.5730\n",
      "Epoch 1297/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5153 - acc: 0.2118 - precision_3: 0.7381 - recall_3: 0.2188 - val_loss: 1.5027 - val_acc: 0.4919 - val_precision_3: 0.4885 - val_recall_3: 0.5730\n",
      "Epoch 1298/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5260 - acc: 0.1929 - precision_3: 0.7241 - recall_3: 0.1976 - val_loss: 1.5023 - val_acc: 0.4865 - val_precision_3: 0.4840 - val_recall_3: 0.5730\n",
      "Epoch 1299/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5215 - acc: 0.2000 - precision_3: 0.7748 - recall_3: 0.2024 - val_loss: 1.4977 - val_acc: 0.4865 - val_precision_3: 0.4749 - val_recall_3: 0.5622\n",
      "Epoch 1300/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5257 - acc: 0.1929 - precision_3: 0.7387 - recall_3: 0.1929 - val_loss: 1.4963 - val_acc: 0.4919 - val_precision_3: 0.4747 - val_recall_3: 0.5568\n",
      "Epoch 1301/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5298 - acc: 0.1882 - precision_3: 0.7257 - recall_3: 0.1929 - val_loss: 1.4963 - val_acc: 0.4919 - val_precision_3: 0.4747 - val_recall_3: 0.5568\n",
      "Epoch 1302/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5263 - acc: 0.2000 - precision_3: 0.6967 - recall_3: 0.2000 - val_loss: 1.4977 - val_acc: 0.4919 - val_precision_3: 0.4747 - val_recall_3: 0.5568\n",
      "Epoch 1303/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5328 - acc: 0.1812 - precision_3: 0.6903 - recall_3: 0.1835 - val_loss: 1.5013 - val_acc: 0.4757 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1304/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5022 - acc: 0.2400 - precision_3: 0.7556 - recall_3: 0.2400 - val_loss: 1.5037 - val_acc: 0.4757 - val_precision_3: 0.4883 - val_recall_3: 0.5622\n",
      "Epoch 1305/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5238 - acc: 0.2000 - precision_3: 0.7040 - recall_3: 0.2071 - val_loss: 1.5048 - val_acc: 0.4757 - val_precision_3: 0.4906 - val_recall_3: 0.5622\n",
      "Epoch 1306/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5337 - acc: 0.1859 - precision_3: 0.7018 - recall_3: 0.1882 - val_loss: 1.5060 - val_acc: 0.4811 - val_precision_3: 0.4906 - val_recall_3: 0.5622\n",
      "Epoch 1307/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5288 - acc: 0.1859 - precision_3: 0.7117 - recall_3: 0.1859 - val_loss: 1.5107 - val_acc: 0.4595 - val_precision_3: 0.4880 - val_recall_3: 0.5514\n",
      "Epoch 1308/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5230 - acc: 0.2071 - precision_3: 0.6822 - recall_3: 0.2071 - val_loss: 1.5130 - val_acc: 0.4595 - val_precision_3: 0.4952 - val_recall_3: 0.5568\n",
      "Epoch 1309/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5320 - acc: 0.1812 - precision_3: 0.7624 - recall_3: 0.1812 - val_loss: 1.5155 - val_acc: 0.4595 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 1310/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5262 - acc: 0.1882 - precision_3: 0.7119 - recall_3: 0.1976 - val_loss: 1.5149 - val_acc: 0.4595 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 1311/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5197 - acc: 0.2024 - precision_3: 0.7632 - recall_3: 0.2047 - val_loss: 1.5154 - val_acc: 0.4595 - val_precision_3: 0.4928 - val_recall_3: 0.5514\n",
      "Epoch 1312/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5045 - acc: 0.2353 - precision_3: 0.7391 - recall_3: 0.2400 - val_loss: 1.5147 - val_acc: 0.4649 - val_precision_3: 0.4952 - val_recall_3: 0.5568\n",
      "Epoch 1313/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5133 - acc: 0.2259 - precision_3: 0.7164 - recall_3: 0.2259 - val_loss: 1.5136 - val_acc: 0.4703 - val_precision_3: 0.4976 - val_recall_3: 0.5622\n",
      "Epoch 1314/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5170 - acc: 0.2071 - precision_3: 0.7876 - recall_3: 0.2094 - val_loss: 1.5154 - val_acc: 0.4541 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 1315/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5080 - acc: 0.2282 - precision_3: 0.7463 - recall_3: 0.2353 - val_loss: 1.5171 - val_acc: 0.4541 - val_precision_3: 0.4926 - val_recall_3: 0.5405\n",
      "Epoch 1316/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5269 - acc: 0.1953 - precision_3: 0.7281 - recall_3: 0.1953 - val_loss: 1.5179 - val_acc: 0.4432 - val_precision_3: 0.4926 - val_recall_3: 0.5405\n",
      "Epoch 1317/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5242 - acc: 0.1929 - precision_3: 0.7069 - recall_3: 0.1929 - val_loss: 1.5182 - val_acc: 0.4432 - val_precision_3: 0.4925 - val_recall_3: 0.5351\n",
      "Epoch 1318/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5181 - acc: 0.2118 - precision_3: 0.7317 - recall_3: 0.2118 - val_loss: 1.5188 - val_acc: 0.4432 - val_precision_3: 0.4950 - val_recall_3: 0.5351\n",
      "Epoch 1319/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5159 - acc: 0.2094 - precision_3: 0.7222 - recall_3: 0.2141 - val_loss: 1.5186 - val_acc: 0.4432 - val_precision_3: 0.4950 - val_recall_3: 0.5351\n",
      "Epoch 1320/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5134 - acc: 0.2118 - precision_3: 0.7623 - recall_3: 0.2188 - val_loss: 1.5184 - val_acc: 0.4432 - val_precision_3: 0.5000 - val_recall_3: 0.5351\n",
      "Epoch 1321/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5303 - acc: 0.1812 - precision_3: 0.7383 - recall_3: 0.1859 - val_loss: 1.5163 - val_acc: 0.4486 - val_precision_3: 0.4950 - val_recall_3: 0.5405\n",
      "Epoch 1322/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5131 - acc: 0.2188 - precision_3: 0.7642 - recall_3: 0.2212 - val_loss: 1.5135 - val_acc: 0.4595 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1323/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5328 - acc: 0.1788 - precision_3: 0.6752 - recall_3: 0.1859 - val_loss: 1.5108 - val_acc: 0.4649 - val_precision_3: 0.4831 - val_recall_3: 0.5405\n",
      "Epoch 1324/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.4965 - acc: 0.2541 - precision_3: 0.7857 - recall_3: 0.2588 - val_loss: 1.5090 - val_acc: 0.4649 - val_precision_3: 0.4783 - val_recall_3: 0.5351\n",
      "Epoch 1325/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5277 - acc: 0.1929 - precision_3: 0.7411 - recall_3: 0.1953 - val_loss: 1.5072 - val_acc: 0.4649 - val_precision_3: 0.4806 - val_recall_3: 0.5351\n",
      "Epoch 1326/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5058 - acc: 0.2376 - precision_3: 0.7829 - recall_3: 0.2376 - val_loss: 1.5056 - val_acc: 0.4703 - val_precision_3: 0.4854 - val_recall_3: 0.5405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1327/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5298 - acc: 0.1835 - precision_3: 0.7054 - recall_3: 0.1859 - val_loss: 1.5044 - val_acc: 0.4757 - val_precision_3: 0.4808 - val_recall_3: 0.5405\n",
      "Epoch 1328/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5270 - acc: 0.1882 - precision_3: 0.7345 - recall_3: 0.1953 - val_loss: 1.5041 - val_acc: 0.4757 - val_precision_3: 0.4831 - val_recall_3: 0.5405\n",
      "Epoch 1329/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5265 - acc: 0.1906 - precision_3: 0.7545 - recall_3: 0.1953 - val_loss: 1.5060 - val_acc: 0.4703 - val_precision_3: 0.4857 - val_recall_3: 0.5514\n",
      "Epoch 1330/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5141 - acc: 0.2165 - precision_3: 0.7244 - recall_3: 0.2165 - val_loss: 1.5074 - val_acc: 0.4595 - val_precision_3: 0.4856 - val_recall_3: 0.5459\n",
      "Epoch 1331/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5260 - acc: 0.1906 - precision_3: 0.6917 - recall_3: 0.1953 - val_loss: 1.5078 - val_acc: 0.4595 - val_precision_3: 0.4856 - val_recall_3: 0.5459\n",
      "Epoch 1332/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.4960 - acc: 0.2518 - precision_3: 0.7448 - recall_3: 0.2541 - val_loss: 1.5078 - val_acc: 0.4649 - val_precision_3: 0.4880 - val_recall_3: 0.5514\n",
      "Epoch 1333/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5337 - acc: 0.1812 - precision_3: 0.7130 - recall_3: 0.1812 - val_loss: 1.5066 - val_acc: 0.4703 - val_precision_3: 0.4857 - val_recall_3: 0.5514\n",
      "Epoch 1334/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5157 - acc: 0.2141 - precision_3: 0.7302 - recall_3: 0.2165 - val_loss: 1.5034 - val_acc: 0.4703 - val_precision_3: 0.4808 - val_recall_3: 0.5405\n",
      "Epoch 1335/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5115 - acc: 0.2235 - precision_3: 0.7405 - recall_3: 0.2282 - val_loss: 1.5019 - val_acc: 0.4757 - val_precision_3: 0.4854 - val_recall_3: 0.5405\n",
      "Epoch 1336/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5081 - acc: 0.2306 - precision_3: 0.7444 - recall_3: 0.2329 - val_loss: 1.5016 - val_acc: 0.4703 - val_precision_3: 0.4854 - val_recall_3: 0.5405\n",
      "Epoch 1337/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5244 - acc: 0.1929 - precision_3: 0.7589 - recall_3: 0.2000 - val_loss: 1.5006 - val_acc: 0.4757 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1338/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5251 - acc: 0.2000 - precision_3: 0.6800 - recall_3: 0.2000 - val_loss: 1.4978 - val_acc: 0.4865 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 1339/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5202 - acc: 0.2094 - precision_3: 0.7521 - recall_3: 0.2141 - val_loss: 1.4976 - val_acc: 0.4865 - val_precision_3: 0.4928 - val_recall_3: 0.5514\n",
      "Epoch 1340/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5308 - acc: 0.1718 - precision_3: 0.7170 - recall_3: 0.1788 - val_loss: 1.4988 - val_acc: 0.4865 - val_precision_3: 0.4928 - val_recall_3: 0.5514\n",
      "Epoch 1341/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5284 - acc: 0.1859 - precision_3: 0.6833 - recall_3: 0.1929 - val_loss: 1.5003 - val_acc: 0.4703 - val_precision_3: 0.4877 - val_recall_3: 0.5351\n",
      "Epoch 1342/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5301 - acc: 0.1835 - precision_3: 0.7745 - recall_3: 0.1859 - val_loss: 1.5014 - val_acc: 0.4757 - val_precision_3: 0.4877 - val_recall_3: 0.5351\n",
      "Epoch 1343/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5159 - acc: 0.2071 - precision_3: 0.7739 - recall_3: 0.2094 - val_loss: 1.5028 - val_acc: 0.4757 - val_precision_3: 0.4900 - val_recall_3: 0.5297\n",
      "Epoch 1344/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5228 - acc: 0.2000 - precision_3: 0.7478 - recall_3: 0.2024 - val_loss: 1.5047 - val_acc: 0.4811 - val_precision_3: 0.4927 - val_recall_3: 0.5459\n",
      "Epoch 1345/2000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.5112 - acc: 0.2188 - precision_3: 0.7661 - recall_3: 0.2235 - val_loss: 1.5059 - val_acc: 0.4757 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1346/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5186 - acc: 0.2118 - precision_3: 0.7459 - recall_3: 0.2141 - val_loss: 1.5067 - val_acc: 0.4703 - val_precision_3: 0.4927 - val_recall_3: 0.5459\n",
      "Epoch 1347/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5189 - acc: 0.2024 - precision_3: 0.7250 - recall_3: 0.2047 - val_loss: 1.4984 - val_acc: 0.4811 - val_precision_3: 0.4791 - val_recall_3: 0.5568\n",
      "Epoch 1348/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5203 - acc: 0.1976 - precision_3: 0.7632 - recall_3: 0.2047 - val_loss: 1.4953 - val_acc: 0.4865 - val_precision_3: 0.4747 - val_recall_3: 0.5568\n",
      "Epoch 1349/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5183 - acc: 0.2047 - precision_3: 0.7355 - recall_3: 0.2094 - val_loss: 1.4936 - val_acc: 0.5027 - val_precision_3: 0.4818 - val_recall_3: 0.5730\n",
      "Epoch 1350/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5320 - acc: 0.1788 - precision_3: 0.6964 - recall_3: 0.1835 - val_loss: 1.4928 - val_acc: 0.5027 - val_precision_3: 0.4818 - val_recall_3: 0.5730\n",
      "Epoch 1351/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5279 - acc: 0.1859 - precision_3: 0.7547 - recall_3: 0.1882 - val_loss: 1.4923 - val_acc: 0.5027 - val_precision_3: 0.4818 - val_recall_3: 0.5730\n",
      "Epoch 1352/2000\n",
      "85/85 [==============================] - 0s 621us/sample - loss: 1.5275 - acc: 0.1929 - precision_3: 0.6917 - recall_3: 0.1953 - val_loss: 1.4929 - val_acc: 0.4973 - val_precision_3: 0.4818 - val_recall_3: 0.5730\n",
      "Epoch 1353/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5264 - acc: 0.1882 - precision_3: 0.7321 - recall_3: 0.1929 - val_loss: 1.4936 - val_acc: 0.4973 - val_precision_3: 0.4864 - val_recall_3: 0.5784\n",
      "Epoch 1354/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5276 - acc: 0.1906 - precision_3: 0.7455 - recall_3: 0.1929 - val_loss: 1.4933 - val_acc: 0.4973 - val_precision_3: 0.4862 - val_recall_3: 0.5730\n",
      "Epoch 1355/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5162 - acc: 0.2118 - precision_3: 0.7132 - recall_3: 0.2165 - val_loss: 1.4937 - val_acc: 0.4865 - val_precision_3: 0.4839 - val_recall_3: 0.5676\n",
      "Epoch 1356/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5320 - acc: 0.1741 - precision_3: 0.6610 - recall_3: 0.1835 - val_loss: 1.4943 - val_acc: 0.4865 - val_precision_3: 0.4864 - val_recall_3: 0.5784\n",
      "Epoch 1357/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.5145 - acc: 0.2141 - precision_3: 0.7603 - recall_3: 0.2165 - val_loss: 1.4947 - val_acc: 0.4919 - val_precision_3: 0.4842 - val_recall_3: 0.5784\n",
      "Epoch 1358/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5234 - acc: 0.2000 - precision_3: 0.7500 - recall_3: 0.2047 - val_loss: 1.4936 - val_acc: 0.4865 - val_precision_3: 0.4795 - val_recall_3: 0.5676\n",
      "Epoch 1359/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5195 - acc: 0.2000 - precision_3: 0.7521 - recall_3: 0.2071 - val_loss: 1.4945 - val_acc: 0.4919 - val_precision_3: 0.4771 - val_recall_3: 0.5622\n",
      "Epoch 1360/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5206 - acc: 0.2024 - precision_3: 0.7227 - recall_3: 0.2024 - val_loss: 1.4948 - val_acc: 0.4973 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1361/2000\n",
      "85/85 [==============================] - 0s 633us/sample - loss: 1.5147 - acc: 0.2094 - precision_3: 0.7222 - recall_3: 0.2141 - val_loss: 1.4954 - val_acc: 0.4919 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1362/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5344 - acc: 0.1718 - precision_3: 0.6579 - recall_3: 0.1765 - val_loss: 1.4966 - val_acc: 0.4865 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1363/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5227 - acc: 0.2024 - precision_3: 0.7258 - recall_3: 0.2118 - val_loss: 1.4982 - val_acc: 0.4703 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1364/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.5277 - acc: 0.1812 - precision_3: 0.7596 - recall_3: 0.1859 - val_loss: 1.4988 - val_acc: 0.4703 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1365/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5201 - acc: 0.2000 - precision_3: 0.7727 - recall_3: 0.2000 - val_loss: 1.5009 - val_acc: 0.4595 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1366/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5146 - acc: 0.2165 - precision_3: 0.7667 - recall_3: 0.2165 - val_loss: 1.5016 - val_acc: 0.4649 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1367/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5269 - acc: 0.1882 - precision_3: 0.6923 - recall_3: 0.1906 - val_loss: 1.5023 - val_acc: 0.4595 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1368/2000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.5207 - acc: 0.2024 - precision_3: 0.7295 - recall_3: 0.2094 - val_loss: 1.5017 - val_acc: 0.4595 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1369/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5192 - acc: 0.2141 - precision_3: 0.7165 - recall_3: 0.2141 - val_loss: 1.5015 - val_acc: 0.4649 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1370/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5288 - acc: 0.1953 - precision_3: 0.6911 - recall_3: 0.2000 - val_loss: 1.5020 - val_acc: 0.4649 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1371/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5112 - acc: 0.2188 - precision_3: 0.7402 - recall_3: 0.2212 - val_loss: 1.5018 - val_acc: 0.4757 - val_precision_3: 0.4907 - val_recall_3: 0.5730\n",
      "Epoch 1372/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5264 - acc: 0.1882 - precision_3: 0.7193 - recall_3: 0.1929 - val_loss: 1.5016 - val_acc: 0.4811 - val_precision_3: 0.4885 - val_recall_3: 0.5730\n",
      "Epoch 1373/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5207 - acc: 0.1906 - precision_3: 0.7850 - recall_3: 0.1976 - val_loss: 1.5013 - val_acc: 0.4703 - val_precision_3: 0.4907 - val_recall_3: 0.5730\n",
      "Epoch 1374/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5422 - acc: 0.1600 - precision_3: 0.6731 - recall_3: 0.1647 - val_loss: 1.5012 - val_acc: 0.4757 - val_precision_3: 0.4907 - val_recall_3: 0.5730\n",
      "Epoch 1375/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5217 - acc: 0.2047 - precision_3: 0.7063 - recall_3: 0.2094 - val_loss: 1.5007 - val_acc: 0.4811 - val_precision_3: 0.4862 - val_recall_3: 0.5730\n",
      "Epoch 1376/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5249 - acc: 0.1976 - precision_3: 0.7107 - recall_3: 0.2024 - val_loss: 1.5006 - val_acc: 0.4811 - val_precision_3: 0.4885 - val_recall_3: 0.5730\n",
      "Epoch 1377/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5306 - acc: 0.1835 - precision_3: 0.6930 - recall_3: 0.1859 - val_loss: 1.4997 - val_acc: 0.4811 - val_precision_3: 0.4861 - val_recall_3: 0.5676\n",
      "Epoch 1378/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5256 - acc: 0.1976 - precision_3: 0.7059 - recall_3: 0.1976 - val_loss: 1.5001 - val_acc: 0.4811 - val_precision_3: 0.4953 - val_recall_3: 0.5676\n",
      "Epoch 1379/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5065 - acc: 0.2259 - precision_3: 0.7444 - recall_3: 0.2329 - val_loss: 1.5019 - val_acc: 0.4757 - val_precision_3: 0.4952 - val_recall_3: 0.5622\n",
      "Epoch 1380/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5250 - acc: 0.2000 - precision_3: 0.7288 - recall_3: 0.2024 - val_loss: 1.5031 - val_acc: 0.4703 - val_precision_3: 0.4976 - val_recall_3: 0.5622\n",
      "Epoch 1381/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5326 - acc: 0.1765 - precision_3: 0.7404 - recall_3: 0.1812 - val_loss: 1.5035 - val_acc: 0.4649 - val_precision_3: 0.4976 - val_recall_3: 0.5622\n",
      "Epoch 1382/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5162 - acc: 0.2141 - precision_3: 0.7068 - recall_3: 0.2212 - val_loss: 1.5038 - val_acc: 0.4649 - val_precision_3: 0.4953 - val_recall_3: 0.5676\n",
      "Epoch 1383/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5375 - acc: 0.1741 - precision_3: 0.6667 - recall_3: 0.1788 - val_loss: 1.5052 - val_acc: 0.4595 - val_precision_3: 0.4907 - val_recall_3: 0.5676\n",
      "Epoch 1384/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5233 - acc: 0.2000 - precision_3: 0.7227 - recall_3: 0.2024 - val_loss: 1.5085 - val_acc: 0.4649 - val_precision_3: 0.4953 - val_recall_3: 0.5730\n",
      "Epoch 1385/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5164 - acc: 0.2118 - precision_3: 0.7603 - recall_3: 0.2165 - val_loss: 1.5105 - val_acc: 0.4649 - val_precision_3: 0.4953 - val_recall_3: 0.5730\n",
      "Epoch 1386/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5369 - acc: 0.1718 - precision_3: 0.6466 - recall_3: 0.1765 - val_loss: 1.5108 - val_acc: 0.4649 - val_precision_3: 0.4977 - val_recall_3: 0.5730\n",
      "Epoch 1387/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5255 - acc: 0.1976 - precision_3: 0.7500 - recall_3: 0.1976 - val_loss: 1.5106 - val_acc: 0.4595 - val_precision_3: 0.4906 - val_recall_3: 0.5622\n",
      "Epoch 1388/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5319 - acc: 0.1788 - precision_3: 0.7358 - recall_3: 0.1835 - val_loss: 1.5083 - val_acc: 0.4703 - val_precision_3: 0.4884 - val_recall_3: 0.5676\n",
      "Epoch 1389/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5216 - acc: 0.1953 - precision_3: 0.7568 - recall_3: 0.1976 - val_loss: 1.5066 - val_acc: 0.4703 - val_precision_3: 0.4885 - val_recall_3: 0.5730\n",
      "Epoch 1390/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5241 - acc: 0.1976 - precision_3: 0.7167 - recall_3: 0.2024 - val_loss: 1.5056 - val_acc: 0.4649 - val_precision_3: 0.4861 - val_recall_3: 0.5676\n",
      "Epoch 1391/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5229 - acc: 0.1906 - precision_3: 0.7500 - recall_3: 0.1976 - val_loss: 1.5055 - val_acc: 0.4703 - val_precision_3: 0.4907 - val_recall_3: 0.5730\n",
      "Epoch 1392/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5225 - acc: 0.1929 - precision_3: 0.7059 - recall_3: 0.1976 - val_loss: 1.5062 - val_acc: 0.4649 - val_precision_3: 0.4884 - val_recall_3: 0.5676\n",
      "Epoch 1393/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5230 - acc: 0.1953 - precision_3: 0.7131 - recall_3: 0.2047 - val_loss: 1.5056 - val_acc: 0.4649 - val_precision_3: 0.4930 - val_recall_3: 0.5676\n",
      "Epoch 1394/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5280 - acc: 0.1906 - precision_3: 0.7043 - recall_3: 0.1906 - val_loss: 1.5060 - val_acc: 0.4541 - val_precision_3: 0.4930 - val_recall_3: 0.5676\n",
      "Epoch 1395/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5184 - acc: 0.2047 - precision_3: 0.7395 - recall_3: 0.2071 - val_loss: 1.5054 - val_acc: 0.4649 - val_precision_3: 0.4929 - val_recall_3: 0.5622\n",
      "Epoch 1396/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5266 - acc: 0.1882 - precision_3: 0.7455 - recall_3: 0.1929 - val_loss: 1.5033 - val_acc: 0.4595 - val_precision_3: 0.4905 - val_recall_3: 0.5568\n",
      "Epoch 1397/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5125 - acc: 0.2141 - precision_3: 0.7520 - recall_3: 0.2212 - val_loss: 1.5023 - val_acc: 0.4649 - val_precision_3: 0.4928 - val_recall_3: 0.5568\n",
      "Epoch 1398/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5171 - acc: 0.2047 - precision_3: 0.7236 - recall_3: 0.2094 - val_loss: 1.5032 - val_acc: 0.4595 - val_precision_3: 0.4905 - val_recall_3: 0.5568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1399/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5267 - acc: 0.1859 - precision_3: 0.6897 - recall_3: 0.1882 - val_loss: 1.5041 - val_acc: 0.4595 - val_precision_3: 0.4905 - val_recall_3: 0.5568\n",
      "Epoch 1400/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5221 - acc: 0.2094 - precision_3: 0.7109 - recall_3: 0.2141 - val_loss: 1.5042 - val_acc: 0.4595 - val_precision_3: 0.4928 - val_recall_3: 0.5568\n",
      "Epoch 1401/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5339 - acc: 0.1765 - precision_3: 0.6818 - recall_3: 0.1765 - val_loss: 1.5062 - val_acc: 0.4649 - val_precision_3: 0.4928 - val_recall_3: 0.5568\n",
      "Epoch 1402/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5201 - acc: 0.2047 - precision_3: 0.7200 - recall_3: 0.2118 - val_loss: 1.5092 - val_acc: 0.4595 - val_precision_3: 0.4902 - val_recall_3: 0.5405\n",
      "Epoch 1403/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5212 - acc: 0.2000 - precision_3: 0.7748 - recall_3: 0.2024 - val_loss: 1.5109 - val_acc: 0.4595 - val_precision_3: 0.4878 - val_recall_3: 0.5405\n",
      "Epoch 1404/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5093 - acc: 0.2353 - precision_3: 0.7536 - recall_3: 0.2447 - val_loss: 1.5109 - val_acc: 0.4595 - val_precision_3: 0.4878 - val_recall_3: 0.5405\n",
      "Epoch 1405/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5080 - acc: 0.2306 - precision_3: 0.7500 - recall_3: 0.2329 - val_loss: 1.5109 - val_acc: 0.4541 - val_precision_3: 0.4878 - val_recall_3: 0.5405\n",
      "Epoch 1406/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5029 - acc: 0.2353 - precision_3: 0.7153 - recall_3: 0.2424 - val_loss: 1.5109 - val_acc: 0.4541 - val_precision_3: 0.4902 - val_recall_3: 0.5405\n",
      "Epoch 1407/2000\n",
      "85/85 [==============================] - 0s 576us/sample - loss: 1.5353 - acc: 0.1741 - precision_3: 0.6881 - recall_3: 0.1765 - val_loss: 1.5103 - val_acc: 0.4541 - val_precision_3: 0.4878 - val_recall_3: 0.5405\n",
      "Epoch 1408/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5185 - acc: 0.2047 - precision_3: 0.7500 - recall_3: 0.2118 - val_loss: 1.5097 - val_acc: 0.4541 - val_precision_3: 0.4927 - val_recall_3: 0.5459\n",
      "Epoch 1409/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5225 - acc: 0.1976 - precision_3: 0.6718 - recall_3: 0.2071 - val_loss: 1.5097 - val_acc: 0.4595 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1410/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5292 - acc: 0.1882 - precision_3: 0.7009 - recall_3: 0.1929 - val_loss: 1.5098 - val_acc: 0.4541 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1411/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5059 - acc: 0.2329 - precision_3: 0.7391 - recall_3: 0.2400 - val_loss: 1.5092 - val_acc: 0.4595 - val_precision_3: 0.4879 - val_recall_3: 0.5459\n",
      "Epoch 1412/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5104 - acc: 0.2212 - precision_3: 0.7143 - recall_3: 0.2353 - val_loss: 1.5098 - val_acc: 0.4595 - val_precision_3: 0.4879 - val_recall_3: 0.5459\n",
      "Epoch 1413/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5346 - acc: 0.1788 - precision_3: 0.6930 - recall_3: 0.1859 - val_loss: 1.5117 - val_acc: 0.4595 - val_precision_3: 0.4952 - val_recall_3: 0.5568\n",
      "Epoch 1414/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5132 - acc: 0.2212 - precision_3: 0.7460 - recall_3: 0.2212 - val_loss: 1.5137 - val_acc: 0.4595 - val_precision_3: 0.4902 - val_recall_3: 0.5405\n",
      "Epoch 1415/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5053 - acc: 0.2329 - precision_3: 0.7710 - recall_3: 0.2376 - val_loss: 1.5146 - val_acc: 0.4649 - val_precision_3: 0.4878 - val_recall_3: 0.5405\n",
      "Epoch 1416/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5132 - acc: 0.2212 - precision_3: 0.6985 - recall_3: 0.2235 - val_loss: 1.5153 - val_acc: 0.4541 - val_precision_3: 0.4925 - val_recall_3: 0.5351\n",
      "Epoch 1417/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5025 - acc: 0.2306 - precision_3: 0.7744 - recall_3: 0.2424 - val_loss: 1.5158 - val_acc: 0.4541 - val_precision_3: 0.4901 - val_recall_3: 0.5351\n",
      "Epoch 1418/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5333 - acc: 0.1812 - precision_3: 0.7429 - recall_3: 0.1835 - val_loss: 1.5171 - val_acc: 0.4595 - val_precision_3: 0.4925 - val_recall_3: 0.5351\n",
      "Epoch 1419/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5228 - acc: 0.1953 - precision_3: 0.7213 - recall_3: 0.2071 - val_loss: 1.5173 - val_acc: 0.4595 - val_precision_3: 0.4901 - val_recall_3: 0.5351\n",
      "Epoch 1420/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5134 - acc: 0.2188 - precision_3: 0.6957 - recall_3: 0.2259 - val_loss: 1.5155 - val_acc: 0.4595 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1421/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5155 - acc: 0.2047 - precision_3: 0.7719 - recall_3: 0.2071 - val_loss: 1.5139 - val_acc: 0.4541 - val_precision_3: 0.4854 - val_recall_3: 0.5405\n",
      "Epoch 1422/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5328 - acc: 0.1765 - precision_3: 0.7525 - recall_3: 0.1788 - val_loss: 1.5142 - val_acc: 0.4595 - val_precision_3: 0.4878 - val_recall_3: 0.5405\n",
      "Epoch 1423/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5267 - acc: 0.1882 - precision_3: 0.6949 - recall_3: 0.1929 - val_loss: 1.5144 - val_acc: 0.4541 - val_precision_3: 0.4902 - val_recall_3: 0.5405\n",
      "Epoch 1424/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5188 - acc: 0.2094 - precision_3: 0.7054 - recall_3: 0.2141 - val_loss: 1.5143 - val_acc: 0.4541 - val_precision_3: 0.4902 - val_recall_3: 0.5405\n",
      "Epoch 1425/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5111 - acc: 0.2212 - precision_3: 0.7642 - recall_3: 0.2212 - val_loss: 1.5126 - val_acc: 0.4649 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 1426/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5042 - acc: 0.2329 - precision_3: 0.7846 - recall_3: 0.2400 - val_loss: 1.5104 - val_acc: 0.4541 - val_precision_3: 0.4951 - val_recall_3: 0.5459\n",
      "Epoch 1427/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5284 - acc: 0.1788 - precision_3: 0.7273 - recall_3: 0.1882 - val_loss: 1.5072 - val_acc: 0.4649 - val_precision_3: 0.4789 - val_recall_3: 0.5514\n",
      "Epoch 1428/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5293 - acc: 0.1812 - precision_3: 0.7091 - recall_3: 0.1835 - val_loss: 1.5058 - val_acc: 0.4757 - val_precision_3: 0.4811 - val_recall_3: 0.5514\n",
      "Epoch 1429/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5219 - acc: 0.2024 - precision_3: 0.7311 - recall_3: 0.2047 - val_loss: 1.5056 - val_acc: 0.4703 - val_precision_3: 0.4787 - val_recall_3: 0.5459\n",
      "Epoch 1430/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5301 - acc: 0.1835 - precision_3: 0.7248 - recall_3: 0.1859 - val_loss: 1.5045 - val_acc: 0.4811 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1431/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5215 - acc: 0.1976 - precision_3: 0.7391 - recall_3: 0.2000 - val_loss: 1.5043 - val_acc: 0.4811 - val_precision_3: 0.4882 - val_recall_3: 0.5568\n",
      "Epoch 1432/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5002 - acc: 0.2400 - precision_3: 0.7969 - recall_3: 0.2400 - val_loss: 1.5044 - val_acc: 0.4757 - val_precision_3: 0.4906 - val_recall_3: 0.5622\n",
      "Epoch 1433/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5137 - acc: 0.2188 - precision_3: 0.6713 - recall_3: 0.2259 - val_loss: 1.5059 - val_acc: 0.4649 - val_precision_3: 0.4857 - val_recall_3: 0.5514\n",
      "Epoch 1434/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5166 - acc: 0.2071 - precision_3: 0.7209 - recall_3: 0.2188 - val_loss: 1.5065 - val_acc: 0.4649 - val_precision_3: 0.4857 - val_recall_3: 0.5514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1435/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5252 - acc: 0.1953 - precision_3: 0.7368 - recall_3: 0.1976 - val_loss: 1.5083 - val_acc: 0.4541 - val_precision_3: 0.4856 - val_recall_3: 0.5459\n",
      "Epoch 1436/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5205 - acc: 0.2071 - precision_3: 0.7008 - recall_3: 0.2094 - val_loss: 1.5111 - val_acc: 0.4432 - val_precision_3: 0.4829 - val_recall_3: 0.5351\n",
      "Epoch 1437/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5138 - acc: 0.2188 - precision_3: 0.7422 - recall_3: 0.2235 - val_loss: 1.5122 - val_acc: 0.4432 - val_precision_3: 0.4757 - val_recall_3: 0.5297\n",
      "Epoch 1438/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5024 - acc: 0.2306 - precision_3: 0.7937 - recall_3: 0.2353 - val_loss: 1.5118 - val_acc: 0.4432 - val_precision_3: 0.4783 - val_recall_3: 0.5351\n",
      "Epoch 1439/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5100 - acc: 0.2141 - precision_3: 0.7705 - recall_3: 0.2212 - val_loss: 1.5108 - val_acc: 0.4432 - val_precision_3: 0.4783 - val_recall_3: 0.5351\n",
      "Epoch 1440/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5365 - acc: 0.1741 - precision_3: 0.7353 - recall_3: 0.1765 - val_loss: 1.5100 - val_acc: 0.4432 - val_precision_3: 0.4739 - val_recall_3: 0.5405\n",
      "Epoch 1441/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5291 - acc: 0.1835 - precision_3: 0.7117 - recall_3: 0.1859 - val_loss: 1.5086 - val_acc: 0.4486 - val_precision_3: 0.4739 - val_recall_3: 0.5405\n",
      "Epoch 1442/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5229 - acc: 0.1976 - precision_3: 0.7522 - recall_3: 0.2000 - val_loss: 1.5070 - val_acc: 0.4541 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1443/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5200 - acc: 0.2047 - precision_3: 0.7236 - recall_3: 0.2094 - val_loss: 1.5059 - val_acc: 0.4541 - val_precision_3: 0.4880 - val_recall_3: 0.5514\n",
      "Epoch 1444/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5348 - acc: 0.1741 - precision_3: 0.6441 - recall_3: 0.1788 - val_loss: 1.5051 - val_acc: 0.4595 - val_precision_3: 0.4882 - val_recall_3: 0.5568\n",
      "Epoch 1445/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5235 - acc: 0.2000 - precision_3: 0.7456 - recall_3: 0.2000 - val_loss: 1.5052 - val_acc: 0.4541 - val_precision_3: 0.4858 - val_recall_3: 0.5568\n",
      "Epoch 1446/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5175 - acc: 0.2094 - precision_3: 0.7563 - recall_3: 0.2118 - val_loss: 1.5059 - val_acc: 0.4432 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1447/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5232 - acc: 0.1929 - precision_3: 0.7203 - recall_3: 0.2000 - val_loss: 1.5077 - val_acc: 0.4378 - val_precision_3: 0.4811 - val_recall_3: 0.5514\n",
      "Epoch 1448/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5300 - acc: 0.1882 - precision_3: 0.7043 - recall_3: 0.1906 - val_loss: 1.5111 - val_acc: 0.4378 - val_precision_3: 0.4709 - val_recall_3: 0.5243\n",
      "Epoch 1449/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5135 - acc: 0.2188 - precision_3: 0.7381 - recall_3: 0.2188 - val_loss: 1.5146 - val_acc: 0.4432 - val_precision_3: 0.4826 - val_recall_3: 0.5243\n",
      "Epoch 1450/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5144 - acc: 0.2118 - precision_3: 0.7422 - recall_3: 0.2235 - val_loss: 1.5195 - val_acc: 0.4378 - val_precision_3: 0.4724 - val_recall_3: 0.5081\n",
      "Epoch 1451/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5228 - acc: 0.1976 - precision_3: 0.6935 - recall_3: 0.2024 - val_loss: 1.5219 - val_acc: 0.4378 - val_precision_3: 0.4923 - val_recall_3: 0.5189\n",
      "Epoch 1452/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5258 - acc: 0.1835 - precision_3: 0.7241 - recall_3: 0.1976 - val_loss: 1.5227 - val_acc: 0.4432 - val_precision_3: 0.4897 - val_recall_3: 0.5135\n",
      "Epoch 1453/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5158 - acc: 0.2118 - precision_3: 0.7244 - recall_3: 0.2165 - val_loss: 1.5220 - val_acc: 0.4324 - val_precision_3: 0.4872 - val_recall_3: 0.5135\n",
      "Epoch 1454/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.4987 - acc: 0.2541 - precision_3: 0.7466 - recall_3: 0.2565 - val_loss: 1.5210 - val_acc: 0.4541 - val_precision_3: 0.4874 - val_recall_3: 0.5243\n",
      "Epoch 1455/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5089 - acc: 0.2306 - precision_3: 0.7812 - recall_3: 0.2353 - val_loss: 1.5202 - val_acc: 0.4541 - val_precision_3: 0.4850 - val_recall_3: 0.5243\n",
      "Epoch 1456/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5229 - acc: 0.1953 - precision_3: 0.7545 - recall_3: 0.1953 - val_loss: 1.5197 - val_acc: 0.4541 - val_precision_3: 0.4776 - val_recall_3: 0.5189\n",
      "Epoch 1457/2000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.5050 - acc: 0.2306 - precision_3: 0.7518 - recall_3: 0.2424 - val_loss: 1.5194 - val_acc: 0.4486 - val_precision_3: 0.4752 - val_recall_3: 0.5189\n",
      "Epoch 1458/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5221 - acc: 0.1976 - precision_3: 0.7107 - recall_3: 0.2024 - val_loss: 1.5198 - val_acc: 0.4541 - val_precision_3: 0.4802 - val_recall_3: 0.5243\n",
      "Epoch 1459/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5147 - acc: 0.2165 - precision_3: 0.7623 - recall_3: 0.2188 - val_loss: 1.5202 - val_acc: 0.4486 - val_precision_3: 0.4851 - val_recall_3: 0.5297\n",
      "Epoch 1460/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5119 - acc: 0.2212 - precision_3: 0.7206 - recall_3: 0.2306 - val_loss: 1.5194 - val_acc: 0.4486 - val_precision_3: 0.4755 - val_recall_3: 0.5243\n",
      "Epoch 1461/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5165 - acc: 0.2094 - precision_3: 0.7521 - recall_3: 0.2141 - val_loss: 1.5176 - val_acc: 0.4486 - val_precision_3: 0.4806 - val_recall_3: 0.5351\n",
      "Epoch 1462/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5222 - acc: 0.2000 - precision_3: 0.7500 - recall_3: 0.2047 - val_loss: 1.5172 - val_acc: 0.4486 - val_precision_3: 0.4854 - val_recall_3: 0.5405\n",
      "Epoch 1463/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5163 - acc: 0.2141 - precision_3: 0.7165 - recall_3: 0.2141 - val_loss: 1.5166 - val_acc: 0.4486 - val_precision_3: 0.4951 - val_recall_3: 0.5459\n",
      "Epoch 1464/2000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.5150 - acc: 0.2165 - precision_3: 0.7360 - recall_3: 0.2165 - val_loss: 1.5171 - val_acc: 0.4486 - val_precision_3: 0.4927 - val_recall_3: 0.5459\n",
      "Epoch 1465/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5217 - acc: 0.1929 - precision_3: 0.7411 - recall_3: 0.1953 - val_loss: 1.5167 - val_acc: 0.4486 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1466/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5286 - acc: 0.1788 - precision_3: 0.7404 - recall_3: 0.1812 - val_loss: 1.5160 - val_acc: 0.4486 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1467/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5121 - acc: 0.2118 - precision_3: 0.7323 - recall_3: 0.2188 - val_loss: 1.5149 - val_acc: 0.4432 - val_precision_3: 0.4975 - val_recall_3: 0.5459\n",
      "Epoch 1468/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5224 - acc: 0.1906 - precision_3: 0.7414 - recall_3: 0.2024 - val_loss: 1.5150 - val_acc: 0.4486 - val_precision_3: 0.5049 - val_recall_3: 0.5568\n",
      "Epoch 1469/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5210 - acc: 0.2118 - precision_3: 0.7647 - recall_3: 0.2141 - val_loss: 1.5181 - val_acc: 0.4324 - val_precision_3: 0.4924 - val_recall_3: 0.5243\n",
      "Epoch 1470/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5294 - acc: 0.1765 - precision_3: 0.7182 - recall_3: 0.1859 - val_loss: 1.5207 - val_acc: 0.4432 - val_precision_3: 0.4975 - val_recall_3: 0.5405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1471/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5182 - acc: 0.2024 - precision_3: 0.7719 - recall_3: 0.2071 - val_loss: 1.5207 - val_acc: 0.4432 - val_precision_3: 0.4975 - val_recall_3: 0.5351\n",
      "Epoch 1472/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5291 - acc: 0.1859 - precision_3: 0.7273 - recall_3: 0.1882 - val_loss: 1.5205 - val_acc: 0.4432 - val_precision_3: 0.4975 - val_recall_3: 0.5297\n",
      "Epoch 1473/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5394 - acc: 0.1647 - precision_3: 0.7172 - recall_3: 0.1671 - val_loss: 1.5201 - val_acc: 0.4432 - val_precision_3: 0.5000 - val_recall_3: 0.5351\n",
      "Epoch 1474/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5181 - acc: 0.2071 - precision_3: 0.7460 - recall_3: 0.2212 - val_loss: 1.5194 - val_acc: 0.4541 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 1475/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5181 - acc: 0.2024 - precision_3: 0.7436 - recall_3: 0.2047 - val_loss: 1.5193 - val_acc: 0.4486 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 1476/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5240 - acc: 0.1929 - precision_3: 0.7179 - recall_3: 0.1976 - val_loss: 1.5154 - val_acc: 0.4486 - val_precision_3: 0.5126 - val_recall_3: 0.5514\n",
      "Epoch 1477/2000\n",
      "85/85 [==============================] - 0s 633us/sample - loss: 1.5039 - acc: 0.2329 - precision_3: 0.8080 - recall_3: 0.2376 - val_loss: 1.5124 - val_acc: 0.4649 - val_precision_3: 0.5124 - val_recall_3: 0.5568\n",
      "Epoch 1478/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5079 - acc: 0.2188 - precision_3: 0.8051 - recall_3: 0.2235 - val_loss: 1.5105 - val_acc: 0.4486 - val_precision_3: 0.5124 - val_recall_3: 0.5568\n",
      "Epoch 1479/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5300 - acc: 0.1835 - precision_3: 0.7647 - recall_3: 0.1835 - val_loss: 1.5083 - val_acc: 0.4541 - val_precision_3: 0.5196 - val_recall_3: 0.5730\n",
      "Epoch 1480/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5179 - acc: 0.2118 - precision_3: 0.7280 - recall_3: 0.2141 - val_loss: 1.5061 - val_acc: 0.4486 - val_precision_3: 0.5121 - val_recall_3: 0.5730\n",
      "Epoch 1481/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5132 - acc: 0.2141 - precision_3: 0.7460 - recall_3: 0.2212 - val_loss: 1.5051 - val_acc: 0.4486 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1482/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5182 - acc: 0.2094 - precision_3: 0.7521 - recall_3: 0.2141 - val_loss: 1.5055 - val_acc: 0.4486 - val_precision_3: 0.4976 - val_recall_3: 0.5622\n",
      "Epoch 1483/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5176 - acc: 0.2141 - precision_3: 0.7419 - recall_3: 0.2165 - val_loss: 1.5083 - val_acc: 0.4486 - val_precision_3: 0.4976 - val_recall_3: 0.5568\n",
      "Epoch 1484/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5115 - acc: 0.2141 - precision_3: 0.7500 - recall_3: 0.2188 - val_loss: 1.5073 - val_acc: 0.4486 - val_precision_3: 0.4858 - val_recall_3: 0.5568\n",
      "Epoch 1485/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5018 - acc: 0.2424 - precision_3: 0.7609 - recall_3: 0.2471 - val_loss: 1.5076 - val_acc: 0.4486 - val_precision_3: 0.4882 - val_recall_3: 0.5568\n",
      "Epoch 1486/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5249 - acc: 0.1906 - precision_3: 0.7321 - recall_3: 0.1929 - val_loss: 1.5083 - val_acc: 0.4541 - val_precision_3: 0.4883 - val_recall_3: 0.5622\n",
      "Epoch 1487/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5345 - acc: 0.1788 - precision_3: 0.6842 - recall_3: 0.1835 - val_loss: 1.5081 - val_acc: 0.4486 - val_precision_3: 0.4884 - val_recall_3: 0.5676\n",
      "Epoch 1488/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5004 - acc: 0.2329 - precision_3: 0.7969 - recall_3: 0.2400 - val_loss: 1.5074 - val_acc: 0.4541 - val_precision_3: 0.4861 - val_recall_3: 0.5676\n",
      "Epoch 1489/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5039 - acc: 0.2282 - precision_3: 0.7967 - recall_3: 0.2306 - val_loss: 1.5069 - val_acc: 0.4541 - val_precision_3: 0.4930 - val_recall_3: 0.5730\n",
      "Epoch 1490/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5110 - acc: 0.2212 - precision_3: 0.6957 - recall_3: 0.2259 - val_loss: 1.5050 - val_acc: 0.4811 - val_precision_3: 0.4908 - val_recall_3: 0.5784\n",
      "Epoch 1491/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5340 - acc: 0.1788 - precision_3: 0.6446 - recall_3: 0.1835 - val_loss: 1.5046 - val_acc: 0.4811 - val_precision_3: 0.4977 - val_recall_3: 0.5784\n",
      "Epoch 1492/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5242 - acc: 0.1929 - precision_3: 0.7241 - recall_3: 0.1976 - val_loss: 1.5059 - val_acc: 0.4757 - val_precision_3: 0.4977 - val_recall_3: 0.5784\n",
      "Epoch 1493/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5283 - acc: 0.1976 - precision_3: 0.7107 - recall_3: 0.2024 - val_loss: 1.5058 - val_acc: 0.4703 - val_precision_3: 0.4977 - val_recall_3: 0.5784\n",
      "Epoch 1494/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5131 - acc: 0.2165 - precision_3: 0.7750 - recall_3: 0.2188 - val_loss: 1.5073 - val_acc: 0.4649 - val_precision_3: 0.4884 - val_recall_3: 0.5676\n",
      "Epoch 1495/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5349 - acc: 0.1741 - precision_3: 0.6972 - recall_3: 0.1788 - val_loss: 1.5085 - val_acc: 0.4541 - val_precision_3: 0.4861 - val_recall_3: 0.5676\n",
      "Epoch 1496/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.4981 - acc: 0.2494 - precision_3: 0.7279 - recall_3: 0.2518 - val_loss: 1.5097 - val_acc: 0.4432 - val_precision_3: 0.4813 - val_recall_3: 0.5568\n",
      "Epoch 1497/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5169 - acc: 0.2118 - precision_3: 0.7459 - recall_3: 0.2141 - val_loss: 1.5101 - val_acc: 0.4324 - val_precision_3: 0.4766 - val_recall_3: 0.5514\n",
      "Epoch 1498/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5199 - acc: 0.1953 - precision_3: 0.8218 - recall_3: 0.1953 - val_loss: 1.5100 - val_acc: 0.4324 - val_precision_3: 0.4811 - val_recall_3: 0.5514\n",
      "Epoch 1499/2000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.5146 - acc: 0.2094 - precision_3: 0.7419 - recall_3: 0.2165 - val_loss: 1.5097 - val_acc: 0.4324 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1500/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.4941 - acc: 0.2541 - precision_3: 0.8308 - recall_3: 0.2541 - val_loss: 1.5072 - val_acc: 0.4486 - val_precision_3: 0.4744 - val_recall_3: 0.5514\n",
      "Epoch 1501/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5166 - acc: 0.2071 - precision_3: 0.7542 - recall_3: 0.2094 - val_loss: 1.5058 - val_acc: 0.4541 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1502/2000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.5280 - acc: 0.1859 - precision_3: 0.8081 - recall_3: 0.1882 - val_loss: 1.5051 - val_acc: 0.4432 - val_precision_3: 0.4817 - val_recall_3: 0.5676\n",
      "Epoch 1503/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5130 - acc: 0.2282 - precision_3: 0.6828 - recall_3: 0.2329 - val_loss: 1.5034 - val_acc: 0.4486 - val_precision_3: 0.4907 - val_recall_3: 0.5676\n",
      "Epoch 1504/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5003 - acc: 0.2329 - precision_3: 0.8547 - recall_3: 0.2353 - val_loss: 1.5022 - val_acc: 0.4486 - val_precision_3: 0.4839 - val_recall_3: 0.5676\n",
      "Epoch 1505/2000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.5113 - acc: 0.2118 - precision_3: 0.7519 - recall_3: 0.2282 - val_loss: 1.5027 - val_acc: 0.4486 - val_precision_3: 0.4862 - val_recall_3: 0.5730\n",
      "Epoch 1506/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5090 - acc: 0.2259 - precision_3: 0.7122 - recall_3: 0.2329 - val_loss: 1.5029 - val_acc: 0.4486 - val_precision_3: 0.4907 - val_recall_3: 0.5730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1507/2000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.5269 - acc: 0.1882 - precision_3: 0.7364 - recall_3: 0.1906 - val_loss: 1.5029 - val_acc: 0.4541 - val_precision_3: 0.4931 - val_recall_3: 0.5784\n",
      "Epoch 1508/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5048 - acc: 0.2306 - precision_3: 0.7846 - recall_3: 0.2400 - val_loss: 1.5044 - val_acc: 0.4378 - val_precision_3: 0.4908 - val_recall_3: 0.5784\n",
      "Epoch 1509/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5346 - acc: 0.1788 - precision_3: 0.7451 - recall_3: 0.1788 - val_loss: 1.5082 - val_acc: 0.4432 - val_precision_3: 0.5000 - val_recall_3: 0.5676\n",
      "Epoch 1510/2000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.5386 - acc: 0.1671 - precision_3: 0.6762 - recall_3: 0.1671 - val_loss: 1.5090 - val_acc: 0.4378 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1511/2000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.5153 - acc: 0.2141 - precision_3: 0.7881 - recall_3: 0.2188 - val_loss: 1.5088 - val_acc: 0.4432 - val_precision_3: 0.5024 - val_recall_3: 0.5622\n",
      "Epoch 1512/2000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.5165 - acc: 0.2165 - precision_3: 0.7642 - recall_3: 0.2212 - val_loss: 1.5082 - val_acc: 0.4541 - val_precision_3: 0.5024 - val_recall_3: 0.5622\n",
      "Epoch 1513/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.4856 - acc: 0.2800 - precision_3: 0.7778 - recall_3: 0.2800 - val_loss: 1.5076 - val_acc: 0.4541 - val_precision_3: 0.5024 - val_recall_3: 0.5622\n",
      "Epoch 1514/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5133 - acc: 0.2118 - precision_3: 0.7459 - recall_3: 0.2141 - val_loss: 1.5057 - val_acc: 0.4541 - val_precision_3: 0.5000 - val_recall_3: 0.5676\n",
      "Epoch 1515/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5136 - acc: 0.2118 - precision_3: 0.7521 - recall_3: 0.2141 - val_loss: 1.5057 - val_acc: 0.4595 - val_precision_3: 0.5070 - val_recall_3: 0.5838\n",
      "Epoch 1516/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5249 - acc: 0.1953 - precision_3: 0.6935 - recall_3: 0.2024 - val_loss: 1.5049 - val_acc: 0.4649 - val_precision_3: 0.5047 - val_recall_3: 0.5784\n",
      "Epoch 1517/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5226 - acc: 0.1929 - precision_3: 0.7368 - recall_3: 0.1976 - val_loss: 1.5055 - val_acc: 0.4649 - val_precision_3: 0.5047 - val_recall_3: 0.5784\n",
      "Epoch 1518/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5269 - acc: 0.1882 - precision_3: 0.7069 - recall_3: 0.1929 - val_loss: 1.5051 - val_acc: 0.4541 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1519/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5350 - acc: 0.1741 - precision_3: 0.6818 - recall_3: 0.1765 - val_loss: 1.5044 - val_acc: 0.4595 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1520/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.4995 - acc: 0.2424 - precision_3: 0.8062 - recall_3: 0.2447 - val_loss: 1.5041 - val_acc: 0.4595 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1521/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5320 - acc: 0.1859 - precision_3: 0.6695 - recall_3: 0.1859 - val_loss: 1.5027 - val_acc: 0.4595 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1522/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5338 - acc: 0.1788 - precision_3: 0.6783 - recall_3: 0.1835 - val_loss: 1.4999 - val_acc: 0.4703 - val_precision_3: 0.5000 - val_recall_3: 0.5676\n",
      "Epoch 1523/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5075 - acc: 0.2259 - precision_3: 0.7619 - recall_3: 0.2259 - val_loss: 1.4986 - val_acc: 0.4757 - val_precision_3: 0.4953 - val_recall_3: 0.5676\n",
      "Epoch 1524/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5276 - acc: 0.1835 - precision_3: 0.7670 - recall_3: 0.1859 - val_loss: 1.4984 - val_acc: 0.4811 - val_precision_3: 0.5000 - val_recall_3: 0.5730\n",
      "Epoch 1525/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5082 - acc: 0.2306 - precision_3: 0.7597 - recall_3: 0.2306 - val_loss: 1.4992 - val_acc: 0.4757 - val_precision_3: 0.4976 - val_recall_3: 0.5676\n",
      "Epoch 1526/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5220 - acc: 0.2047 - precision_3: 0.6984 - recall_3: 0.2071 - val_loss: 1.5000 - val_acc: 0.4703 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1527/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5213 - acc: 0.2071 - precision_3: 0.6923 - recall_3: 0.2118 - val_loss: 1.5013 - val_acc: 0.4703 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1528/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5165 - acc: 0.2071 - precision_3: 0.7479 - recall_3: 0.2094 - val_loss: 1.5028 - val_acc: 0.4703 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1529/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5066 - acc: 0.2212 - precision_3: 0.7734 - recall_3: 0.2329 - val_loss: 1.5039 - val_acc: 0.4595 - val_precision_3: 0.5048 - val_recall_3: 0.5676\n",
      "Epoch 1530/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5292 - acc: 0.1812 - precision_3: 0.7358 - recall_3: 0.1835 - val_loss: 1.5041 - val_acc: 0.4703 - val_precision_3: 0.4953 - val_recall_3: 0.5676\n",
      "Epoch 1531/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5080 - acc: 0.2329 - precision_3: 0.7734 - recall_3: 0.2329 - val_loss: 1.5049 - val_acc: 0.4757 - val_precision_3: 0.4953 - val_recall_3: 0.5676\n",
      "Epoch 1532/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5047 - acc: 0.2329 - precision_3: 0.7407 - recall_3: 0.2353 - val_loss: 1.5057 - val_acc: 0.4757 - val_precision_3: 0.5000 - val_recall_3: 0.5676\n",
      "Epoch 1533/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5121 - acc: 0.2165 - precision_3: 0.8120 - recall_3: 0.2235 - val_loss: 1.5073 - val_acc: 0.4649 - val_precision_3: 0.5048 - val_recall_3: 0.5676\n",
      "Epoch 1534/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5142 - acc: 0.2235 - precision_3: 0.7442 - recall_3: 0.2259 - val_loss: 1.5073 - val_acc: 0.4649 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1535/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5082 - acc: 0.2259 - precision_3: 0.7559 - recall_3: 0.2259 - val_loss: 1.5066 - val_acc: 0.4757 - val_precision_3: 0.5073 - val_recall_3: 0.5622\n",
      "Epoch 1536/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5138 - acc: 0.2165 - precision_3: 0.7480 - recall_3: 0.2165 - val_loss: 1.5064 - val_acc: 0.4757 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1537/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5045 - acc: 0.2306 - precision_3: 0.7634 - recall_3: 0.2353 - val_loss: 1.5078 - val_acc: 0.4649 - val_precision_3: 0.5024 - val_recall_3: 0.5568\n",
      "Epoch 1538/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5242 - acc: 0.1906 - precision_3: 0.7706 - recall_3: 0.1976 - val_loss: 1.5089 - val_acc: 0.4649 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 1539/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5152 - acc: 0.2071 - precision_3: 0.7712 - recall_3: 0.2141 - val_loss: 1.5103 - val_acc: 0.4649 - val_precision_3: 0.5050 - val_recall_3: 0.5459\n",
      "Epoch 1540/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5181 - acc: 0.1953 - precision_3: 0.7373 - recall_3: 0.2047 - val_loss: 1.5110 - val_acc: 0.4649 - val_precision_3: 0.5025 - val_recall_3: 0.5514\n",
      "Epoch 1541/2000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.5312 - acc: 0.1812 - precision_3: 0.6723 - recall_3: 0.1882 - val_loss: 1.5121 - val_acc: 0.4595 - val_precision_3: 0.5000 - val_recall_3: 0.5459\n",
      "Epoch 1542/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5165 - acc: 0.2118 - precision_3: 0.7317 - recall_3: 0.2118 - val_loss: 1.5110 - val_acc: 0.4595 - val_precision_3: 0.4975 - val_recall_3: 0.5459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1543/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5135 - acc: 0.2212 - precision_3: 0.7402 - recall_3: 0.2212 - val_loss: 1.5112 - val_acc: 0.4649 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 1544/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5119 - acc: 0.2212 - precision_3: 0.7769 - recall_3: 0.2212 - val_loss: 1.5113 - val_acc: 0.4595 - val_precision_3: 0.5025 - val_recall_3: 0.5459\n",
      "Epoch 1545/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5063 - acc: 0.2212 - precision_3: 0.7903 - recall_3: 0.2306 - val_loss: 1.5084 - val_acc: 0.4541 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1546/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5130 - acc: 0.2094 - precision_3: 0.7647 - recall_3: 0.2141 - val_loss: 1.5047 - val_acc: 0.4595 - val_precision_3: 0.4976 - val_recall_3: 0.5676\n",
      "Epoch 1547/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5266 - acc: 0.1953 - precision_3: 0.7368 - recall_3: 0.1976 - val_loss: 1.5049 - val_acc: 0.4649 - val_precision_3: 0.4928 - val_recall_3: 0.5568\n",
      "Epoch 1548/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5210 - acc: 0.1953 - precision_3: 0.7706 - recall_3: 0.1976 - val_loss: 1.5051 - val_acc: 0.4595 - val_precision_3: 0.4976 - val_recall_3: 0.5568\n",
      "Epoch 1549/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5145 - acc: 0.2094 - precision_3: 0.7759 - recall_3: 0.2118 - val_loss: 1.5055 - val_acc: 0.4595 - val_precision_3: 0.4976 - val_recall_3: 0.5568\n",
      "Epoch 1550/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5066 - acc: 0.2329 - precision_3: 0.8080 - recall_3: 0.2376 - val_loss: 1.5057 - val_acc: 0.4649 - val_precision_3: 0.5000 - val_recall_3: 0.5514\n",
      "Epoch 1551/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5227 - acc: 0.2047 - precision_3: 0.6822 - recall_3: 0.2071 - val_loss: 1.5079 - val_acc: 0.4595 - val_precision_3: 0.5000 - val_recall_3: 0.5568\n",
      "Epoch 1552/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5163 - acc: 0.2118 - precision_3: 0.7541 - recall_3: 0.2165 - val_loss: 1.5084 - val_acc: 0.4649 - val_precision_3: 0.4976 - val_recall_3: 0.5568\n",
      "Epoch 1553/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5114 - acc: 0.2259 - precision_3: 0.7934 - recall_3: 0.2259 - val_loss: 1.5074 - val_acc: 0.4649 - val_precision_3: 0.5024 - val_recall_3: 0.5568\n",
      "Epoch 1554/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5111 - acc: 0.2188 - precision_3: 0.7949 - recall_3: 0.2188 - val_loss: 1.5067 - val_acc: 0.4649 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1555/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5204 - acc: 0.1953 - precision_3: 0.7544 - recall_3: 0.2024 - val_loss: 1.5061 - val_acc: 0.4703 - val_precision_3: 0.5074 - val_recall_3: 0.5568\n",
      "Epoch 1556/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5298 - acc: 0.1788 - precision_3: 0.8444 - recall_3: 0.1788 - val_loss: 1.5070 - val_acc: 0.4703 - val_precision_3: 0.5123 - val_recall_3: 0.5622\n",
      "Epoch 1557/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5122 - acc: 0.2306 - precision_3: 0.7313 - recall_3: 0.2306 - val_loss: 1.5090 - val_acc: 0.4486 - val_precision_3: 0.5049 - val_recall_3: 0.5568\n",
      "Epoch 1558/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5031 - acc: 0.2353 - precision_3: 0.7820 - recall_3: 0.2447 - val_loss: 1.5087 - val_acc: 0.4432 - val_precision_3: 0.5000 - val_recall_3: 0.5568\n",
      "Epoch 1559/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5092 - acc: 0.2235 - precision_3: 0.7619 - recall_3: 0.2259 - val_loss: 1.5084 - val_acc: 0.4432 - val_precision_3: 0.4928 - val_recall_3: 0.5568\n",
      "Epoch 1560/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5118 - acc: 0.2141 - precision_3: 0.7603 - recall_3: 0.2165 - val_loss: 1.5086 - val_acc: 0.4432 - val_precision_3: 0.4880 - val_recall_3: 0.5514\n",
      "Epoch 1561/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5233 - acc: 0.2024 - precision_3: 0.7097 - recall_3: 0.2071 - val_loss: 1.5088 - val_acc: 0.4432 - val_precision_3: 0.4833 - val_recall_3: 0.5459\n",
      "Epoch 1562/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5095 - acc: 0.2235 - precision_3: 0.7557 - recall_3: 0.2329 - val_loss: 1.5095 - val_acc: 0.4378 - val_precision_3: 0.4810 - val_recall_3: 0.5459\n",
      "Epoch 1563/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5313 - acc: 0.1835 - precision_3: 0.7207 - recall_3: 0.1882 - val_loss: 1.5099 - val_acc: 0.4378 - val_precision_3: 0.4833 - val_recall_3: 0.5459\n",
      "Epoch 1564/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5298 - acc: 0.1765 - precision_3: 0.7308 - recall_3: 0.1788 - val_loss: 1.5093 - val_acc: 0.4378 - val_precision_3: 0.4880 - val_recall_3: 0.5514\n",
      "Epoch 1565/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.4996 - acc: 0.2376 - precision_3: 0.7984 - recall_3: 0.2424 - val_loss: 1.5094 - val_acc: 0.4378 - val_precision_3: 0.4880 - val_recall_3: 0.5514\n",
      "Epoch 1566/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5140 - acc: 0.2118 - precision_3: 0.7302 - recall_3: 0.2165 - val_loss: 1.5091 - val_acc: 0.4378 - val_precision_3: 0.4904 - val_recall_3: 0.5514\n",
      "Epoch 1567/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5026 - acc: 0.2329 - precision_3: 0.8016 - recall_3: 0.2376 - val_loss: 1.5087 - val_acc: 0.4378 - val_precision_3: 0.4904 - val_recall_3: 0.5514\n",
      "Epoch 1568/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5192 - acc: 0.1976 - precision_3: 0.7500 - recall_3: 0.1976 - val_loss: 1.5082 - val_acc: 0.4378 - val_precision_3: 0.4904 - val_recall_3: 0.5514\n",
      "Epoch 1569/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5126 - acc: 0.2188 - precision_3: 0.7815 - recall_3: 0.2188 - val_loss: 1.5075 - val_acc: 0.4432 - val_precision_3: 0.4857 - val_recall_3: 0.5514\n",
      "Epoch 1570/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5121 - acc: 0.2188 - precision_3: 0.7480 - recall_3: 0.2235 - val_loss: 1.5060 - val_acc: 0.4378 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1571/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5196 - acc: 0.2071 - precision_3: 0.7177 - recall_3: 0.2094 - val_loss: 1.5047 - val_acc: 0.4432 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1572/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5107 - acc: 0.2212 - precision_3: 0.7348 - recall_3: 0.2282 - val_loss: 1.5047 - val_acc: 0.4541 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1573/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5165 - acc: 0.2024 - precision_3: 0.7652 - recall_3: 0.2071 - val_loss: 1.5051 - val_acc: 0.4486 - val_precision_3: 0.4883 - val_recall_3: 0.5622\n",
      "Epoch 1574/2000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.5136 - acc: 0.2141 - precision_3: 0.7667 - recall_3: 0.2165 - val_loss: 1.5056 - val_acc: 0.4486 - val_precision_3: 0.4858 - val_recall_3: 0.5568\n",
      "Epoch 1575/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5253 - acc: 0.1976 - precision_3: 0.6967 - recall_3: 0.2000 - val_loss: 1.5062 - val_acc: 0.4432 - val_precision_3: 0.4905 - val_recall_3: 0.5568\n",
      "Epoch 1576/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5166 - acc: 0.2141 - precision_3: 0.7623 - recall_3: 0.2188 - val_loss: 1.5078 - val_acc: 0.4432 - val_precision_3: 0.4882 - val_recall_3: 0.5568\n",
      "Epoch 1577/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5101 - acc: 0.2212 - precision_3: 0.8067 - recall_3: 0.2259 - val_loss: 1.5097 - val_acc: 0.4378 - val_precision_3: 0.4836 - val_recall_3: 0.5568\n",
      "Epoch 1578/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5108 - acc: 0.2212 - precision_3: 0.7787 - recall_3: 0.2235 - val_loss: 1.5090 - val_acc: 0.4486 - val_precision_3: 0.4860 - val_recall_3: 0.5622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1579/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5144 - acc: 0.2094 - precision_3: 0.6992 - recall_3: 0.2188 - val_loss: 1.5086 - val_acc: 0.4541 - val_precision_3: 0.4930 - val_recall_3: 0.5730\n",
      "Epoch 1580/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5018 - acc: 0.2447 - precision_3: 0.7939 - recall_3: 0.2447 - val_loss: 1.5085 - val_acc: 0.4486 - val_precision_3: 0.4885 - val_recall_3: 0.5730\n",
      "Epoch 1581/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5146 - acc: 0.2141 - precision_3: 0.7500 - recall_3: 0.2188 - val_loss: 1.5096 - val_acc: 0.4486 - val_precision_3: 0.4862 - val_recall_3: 0.5730\n",
      "Epoch 1582/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5064 - acc: 0.2329 - precision_3: 0.7063 - recall_3: 0.2376 - val_loss: 1.5105 - val_acc: 0.4432 - val_precision_3: 0.4839 - val_recall_3: 0.5676\n",
      "Epoch 1583/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5170 - acc: 0.2094 - precision_3: 0.7563 - recall_3: 0.2118 - val_loss: 1.5114 - val_acc: 0.4432 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1584/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5091 - acc: 0.2235 - precision_3: 0.7724 - recall_3: 0.2235 - val_loss: 1.5118 - val_acc: 0.4432 - val_precision_3: 0.4793 - val_recall_3: 0.5622\n",
      "Epoch 1585/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5236 - acc: 0.2024 - precision_3: 0.7107 - recall_3: 0.2024 - val_loss: 1.5104 - val_acc: 0.4378 - val_precision_3: 0.4815 - val_recall_3: 0.5622\n",
      "Epoch 1586/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5072 - acc: 0.2282 - precision_3: 0.7424 - recall_3: 0.2306 - val_loss: 1.5100 - val_acc: 0.4378 - val_precision_3: 0.4883 - val_recall_3: 0.5622\n",
      "Epoch 1587/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5097 - acc: 0.2235 - precision_3: 0.7805 - recall_3: 0.2259 - val_loss: 1.5098 - val_acc: 0.4432 - val_precision_3: 0.4907 - val_recall_3: 0.5676\n",
      "Epoch 1588/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5251 - acc: 0.2000 - precision_3: 0.7391 - recall_3: 0.2000 - val_loss: 1.5090 - val_acc: 0.4486 - val_precision_3: 0.4953 - val_recall_3: 0.5676\n",
      "Epoch 1589/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5252 - acc: 0.1859 - precision_3: 0.7921 - recall_3: 0.1882 - val_loss: 1.5090 - val_acc: 0.4541 - val_precision_3: 0.4930 - val_recall_3: 0.5676\n",
      "Epoch 1590/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5137 - acc: 0.2188 - precision_3: 0.7460 - recall_3: 0.2212 - val_loss: 1.5104 - val_acc: 0.4486 - val_precision_3: 0.4860 - val_recall_3: 0.5622\n",
      "Epoch 1591/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5288 - acc: 0.1859 - precision_3: 0.7453 - recall_3: 0.1859 - val_loss: 1.5110 - val_acc: 0.4432 - val_precision_3: 0.4905 - val_recall_3: 0.5568\n",
      "Epoch 1592/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5255 - acc: 0.1953 - precision_3: 0.7434 - recall_3: 0.1976 - val_loss: 1.5091 - val_acc: 0.4486 - val_precision_3: 0.4928 - val_recall_3: 0.5568\n",
      "Epoch 1593/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5094 - acc: 0.2235 - precision_3: 0.8796 - recall_3: 0.2235 - val_loss: 1.5084 - val_acc: 0.4486 - val_precision_3: 0.4952 - val_recall_3: 0.5622\n",
      "Epoch 1594/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5242 - acc: 0.1906 - precision_3: 0.6975 - recall_3: 0.1953 - val_loss: 1.5091 - val_acc: 0.4541 - val_precision_3: 0.4952 - val_recall_3: 0.5622\n",
      "Epoch 1595/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5248 - acc: 0.1859 - precision_3: 0.7232 - recall_3: 0.1906 - val_loss: 1.5104 - val_acc: 0.4595 - val_precision_3: 0.4929 - val_recall_3: 0.5622\n",
      "Epoch 1596/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5044 - acc: 0.2400 - precision_3: 0.7153 - recall_3: 0.2424 - val_loss: 1.5113 - val_acc: 0.4595 - val_precision_3: 0.4929 - val_recall_3: 0.5622\n",
      "Epoch 1597/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5123 - acc: 0.2306 - precision_3: 0.7313 - recall_3: 0.2306 - val_loss: 1.5117 - val_acc: 0.4595 - val_precision_3: 0.4929 - val_recall_3: 0.5622\n",
      "Epoch 1598/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5219 - acc: 0.1976 - precision_3: 0.6935 - recall_3: 0.2024 - val_loss: 1.5114 - val_acc: 0.4595 - val_precision_3: 0.4906 - val_recall_3: 0.5622\n",
      "Epoch 1599/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.4976 - acc: 0.2494 - precision_3: 0.7569 - recall_3: 0.2565 - val_loss: 1.5113 - val_acc: 0.4595 - val_precision_3: 0.4906 - val_recall_3: 0.5622\n",
      "Epoch 1600/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5209 - acc: 0.1976 - precision_3: 0.7167 - recall_3: 0.2024 - val_loss: 1.5133 - val_acc: 0.4595 - val_precision_3: 0.4858 - val_recall_3: 0.5568\n",
      "Epoch 1601/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5178 - acc: 0.2047 - precision_3: 0.8286 - recall_3: 0.2047 - val_loss: 1.5138 - val_acc: 0.4649 - val_precision_3: 0.4857 - val_recall_3: 0.5514\n",
      "Epoch 1602/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5122 - acc: 0.2188 - precision_3: 0.7833 - recall_3: 0.2212 - val_loss: 1.5142 - val_acc: 0.4649 - val_precision_3: 0.4787 - val_recall_3: 0.5459\n",
      "Epoch 1603/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5000 - acc: 0.2376 - precision_3: 0.7846 - recall_3: 0.2400 - val_loss: 1.5135 - val_acc: 0.4595 - val_precision_3: 0.4813 - val_recall_3: 0.5568\n",
      "Epoch 1604/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5083 - acc: 0.2212 - precision_3: 0.7742 - recall_3: 0.2259 - val_loss: 1.5130 - val_acc: 0.4595 - val_precision_3: 0.4813 - val_recall_3: 0.5568\n",
      "Epoch 1605/2000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.5207 - acc: 0.2047 - precision_3: 0.7177 - recall_3: 0.2094 - val_loss: 1.5127 - val_acc: 0.4595 - val_precision_3: 0.4813 - val_recall_3: 0.5568\n",
      "Epoch 1606/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5089 - acc: 0.2212 - precision_3: 0.8276 - recall_3: 0.2259 - val_loss: 1.5135 - val_acc: 0.4541 - val_precision_3: 0.4813 - val_recall_3: 0.5568\n",
      "Epoch 1607/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5179 - acc: 0.2024 - precision_3: 0.7565 - recall_3: 0.2047 - val_loss: 1.5133 - val_acc: 0.4541 - val_precision_3: 0.4769 - val_recall_3: 0.5568\n",
      "Epoch 1608/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5204 - acc: 0.2141 - precision_3: 0.6912 - recall_3: 0.2212 - val_loss: 1.5126 - val_acc: 0.4486 - val_precision_3: 0.4791 - val_recall_3: 0.5568\n",
      "Epoch 1609/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5004 - acc: 0.2424 - precision_3: 0.7879 - recall_3: 0.2447 - val_loss: 1.5127 - val_acc: 0.4432 - val_precision_3: 0.4766 - val_recall_3: 0.5514\n",
      "Epoch 1610/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5089 - acc: 0.2235 - precision_3: 0.7252 - recall_3: 0.2235 - val_loss: 1.5126 - val_acc: 0.4486 - val_precision_3: 0.4860 - val_recall_3: 0.5622\n",
      "Epoch 1611/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5061 - acc: 0.2306 - precision_3: 0.7424 - recall_3: 0.2306 - val_loss: 1.5136 - val_acc: 0.4324 - val_precision_3: 0.4811 - val_recall_3: 0.5514\n",
      "Epoch 1612/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5176 - acc: 0.2071 - precision_3: 0.7672 - recall_3: 0.2094 - val_loss: 1.5135 - val_acc: 0.4378 - val_precision_3: 0.4906 - val_recall_3: 0.5622\n",
      "Epoch 1613/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5102 - acc: 0.2188 - precision_3: 0.7724 - recall_3: 0.2235 - val_loss: 1.5130 - val_acc: 0.4432 - val_precision_3: 0.4977 - val_recall_3: 0.5838\n",
      "Epoch 1614/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5054 - acc: 0.2353 - precision_3: 0.7153 - recall_3: 0.2424 - val_loss: 1.5127 - val_acc: 0.4486 - val_precision_3: 0.5000 - val_recall_3: 0.5892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1615/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5140 - acc: 0.2141 - precision_3: 0.7863 - recall_3: 0.2165 - val_loss: 1.5125 - val_acc: 0.4541 - val_precision_3: 0.5000 - val_recall_3: 0.5946\n",
      "Epoch 1616/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5079 - acc: 0.2212 - precision_3: 0.7805 - recall_3: 0.2259 - val_loss: 1.5119 - val_acc: 0.4541 - val_precision_3: 0.5000 - val_recall_3: 0.5946\n",
      "Epoch 1617/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.5258 - acc: 0.1906 - precision_3: 0.7168 - recall_3: 0.1906 - val_loss: 1.5126 - val_acc: 0.4541 - val_precision_3: 0.4932 - val_recall_3: 0.5892\n",
      "Epoch 1618/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5335 - acc: 0.1741 - precision_3: 0.7103 - recall_3: 0.1788 - val_loss: 1.5136 - val_acc: 0.4486 - val_precision_3: 0.4932 - val_recall_3: 0.5838\n",
      "Epoch 1619/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5190 - acc: 0.2024 - precision_3: 0.7350 - recall_3: 0.2024 - val_loss: 1.5155 - val_acc: 0.4270 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1620/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5070 - acc: 0.2282 - precision_3: 0.7674 - recall_3: 0.2329 - val_loss: 1.5168 - val_acc: 0.4270 - val_precision_3: 0.4811 - val_recall_3: 0.5514\n",
      "Epoch 1621/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5047 - acc: 0.2306 - precision_3: 0.7538 - recall_3: 0.2306 - val_loss: 1.5171 - val_acc: 0.4270 - val_precision_3: 0.4787 - val_recall_3: 0.5459\n",
      "Epoch 1622/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5068 - acc: 0.2282 - precision_3: 0.7951 - recall_3: 0.2282 - val_loss: 1.5172 - val_acc: 0.4324 - val_precision_3: 0.4764 - val_recall_3: 0.5459\n",
      "Epoch 1623/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5231 - acc: 0.1929 - precision_3: 0.7757 - recall_3: 0.1953 - val_loss: 1.5171 - val_acc: 0.4270 - val_precision_3: 0.4787 - val_recall_3: 0.5459\n",
      "Epoch 1624/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5265 - acc: 0.1906 - precision_3: 0.7642 - recall_3: 0.1906 - val_loss: 1.5164 - val_acc: 0.4378 - val_precision_3: 0.4789 - val_recall_3: 0.5514\n",
      "Epoch 1625/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.4989 - acc: 0.2424 - precision_3: 0.8320 - recall_3: 0.2447 - val_loss: 1.5161 - val_acc: 0.4324 - val_precision_3: 0.4739 - val_recall_3: 0.5405\n",
      "Epoch 1626/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5214 - acc: 0.2024 - precision_3: 0.7008 - recall_3: 0.2094 - val_loss: 1.5167 - val_acc: 0.4270 - val_precision_3: 0.4714 - val_recall_3: 0.5351\n",
      "Epoch 1627/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5023 - acc: 0.2306 - precision_3: 0.8130 - recall_3: 0.2353 - val_loss: 1.5165 - val_acc: 0.4270 - val_precision_3: 0.4593 - val_recall_3: 0.5189\n",
      "Epoch 1628/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5272 - acc: 0.1882 - precision_3: 0.6957 - recall_3: 0.1882 - val_loss: 1.5168 - val_acc: 0.4270 - val_precision_3: 0.4638 - val_recall_3: 0.5189\n",
      "Epoch 1629/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5300 - acc: 0.1859 - precision_3: 0.6957 - recall_3: 0.1882 - val_loss: 1.5167 - val_acc: 0.4162 - val_precision_3: 0.4732 - val_recall_3: 0.5243\n",
      "Epoch 1630/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5128 - acc: 0.2118 - precision_3: 0.7863 - recall_3: 0.2165 - val_loss: 1.5155 - val_acc: 0.4216 - val_precision_3: 0.4880 - val_recall_3: 0.5514\n",
      "Epoch 1631/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5345 - acc: 0.1741 - precision_3: 0.6881 - recall_3: 0.1765 - val_loss: 1.5148 - val_acc: 0.4324 - val_precision_3: 0.4905 - val_recall_3: 0.5568\n",
      "Epoch 1632/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5210 - acc: 0.2000 - precision_3: 0.7391 - recall_3: 0.2000 - val_loss: 1.5144 - val_acc: 0.4324 - val_precision_3: 0.5000 - val_recall_3: 0.5676\n",
      "Epoch 1633/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5139 - acc: 0.2141 - precision_3: 0.7500 - recall_3: 0.2188 - val_loss: 1.5134 - val_acc: 0.4432 - val_precision_3: 0.5000 - val_recall_3: 0.5784\n",
      "Epoch 1634/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5005 - acc: 0.2494 - precision_3: 0.8030 - recall_3: 0.2494 - val_loss: 1.5134 - val_acc: 0.4432 - val_precision_3: 0.5071 - val_recall_3: 0.5784\n",
      "Epoch 1635/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5253 - acc: 0.1976 - precision_3: 0.6617 - recall_3: 0.2071 - val_loss: 1.5131 - val_acc: 0.4486 - val_precision_3: 0.5000 - val_recall_3: 0.5622\n",
      "Epoch 1636/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5136 - acc: 0.2188 - precision_3: 0.7099 - recall_3: 0.2188 - val_loss: 1.5128 - val_acc: 0.4486 - val_precision_3: 0.5073 - val_recall_3: 0.5622\n",
      "Epoch 1637/2000\n",
      "85/85 [==============================] - 0s 621us/sample - loss: 1.5262 - acc: 0.1953 - precision_3: 0.7119 - recall_3: 0.1976 - val_loss: 1.5121 - val_acc: 0.4486 - val_precision_3: 0.5049 - val_recall_3: 0.5622\n",
      "Epoch 1638/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5244 - acc: 0.1976 - precision_3: 0.7391 - recall_3: 0.2000 - val_loss: 1.5128 - val_acc: 0.4486 - val_precision_3: 0.5024 - val_recall_3: 0.5622\n",
      "Epoch 1639/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5125 - acc: 0.2071 - precision_3: 0.7965 - recall_3: 0.2118 - val_loss: 1.5137 - val_acc: 0.4541 - val_precision_3: 0.4951 - val_recall_3: 0.5459\n",
      "Epoch 1640/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5076 - acc: 0.2165 - precision_3: 0.7638 - recall_3: 0.2282 - val_loss: 1.5141 - val_acc: 0.4486 - val_precision_3: 0.4902 - val_recall_3: 0.5405\n",
      "Epoch 1641/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5124 - acc: 0.2118 - precision_3: 0.7480 - recall_3: 0.2235 - val_loss: 1.5136 - val_acc: 0.4486 - val_precision_3: 0.4926 - val_recall_3: 0.5405\n",
      "Epoch 1642/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5082 - acc: 0.2212 - precision_3: 0.8261 - recall_3: 0.2235 - val_loss: 1.5134 - val_acc: 0.4486 - val_precision_3: 0.4828 - val_recall_3: 0.5297\n",
      "Epoch 1643/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5189 - acc: 0.2071 - precision_3: 0.7087 - recall_3: 0.2118 - val_loss: 1.5137 - val_acc: 0.4595 - val_precision_3: 0.4828 - val_recall_3: 0.5297\n",
      "Epoch 1644/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.4958 - acc: 0.2424 - precision_3: 0.8106 - recall_3: 0.2518 - val_loss: 1.5147 - val_acc: 0.4703 - val_precision_3: 0.4899 - val_recall_3: 0.5243\n",
      "Epoch 1645/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5080 - acc: 0.2282 - precision_3: 0.7615 - recall_3: 0.2329 - val_loss: 1.5142 - val_acc: 0.4595 - val_precision_3: 0.4899 - val_recall_3: 0.5243\n",
      "Epoch 1646/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5204 - acc: 0.1976 - precision_3: 0.7798 - recall_3: 0.2000 - val_loss: 1.5145 - val_acc: 0.4649 - val_precision_3: 0.4925 - val_recall_3: 0.5297\n",
      "Epoch 1647/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5189 - acc: 0.2047 - precision_3: 0.8000 - recall_3: 0.2071 - val_loss: 1.5131 - val_acc: 0.4595 - val_precision_3: 0.4900 - val_recall_3: 0.5297\n",
      "Epoch 1648/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5230 - acc: 0.1906 - precision_3: 0.7615 - recall_3: 0.1953 - val_loss: 1.5121 - val_acc: 0.4595 - val_precision_3: 0.4851 - val_recall_3: 0.5297\n",
      "Epoch 1649/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5067 - acc: 0.2353 - precision_3: 0.7669 - recall_3: 0.2400 - val_loss: 1.5116 - val_acc: 0.4649 - val_precision_3: 0.4853 - val_recall_3: 0.5351\n",
      "Epoch 1650/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5112 - acc: 0.2306 - precision_3: 0.7717 - recall_3: 0.2306 - val_loss: 1.5119 - val_acc: 0.4541 - val_precision_3: 0.4851 - val_recall_3: 0.5297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1651/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5206 - acc: 0.2071 - precision_3: 0.7561 - recall_3: 0.2188 - val_loss: 1.5131 - val_acc: 0.4541 - val_precision_3: 0.4848 - val_recall_3: 0.5189\n",
      "Epoch 1652/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5232 - acc: 0.1906 - precision_3: 0.7500 - recall_3: 0.1976 - val_loss: 1.5129 - val_acc: 0.4541 - val_precision_3: 0.4826 - val_recall_3: 0.5243\n",
      "Epoch 1653/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5134 - acc: 0.2094 - precision_3: 0.7561 - recall_3: 0.2188 - val_loss: 1.5114 - val_acc: 0.4595 - val_precision_3: 0.4802 - val_recall_3: 0.5243\n",
      "Epoch 1654/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5158 - acc: 0.2024 - precision_3: 0.8000 - recall_3: 0.2071 - val_loss: 1.5100 - val_acc: 0.4595 - val_precision_3: 0.4806 - val_recall_3: 0.5351\n",
      "Epoch 1655/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5226 - acc: 0.2024 - precision_3: 0.6772 - recall_3: 0.2024 - val_loss: 1.5080 - val_acc: 0.4541 - val_precision_3: 0.4806 - val_recall_3: 0.5351\n",
      "Epoch 1656/2000\n",
      "85/85 [==============================] - 0s 621us/sample - loss: 1.5111 - acc: 0.2165 - precision_3: 0.7197 - recall_3: 0.2235 - val_loss: 1.5061 - val_acc: 0.4649 - val_precision_3: 0.4785 - val_recall_3: 0.5405\n",
      "Epoch 1657/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5174 - acc: 0.2141 - precision_3: 0.7077 - recall_3: 0.2165 - val_loss: 1.5059 - val_acc: 0.4595 - val_precision_3: 0.4785 - val_recall_3: 0.5405\n",
      "Epoch 1658/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5181 - acc: 0.2000 - precision_3: 0.7355 - recall_3: 0.2094 - val_loss: 1.5051 - val_acc: 0.4649 - val_precision_3: 0.4714 - val_recall_3: 0.5351\n",
      "Epoch 1659/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5054 - acc: 0.2447 - precision_3: 0.7222 - recall_3: 0.2447 - val_loss: 1.5026 - val_acc: 0.4541 - val_precision_3: 0.4695 - val_recall_3: 0.5405\n",
      "Epoch 1660/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5130 - acc: 0.2141 - precision_3: 0.7642 - recall_3: 0.2212 - val_loss: 1.5019 - val_acc: 0.4595 - val_precision_3: 0.4742 - val_recall_3: 0.5459\n",
      "Epoch 1661/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5215 - acc: 0.1929 - precision_3: 0.7434 - recall_3: 0.1976 - val_loss: 1.4999 - val_acc: 0.4649 - val_precision_3: 0.4676 - val_recall_3: 0.5459\n",
      "Epoch 1662/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5139 - acc: 0.2094 - precision_3: 0.7459 - recall_3: 0.2141 - val_loss: 1.4989 - val_acc: 0.4595 - val_precision_3: 0.4676 - val_recall_3: 0.5459\n",
      "Epoch 1663/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5034 - acc: 0.2282 - precision_3: 0.7674 - recall_3: 0.2329 - val_loss: 1.4989 - val_acc: 0.4649 - val_precision_3: 0.4679 - val_recall_3: 0.5514\n",
      "Epoch 1664/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5059 - acc: 0.2376 - precision_3: 0.8031 - recall_3: 0.2400 - val_loss: 1.5000 - val_acc: 0.4595 - val_precision_3: 0.4658 - val_recall_3: 0.5514\n",
      "Epoch 1665/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5171 - acc: 0.2094 - precision_3: 0.7826 - recall_3: 0.2118 - val_loss: 1.5080 - val_acc: 0.4649 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1666/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5092 - acc: 0.2306 - precision_3: 0.7259 - recall_3: 0.2306 - val_loss: 1.5149 - val_acc: 0.4432 - val_precision_3: 0.4783 - val_recall_3: 0.5351\n",
      "Epoch 1667/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5091 - acc: 0.2306 - precision_3: 0.7299 - recall_3: 0.2353 - val_loss: 1.5180 - val_acc: 0.4486 - val_precision_3: 0.4853 - val_recall_3: 0.5351\n",
      "Epoch 1668/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5142 - acc: 0.2165 - precision_3: 0.6912 - recall_3: 0.2212 - val_loss: 1.5187 - val_acc: 0.4486 - val_precision_3: 0.4829 - val_recall_3: 0.5351\n",
      "Epoch 1669/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5294 - acc: 0.1859 - precision_3: 0.6897 - recall_3: 0.1882 - val_loss: 1.5190 - val_acc: 0.4378 - val_precision_3: 0.4800 - val_recall_3: 0.5189\n",
      "Epoch 1670/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.4989 - acc: 0.2424 - precision_3: 0.7879 - recall_3: 0.2447 - val_loss: 1.5192 - val_acc: 0.4432 - val_precision_3: 0.4874 - val_recall_3: 0.5243\n",
      "Epoch 1671/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5108 - acc: 0.2141 - precision_3: 0.7931 - recall_3: 0.2165 - val_loss: 1.5176 - val_acc: 0.4432 - val_precision_3: 0.4899 - val_recall_3: 0.5243\n",
      "Epoch 1672/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5003 - acc: 0.2471 - precision_3: 0.7260 - recall_3: 0.2494 - val_loss: 1.5174 - val_acc: 0.4486 - val_precision_3: 0.4876 - val_recall_3: 0.5297\n",
      "Epoch 1673/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5236 - acc: 0.2024 - precision_3: 0.7227 - recall_3: 0.2024 - val_loss: 1.5169 - val_acc: 0.4541 - val_precision_3: 0.4829 - val_recall_3: 0.5351\n",
      "Epoch 1674/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5100 - acc: 0.2235 - precision_3: 0.7037 - recall_3: 0.2235 - val_loss: 1.5176 - val_acc: 0.4541 - val_precision_3: 0.4757 - val_recall_3: 0.5297\n",
      "Epoch 1675/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5158 - acc: 0.2141 - precision_3: 0.7731 - recall_3: 0.2165 - val_loss: 1.5178 - val_acc: 0.4486 - val_precision_3: 0.4732 - val_recall_3: 0.5243\n",
      "Epoch 1676/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.5254 - acc: 0.1929 - precision_3: 0.7025 - recall_3: 0.2000 - val_loss: 1.5174 - val_acc: 0.4541 - val_precision_3: 0.4734 - val_recall_3: 0.5297\n",
      "Epoch 1677/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5193 - acc: 0.2000 - precision_3: 0.7288 - recall_3: 0.2024 - val_loss: 1.5161 - val_acc: 0.4541 - val_precision_3: 0.4762 - val_recall_3: 0.5405\n",
      "Epoch 1678/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.4990 - acc: 0.2447 - precision_3: 0.7737 - recall_3: 0.2494 - val_loss: 1.5160 - val_acc: 0.4541 - val_precision_3: 0.4762 - val_recall_3: 0.5405\n",
      "Epoch 1679/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5188 - acc: 0.2047 - precision_3: 0.7857 - recall_3: 0.2071 - val_loss: 1.5144 - val_acc: 0.4432 - val_precision_3: 0.4789 - val_recall_3: 0.5514\n",
      "Epoch 1680/2000\n",
      "85/85 [==============================] - 0s 621us/sample - loss: 1.5038 - acc: 0.2306 - precision_3: 0.7717 - recall_3: 0.2306 - val_loss: 1.5145 - val_acc: 0.4432 - val_precision_3: 0.4720 - val_recall_3: 0.5459\n",
      "Epoch 1681/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5011 - acc: 0.2353 - precision_3: 0.8016 - recall_3: 0.2376 - val_loss: 1.5155 - val_acc: 0.4432 - val_precision_3: 0.4787 - val_recall_3: 0.5459\n",
      "Epoch 1682/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5057 - acc: 0.2259 - precision_3: 0.7218 - recall_3: 0.2259 - val_loss: 1.5165 - val_acc: 0.4432 - val_precision_3: 0.4762 - val_recall_3: 0.5405\n",
      "Epoch 1683/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5243 - acc: 0.1906 - precision_3: 0.7736 - recall_3: 0.1929 - val_loss: 1.5165 - val_acc: 0.4486 - val_precision_3: 0.4762 - val_recall_3: 0.5405\n",
      "Epoch 1684/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5220 - acc: 0.1976 - precision_3: 0.7131 - recall_3: 0.2047 - val_loss: 1.5157 - val_acc: 0.4486 - val_precision_3: 0.4764 - val_recall_3: 0.5459\n",
      "Epoch 1685/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5182 - acc: 0.2000 - precision_3: 0.7414 - recall_3: 0.2024 - val_loss: 1.5147 - val_acc: 0.4486 - val_precision_3: 0.4742 - val_recall_3: 0.5459\n",
      "Epoch 1686/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5147 - acc: 0.2094 - precision_3: 0.8182 - recall_3: 0.2118 - val_loss: 1.5135 - val_acc: 0.4486 - val_precision_3: 0.4720 - val_recall_3: 0.5459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1687/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5093 - acc: 0.2165 - precision_3: 0.7619 - recall_3: 0.2259 - val_loss: 1.5147 - val_acc: 0.4432 - val_precision_3: 0.4695 - val_recall_3: 0.5405\n",
      "Epoch 1688/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.4926 - acc: 0.2612 - precision_3: 0.7929 - recall_3: 0.2612 - val_loss: 1.5197 - val_acc: 0.4486 - val_precision_3: 0.4806 - val_recall_3: 0.5351\n",
      "Epoch 1689/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5218 - acc: 0.2024 - precision_3: 0.7227 - recall_3: 0.2024 - val_loss: 1.5222 - val_acc: 0.4324 - val_precision_3: 0.4757 - val_recall_3: 0.5297\n",
      "Epoch 1690/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5127 - acc: 0.2118 - precision_3: 0.7686 - recall_3: 0.2188 - val_loss: 1.5253 - val_acc: 0.4324 - val_precision_3: 0.4683 - val_recall_3: 0.5189\n",
      "Epoch 1691/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5096 - acc: 0.2188 - precision_3: 0.7851 - recall_3: 0.2235 - val_loss: 1.5259 - val_acc: 0.4108 - val_precision_3: 0.4660 - val_recall_3: 0.5189\n",
      "Epoch 1692/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5284 - acc: 0.1812 - precision_3: 0.7290 - recall_3: 0.1835 - val_loss: 1.5243 - val_acc: 0.4432 - val_precision_3: 0.4712 - val_recall_3: 0.5297\n",
      "Epoch 1693/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5011 - acc: 0.2353 - precision_3: 0.8403 - recall_3: 0.2353 - val_loss: 1.5230 - val_acc: 0.4486 - val_precision_3: 0.4689 - val_recall_3: 0.5297\n",
      "Epoch 1694/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5034 - acc: 0.2424 - precision_3: 0.7574 - recall_3: 0.2424 - val_loss: 1.5232 - val_acc: 0.4432 - val_precision_3: 0.4545 - val_recall_3: 0.5135\n",
      "Epoch 1695/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5297 - acc: 0.1835 - precision_3: 0.7222 - recall_3: 0.1835 - val_loss: 1.5230 - val_acc: 0.4486 - val_precision_3: 0.4579 - val_recall_3: 0.5297\n",
      "Epoch 1696/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5216 - acc: 0.2024 - precision_3: 0.7227 - recall_3: 0.2024 - val_loss: 1.5222 - val_acc: 0.4541 - val_precision_3: 0.4601 - val_recall_3: 0.5297\n",
      "Epoch 1697/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5093 - acc: 0.2188 - precision_3: 0.7462 - recall_3: 0.2282 - val_loss: 1.5218 - val_acc: 0.4541 - val_precision_3: 0.4579 - val_recall_3: 0.5297\n",
      "Epoch 1698/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5132 - acc: 0.2165 - precision_3: 0.7422 - recall_3: 0.2235 - val_loss: 1.5211 - val_acc: 0.4595 - val_precision_3: 0.4670 - val_recall_3: 0.5351\n",
      "Epoch 1699/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5022 - acc: 0.2329 - precision_3: 0.7674 - recall_3: 0.2329 - val_loss: 1.5206 - val_acc: 0.4595 - val_precision_3: 0.4670 - val_recall_3: 0.5351\n",
      "Epoch 1700/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5352 - acc: 0.1788 - precision_3: 0.6814 - recall_3: 0.1812 - val_loss: 1.5220 - val_acc: 0.4432 - val_precision_3: 0.4612 - val_recall_3: 0.5135\n",
      "Epoch 1701/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5091 - acc: 0.2235 - precision_3: 0.7615 - recall_3: 0.2329 - val_loss: 1.5222 - val_acc: 0.4270 - val_precision_3: 0.4634 - val_recall_3: 0.5135\n",
      "Epoch 1702/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5165 - acc: 0.2071 - precision_3: 0.7355 - recall_3: 0.2094 - val_loss: 1.5224 - val_acc: 0.4324 - val_precision_3: 0.4706 - val_recall_3: 0.5189\n",
      "Epoch 1703/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5111 - acc: 0.2165 - precision_3: 0.7561 - recall_3: 0.2188 - val_loss: 1.5220 - val_acc: 0.4378 - val_precision_3: 0.4732 - val_recall_3: 0.5243\n",
      "Epoch 1704/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5039 - acc: 0.2306 - precision_3: 0.8305 - recall_3: 0.2306 - val_loss: 1.5223 - val_acc: 0.4378 - val_precision_3: 0.4755 - val_recall_3: 0.5243\n",
      "Epoch 1705/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5149 - acc: 0.2071 - precision_3: 0.7672 - recall_3: 0.2094 - val_loss: 1.5228 - val_acc: 0.4270 - val_precision_3: 0.4755 - val_recall_3: 0.5243\n",
      "Epoch 1706/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5251 - acc: 0.1882 - precision_3: 0.7232 - recall_3: 0.1906 - val_loss: 1.5234 - val_acc: 0.4270 - val_precision_3: 0.4709 - val_recall_3: 0.5243\n",
      "Epoch 1707/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5211 - acc: 0.2024 - precision_3: 0.7699 - recall_3: 0.2047 - val_loss: 1.5236 - val_acc: 0.4270 - val_precision_3: 0.4729 - val_recall_3: 0.5189\n",
      "Epoch 1708/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5323 - acc: 0.1882 - precision_3: 0.6807 - recall_3: 0.1906 - val_loss: 1.5227 - val_acc: 0.4270 - val_precision_3: 0.4729 - val_recall_3: 0.5189\n",
      "Epoch 1709/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5032 - acc: 0.2306 - precision_3: 0.7463 - recall_3: 0.2353 - val_loss: 1.5211 - val_acc: 0.4378 - val_precision_3: 0.4780 - val_recall_3: 0.5297\n",
      "Epoch 1710/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5195 - acc: 0.2024 - precision_3: 0.7963 - recall_3: 0.2024 - val_loss: 1.5211 - val_acc: 0.4432 - val_precision_3: 0.4732 - val_recall_3: 0.5243\n",
      "Epoch 1711/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5119 - acc: 0.2188 - precision_3: 0.7561 - recall_3: 0.2188 - val_loss: 1.5208 - val_acc: 0.4432 - val_precision_3: 0.4734 - val_recall_3: 0.5297\n",
      "Epoch 1712/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5234 - acc: 0.1929 - precision_3: 0.7778 - recall_3: 0.1976 - val_loss: 1.5215 - val_acc: 0.4378 - val_precision_3: 0.4683 - val_recall_3: 0.5189\n",
      "Epoch 1713/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5275 - acc: 0.1835 - precision_3: 0.7453 - recall_3: 0.1859 - val_loss: 1.5216 - val_acc: 0.4486 - val_precision_3: 0.4638 - val_recall_3: 0.5189\n",
      "Epoch 1714/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5203 - acc: 0.1906 - precision_3: 0.7241 - recall_3: 0.1976 - val_loss: 1.5205 - val_acc: 0.4486 - val_precision_3: 0.4663 - val_recall_3: 0.5243\n",
      "Epoch 1715/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5138 - acc: 0.2094 - precision_3: 0.7583 - recall_3: 0.2141 - val_loss: 1.5198 - val_acc: 0.4486 - val_precision_3: 0.4663 - val_recall_3: 0.5243\n",
      "Epoch 1716/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5163 - acc: 0.2000 - precision_3: 0.7876 - recall_3: 0.2094 - val_loss: 1.5198 - val_acc: 0.4432 - val_precision_3: 0.4709 - val_recall_3: 0.5243\n",
      "Epoch 1717/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5138 - acc: 0.2141 - precision_3: 0.7480 - recall_3: 0.2165 - val_loss: 1.5182 - val_acc: 0.4378 - val_precision_3: 0.4638 - val_recall_3: 0.5189\n",
      "Epoch 1718/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5248 - acc: 0.1882 - precision_3: 0.7009 - recall_3: 0.1929 - val_loss: 1.5170 - val_acc: 0.4486 - val_precision_3: 0.4667 - val_recall_3: 0.5297\n",
      "Epoch 1719/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5299 - acc: 0.1812 - precision_3: 0.7000 - recall_3: 0.1812 - val_loss: 1.5167 - val_acc: 0.4432 - val_precision_3: 0.4670 - val_recall_3: 0.5351\n",
      "Epoch 1720/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5130 - acc: 0.2235 - precision_3: 0.7364 - recall_3: 0.2235 - val_loss: 1.5175 - val_acc: 0.4324 - val_precision_3: 0.4670 - val_recall_3: 0.5351\n",
      "Epoch 1721/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5216 - acc: 0.2118 - precision_3: 0.6977 - recall_3: 0.2118 - val_loss: 1.5170 - val_acc: 0.4378 - val_precision_3: 0.4717 - val_recall_3: 0.5405\n",
      "Epoch 1722/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5117 - acc: 0.2188 - precision_3: 0.7787 - recall_3: 0.2235 - val_loss: 1.5166 - val_acc: 0.4324 - val_precision_3: 0.4670 - val_recall_3: 0.5351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1723/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5195 - acc: 0.2071 - precision_3: 0.7458 - recall_3: 0.2071 - val_loss: 1.5164 - val_acc: 0.4324 - val_precision_3: 0.4717 - val_recall_3: 0.5405\n",
      "Epoch 1724/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5085 - acc: 0.2259 - precision_3: 0.7638 - recall_3: 0.2282 - val_loss: 1.5154 - val_acc: 0.4324 - val_precision_3: 0.4720 - val_recall_3: 0.5459\n",
      "Epoch 1725/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5150 - acc: 0.2071 - precision_3: 0.8091 - recall_3: 0.2094 - val_loss: 1.5159 - val_acc: 0.4324 - val_precision_3: 0.4742 - val_recall_3: 0.5459\n",
      "Epoch 1726/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5119 - acc: 0.2212 - precision_3: 0.8120 - recall_3: 0.2235 - val_loss: 1.5151 - val_acc: 0.4270 - val_precision_3: 0.4764 - val_recall_3: 0.5459\n",
      "Epoch 1727/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5255 - acc: 0.1835 - precision_3: 0.7900 - recall_3: 0.1859 - val_loss: 1.5140 - val_acc: 0.4324 - val_precision_3: 0.4793 - val_recall_3: 0.5622\n",
      "Epoch 1728/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5257 - acc: 0.1929 - precision_3: 0.7069 - recall_3: 0.1929 - val_loss: 1.5131 - val_acc: 0.4432 - val_precision_3: 0.4747 - val_recall_3: 0.5568\n",
      "Epoch 1729/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5043 - acc: 0.2400 - precision_3: 0.7518 - recall_3: 0.2424 - val_loss: 1.5100 - val_acc: 0.4324 - val_precision_3: 0.4703 - val_recall_3: 0.5568\n",
      "Epoch 1730/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5339 - acc: 0.1694 - precision_3: 0.7200 - recall_3: 0.1694 - val_loss: 1.5077 - val_acc: 0.4324 - val_precision_3: 0.4725 - val_recall_3: 0.5568\n",
      "Epoch 1731/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5149 - acc: 0.2188 - precision_3: 0.7581 - recall_3: 0.2212 - val_loss: 1.5084 - val_acc: 0.4324 - val_precision_3: 0.4698 - val_recall_3: 0.5459\n",
      "Epoch 1732/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5072 - acc: 0.2282 - precision_3: 0.7597 - recall_3: 0.2306 - val_loss: 1.5090 - val_acc: 0.4324 - val_precision_3: 0.4698 - val_recall_3: 0.5459\n",
      "Epoch 1733/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5043 - acc: 0.2212 - precision_3: 0.7917 - recall_3: 0.2235 - val_loss: 1.5094 - val_acc: 0.4324 - val_precision_3: 0.4720 - val_recall_3: 0.5459\n",
      "Epoch 1734/2000\n",
      "85/85 [==============================] - 0s 529us/sample - loss: 1.5128 - acc: 0.2071 - precision_3: 0.7895 - recall_3: 0.2118 - val_loss: 1.5081 - val_acc: 0.4324 - val_precision_3: 0.4725 - val_recall_3: 0.5568\n",
      "Epoch 1735/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5183 - acc: 0.2047 - precision_3: 0.7436 - recall_3: 0.2047 - val_loss: 1.5073 - val_acc: 0.4324 - val_precision_3: 0.4725 - val_recall_3: 0.5568\n",
      "Epoch 1736/2000\n",
      "85/85 [==============================] - 0s 529us/sample - loss: 1.5252 - acc: 0.1906 - precision_3: 0.7304 - recall_3: 0.1976 - val_loss: 1.5091 - val_acc: 0.4324 - val_precision_3: 0.4769 - val_recall_3: 0.5568\n",
      "Epoch 1737/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5055 - acc: 0.2188 - precision_3: 0.8067 - recall_3: 0.2259 - val_loss: 1.5097 - val_acc: 0.4378 - val_precision_3: 0.4725 - val_recall_3: 0.5568\n",
      "Epoch 1738/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5213 - acc: 0.1953 - precision_3: 0.7350 - recall_3: 0.2024 - val_loss: 1.5111 - val_acc: 0.4378 - val_precision_3: 0.4725 - val_recall_3: 0.5568\n",
      "Epoch 1739/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5049 - acc: 0.2329 - precision_3: 0.7795 - recall_3: 0.2329 - val_loss: 1.5127 - val_acc: 0.4378 - val_precision_3: 0.4789 - val_recall_3: 0.5514\n",
      "Epoch 1740/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5051 - acc: 0.2235 - precision_3: 0.8205 - recall_3: 0.2259 - val_loss: 1.5148 - val_acc: 0.4378 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1741/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5153 - acc: 0.2094 - precision_3: 0.7826 - recall_3: 0.2118 - val_loss: 1.5170 - val_acc: 0.4378 - val_precision_3: 0.4829 - val_recall_3: 0.5351\n",
      "Epoch 1742/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5185 - acc: 0.1953 - precision_3: 0.8077 - recall_3: 0.1976 - val_loss: 1.5178 - val_acc: 0.4324 - val_precision_3: 0.4853 - val_recall_3: 0.5351\n",
      "Epoch 1743/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5179 - acc: 0.2094 - precision_3: 0.7077 - recall_3: 0.2165 - val_loss: 1.5175 - val_acc: 0.4270 - val_precision_3: 0.4706 - val_recall_3: 0.5189\n",
      "Epoch 1744/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5213 - acc: 0.1976 - precision_3: 0.7636 - recall_3: 0.1976 - val_loss: 1.5163 - val_acc: 0.4270 - val_precision_3: 0.4692 - val_recall_3: 0.5351\n",
      "Epoch 1745/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5155 - acc: 0.2141 - precision_3: 0.7583 - recall_3: 0.2141 - val_loss: 1.5151 - val_acc: 0.4324 - val_precision_3: 0.4698 - val_recall_3: 0.5459\n",
      "Epoch 1746/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5264 - acc: 0.1859 - precision_3: 0.7523 - recall_3: 0.1929 - val_loss: 1.5128 - val_acc: 0.4324 - val_precision_3: 0.4679 - val_recall_3: 0.5514\n",
      "Epoch 1747/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5196 - acc: 0.2024 - precision_3: 0.6875 - recall_3: 0.2071 - val_loss: 1.5110 - val_acc: 0.4324 - val_precision_3: 0.4722 - val_recall_3: 0.5514\n",
      "Epoch 1748/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5090 - acc: 0.2165 - precision_3: 0.8230 - recall_3: 0.2188 - val_loss: 1.5104 - val_acc: 0.4378 - val_precision_3: 0.4747 - val_recall_3: 0.5568\n",
      "Epoch 1749/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5150 - acc: 0.2118 - precision_3: 0.7132 - recall_3: 0.2165 - val_loss: 1.5057 - val_acc: 0.4595 - val_precision_3: 0.4749 - val_recall_3: 0.5622\n",
      "Epoch 1750/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5113 - acc: 0.2165 - precision_3: 0.7623 - recall_3: 0.2188 - val_loss: 1.5006 - val_acc: 0.4865 - val_precision_3: 0.4685 - val_recall_3: 0.5622\n",
      "Epoch 1751/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5068 - acc: 0.2353 - precision_3: 0.7305 - recall_3: 0.2424 - val_loss: 1.4993 - val_acc: 0.4811 - val_precision_3: 0.4749 - val_recall_3: 0.5622\n",
      "Epoch 1752/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5226 - acc: 0.1953 - precision_3: 0.7391 - recall_3: 0.2000 - val_loss: 1.4991 - val_acc: 0.4757 - val_precision_3: 0.4817 - val_recall_3: 0.5676\n",
      "Epoch 1753/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5150 - acc: 0.2000 - precision_3: 0.7672 - recall_3: 0.2094 - val_loss: 1.4988 - val_acc: 0.4865 - val_precision_3: 0.4795 - val_recall_3: 0.5676\n",
      "Epoch 1754/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5167 - acc: 0.1953 - precision_3: 0.7788 - recall_3: 0.2071 - val_loss: 1.4989 - val_acc: 0.4865 - val_precision_3: 0.4773 - val_recall_3: 0.5676\n",
      "Epoch 1755/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5201 - acc: 0.1953 - precision_3: 0.7870 - recall_3: 0.2000 - val_loss: 1.4995 - val_acc: 0.4919 - val_precision_3: 0.4796 - val_recall_3: 0.5730\n",
      "Epoch 1756/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5255 - acc: 0.1859 - precision_3: 0.7431 - recall_3: 0.1906 - val_loss: 1.4995 - val_acc: 0.4919 - val_precision_3: 0.4773 - val_recall_3: 0.5676\n",
      "Epoch 1757/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5073 - acc: 0.2235 - precision_3: 0.7538 - recall_3: 0.2306 - val_loss: 1.5008 - val_acc: 0.4811 - val_precision_3: 0.4771 - val_recall_3: 0.5622\n",
      "Epoch 1758/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5128 - acc: 0.2118 - precision_3: 0.7500 - recall_3: 0.2188 - val_loss: 1.5023 - val_acc: 0.4811 - val_precision_3: 0.4771 - val_recall_3: 0.5622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1759/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5009 - acc: 0.2259 - precision_3: 0.8475 - recall_3: 0.2353 - val_loss: 1.5035 - val_acc: 0.4595 - val_precision_3: 0.4861 - val_recall_3: 0.5676\n",
      "Epoch 1760/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5214 - acc: 0.1976 - precision_3: 0.7611 - recall_3: 0.2024 - val_loss: 1.5055 - val_acc: 0.4486 - val_precision_3: 0.4764 - val_recall_3: 0.5459\n",
      "Epoch 1761/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5107 - acc: 0.2235 - precision_3: 0.7252 - recall_3: 0.2235 - val_loss: 1.5070 - val_acc: 0.4486 - val_precision_3: 0.4744 - val_recall_3: 0.5514\n",
      "Epoch 1762/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.4955 - acc: 0.2494 - precision_3: 0.8182 - recall_3: 0.2541 - val_loss: 1.5072 - val_acc: 0.4486 - val_precision_3: 0.4766 - val_recall_3: 0.5514\n",
      "Epoch 1763/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5216 - acc: 0.2000 - precision_3: 0.7311 - recall_3: 0.2047 - val_loss: 1.5064 - val_acc: 0.4486 - val_precision_3: 0.4789 - val_recall_3: 0.5514\n",
      "Epoch 1764/2000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.5110 - acc: 0.2188 - precision_3: 0.7540 - recall_3: 0.2235 - val_loss: 1.5076 - val_acc: 0.4432 - val_precision_3: 0.4833 - val_recall_3: 0.5459\n",
      "Epoch 1765/2000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.5276 - acc: 0.1882 - precision_3: 0.6807 - recall_3: 0.1906 - val_loss: 1.5093 - val_acc: 0.4378 - val_precision_3: 0.4810 - val_recall_3: 0.5459\n",
      "Epoch 1766/2000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.5036 - acc: 0.2306 - precision_3: 0.8115 - recall_3: 0.2329 - val_loss: 1.5119 - val_acc: 0.4270 - val_precision_3: 0.4854 - val_recall_3: 0.5405\n",
      "Epoch 1767/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5108 - acc: 0.2165 - precision_3: 0.7686 - recall_3: 0.2188 - val_loss: 1.5137 - val_acc: 0.4270 - val_precision_3: 0.4856 - val_recall_3: 0.5459\n",
      "Epoch 1768/2000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.5137 - acc: 0.2118 - precision_3: 0.7647 - recall_3: 0.2141 - val_loss: 1.5129 - val_acc: 0.4378 - val_precision_3: 0.4880 - val_recall_3: 0.5514\n",
      "Epoch 1769/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5231 - acc: 0.1953 - precision_3: 0.7477 - recall_3: 0.1953 - val_loss: 1.5159 - val_acc: 0.4270 - val_precision_3: 0.4856 - val_recall_3: 0.5459\n",
      "Epoch 1770/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5061 - acc: 0.2259 - precision_3: 0.7903 - recall_3: 0.2306 - val_loss: 1.5160 - val_acc: 0.4270 - val_precision_3: 0.4808 - val_recall_3: 0.5405\n",
      "Epoch 1771/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5174 - acc: 0.2047 - precision_3: 0.7479 - recall_3: 0.2094 - val_loss: 1.5157 - val_acc: 0.4270 - val_precision_3: 0.4762 - val_recall_3: 0.5405\n",
      "Epoch 1772/2000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.5298 - acc: 0.1882 - precision_3: 0.6838 - recall_3: 0.1882 - val_loss: 1.5168 - val_acc: 0.4270 - val_precision_3: 0.4737 - val_recall_3: 0.5351\n",
      "Epoch 1773/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.4969 - acc: 0.2518 - precision_3: 0.7926 - recall_3: 0.2518 - val_loss: 1.5176 - val_acc: 0.4270 - val_precision_3: 0.4737 - val_recall_3: 0.5351\n",
      "Epoch 1774/2000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.5157 - acc: 0.2071 - precision_3: 0.7807 - recall_3: 0.2094 - val_loss: 1.5187 - val_acc: 0.4216 - val_precision_3: 0.4783 - val_recall_3: 0.5351\n",
      "Epoch 1775/2000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.5011 - acc: 0.2235 - precision_3: 0.7967 - recall_3: 0.2306 - val_loss: 1.5187 - val_acc: 0.4216 - val_precision_3: 0.4806 - val_recall_3: 0.5351\n",
      "Epoch 1776/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5312 - acc: 0.1882 - precision_3: 0.7273 - recall_3: 0.1882 - val_loss: 1.5198 - val_acc: 0.4216 - val_precision_3: 0.4734 - val_recall_3: 0.5297\n",
      "Epoch 1777/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5002 - acc: 0.2400 - precision_3: 0.7984 - recall_3: 0.2424 - val_loss: 1.5200 - val_acc: 0.4216 - val_precision_3: 0.4757 - val_recall_3: 0.5297\n",
      "Epoch 1778/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5142 - acc: 0.2118 - precision_3: 0.7826 - recall_3: 0.2118 - val_loss: 1.5223 - val_acc: 0.4432 - val_precision_3: 0.4737 - val_recall_3: 0.5351\n",
      "Epoch 1779/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5099 - acc: 0.2259 - precision_3: 0.7638 - recall_3: 0.2282 - val_loss: 1.5239 - val_acc: 0.4432 - val_precision_3: 0.4689 - val_recall_3: 0.5297\n",
      "Epoch 1780/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5234 - acc: 0.1929 - precision_3: 0.7664 - recall_3: 0.1929 - val_loss: 1.5238 - val_acc: 0.4378 - val_precision_3: 0.4663 - val_recall_3: 0.5243\n",
      "Epoch 1781/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5187 - acc: 0.2047 - precision_3: 0.7063 - recall_3: 0.2094 - val_loss: 1.5230 - val_acc: 0.4270 - val_precision_3: 0.4667 - val_recall_3: 0.5297\n",
      "Epoch 1782/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5265 - acc: 0.1906 - precision_3: 0.6923 - recall_3: 0.1906 - val_loss: 1.5228 - val_acc: 0.4324 - val_precision_3: 0.4692 - val_recall_3: 0.5351\n",
      "Epoch 1783/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5063 - acc: 0.2306 - precision_3: 0.7920 - recall_3: 0.2329 - val_loss: 1.5221 - val_acc: 0.4270 - val_precision_3: 0.4667 - val_recall_3: 0.5297\n",
      "Epoch 1784/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5334 - acc: 0.1765 - precision_3: 0.7308 - recall_3: 0.1788 - val_loss: 1.5226 - val_acc: 0.4270 - val_precision_3: 0.4645 - val_recall_3: 0.5297\n",
      "Epoch 1785/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5095 - acc: 0.2212 - precision_3: 0.7540 - recall_3: 0.2235 - val_loss: 1.5209 - val_acc: 0.4432 - val_precision_3: 0.4623 - val_recall_3: 0.5297\n",
      "Epoch 1786/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5169 - acc: 0.2094 - precision_3: 0.7222 - recall_3: 0.2141 - val_loss: 1.5175 - val_acc: 0.4378 - val_precision_3: 0.4648 - val_recall_3: 0.5351\n",
      "Epoch 1787/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5080 - acc: 0.2376 - precision_3: 0.7630 - recall_3: 0.2424 - val_loss: 1.5136 - val_acc: 0.4486 - val_precision_3: 0.4525 - val_recall_3: 0.5405\n",
      "Epoch 1788/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5143 - acc: 0.2165 - precision_3: 0.7500 - recall_3: 0.2188 - val_loss: 1.5100 - val_acc: 0.4432 - val_precision_3: 0.4493 - val_recall_3: 0.5514\n",
      "Epoch 1789/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.4966 - acc: 0.2424 - precision_3: 0.7820 - recall_3: 0.2447 - val_loss: 1.5079 - val_acc: 0.4432 - val_precision_3: 0.4493 - val_recall_3: 0.5514\n",
      "Epoch 1790/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5117 - acc: 0.2118 - precision_3: 0.7583 - recall_3: 0.2141 - val_loss: 1.5070 - val_acc: 0.4324 - val_precision_3: 0.4533 - val_recall_3: 0.5514\n",
      "Epoch 1791/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5345 - acc: 0.1694 - precision_3: 0.6814 - recall_3: 0.1812 - val_loss: 1.5065 - val_acc: 0.4378 - val_precision_3: 0.4602 - val_recall_3: 0.5622\n",
      "Epoch 1792/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5218 - acc: 0.1953 - precision_3: 0.7119 - recall_3: 0.1976 - val_loss: 1.5069 - val_acc: 0.4378 - val_precision_3: 0.4622 - val_recall_3: 0.5622\n",
      "Epoch 1793/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5024 - acc: 0.2353 - precision_3: 0.7829 - recall_3: 0.2376 - val_loss: 1.5075 - val_acc: 0.4432 - val_precision_3: 0.4619 - val_recall_3: 0.5568\n",
      "Epoch 1794/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5132 - acc: 0.2094 - precision_3: 0.7759 - recall_3: 0.2118 - val_loss: 1.5070 - val_acc: 0.4432 - val_precision_3: 0.4661 - val_recall_3: 0.5568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1795/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5155 - acc: 0.2118 - precision_3: 0.7302 - recall_3: 0.2165 - val_loss: 1.5072 - val_acc: 0.4486 - val_precision_3: 0.4706 - val_recall_3: 0.5622\n",
      "Epoch 1796/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5023 - acc: 0.2306 - precision_3: 0.8065 - recall_3: 0.2353 - val_loss: 1.5064 - val_acc: 0.4432 - val_precision_3: 0.4685 - val_recall_3: 0.5622\n",
      "Epoch 1797/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5151 - acc: 0.2141 - precision_3: 0.7521 - recall_3: 0.2141 - val_loss: 1.5071 - val_acc: 0.4541 - val_precision_3: 0.4725 - val_recall_3: 0.5568\n",
      "Epoch 1798/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5077 - acc: 0.2329 - precision_3: 0.7634 - recall_3: 0.2353 - val_loss: 1.5081 - val_acc: 0.4486 - val_precision_3: 0.4720 - val_recall_3: 0.5459\n",
      "Epoch 1799/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5152 - acc: 0.2118 - precision_3: 0.7797 - recall_3: 0.2165 - val_loss: 1.5058 - val_acc: 0.4649 - val_precision_3: 0.4766 - val_recall_3: 0.5514\n",
      "Epoch 1800/2000\n",
      "85/85 [==============================] - 0s 552us/sample - loss: 1.5192 - acc: 0.1953 - precision_3: 0.8218 - recall_3: 0.1953 - val_loss: 1.5026 - val_acc: 0.4703 - val_precision_3: 0.4703 - val_recall_3: 0.5568\n",
      "Epoch 1801/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5125 - acc: 0.2141 - precision_3: 0.7913 - recall_3: 0.2141 - val_loss: 1.5022 - val_acc: 0.4703 - val_precision_3: 0.4703 - val_recall_3: 0.5568\n",
      "Epoch 1802/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.4983 - acc: 0.2471 - precision_3: 0.7895 - recall_3: 0.2471 - val_loss: 1.5015 - val_acc: 0.4703 - val_precision_3: 0.4771 - val_recall_3: 0.5622\n",
      "Epoch 1803/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5103 - acc: 0.2165 - precision_3: 0.7385 - recall_3: 0.2259 - val_loss: 1.5005 - val_acc: 0.4703 - val_precision_3: 0.4749 - val_recall_3: 0.5622\n",
      "Epoch 1804/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5058 - acc: 0.2235 - precision_3: 0.7597 - recall_3: 0.2306 - val_loss: 1.5004 - val_acc: 0.4703 - val_precision_3: 0.4771 - val_recall_3: 0.5622\n",
      "Epoch 1805/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5059 - acc: 0.2329 - precision_3: 0.7557 - recall_3: 0.2329 - val_loss: 1.5001 - val_acc: 0.4703 - val_precision_3: 0.4773 - val_recall_3: 0.5676\n",
      "Epoch 1806/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5202 - acc: 0.1976 - precision_3: 0.7636 - recall_3: 0.1976 - val_loss: 1.5009 - val_acc: 0.4757 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1807/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5142 - acc: 0.2165 - precision_3: 0.7197 - recall_3: 0.2235 - val_loss: 1.5008 - val_acc: 0.4703 - val_precision_3: 0.4861 - val_recall_3: 0.5676\n",
      "Epoch 1808/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5072 - acc: 0.2259 - precision_3: 0.7886 - recall_3: 0.2282 - val_loss: 1.5006 - val_acc: 0.4703 - val_precision_3: 0.4907 - val_recall_3: 0.5730\n",
      "Epoch 1809/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5103 - acc: 0.2235 - precision_3: 0.7029 - recall_3: 0.2282 - val_loss: 1.5022 - val_acc: 0.4649 - val_precision_3: 0.4884 - val_recall_3: 0.5676\n",
      "Epoch 1810/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5065 - acc: 0.2212 - precision_3: 0.8319 - recall_3: 0.2212 - val_loss: 1.5040 - val_acc: 0.4486 - val_precision_3: 0.4791 - val_recall_3: 0.5568\n",
      "Epoch 1811/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5078 - acc: 0.2235 - precision_3: 0.7724 - recall_3: 0.2235 - val_loss: 1.5055 - val_acc: 0.4486 - val_precision_3: 0.4722 - val_recall_3: 0.5514\n",
      "Epoch 1812/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5076 - acc: 0.2282 - precision_3: 0.7656 - recall_3: 0.2306 - val_loss: 1.5073 - val_acc: 0.4486 - val_precision_3: 0.4725 - val_recall_3: 0.5568\n",
      "Epoch 1813/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5126 - acc: 0.2235 - precision_3: 0.7080 - recall_3: 0.2282 - val_loss: 1.5088 - val_acc: 0.4432 - val_precision_3: 0.4722 - val_recall_3: 0.5514\n",
      "Epoch 1814/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5081 - acc: 0.2188 - precision_3: 0.7966 - recall_3: 0.2212 - val_loss: 1.5103 - val_acc: 0.4432 - val_precision_3: 0.4722 - val_recall_3: 0.5514\n",
      "Epoch 1815/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5121 - acc: 0.2165 - precision_3: 0.7833 - recall_3: 0.2212 - val_loss: 1.5129 - val_acc: 0.4432 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1816/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5052 - acc: 0.2329 - precision_3: 0.7769 - recall_3: 0.2376 - val_loss: 1.5141 - val_acc: 0.4432 - val_precision_3: 0.4906 - val_recall_3: 0.5622\n",
      "Epoch 1817/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5106 - acc: 0.2212 - precision_3: 0.8034 - recall_3: 0.2212 - val_loss: 1.5119 - val_acc: 0.4324 - val_precision_3: 0.4904 - val_recall_3: 0.5514\n",
      "Epoch 1818/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.5312 - acc: 0.1765 - precision_3: 0.7600 - recall_3: 0.1788 - val_loss: 1.5100 - val_acc: 0.4432 - val_precision_3: 0.4928 - val_recall_3: 0.5514\n",
      "Epoch 1819/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5080 - acc: 0.2306 - precision_3: 0.7795 - recall_3: 0.2329 - val_loss: 1.5088 - val_acc: 0.4486 - val_precision_3: 0.4976 - val_recall_3: 0.5514\n",
      "Epoch 1820/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5187 - acc: 0.2024 - precision_3: 0.7652 - recall_3: 0.2071 - val_loss: 1.5084 - val_acc: 0.4486 - val_precision_3: 0.4951 - val_recall_3: 0.5514\n",
      "Epoch 1821/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5044 - acc: 0.2306 - precision_3: 0.7674 - recall_3: 0.2329 - val_loss: 1.5083 - val_acc: 0.4432 - val_precision_3: 0.4952 - val_recall_3: 0.5568\n",
      "Epoch 1822/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5331 - acc: 0.1718 - precision_3: 0.7000 - recall_3: 0.1812 - val_loss: 1.5091 - val_acc: 0.4324 - val_precision_3: 0.4878 - val_recall_3: 0.5405\n",
      "Epoch 1823/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5330 - acc: 0.1765 - precision_3: 0.7075 - recall_3: 0.1765 - val_loss: 1.5104 - val_acc: 0.4270 - val_precision_3: 0.4877 - val_recall_3: 0.5351\n",
      "Epoch 1824/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5127 - acc: 0.2165 - precision_3: 0.7863 - recall_3: 0.2165 - val_loss: 1.5108 - val_acc: 0.4324 - val_precision_3: 0.4878 - val_recall_3: 0.5405\n",
      "Epoch 1825/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.4996 - acc: 0.2400 - precision_3: 0.7846 - recall_3: 0.2400 - val_loss: 1.5094 - val_acc: 0.4378 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1826/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5319 - acc: 0.1741 - precision_3: 0.6909 - recall_3: 0.1788 - val_loss: 1.5089 - val_acc: 0.4432 - val_precision_3: 0.4927 - val_recall_3: 0.5459\n",
      "Epoch 1827/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5188 - acc: 0.2000 - precision_3: 0.7768 - recall_3: 0.2047 - val_loss: 1.5079 - val_acc: 0.4432 - val_precision_3: 0.4903 - val_recall_3: 0.5459\n",
      "Epoch 1828/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5205 - acc: 0.1953 - precision_3: 0.7143 - recall_3: 0.2000 - val_loss: 1.5075 - val_acc: 0.4378 - val_precision_3: 0.4833 - val_recall_3: 0.5459\n",
      "Epoch 1829/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5111 - acc: 0.2235 - precision_3: 0.7724 - recall_3: 0.2235 - val_loss: 1.5071 - val_acc: 0.4432 - val_precision_3: 0.4905 - val_recall_3: 0.5568\n",
      "Epoch 1830/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5273 - acc: 0.1859 - precision_3: 0.7961 - recall_3: 0.1929 - val_loss: 1.5077 - val_acc: 0.4378 - val_precision_3: 0.4856 - val_recall_3: 0.5459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1831/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5091 - acc: 0.2212 - precision_3: 0.7769 - recall_3: 0.2212 - val_loss: 1.5079 - val_acc: 0.4378 - val_precision_3: 0.4810 - val_recall_3: 0.5459\n",
      "Epoch 1832/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.4992 - acc: 0.2424 - precision_3: 0.7591 - recall_3: 0.2447 - val_loss: 1.5079 - val_acc: 0.4378 - val_precision_3: 0.4833 - val_recall_3: 0.5459\n",
      "Epoch 1833/2000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.5047 - acc: 0.2329 - precision_3: 0.7874 - recall_3: 0.2353 - val_loss: 1.5063 - val_acc: 0.4541 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1834/2000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.5245 - acc: 0.1835 - precision_3: 0.7524 - recall_3: 0.1859 - val_loss: 1.5053 - val_acc: 0.4541 - val_precision_3: 0.4762 - val_recall_3: 0.5405\n",
      "Epoch 1835/2000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.5169 - acc: 0.2071 - precision_3: 0.7438 - recall_3: 0.2118 - val_loss: 1.5034 - val_acc: 0.4541 - val_precision_3: 0.4762 - val_recall_3: 0.5405\n",
      "Epoch 1836/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5032 - acc: 0.2353 - precision_3: 0.8279 - recall_3: 0.2376 - val_loss: 1.5010 - val_acc: 0.4703 - val_precision_3: 0.4720 - val_recall_3: 0.5459\n",
      "Epoch 1837/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5049 - acc: 0.2353 - precision_3: 0.7153 - recall_3: 0.2424 - val_loss: 1.5002 - val_acc: 0.4649 - val_precision_3: 0.4722 - val_recall_3: 0.5514\n",
      "Epoch 1838/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5193 - acc: 0.2094 - precision_3: 0.7087 - recall_3: 0.2118 - val_loss: 1.4995 - val_acc: 0.4649 - val_precision_3: 0.4749 - val_recall_3: 0.5622\n",
      "Epoch 1839/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5197 - acc: 0.1976 - precision_3: 0.7143 - recall_3: 0.2000 - val_loss: 1.4997 - val_acc: 0.4649 - val_precision_3: 0.4727 - val_recall_3: 0.5622\n",
      "Epoch 1840/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5129 - acc: 0.2165 - precision_3: 0.7402 - recall_3: 0.2212 - val_loss: 1.5018 - val_acc: 0.4649 - val_precision_3: 0.4722 - val_recall_3: 0.5514\n",
      "Epoch 1841/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5044 - acc: 0.2282 - precision_3: 0.7951 - recall_3: 0.2282 - val_loss: 1.5034 - val_acc: 0.4649 - val_precision_3: 0.4720 - val_recall_3: 0.5459\n",
      "Epoch 1842/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5132 - acc: 0.2024 - precision_3: 0.7946 - recall_3: 0.2094 - val_loss: 1.5050 - val_acc: 0.4595 - val_precision_3: 0.4648 - val_recall_3: 0.5351\n",
      "Epoch 1843/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5039 - acc: 0.2259 - precision_3: 0.7857 - recall_3: 0.2329 - val_loss: 1.5057 - val_acc: 0.4595 - val_precision_3: 0.4739 - val_recall_3: 0.5405\n",
      "Epoch 1844/2000\n",
      "85/85 [==============================] - 0s 528us/sample - loss: 1.5133 - acc: 0.2141 - precision_3: 0.7797 - recall_3: 0.2165 - val_loss: 1.5058 - val_acc: 0.4541 - val_precision_3: 0.4739 - val_recall_3: 0.5405\n",
      "Epoch 1845/2000\n",
      "85/85 [==============================] - 0s 539us/sample - loss: 1.5087 - acc: 0.2259 - precision_3: 0.7717 - recall_3: 0.2306 - val_loss: 1.5065 - val_acc: 0.4486 - val_precision_3: 0.4692 - val_recall_3: 0.5351\n",
      "Epoch 1846/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5211 - acc: 0.1906 - precision_3: 0.7593 - recall_3: 0.1929 - val_loss: 1.5066 - val_acc: 0.4541 - val_precision_3: 0.4692 - val_recall_3: 0.5351\n",
      "Epoch 1847/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5115 - acc: 0.2141 - precision_3: 0.7863 - recall_3: 0.2165 - val_loss: 1.5065 - val_acc: 0.4541 - val_precision_3: 0.4764 - val_recall_3: 0.5459\n",
      "Epoch 1848/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5164 - acc: 0.2000 - precision_3: 0.7909 - recall_3: 0.2047 - val_loss: 1.5067 - val_acc: 0.4486 - val_precision_3: 0.4739 - val_recall_3: 0.5405\n",
      "Epoch 1849/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5179 - acc: 0.2024 - precision_3: 0.7632 - recall_3: 0.2047 - val_loss: 1.5074 - val_acc: 0.4486 - val_precision_3: 0.4689 - val_recall_3: 0.5297\n",
      "Epoch 1850/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5128 - acc: 0.2094 - precision_3: 0.7627 - recall_3: 0.2118 - val_loss: 1.5076 - val_acc: 0.4486 - val_precision_3: 0.4712 - val_recall_3: 0.5297\n",
      "Epoch 1851/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5212 - acc: 0.2000 - precision_3: 0.7522 - recall_3: 0.2000 - val_loss: 1.5081 - val_acc: 0.4432 - val_precision_3: 0.4689 - val_recall_3: 0.5297\n",
      "Epoch 1852/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5098 - acc: 0.2165 - precision_3: 0.8440 - recall_3: 0.2165 - val_loss: 1.5092 - val_acc: 0.4378 - val_precision_3: 0.4739 - val_recall_3: 0.5405\n",
      "Epoch 1853/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5055 - acc: 0.2282 - precision_3: 0.7717 - recall_3: 0.2306 - val_loss: 1.5098 - val_acc: 0.4378 - val_precision_3: 0.4739 - val_recall_3: 0.5405\n",
      "Epoch 1854/2000\n",
      "85/85 [==============================] - 0s 621us/sample - loss: 1.5117 - acc: 0.2165 - precision_3: 0.7705 - recall_3: 0.2212 - val_loss: 1.5120 - val_acc: 0.4378 - val_precision_3: 0.4714 - val_recall_3: 0.5351\n",
      "Epoch 1855/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5145 - acc: 0.2094 - precision_3: 0.7965 - recall_3: 0.2118 - val_loss: 1.5133 - val_acc: 0.4270 - val_precision_3: 0.4714 - val_recall_3: 0.5351\n",
      "Epoch 1856/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5065 - acc: 0.2259 - precision_3: 0.7869 - recall_3: 0.2259 - val_loss: 1.5161 - val_acc: 0.4216 - val_precision_3: 0.4612 - val_recall_3: 0.5135\n",
      "Epoch 1857/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.4980 - acc: 0.2471 - precision_3: 0.7955 - recall_3: 0.2471 - val_loss: 1.5173 - val_acc: 0.4270 - val_precision_3: 0.4563 - val_recall_3: 0.5081\n",
      "Epoch 1858/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5061 - acc: 0.2282 - precision_3: 0.7638 - recall_3: 0.2282 - val_loss: 1.5175 - val_acc: 0.4324 - val_precision_3: 0.4631 - val_recall_3: 0.5081\n",
      "Epoch 1859/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5068 - acc: 0.2282 - precision_3: 0.7426 - recall_3: 0.2376 - val_loss: 1.5171 - val_acc: 0.4324 - val_precision_3: 0.4657 - val_recall_3: 0.5135\n",
      "Epoch 1860/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5169 - acc: 0.2047 - precision_3: 0.7788 - recall_3: 0.2071 - val_loss: 1.5177 - val_acc: 0.4324 - val_precision_3: 0.4683 - val_recall_3: 0.5189\n",
      "Epoch 1861/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5019 - acc: 0.2329 - precision_3: 0.8417 - recall_3: 0.2376 - val_loss: 1.5184 - val_acc: 0.4378 - val_precision_3: 0.4757 - val_recall_3: 0.5297\n",
      "Epoch 1862/2000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.5469 - acc: 0.1459 - precision_3: 0.6667 - recall_3: 0.1506 - val_loss: 1.5188 - val_acc: 0.4378 - val_precision_3: 0.4757 - val_recall_3: 0.5297\n",
      "Epoch 1863/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5087 - acc: 0.2235 - precision_3: 0.7273 - recall_3: 0.2259 - val_loss: 1.5183 - val_acc: 0.4324 - val_precision_3: 0.4732 - val_recall_3: 0.5243\n",
      "Epoch 1864/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5043 - acc: 0.2259 - precision_3: 0.7778 - recall_3: 0.2306 - val_loss: 1.5174 - val_acc: 0.4324 - val_precision_3: 0.4709 - val_recall_3: 0.5243\n",
      "Epoch 1865/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.4918 - acc: 0.2565 - precision_3: 0.8074 - recall_3: 0.2565 - val_loss: 1.5162 - val_acc: 0.4378 - val_precision_3: 0.4734 - val_recall_3: 0.5297\n",
      "Epoch 1866/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5278 - acc: 0.1859 - precision_3: 0.7069 - recall_3: 0.1929 - val_loss: 1.5147 - val_acc: 0.4432 - val_precision_3: 0.4739 - val_recall_3: 0.5405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1867/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5081 - acc: 0.2212 - precision_3: 0.7698 - recall_3: 0.2282 - val_loss: 1.5130 - val_acc: 0.4378 - val_precision_3: 0.4626 - val_recall_3: 0.5351\n",
      "Epoch 1868/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.4991 - acc: 0.2329 - precision_3: 0.7907 - recall_3: 0.2400 - val_loss: 1.5125 - val_acc: 0.4378 - val_precision_3: 0.4626 - val_recall_3: 0.5351\n",
      "Epoch 1869/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.4918 - acc: 0.2518 - precision_3: 0.8106 - recall_3: 0.2518 - val_loss: 1.5119 - val_acc: 0.4324 - val_precision_3: 0.4648 - val_recall_3: 0.5351\n",
      "Epoch 1870/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5112 - acc: 0.2118 - precision_3: 0.7712 - recall_3: 0.2141 - val_loss: 1.5119 - val_acc: 0.4324 - val_precision_3: 0.4626 - val_recall_3: 0.5351\n",
      "Epoch 1871/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5023 - acc: 0.2259 - precision_3: 0.8448 - recall_3: 0.2306 - val_loss: 1.5116 - val_acc: 0.4324 - val_precision_3: 0.4605 - val_recall_3: 0.5351\n",
      "Epoch 1872/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5271 - acc: 0.1859 - precision_3: 0.7822 - recall_3: 0.1859 - val_loss: 1.5122 - val_acc: 0.4324 - val_precision_3: 0.4648 - val_recall_3: 0.5351\n",
      "Epoch 1873/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.4913 - acc: 0.2494 - precision_3: 0.7941 - recall_3: 0.2541 - val_loss: 1.5122 - val_acc: 0.4270 - val_precision_3: 0.4645 - val_recall_3: 0.5297\n",
      "Epoch 1874/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5125 - acc: 0.2165 - precision_3: 0.7881 - recall_3: 0.2188 - val_loss: 1.5131 - val_acc: 0.4270 - val_precision_3: 0.4645 - val_recall_3: 0.5297\n",
      "Epoch 1875/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5068 - acc: 0.2282 - precision_3: 0.7388 - recall_3: 0.2329 - val_loss: 1.5133 - val_acc: 0.4216 - val_precision_3: 0.4667 - val_recall_3: 0.5297\n",
      "Epoch 1876/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.4940 - acc: 0.2447 - precision_3: 0.8308 - recall_3: 0.2541 - val_loss: 1.5126 - val_acc: 0.4216 - val_precision_3: 0.4695 - val_recall_3: 0.5405\n",
      "Epoch 1877/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5116 - acc: 0.2118 - precision_3: 0.7982 - recall_3: 0.2141 - val_loss: 1.5122 - val_acc: 0.4216 - val_precision_3: 0.4670 - val_recall_3: 0.5351\n",
      "Epoch 1878/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5023 - acc: 0.2400 - precision_3: 0.8095 - recall_3: 0.2400 - val_loss: 1.5113 - val_acc: 0.4270 - val_precision_3: 0.4720 - val_recall_3: 0.5459\n",
      "Epoch 1879/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5130 - acc: 0.2165 - precision_3: 0.7815 - recall_3: 0.2188 - val_loss: 1.5117 - val_acc: 0.4324 - val_precision_3: 0.4836 - val_recall_3: 0.5568\n",
      "Epoch 1880/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5118 - acc: 0.2212 - precision_3: 0.8246 - recall_3: 0.2212 - val_loss: 1.5127 - val_acc: 0.4270 - val_precision_3: 0.4857 - val_recall_3: 0.5514\n",
      "Epoch 1881/2000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.5073 - acc: 0.2259 - precision_3: 0.7760 - recall_3: 0.2282 - val_loss: 1.5136 - val_acc: 0.4324 - val_precision_3: 0.4857 - val_recall_3: 0.5514\n",
      "Epoch 1882/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5216 - acc: 0.1882 - precision_3: 0.8182 - recall_3: 0.1906 - val_loss: 1.5142 - val_acc: 0.4324 - val_precision_3: 0.4783 - val_recall_3: 0.5351\n",
      "Epoch 1883/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5059 - acc: 0.2235 - precision_3: 0.8421 - recall_3: 0.2259 - val_loss: 1.5137 - val_acc: 0.4216 - val_precision_3: 0.4833 - val_recall_3: 0.5459\n",
      "Epoch 1884/2000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.5149 - acc: 0.2094 - precision_3: 0.7459 - recall_3: 0.2141 - val_loss: 1.5128 - val_acc: 0.4162 - val_precision_3: 0.4806 - val_recall_3: 0.5351\n",
      "Epoch 1885/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5068 - acc: 0.2235 - precision_3: 0.8000 - recall_3: 0.2259 - val_loss: 1.5138 - val_acc: 0.4216 - val_precision_3: 0.4734 - val_recall_3: 0.5297\n",
      "Epoch 1886/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5163 - acc: 0.2094 - precision_3: 0.7302 - recall_3: 0.2165 - val_loss: 1.5146 - val_acc: 0.4162 - val_precision_3: 0.4657 - val_recall_3: 0.5135\n",
      "Epoch 1887/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.4974 - acc: 0.2400 - precision_3: 0.7852 - recall_3: 0.2494 - val_loss: 1.5149 - val_acc: 0.4162 - val_precision_3: 0.4732 - val_recall_3: 0.5243\n",
      "Epoch 1888/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5123 - acc: 0.2141 - precision_3: 0.7931 - recall_3: 0.2165 - val_loss: 1.5148 - val_acc: 0.4270 - val_precision_3: 0.4783 - val_recall_3: 0.5351\n",
      "Epoch 1889/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.4888 - acc: 0.2565 - precision_3: 0.8358 - recall_3: 0.2635 - val_loss: 1.5139 - val_acc: 0.4270 - val_precision_3: 0.4833 - val_recall_3: 0.5459\n",
      "Epoch 1890/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5267 - acc: 0.1929 - precision_3: 0.7009 - recall_3: 0.1929 - val_loss: 1.5138 - val_acc: 0.4162 - val_precision_3: 0.4833 - val_recall_3: 0.5459\n",
      "Epoch 1891/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5043 - acc: 0.2235 - precision_3: 0.7752 - recall_3: 0.2353 - val_loss: 1.5145 - val_acc: 0.4324 - val_precision_3: 0.4906 - val_recall_3: 0.5622\n",
      "Epoch 1892/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5206 - acc: 0.1953 - precision_3: 0.7589 - recall_3: 0.2000 - val_loss: 1.5148 - val_acc: 0.4378 - val_precision_3: 0.4930 - val_recall_3: 0.5676\n",
      "Epoch 1893/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5063 - acc: 0.2329 - precision_3: 0.7246 - recall_3: 0.2353 - val_loss: 1.5148 - val_acc: 0.4378 - val_precision_3: 0.4884 - val_recall_3: 0.5676\n",
      "Epoch 1894/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.4922 - acc: 0.2518 - precision_3: 0.8372 - recall_3: 0.2541 - val_loss: 1.5153 - val_acc: 0.4378 - val_precision_3: 0.4884 - val_recall_3: 0.5676\n",
      "Epoch 1895/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5160 - acc: 0.2094 - precision_3: 0.7672 - recall_3: 0.2094 - val_loss: 1.5147 - val_acc: 0.4378 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1896/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5101 - acc: 0.2188 - precision_3: 0.7520 - recall_3: 0.2212 - val_loss: 1.5129 - val_acc: 0.4162 - val_precision_3: 0.4766 - val_recall_3: 0.5514\n",
      "Epoch 1897/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5274 - acc: 0.1859 - precision_3: 0.7043 - recall_3: 0.1906 - val_loss: 1.5119 - val_acc: 0.4162 - val_precision_3: 0.4722 - val_recall_3: 0.5514\n",
      "Epoch 1898/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5217 - acc: 0.1953 - precision_3: 0.6967 - recall_3: 0.2000 - val_loss: 1.5114 - val_acc: 0.4162 - val_precision_3: 0.4698 - val_recall_3: 0.5459\n",
      "Epoch 1899/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5163 - acc: 0.2071 - precision_3: 0.7719 - recall_3: 0.2071 - val_loss: 1.5105 - val_acc: 0.4162 - val_precision_3: 0.4700 - val_recall_3: 0.5514\n",
      "Epoch 1900/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5142 - acc: 0.2024 - precision_3: 0.7788 - recall_3: 0.2071 - val_loss: 1.5096 - val_acc: 0.4216 - val_precision_3: 0.4682 - val_recall_3: 0.5568\n",
      "Epoch 1901/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5118 - acc: 0.2165 - precision_3: 0.7559 - recall_3: 0.2259 - val_loss: 1.5086 - val_acc: 0.4270 - val_precision_3: 0.4688 - val_recall_3: 0.5676\n",
      "Epoch 1902/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.5158 - acc: 0.2118 - precision_3: 0.7280 - recall_3: 0.2141 - val_loss: 1.5070 - val_acc: 0.4216 - val_precision_3: 0.4730 - val_recall_3: 0.5676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1903/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5106 - acc: 0.2165 - precision_3: 0.8070 - recall_3: 0.2165 - val_loss: 1.5075 - val_acc: 0.4216 - val_precision_3: 0.4751 - val_recall_3: 0.5676\n",
      "Epoch 1904/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5163 - acc: 0.2024 - precision_3: 0.7395 - recall_3: 0.2071 - val_loss: 1.5091 - val_acc: 0.4216 - val_precision_3: 0.4682 - val_recall_3: 0.5568\n",
      "Epoch 1905/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5065 - acc: 0.2235 - precision_3: 0.7348 - recall_3: 0.2282 - val_loss: 1.5085 - val_acc: 0.4216 - val_precision_3: 0.4682 - val_recall_3: 0.5568\n",
      "Epoch 1906/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5110 - acc: 0.2071 - precision_3: 0.8018 - recall_3: 0.2094 - val_loss: 1.5074 - val_acc: 0.4216 - val_precision_3: 0.4749 - val_recall_3: 0.5622\n",
      "Epoch 1907/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5153 - acc: 0.2094 - precision_3: 0.7982 - recall_3: 0.2141 - val_loss: 1.5064 - val_acc: 0.4216 - val_precision_3: 0.4727 - val_recall_3: 0.5622\n",
      "Epoch 1908/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5108 - acc: 0.2165 - precision_3: 0.7797 - recall_3: 0.2165 - val_loss: 1.5068 - val_acc: 0.4270 - val_precision_3: 0.4727 - val_recall_3: 0.5622\n",
      "Epoch 1909/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5077 - acc: 0.2188 - precision_3: 0.8136 - recall_3: 0.2259 - val_loss: 1.5073 - val_acc: 0.4216 - val_precision_3: 0.4703 - val_recall_3: 0.5568\n",
      "Epoch 1910/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5049 - acc: 0.2306 - precision_3: 0.8080 - recall_3: 0.2376 - val_loss: 1.5080 - val_acc: 0.4216 - val_precision_3: 0.4679 - val_recall_3: 0.5514\n",
      "Epoch 1911/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.4968 - acc: 0.2447 - precision_3: 0.8268 - recall_3: 0.2471 - val_loss: 1.5082 - val_acc: 0.4216 - val_precision_3: 0.4615 - val_recall_3: 0.5514\n",
      "Epoch 1912/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5007 - acc: 0.2306 - precision_3: 0.7727 - recall_3: 0.2400 - val_loss: 1.5082 - val_acc: 0.4216 - val_precision_3: 0.4640 - val_recall_3: 0.5568\n",
      "Epoch 1913/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5147 - acc: 0.2094 - precision_3: 0.7778 - recall_3: 0.2141 - val_loss: 1.5076 - val_acc: 0.4270 - val_precision_3: 0.4775 - val_recall_3: 0.5730\n",
      "Epoch 1914/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5187 - acc: 0.1953 - precision_3: 0.8000 - recall_3: 0.1976 - val_loss: 1.5076 - val_acc: 0.4162 - val_precision_3: 0.4795 - val_recall_3: 0.5676\n",
      "Epoch 1915/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5042 - acc: 0.2282 - precision_3: 0.8099 - recall_3: 0.2306 - val_loss: 1.5072 - val_acc: 0.4270 - val_precision_3: 0.4839 - val_recall_3: 0.5676\n",
      "Epoch 1916/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5213 - acc: 0.1953 - precision_3: 0.7636 - recall_3: 0.1976 - val_loss: 1.5075 - val_acc: 0.4324 - val_precision_3: 0.4766 - val_recall_3: 0.5514\n",
      "Epoch 1917/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5011 - acc: 0.2329 - precision_3: 0.8226 - recall_3: 0.2400 - val_loss: 1.5088 - val_acc: 0.4324 - val_precision_3: 0.4810 - val_recall_3: 0.5459\n",
      "Epoch 1918/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.4946 - acc: 0.2518 - precision_3: 0.7956 - recall_3: 0.2565 - val_loss: 1.5068 - val_acc: 0.4486 - val_precision_3: 0.4930 - val_recall_3: 0.5676\n",
      "Epoch 1919/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5114 - acc: 0.2188 - precision_3: 0.7600 - recall_3: 0.2235 - val_loss: 1.5065 - val_acc: 0.4486 - val_precision_3: 0.4977 - val_recall_3: 0.5730\n",
      "Epoch 1920/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5203 - acc: 0.1929 - precision_3: 0.7411 - recall_3: 0.1953 - val_loss: 1.5071 - val_acc: 0.4486 - val_precision_3: 0.5024 - val_recall_3: 0.5622\n",
      "Epoch 1921/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5011 - acc: 0.2400 - precision_3: 0.7761 - recall_3: 0.2447 - val_loss: 1.5081 - val_acc: 0.4595 - val_precision_3: 0.5000 - val_recall_3: 0.5568\n",
      "Epoch 1922/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5081 - acc: 0.2259 - precision_3: 0.7405 - recall_3: 0.2282 - val_loss: 1.5070 - val_acc: 0.4595 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1923/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5249 - acc: 0.1882 - precision_3: 0.7788 - recall_3: 0.1906 - val_loss: 1.5063 - val_acc: 0.4595 - val_precision_3: 0.5000 - val_recall_3: 0.5676\n",
      "Epoch 1924/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5197 - acc: 0.2024 - precision_3: 0.7586 - recall_3: 0.2071 - val_loss: 1.5066 - val_acc: 0.4595 - val_precision_3: 0.5024 - val_recall_3: 0.5676\n",
      "Epoch 1925/2000\n",
      "85/85 [==============================] - 0s 540us/sample - loss: 1.5240 - acc: 0.1929 - precision_3: 0.7179 - recall_3: 0.1976 - val_loss: 1.5082 - val_acc: 0.4486 - val_precision_3: 0.4929 - val_recall_3: 0.5622\n",
      "Epoch 1926/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5204 - acc: 0.2024 - precision_3: 0.7311 - recall_3: 0.2047 - val_loss: 1.5092 - val_acc: 0.4324 - val_precision_3: 0.4904 - val_recall_3: 0.5514\n",
      "Epoch 1927/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5084 - acc: 0.2282 - precision_3: 0.7698 - recall_3: 0.2282 - val_loss: 1.5090 - val_acc: 0.4324 - val_precision_3: 0.4879 - val_recall_3: 0.5459\n",
      "Epoch 1928/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.4994 - acc: 0.2471 - precision_3: 0.8468 - recall_3: 0.2471 - val_loss: 1.5086 - val_acc: 0.4270 - val_precision_3: 0.4854 - val_recall_3: 0.5405\n",
      "Epoch 1929/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5098 - acc: 0.2118 - precision_3: 0.8017 - recall_3: 0.2188 - val_loss: 1.5100 - val_acc: 0.4216 - val_precision_3: 0.4902 - val_recall_3: 0.5405\n",
      "Epoch 1930/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5136 - acc: 0.2141 - precision_3: 0.7266 - recall_3: 0.2188 - val_loss: 1.5123 - val_acc: 0.4216 - val_precision_3: 0.4853 - val_recall_3: 0.5351\n",
      "Epoch 1931/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5116 - acc: 0.2141 - precision_3: 0.7731 - recall_3: 0.2165 - val_loss: 1.5135 - val_acc: 0.4270 - val_precision_3: 0.4780 - val_recall_3: 0.5297\n",
      "Epoch 1932/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5247 - acc: 0.1906 - precision_3: 0.7545 - recall_3: 0.1953 - val_loss: 1.5128 - val_acc: 0.4270 - val_precision_3: 0.4806 - val_recall_3: 0.5351\n",
      "Epoch 1933/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5103 - acc: 0.2165 - precision_3: 0.7381 - recall_3: 0.2188 - val_loss: 1.5116 - val_acc: 0.4270 - val_precision_3: 0.4829 - val_recall_3: 0.5351\n",
      "Epoch 1934/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5137 - acc: 0.2165 - precision_3: 0.7500 - recall_3: 0.2188 - val_loss: 1.5124 - val_acc: 0.4270 - val_precision_3: 0.4853 - val_recall_3: 0.5351\n",
      "Epoch 1935/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.5201 - acc: 0.2024 - precision_3: 0.7373 - recall_3: 0.2047 - val_loss: 1.5134 - val_acc: 0.4270 - val_precision_3: 0.4851 - val_recall_3: 0.5297\n",
      "Epoch 1936/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5134 - acc: 0.2118 - precision_3: 0.7965 - recall_3: 0.2118 - val_loss: 1.5144 - val_acc: 0.4270 - val_precision_3: 0.4802 - val_recall_3: 0.5243\n",
      "Epoch 1937/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5126 - acc: 0.2165 - precision_3: 0.7623 - recall_3: 0.2188 - val_loss: 1.5156 - val_acc: 0.4270 - val_precision_3: 0.4755 - val_recall_3: 0.5243\n",
      "Epoch 1938/2000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.4965 - acc: 0.2424 - precision_3: 0.7737 - recall_3: 0.2494 - val_loss: 1.5168 - val_acc: 0.4216 - val_precision_3: 0.4760 - val_recall_3: 0.5351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1939/2000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.5127 - acc: 0.2071 - precision_3: 0.7928 - recall_3: 0.2071 - val_loss: 1.5166 - val_acc: 0.4162 - val_precision_3: 0.4762 - val_recall_3: 0.5405\n",
      "Epoch 1940/2000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.5176 - acc: 0.2000 - precision_3: 0.7273 - recall_3: 0.2071 - val_loss: 1.5165 - val_acc: 0.4162 - val_precision_3: 0.4737 - val_recall_3: 0.5351\n",
      "Epoch 1941/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.4984 - acc: 0.2376 - precision_3: 0.8160 - recall_3: 0.2400 - val_loss: 1.5172 - val_acc: 0.4216 - val_precision_3: 0.4833 - val_recall_3: 0.5459\n",
      "Epoch 1942/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5097 - acc: 0.2282 - precision_3: 0.8151 - recall_3: 0.2282 - val_loss: 1.5175 - val_acc: 0.4216 - val_precision_3: 0.4834 - val_recall_3: 0.5514\n",
      "Epoch 1943/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5160 - acc: 0.2071 - precision_3: 0.7521 - recall_3: 0.2071 - val_loss: 1.5169 - val_acc: 0.4108 - val_precision_3: 0.4760 - val_recall_3: 0.5351\n",
      "Epoch 1944/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.4952 - acc: 0.2541 - precision_3: 0.8120 - recall_3: 0.2541 - val_loss: 1.5176 - val_acc: 0.4162 - val_precision_3: 0.4734 - val_recall_3: 0.5297\n",
      "Epoch 1945/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5186 - acc: 0.1976 - precision_3: 0.7944 - recall_3: 0.2000 - val_loss: 1.5193 - val_acc: 0.4270 - val_precision_3: 0.4706 - val_recall_3: 0.5189\n",
      "Epoch 1946/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5161 - acc: 0.2024 - precision_3: 0.7542 - recall_3: 0.2094 - val_loss: 1.5182 - val_acc: 0.4324 - val_precision_3: 0.4660 - val_recall_3: 0.5189\n",
      "Epoch 1947/2000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.5191 - acc: 0.2118 - precision_3: 0.7759 - recall_3: 0.2118 - val_loss: 1.5161 - val_acc: 0.4324 - val_precision_3: 0.4641 - val_recall_3: 0.5243\n",
      "Epoch 1948/2000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.5098 - acc: 0.2212 - precision_3: 0.7559 - recall_3: 0.2259 - val_loss: 1.5139 - val_acc: 0.4378 - val_precision_3: 0.4623 - val_recall_3: 0.5297\n",
      "Epoch 1949/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5009 - acc: 0.2353 - precision_3: 0.7953 - recall_3: 0.2376 - val_loss: 1.5122 - val_acc: 0.4324 - val_precision_3: 0.4670 - val_recall_3: 0.5351\n",
      "Epoch 1950/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5126 - acc: 0.2047 - precision_3: 0.7946 - recall_3: 0.2094 - val_loss: 1.5105 - val_acc: 0.4324 - val_precision_3: 0.4739 - val_recall_3: 0.5405\n",
      "Epoch 1951/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5114 - acc: 0.2165 - precision_3: 0.8017 - recall_3: 0.2188 - val_loss: 1.5096 - val_acc: 0.4378 - val_precision_3: 0.4762 - val_recall_3: 0.5405\n",
      "Epoch 1952/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.4989 - acc: 0.2353 - precision_3: 0.8016 - recall_3: 0.2376 - val_loss: 1.5102 - val_acc: 0.4324 - val_precision_3: 0.4810 - val_recall_3: 0.5459\n",
      "Epoch 1953/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5178 - acc: 0.2047 - precision_3: 0.7672 - recall_3: 0.2094 - val_loss: 1.5099 - val_acc: 0.4432 - val_precision_3: 0.4928 - val_recall_3: 0.5514\n",
      "Epoch 1954/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5088 - acc: 0.2188 - precision_3: 0.7851 - recall_3: 0.2235 - val_loss: 1.5117 - val_acc: 0.4324 - val_precision_3: 0.4757 - val_recall_3: 0.5297\n",
      "Epoch 1955/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.4905 - acc: 0.2541 - precision_3: 0.8015 - recall_3: 0.2565 - val_loss: 1.5145 - val_acc: 0.4324 - val_precision_3: 0.4831 - val_recall_3: 0.5405\n",
      "Epoch 1956/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5105 - acc: 0.2165 - precision_3: 0.7661 - recall_3: 0.2235 - val_loss: 1.5156 - val_acc: 0.4324 - val_precision_3: 0.4876 - val_recall_3: 0.5297\n",
      "Epoch 1957/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.4979 - acc: 0.2424 - precision_3: 0.7863 - recall_3: 0.2424 - val_loss: 1.5150 - val_acc: 0.4324 - val_precision_3: 0.4826 - val_recall_3: 0.5243\n",
      "Epoch 1958/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5136 - acc: 0.2118 - precision_3: 0.7258 - recall_3: 0.2118 - val_loss: 1.5131 - val_acc: 0.4378 - val_precision_3: 0.4829 - val_recall_3: 0.5351\n",
      "Epoch 1959/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5039 - acc: 0.2306 - precision_3: 0.8167 - recall_3: 0.2306 - val_loss: 1.5106 - val_acc: 0.4432 - val_precision_3: 0.4806 - val_recall_3: 0.5351\n",
      "Epoch 1960/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5179 - acc: 0.2000 - precision_3: 0.8333 - recall_3: 0.2000 - val_loss: 1.5096 - val_acc: 0.4486 - val_precision_3: 0.4904 - val_recall_3: 0.5514\n",
      "Epoch 1961/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5187 - acc: 0.2047 - precision_3: 0.7311 - recall_3: 0.2047 - val_loss: 1.5084 - val_acc: 0.4541 - val_precision_3: 0.4904 - val_recall_3: 0.5514\n",
      "Epoch 1962/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5111 - acc: 0.2118 - precision_3: 0.8214 - recall_3: 0.2165 - val_loss: 1.5084 - val_acc: 0.4541 - val_precision_3: 0.4951 - val_recall_3: 0.5459\n",
      "Epoch 1963/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.4832 - acc: 0.2682 - precision_3: 0.7986 - recall_3: 0.2706 - val_loss: 1.5087 - val_acc: 0.4541 - val_precision_3: 0.4951 - val_recall_3: 0.5459\n",
      "Epoch 1964/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5248 - acc: 0.1835 - precision_3: 0.7431 - recall_3: 0.1906 - val_loss: 1.5068 - val_acc: 0.4541 - val_precision_3: 0.4928 - val_recall_3: 0.5514\n",
      "Epoch 1965/2000\n",
      "85/85 [==============================] - 0s 574us/sample - loss: 1.5213 - acc: 0.2118 - precision_3: 0.6977 - recall_3: 0.2118 - val_loss: 1.5048 - val_acc: 0.4541 - val_precision_3: 0.4882 - val_recall_3: 0.5568\n",
      "Epoch 1966/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5094 - acc: 0.2259 - precision_3: 0.7698 - recall_3: 0.2282 - val_loss: 1.5029 - val_acc: 0.4595 - val_precision_3: 0.4907 - val_recall_3: 0.5676\n",
      "Epoch 1967/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.4926 - acc: 0.2471 - precision_3: 0.8833 - recall_3: 0.2494 - val_loss: 1.5022 - val_acc: 0.4595 - val_precision_3: 0.4861 - val_recall_3: 0.5676\n",
      "Epoch 1968/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5121 - acc: 0.2188 - precision_3: 0.7561 - recall_3: 0.2188 - val_loss: 1.5022 - val_acc: 0.4541 - val_precision_3: 0.4839 - val_recall_3: 0.5676\n",
      "Epoch 1969/2000\n",
      "85/85 [==============================] - 0s 564us/sample - loss: 1.5122 - acc: 0.2165 - precision_3: 0.7402 - recall_3: 0.2212 - val_loss: 1.5021 - val_acc: 0.4595 - val_precision_3: 0.4930 - val_recall_3: 0.5730\n",
      "Epoch 1970/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5057 - acc: 0.2376 - precision_3: 0.7710 - recall_3: 0.2376 - val_loss: 1.5030 - val_acc: 0.4541 - val_precision_3: 0.4883 - val_recall_3: 0.5622\n",
      "Epoch 1971/2000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.5013 - acc: 0.2353 - precision_3: 0.8000 - recall_3: 0.2353 - val_loss: 1.5035 - val_acc: 0.4595 - val_precision_3: 0.4883 - val_recall_3: 0.5622\n",
      "Epoch 1972/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5207 - acc: 0.1929 - precision_3: 0.7961 - recall_3: 0.1929 - val_loss: 1.5039 - val_acc: 0.4649 - val_precision_3: 0.4907 - val_recall_3: 0.5676\n",
      "Epoch 1973/2000\n",
      "85/85 [==============================] - 0s 611us/sample - loss: 1.4980 - acc: 0.2329 - precision_3: 0.7744 - recall_3: 0.2424 - val_loss: 1.5035 - val_acc: 0.4703 - val_precision_3: 0.4907 - val_recall_3: 0.5730\n",
      "Epoch 1974/2000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.5045 - acc: 0.2306 - precision_3: 0.8049 - recall_3: 0.2329 - val_loss: 1.5005 - val_acc: 0.4703 - val_precision_3: 0.4887 - val_recall_3: 0.5838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1975/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5048 - acc: 0.2306 - precision_3: 0.8376 - recall_3: 0.2306 - val_loss: 1.4983 - val_acc: 0.4703 - val_precision_3: 0.4864 - val_recall_3: 0.5784\n",
      "Epoch 1976/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5146 - acc: 0.2071 - precision_3: 0.7895 - recall_3: 0.2118 - val_loss: 1.4979 - val_acc: 0.4757 - val_precision_3: 0.4864 - val_recall_3: 0.5784\n",
      "Epoch 1977/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.4951 - acc: 0.2494 - precision_3: 0.7941 - recall_3: 0.2541 - val_loss: 1.4988 - val_acc: 0.4757 - val_precision_3: 0.4886 - val_recall_3: 0.5784\n",
      "Epoch 1978/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5061 - acc: 0.2188 - precision_3: 0.8468 - recall_3: 0.2212 - val_loss: 1.4968 - val_acc: 0.4757 - val_precision_3: 0.4864 - val_recall_3: 0.5784\n",
      "Epoch 1979/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5112 - acc: 0.2188 - precision_3: 0.7561 - recall_3: 0.2188 - val_loss: 1.4972 - val_acc: 0.4757 - val_precision_3: 0.4908 - val_recall_3: 0.5784\n",
      "Epoch 1980/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.4995 - acc: 0.2353 - precision_3: 0.8189 - recall_3: 0.2447 - val_loss: 1.4983 - val_acc: 0.4811 - val_precision_3: 0.4932 - val_recall_3: 0.5838\n",
      "Epoch 1981/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5122 - acc: 0.2118 - precision_3: 0.7381 - recall_3: 0.2188 - val_loss: 1.4995 - val_acc: 0.4757 - val_precision_3: 0.4908 - val_recall_3: 0.5784\n",
      "Epoch 1982/2000\n",
      "85/85 [==============================] - 0s 551us/sample - loss: 1.5077 - acc: 0.2306 - precision_3: 0.7734 - recall_3: 0.2329 - val_loss: 1.5007 - val_acc: 0.4703 - val_precision_3: 0.4886 - val_recall_3: 0.5784\n",
      "Epoch 1983/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5168 - acc: 0.2024 - precision_3: 0.7982 - recall_3: 0.2047 - val_loss: 1.5007 - val_acc: 0.4703 - val_precision_3: 0.4931 - val_recall_3: 0.5784\n",
      "Epoch 1984/2000\n",
      "85/85 [==============================] - 0s 586us/sample - loss: 1.5009 - acc: 0.2376 - precision_3: 0.7500 - recall_3: 0.2471 - val_loss: 1.5010 - val_acc: 0.4649 - val_precision_3: 0.4886 - val_recall_3: 0.5784\n",
      "Epoch 1985/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5055 - acc: 0.2188 - precision_3: 0.8034 - recall_3: 0.2212 - val_loss: 1.5019 - val_acc: 0.4649 - val_precision_3: 0.4840 - val_recall_3: 0.5730\n",
      "Epoch 1986/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.5047 - acc: 0.2235 - precision_3: 0.8000 - recall_3: 0.2259 - val_loss: 1.5026 - val_acc: 0.4649 - val_precision_3: 0.4861 - val_recall_3: 0.5676\n",
      "Epoch 1987/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5103 - acc: 0.2235 - precision_3: 0.7698 - recall_3: 0.2282 - val_loss: 1.5026 - val_acc: 0.4757 - val_precision_3: 0.4864 - val_recall_3: 0.5784\n",
      "Epoch 1988/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5109 - acc: 0.2188 - precision_3: 0.7949 - recall_3: 0.2188 - val_loss: 1.5035 - val_acc: 0.4703 - val_precision_3: 0.4865 - val_recall_3: 0.5838\n",
      "Epoch 1989/2000\n",
      "85/85 [==============================] - 0s 563us/sample - loss: 1.5253 - acc: 0.1882 - precision_3: 0.8119 - recall_3: 0.1929 - val_loss: 1.5035 - val_acc: 0.4595 - val_precision_3: 0.4932 - val_recall_3: 0.5892\n",
      "Epoch 1990/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5188 - acc: 0.2024 - precision_3: 0.7818 - recall_3: 0.2024 - val_loss: 1.5041 - val_acc: 0.4541 - val_precision_3: 0.4955 - val_recall_3: 0.5892\n",
      "Epoch 1991/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5150 - acc: 0.2094 - precision_3: 0.7692 - recall_3: 0.2118 - val_loss: 1.5062 - val_acc: 0.4378 - val_precision_3: 0.4954 - val_recall_3: 0.5838\n",
      "Epoch 1992/2000\n",
      "85/85 [==============================] - 0s 598us/sample - loss: 1.4984 - acc: 0.2400 - precision_3: 0.8092 - recall_3: 0.2494 - val_loss: 1.5078 - val_acc: 0.4378 - val_precision_3: 0.4930 - val_recall_3: 0.5730\n",
      "Epoch 1993/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5277 - acc: 0.1859 - precision_3: 0.6991 - recall_3: 0.1859 - val_loss: 1.5084 - val_acc: 0.4324 - val_precision_3: 0.4907 - val_recall_3: 0.5730\n",
      "Epoch 1994/2000\n",
      "85/85 [==============================] - 0s 587us/sample - loss: 1.5055 - acc: 0.2188 - precision_3: 0.7724 - recall_3: 0.2235 - val_loss: 1.5090 - val_acc: 0.4324 - val_precision_3: 0.4907 - val_recall_3: 0.5730\n",
      "Epoch 1995/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5117 - acc: 0.2212 - precision_3: 0.7520 - recall_3: 0.2212 - val_loss: 1.5099 - val_acc: 0.4378 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n",
      "Epoch 1996/2000\n",
      "85/85 [==============================] - 0s 599us/sample - loss: 1.5000 - acc: 0.2306 - precision_3: 0.7727 - recall_3: 0.2400 - val_loss: 1.5112 - val_acc: 0.4378 - val_precision_3: 0.4791 - val_recall_3: 0.5568\n",
      "Epoch 1997/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.4988 - acc: 0.2447 - precision_3: 0.7643 - recall_3: 0.2518 - val_loss: 1.5151 - val_acc: 0.4378 - val_precision_3: 0.4880 - val_recall_3: 0.5514\n",
      "Epoch 1998/2000\n",
      "85/85 [==============================] - 0s 575us/sample - loss: 1.5125 - acc: 0.2118 - precision_3: 0.7287 - recall_3: 0.2212 - val_loss: 1.5157 - val_acc: 0.4432 - val_precision_3: 0.4880 - val_recall_3: 0.5514\n",
      "Epoch 1999/2000\n",
      "85/85 [==============================] - 0s 610us/sample - loss: 1.5274 - acc: 0.1765 - precision_3: 0.7979 - recall_3: 0.1765 - val_loss: 1.5145 - val_acc: 0.4378 - val_precision_3: 0.4907 - val_recall_3: 0.5676\n",
      "Epoch 2000/2000\n",
      "85/85 [==============================] - 0s 622us/sample - loss: 1.5154 - acc: 0.2094 - precision_3: 0.7826 - recall_3: 0.2118 - val_loss: 1.5133 - val_acc: 0.4324 - val_precision_3: 0.4837 - val_recall_3: 0.5622\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "hist = model.fit([tr, pr], lab_train, epochs = 2000, validation_data= [[tt, pt], lab_test], shuffle = True, batch_size = 16, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2659d1fe308>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (8, 5))\n",
    "ax.set_title('Training and Validation Loss Curve for PersonaNet')\n",
    "ax.plot(hist.history['loss'], label = 'Loss')\n",
    "ax.plot(hist.history['val_loss'], label = 'Validation Loss')\n",
    "ax.set_xlabel('Epoch #')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e399744ac8>]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2304x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize = (32, 5))\n",
    "ax1.plot(hist.history['acc'], 'r')\n",
    "ax1.plot(hist.history['val_acc'], 'b')\n",
    "\n",
    "ax2.plot(hist.history['loss'])\n",
    "ax2.plot(hist.history['val_loss'])\n",
    "\n",
    "ax3.plot(hist.history['recall_4'])\n",
    "ax3.plot(hist.history['val_recall_4'])\n",
    "\n",
    "ax4.plot(hist.history['precision_4'])\n",
    "ax4.plot(hist.history['val_precision_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('model_4k_strat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model_10k.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = tt.reshape((53, 24, 24, 1))\n",
    "pt = pt.reshape((53, 24, 24, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([tt, pt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_s = []\n",
    "lab_s = []\n",
    "for i in range(lab_e.shape[0]):\n",
    "    if np.argmax(lab_e[i][0]) == 0 or np.argmax(lab_e[i][0]) == 1:\n",
    "        feat_s.append(np.array(feat[i]))\n",
    "        lab_s.append(lab[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_s = np.array(feat_s)\n",
    "lab_s = np.array(lab_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 5, 5)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "test = lab.copy()\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(test.reshape(-1, 1))\n",
    "op = ohe.transform(lab_s.reshape(-1, 1))\n",
    "op = op.reshape((-1, 5, 5))\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_test = np.vstack((lab_test, op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lab_s\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "test = lab_s.copy()\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohe.fit(test.reshape(-1, 1))\n",
    "op = ohe.transform(test.reshape(-1, 1))\n",
    "op = op.reshape((-1, 5, 5))\n",
    "print(op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = feat_s[:, 0, :, :]\n",
    "pr = feat_s[:, 1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 4 dimension(s) and the array at index 1 has 5 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-09c55e6b736e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \u001b[0marrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 4 dimension(s) and the array at index 1 has 5 dimension(s)"
     ]
    }
   ],
   "source": [
    "tt = np.vstack((tt, tr))\n",
    "pt = np.vstack((pt, pr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2, 24, 24, 1, 1) (4, 5)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(feat_s), np.shape(lab_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for i in range(pred.shape[0]):\n",
    "    xs = []\n",
    "    for j in range(pred.shape[1]):\n",
    "        xs.append(np.argmax(pred[i][j]))\n",
    "    ps.append(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for i in range(lab_test.shape[0]):\n",
    "    qs = []\n",
    "    for j in range(lab_test.shape[1]):\n",
    "        qs.append(np.argmax(lab_test[i][j]))\n",
    "    ls.append(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = np.array(ps)\n",
    "ls = np.array(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = np.array(ps.flatten(), dtype = np.int64)\n",
    "ls = np.array(ls.flatten(), dtype = np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285\n"
     ]
    }
   ],
   "source": [
    "print(len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7584905660377359\n"
     ]
    }
   ],
   "source": [
    "ctr = 0\n",
    "for i in range(len(ps)):\n",
    "    if ps[i] == ls[i]:\n",
    "        ctr += 1\n",
    "print(ctr/float(len(ps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [265, 285]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-513e01a6d7a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [265, 285]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score as acc\n",
    "print(acc(ps, ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Labels for Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-152550916a60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mn_lab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0me_lab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mo_lab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma_lab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mc_lab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "n_lab = ls[:, 0]\n",
    "e_lab = ls[:, 1]\n",
    "o_lab = ls[:, 2]\n",
    "a_lab = ls[:, 3]\n",
    "c_lab = ls[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-41202b46660e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mn_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0me_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mo_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ma_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mc_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "n_pred = ps[:, 0]\n",
    "e_pred = ps[:, 1]\n",
    "o_pred = ps[:, 2]\n",
    "a_pred = ps[:, 3]\n",
    "c_pred = ps[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance for Class N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_lab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3539bf380ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m sk_report_n = classification_report(\n\u001b[0;32m      7\u001b[0m     \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_lab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     y_pred = n_pred.flatten(), labels = [0, 1, 2, 3, 4])\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msk_report_n\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'n_lab' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "sk_report_n = classification_report(\n",
    "    digits=6,\n",
    "    y_true = n_lab.flatten(), \n",
    "    y_pred = n_pred.flatten(), labels = [0, 1, 2, 3, 4])\n",
    "print(sk_report_n)\n",
    "\n",
    "print(f1_score(n_lab, n_pred, average = 'micro'))\n",
    "print(precision_score(n_lab, n_pred, average = 'micro'))\n",
    "print(recall_score(n_lab, n_pred, average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance For Class E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0   0.000000  0.000000  0.000000         0\n",
      "          1   1.000000  0.500000  0.666667         2\n",
      "          2   1.000000  1.000000  1.000000         3\n",
      "          3   0.750000  0.923077  0.827586        13\n",
      "          4   0.933333  0.736842  0.823529        19\n",
      "\n",
      "avg / total   0.877928  0.810811  0.830784        37\n",
      "\n",
      "0.8108108108108109\n",
      "0.8108108108108109\n",
      "0.8108108108108109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\dl\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "sk_report_e = classification_report(\n",
    "    digits=6,\n",
    "    y_true = e_lab.flatten(), \n",
    "    y_pred = e_pred.flatten())\n",
    "print(sk_report_e)\n",
    "\n",
    "print(f1_score(e_lab, e_pred, average = 'micro'))\n",
    "print(precision_score(e_lab, e_pred, average = 'micro'))\n",
    "print(recall_score(e_lab, e_pred, average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance for Class O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1   0.000000  0.000000  0.000000         0\n",
      "          2   0.000000  0.000000  0.000000         1\n",
      "          3   0.875000  0.700000  0.777778        10\n",
      "          4   0.884615  0.884615  0.884615        26\n",
      "\n",
      "avg / total   0.858108  0.810811  0.831832        37\n",
      "\n",
      "0.8108108108108109\n",
      "0.8108108108108109\n",
      "0.8108108108108109\n"
     ]
    }
   ],
   "source": [
    "sk_report_o = classification_report(\n",
    "    digits=6,\n",
    "    y_true = o_lab.flatten(), \n",
    "    y_pred = o_pred.flatten())\n",
    "print(sk_report_o)\n",
    "\n",
    "print(f1_score(o_lab, o_pred, average = 'micro'))\n",
    "print(precision_score(o_lab, o_pred, average = 'micro'))\n",
    "print(recall_score(o_lab, o_pred, average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance for Class A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1   0.000000  0.000000  0.000000         0\n",
      "          2   0.750000  0.750000  0.750000         4\n",
      "          3   0.727273  0.571429  0.640000        14\n",
      "          4   0.761905  0.842105  0.800000        19\n",
      "\n",
      "avg / total   0.747514  0.729730  0.734054        37\n",
      "\n",
      "0.7297297297297297\n",
      "0.7297297297297297\n",
      "0.7297297297297297\n"
     ]
    }
   ],
   "source": [
    "sk_report_a = classification_report(\n",
    "    digits=6,\n",
    "    y_true = a_lab.flatten(), \n",
    "    y_pred = a_pred.flatten())\n",
    "print(sk_report_a)\n",
    "\n",
    "print(f1_score(a_lab, a_pred, average = 'micro'))\n",
    "print(precision_score(a_lab, a_pred, average = 'micro'))\n",
    "print(recall_score(a_lab, a_pred, average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance for Class C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0   0.000000  0.000000  0.000000         0\n",
      "          1   1.000000  1.000000  1.000000         2\n",
      "          2   1.000000  0.500000  0.666667         2\n",
      "          3   1.000000  0.555556  0.714286         9\n",
      "          4   0.851852  0.958333  0.901961        24\n",
      "\n",
      "avg / total   0.903904  0.837838  0.848891        37\n",
      "\n",
      "0.8378378378378378\n",
      "0.8378378378378378\n",
      "0.8378378378378378\n"
     ]
    }
   ],
   "source": [
    "sk_report_c = classification_report(\n",
    "    digits=6,\n",
    "    y_true = c_lab.flatten(), \n",
    "    y_pred = c_pred.flatten())\n",
    "print(sk_report_c)\n",
    "\n",
    "print(f1_score(c_lab, c_pred, average = 'micro'))\n",
    "print(precision_score(c_lab, c_pred, average = 'micro'))\n",
    "print(recall_score(c_lab, c_pred, average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 41\n"
     ]
    }
   ],
   "source": [
    "print(len(ps), len(ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = np.array(ps)\n",
    "ls = np.array(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0   0.000000  0.000000  0.000000         1\n",
      "          1   0.250000  0.250000  0.250000         8\n",
      "          2   0.692308  0.391304  0.500000        23\n",
      "          3   0.557692  0.547170  0.552381        53\n",
      "          4   0.770492  0.783333  0.776860       120\n",
      "\n",
      "avg / total   0.682633  0.653659  0.663411       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "sk_report = classification_report(\n",
    "    digits=6,\n",
    "    y_true = ls.flatten(), \n",
    "    y_pred = ps.flatten())\n",
    "print(sk_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## 5 SAME CNNs ####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122, 5)\n"
     ]
    }
   ],
   "source": [
    "print(lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.fit(lab.reshape(-1, 1))\n",
    "def my_acc(pred, lab_test):\n",
    "    ps = []\n",
    "    for i in range(pred.shape[0]):\n",
    "        ps.append(np.argmax(pred[i]))\n",
    "\n",
    "    ls = []\n",
    "    for i in range(lab_test.shape[0]):\n",
    "        ls.append(ohe.inverse_transform(np.reshape(lab_test[i], (1, -1)))[0][0])\n",
    "    \n",
    "    ps = np.array(ps, dtype = np.int64)\n",
    "    ls = np.array(ls, dtype = np.int64)\n",
    "\n",
    "    ctr = 0\n",
    "    for i in range(len(ps)):\n",
    "        if ps[i] == ls[i]:\n",
    "            ctr += 1\n",
    "    return (ctr/float(len(ps)))\n",
    "\n",
    "def p_acc(pred, lab_test):\n",
    "    acc = tf.py_func(my_acc, [pred, lab_test], np.float64)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2125, 5)\n"
     ]
    }
   ],
   "source": [
    "labo = ohe.transform(lab_train.reshape(-1, 1))\n",
    "print(labo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = lab[:, 0]\n",
    "l1 = lab[:, 1]\n",
    "l2 = lab[:, 2]\n",
    "l3 = lab[:, 3]\n",
    "l4 = lab[:, 4]\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(lab.reshape(-1, 1))\n",
    "\n",
    "l0 = ohe.transform(l0.reshape(-1, 1))\n",
    "l1 = ohe.transform(l1.reshape(-1, 1))\n",
    "l2 = ohe.transform(l2.reshape(-1, 1))\n",
    "l3 = ohe.transform(l3.reshape(-1, 1))\n",
    "l4 = ohe.transform(l4.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ftr0, ftt0, ltr0, ltt0 = train_test_split(feat, l0, test_size = 0.3, shuffle = True) \n",
    "ftr1, ftt1, ltr1, ltt1 = train_test_split(feat, l1, test_size = 0.3, shuffle = True) \n",
    "ftr2, ftt2, ltr2, ltt2 = train_test_split(feat, l2, test_size = 0.3, shuffle = True) \n",
    "ftr3, ftt3, ltr3, ltt3 = train_test_split(feat, l3, test_size = 0.3, shuffle = True) \n",
    "ftr4, ftt4, ltr4, ltt4 = train_test_split(feat, l4, test_size = 0.3, shuffle = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 5)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltt0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inp_t = Input(shape = (24, 24, 1, ))\n",
    "    x = Conv2D(4, (3, 3), strides = 2, activation = 'relu')(inp_t)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate = 0.1)(x)\n",
    "    \n",
    "    \n",
    "    x = Conv2D(8, (3, 3), strides = 2, activation = 'relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(rate = 0.1)(x)\n",
    "\n",
    "    inp_p = Input(shape = (24, 24, 1, ))\n",
    "    y = Conv2D(4, (3, 3), strides = 2, activation = 'relu')(inp_p)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dropout(rate = 0.1)(y)\n",
    "\n",
    "    y = Conv2D(8, (3, 3), strides = 2, activation = 'relu')(y) \n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dropout(rate = 0.1)(y)\n",
    "\n",
    "\n",
    "\n",
    "    flat_x = Flatten()(x)\n",
    "    flat_y = Flatten()(y)\n",
    "\n",
    "    concat = Concatenate()([flat_x, flat_y])\n",
    "    \n",
    "    concat = ReLU()(concat)\n",
    "    concat = BatchNormalization()(concat)\n",
    "    d5 = Dropout(rate = 0.5)(concat)\n",
    "    \n",
    "    z = Dense(6, activation = 'relu')(d5)\n",
    "    z = BatchNormalization()(z)\n",
    "    z = Dropout(0.5)(z)\n",
    "\n",
    "\n",
    "    output = Dense(5)(z)    \n",
    "    output = sigmoid(output)\n",
    "\n",
    "    model = Model(inputs = [inp_t, inp_p], outputs = output)\n",
    "    model.compile(optimizer = Adam(lr = 0.0001), loss = 'categorical_crossentropy', metrics = [p_acc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_87\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_177 (InputLayer)          [(None, 24, 24, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_178 (InputLayer)          [(None, 24, 24, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 11, 11, 4)    40          input_177[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 11, 11, 4)    40          input_178[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 11, 11, 4)    16          conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 11, 11, 4)    16          conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_467 (Dropout)           (None, 11, 11, 4)    0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_469 (Dropout)           (None, 11, 11, 4)    0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 5, 5, 8)      296         dropout_467[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 5, 5, 8)      296         dropout_469[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 5, 5, 8)      32          conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 5, 5, 8)      32          conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_468 (Dropout)           (None, 5, 5, 8)      0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_470 (Dropout)           (None, 5, 5, 8)      0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_176 (Flatten)           (None, 200)          0           dropout_468[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_177 (Flatten)           (None, 200)          0           dropout_470[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 400)          0           flatten_176[0][0]                \n",
      "                                                                 flatten_177[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_61 (ReLU)                 (None, 400)          0           concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 400)          1600        re_lu_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_471 (Dropout)           (None, 400)          0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 6)            2406        dropout_471[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 6)            24          dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_472 (Dropout)           (None, 6)            0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 5)            35          dropout_472[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sigmoid_77 (TensorF [(None, 5)]          0           dense_123[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,833\n",
      "Trainable params: 3,973\n",
      "Non-trainable params: 860\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m0 = create_model()\n",
    "m1 = create_model()\n",
    "m2 = create_model()\n",
    "m3 = create_model()\n",
    "m4 = create_model()\n",
    "m0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-4a49d475130c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlab_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlab_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tt' is not defined"
     ]
    }
   ],
   "source": [
    "hist = m0.fit([t, p], lab_train, epochs = 10000, validation_data= [[tt, pt], lab_test], shuffle = True, batch_size = 32, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24f8d500f08>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 5))\n",
    "ax1.plot(hist_m0.history['p_acc'], 'r')\n",
    "ax1.plot(hist_m0.history['val_p_acc'], 'b')\n",
    "\n",
    "\n",
    "ax2.plot(hist_m0.history['loss'])\n",
    "ax2.plot(hist_m0.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 5)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 85 samples, validate on 37 samples\n",
      "Epoch 1/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.2573 - p_acc: 0.4399 - val_loss: 1.3436 - val_p_acc: 0.2821\n",
      "Epoch 2/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2584 - p_acc: 0.3982 - val_loss: 1.3433 - val_p_acc: 0.3173\n",
      "Epoch 3/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2561 - p_acc: 0.4119 - val_loss: 1.3436 - val_p_acc: 0.2676\n",
      "Epoch 4/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.3520 - p_acc: 0.3462 - val_loss: 1.3447 - val_p_acc: 0.2997\n",
      "Epoch 5/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.2343 - p_acc: 0.5288 - val_loss: 1.3458 - val_p_acc: 0.3029\n",
      "Epoch 6/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.3005 - p_acc: 0.3910 - val_loss: 1.3457 - val_p_acc: 0.3205\n",
      "Epoch 7/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.3288 - p_acc: 0.3165 - val_loss: 1.3459 - val_p_acc: 0.3734\n",
      "Epoch 8/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2592 - p_acc: 0.4295 - val_loss: 1.3454 - val_p_acc: 0.3205\n",
      "Epoch 9/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2442 - p_acc: 0.4367 - val_loss: 1.3445 - val_p_acc: 0.2853\n",
      "Epoch 10/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2855 - p_acc: 0.4175 - val_loss: 1.3443 - val_p_acc: 0.3205\n",
      "Epoch 11/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2130 - p_acc: 0.4591 - val_loss: 1.3431 - val_p_acc: 0.2853\n",
      "Epoch 12/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.2851 - p_acc: 0.4399 - val_loss: 1.3436 - val_p_acc: 0.2853\n",
      "Epoch 13/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2955 - p_acc: 0.4295 - val_loss: 1.3430 - val_p_acc: 0.3205\n",
      "Epoch 14/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2219 - p_acc: 0.5272 - val_loss: 1.3435 - val_p_acc: 0.3381\n",
      "Epoch 15/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.3212 - p_acc: 0.4054 - val_loss: 1.3452 - val_p_acc: 0.3558\n",
      "Epoch 16/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2026 - p_acc: 0.4872 - val_loss: 1.3455 - val_p_acc: 0.3942\n",
      "Epoch 17/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.2703 - p_acc: 0.4623 - val_loss: 1.3444 - val_p_acc: 0.3237\n",
      "Epoch 18/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2805 - p_acc: 0.4784 - val_loss: 1.3447 - val_p_acc: 0.3590\n",
      "Epoch 19/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2465 - p_acc: 0.4992 - val_loss: 1.3449 - val_p_acc: 0.3413\n",
      "Epoch 20/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2167 - p_acc: 0.4519 - val_loss: 1.3452 - val_p_acc: 0.3590\n",
      "Epoch 21/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.1557 - p_acc: 0.5008 - val_loss: 1.3446 - val_p_acc: 0.3237\n",
      "Epoch 22/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2602 - p_acc: 0.3998 - val_loss: 1.3444 - val_p_acc: 0.3766\n",
      "Epoch 23/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 1.2424 - p_acc: 0.5008 - val_loss: 1.3445 - val_p_acc: 0.3766\n",
      "Epoch 24/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2114 - p_acc: 0.4679 - val_loss: 1.3450 - val_p_acc: 0.3413\n",
      "Epoch 25/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.2119 - p_acc: 0.5321 - val_loss: 1.3443 - val_p_acc: 0.3766\n",
      "Epoch 26/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2348 - p_acc: 0.5377 - val_loss: 1.3433 - val_p_acc: 0.3766\n",
      "Epoch 27/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2511 - p_acc: 0.4575 - val_loss: 1.3435 - val_p_acc: 0.3942\n",
      "Epoch 28/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2632 - p_acc: 0.5705 - val_loss: 1.3439 - val_p_acc: 0.3766\n",
      "Epoch 29/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.1985 - p_acc: 0.4575 - val_loss: 1.3444 - val_p_acc: 0.3061\n",
      "Epoch 30/5000\n",
      "85/85 [==============================] - 0s 679us/sample - loss: 1.2003 - p_acc: 0.5601 - val_loss: 1.3447 - val_p_acc: 0.2853\n",
      "Epoch 31/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2052 - p_acc: 0.4768 - val_loss: 1.3445 - val_p_acc: 0.2997\n",
      "Epoch 32/5000\n",
      "85/85 [==============================] - 0s 665us/sample - loss: 1.2450 - p_acc: 0.4103 - val_loss: 1.3443 - val_p_acc: 0.3205\n",
      "Epoch 33/5000\n",
      "85/85 [==============================] - 0s 675us/sample - loss: 1.2532 - p_acc: 0.4263 - val_loss: 1.3437 - val_p_acc: 0.2853\n",
      "Epoch 34/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.2201 - p_acc: 0.5168 - val_loss: 1.3429 - val_p_acc: 0.3381\n",
      "Epoch 35/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1911 - p_acc: 0.4207 - val_loss: 1.3416 - val_p_acc: 0.3205\n",
      "Epoch 36/5000\n",
      "85/85 [==============================] - 0s 674us/sample - loss: 1.2368 - p_acc: 0.3982 - val_loss: 1.3415 - val_p_acc: 0.3029\n",
      "Epoch 37/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2752 - p_acc: 0.4607 - val_loss: 1.3406 - val_p_acc: 0.3558\n",
      "Epoch 38/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2212 - p_acc: 0.4415 - val_loss: 1.3390 - val_p_acc: 0.3381\n",
      "Epoch 39/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2943 - p_acc: 0.4279 - val_loss: 1.3387 - val_p_acc: 0.2853\n",
      "Epoch 40/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.2682 - p_acc: 0.4487 - val_loss: 1.3386 - val_p_acc: 0.3974\n",
      "Epoch 41/5000\n",
      "85/85 [==============================] - 0s 711us/sample - loss: 1.2644 - p_acc: 0.4976 - val_loss: 1.3388 - val_p_acc: 0.2853\n",
      "Epoch 42/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.3019 - p_acc: 0.5288 - val_loss: 1.3382 - val_p_acc: 0.3558\n",
      "Epoch 43/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.2513 - p_acc: 0.4159 - val_loss: 1.3379 - val_p_acc: 0.3798\n",
      "Epoch 44/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1855 - p_acc: 0.5216 - val_loss: 1.3366 - val_p_acc: 0.3029\n",
      "Epoch 45/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1634 - p_acc: 0.5232 - val_loss: 1.3376 - val_p_acc: 0.3205\n",
      "Epoch 46/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2401 - p_acc: 0.4784 - val_loss: 1.3372 - val_p_acc: 0.3974\n",
      "Epoch 47/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2442 - p_acc: 0.4295 - val_loss: 1.3372 - val_p_acc: 0.3622\n",
      "Epoch 48/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2252 - p_acc: 0.4311 - val_loss: 1.3361 - val_p_acc: 0.3622\n",
      "Epoch 49/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2213 - p_acc: 0.4623 - val_loss: 1.3355 - val_p_acc: 0.3974\n",
      "Epoch 50/5000\n",
      "85/85 [==============================] - 0s 689us/sample - loss: 1.2582 - p_acc: 0.4487 - val_loss: 1.3353 - val_p_acc: 0.3798\n",
      "Epoch 51/5000\n",
      "85/85 [==============================] - 0s 675us/sample - loss: 1.1979 - p_acc: 0.4744 - val_loss: 1.3334 - val_p_acc: 0.3974\n",
      "Epoch 52/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2049 - p_acc: 0.4696 - val_loss: 1.3333 - val_p_acc: 0.3798\n",
      "Epoch 53/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.1813 - p_acc: 0.4888 - val_loss: 1.3333 - val_p_acc: 0.3798\n",
      "Epoch 54/5000\n",
      "85/85 [==============================] - 0s 658us/sample - loss: 1.1938 - p_acc: 0.3566 - val_loss: 1.3333 - val_p_acc: 0.3974\n",
      "Epoch 55/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2008 - p_acc: 0.5409 - val_loss: 1.3335 - val_p_acc: 0.3269\n",
      "Epoch 56/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.2216 - p_acc: 0.4936 - val_loss: 1.3321 - val_p_acc: 0.4151\n",
      "Epoch 57/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2280 - p_acc: 0.5216 - val_loss: 1.3305 - val_p_acc: 0.3798\n",
      "Epoch 58/5000\n",
      "85/85 [==============================] - 0s 658us/sample - loss: 1.2618 - p_acc: 0.4888 - val_loss: 1.3305 - val_p_acc: 0.3974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2898 - p_acc: 0.5200 - val_loss: 1.3311 - val_p_acc: 0.3622\n",
      "Epoch 60/5000\n",
      "85/85 [==============================] - 0s 660us/sample - loss: 1.1629 - p_acc: 0.5393 - val_loss: 1.3301 - val_p_acc: 0.3974\n",
      "Epoch 61/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2815 - p_acc: 0.4455 - val_loss: 1.3299 - val_p_acc: 0.3798\n",
      "Epoch 62/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2319 - p_acc: 0.5112 - val_loss: 1.3299 - val_p_acc: 0.3974\n",
      "Epoch 63/5000\n",
      "85/85 [==============================] - 0s 666us/sample - loss: 1.2350 - p_acc: 0.4712 - val_loss: 1.3301 - val_p_acc: 0.3622\n",
      "Epoch 64/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.1936 - p_acc: 0.4712 - val_loss: 1.3312 - val_p_acc: 0.3798\n",
      "Epoch 65/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2749 - p_acc: 0.3357 - val_loss: 1.3304 - val_p_acc: 0.3622\n",
      "Epoch 66/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.2319 - p_acc: 0.4784 - val_loss: 1.3301 - val_p_acc: 0.4327\n",
      "Epoch 67/5000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.2336 - p_acc: 0.3614 - val_loss: 1.3302 - val_p_acc: 0.3798\n",
      "Epoch 68/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.2289 - p_acc: 0.5304 - val_loss: 1.3306 - val_p_acc: 0.3269\n",
      "Epoch 69/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2181 - p_acc: 0.4311 - val_loss: 1.3305 - val_p_acc: 0.3974\n",
      "Epoch 70/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2677 - p_acc: 0.4888 - val_loss: 1.3297 - val_p_acc: 0.3798\n",
      "Epoch 71/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.1722 - p_acc: 0.5705 - val_loss: 1.3285 - val_p_acc: 0.3974\n",
      "Epoch 72/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2440 - p_acc: 0.4816 - val_loss: 1.3290 - val_p_acc: 0.3269\n",
      "Epoch 73/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.2647 - p_acc: 0.4367 - val_loss: 1.3278 - val_p_acc: 0.3269\n",
      "Epoch 74/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2390 - p_acc: 0.5304 - val_loss: 1.3282 - val_p_acc: 0.3974\n",
      "Epoch 75/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2599 - p_acc: 0.4832 - val_loss: 1.3277 - val_p_acc: 0.3974\n",
      "Epoch 76/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2916 - p_acc: 0.4030 - val_loss: 1.3272 - val_p_acc: 0.3446\n",
      "Epoch 77/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2365 - p_acc: 0.4784 - val_loss: 1.3257 - val_p_acc: 0.3798\n",
      "Epoch 78/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.2677 - p_acc: 0.4575 - val_loss: 1.3250 - val_p_acc: 0.3446\n",
      "Epoch 79/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2986 - p_acc: 0.5673 - val_loss: 1.3245 - val_p_acc: 0.3974\n",
      "Epoch 80/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2402 - p_acc: 0.4607 - val_loss: 1.3257 - val_p_acc: 0.3446\n",
      "Epoch 81/5000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.2657 - p_acc: 0.4816 - val_loss: 1.3256 - val_p_acc: 0.3446\n",
      "Epoch 82/5000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.2124 - p_acc: 0.4768 - val_loss: 1.3251 - val_p_acc: 0.3798\n",
      "Epoch 83/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.1841 - p_acc: 0.4800 - val_loss: 1.3234 - val_p_acc: 0.4327\n",
      "Epoch 84/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2404 - p_acc: 0.4503 - val_loss: 1.3220 - val_p_acc: 0.3269\n",
      "Epoch 85/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2176 - p_acc: 0.4728 - val_loss: 1.3224 - val_p_acc: 0.3446\n",
      "Epoch 86/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1637 - p_acc: 0.5256 - val_loss: 1.3229 - val_p_acc: 0.4151\n",
      "Epoch 87/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2507 - p_acc: 0.4503 - val_loss: 1.3225 - val_p_acc: 0.3798\n",
      "Epoch 88/5000\n",
      "85/85 [==============================] - 0s 673us/sample - loss: 1.2055 - p_acc: 0.4607 - val_loss: 1.3222 - val_p_acc: 0.3798\n",
      "Epoch 89/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.2096 - p_acc: 0.5865 - val_loss: 1.3222 - val_p_acc: 0.3622\n",
      "Epoch 90/5000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.2451 - p_acc: 0.4784 - val_loss: 1.3222 - val_p_acc: 0.3798\n",
      "Epoch 91/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.2642 - p_acc: 0.4383 - val_loss: 1.3238 - val_p_acc: 0.4151\n",
      "Epoch 92/5000\n",
      "85/85 [==============================] - 0s 658us/sample - loss: 1.2093 - p_acc: 0.4503 - val_loss: 1.3235 - val_p_acc: 0.3622\n",
      "Epoch 93/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2351 - p_acc: 0.5200 - val_loss: 1.3243 - val_p_acc: 0.3798\n",
      "Epoch 94/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2408 - p_acc: 0.4487 - val_loss: 1.3235 - val_p_acc: 0.3974\n",
      "Epoch 95/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.1917 - p_acc: 0.5096 - val_loss: 1.3223 - val_p_acc: 0.3622\n",
      "Epoch 96/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2183 - p_acc: 0.4535 - val_loss: 1.3207 - val_p_acc: 0.3798\n",
      "Epoch 97/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2055 - p_acc: 0.3998 - val_loss: 1.3206 - val_p_acc: 0.3622\n",
      "Epoch 98/5000\n",
      "85/85 [==============================] - 0s 644us/sample - loss: 1.2645 - p_acc: 0.4087 - val_loss: 1.3200 - val_p_acc: 0.3446\n",
      "Epoch 99/5000\n",
      "85/85 [==============================] - 0s 656us/sample - loss: 1.2598 - p_acc: 0.4559 - val_loss: 1.3196 - val_p_acc: 0.3798\n",
      "Epoch 100/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2363 - p_acc: 0.5024 - val_loss: 1.3191 - val_p_acc: 0.3622\n",
      "Epoch 101/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.1899 - p_acc: 0.5216 - val_loss: 1.3184 - val_p_acc: 0.3974\n",
      "Epoch 102/5000\n",
      "85/85 [==============================] - 0s 678us/sample - loss: 1.1984 - p_acc: 0.4623 - val_loss: 1.3183 - val_p_acc: 0.3413\n",
      "Epoch 103/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2462 - p_acc: 0.3702 - val_loss: 1.3190 - val_p_acc: 0.3798\n",
      "Epoch 104/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.1859 - p_acc: 0.5337 - val_loss: 1.3191 - val_p_acc: 0.3798\n",
      "Epoch 105/5000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.2447 - p_acc: 0.3822 - val_loss: 1.3193 - val_p_acc: 0.3413\n",
      "Epoch 106/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1823 - p_acc: 0.5200 - val_loss: 1.3187 - val_p_acc: 0.3622\n",
      "Epoch 107/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.2419 - p_acc: 0.3774 - val_loss: 1.3187 - val_p_acc: 0.4151\n",
      "Epoch 108/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.2099 - p_acc: 0.4487 - val_loss: 1.3186 - val_p_acc: 0.4151\n",
      "Epoch 109/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.1978 - p_acc: 0.5128 - val_loss: 1.3183 - val_p_acc: 0.3798\n",
      "Epoch 110/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2077 - p_acc: 0.4920 - val_loss: 1.3187 - val_p_acc: 0.3974\n",
      "Epoch 111/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.1895 - p_acc: 0.5040 - val_loss: 1.3183 - val_p_acc: 0.4151\n",
      "Epoch 112/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.2420 - p_acc: 0.4191 - val_loss: 1.3182 - val_p_acc: 0.4183\n",
      "Epoch 113/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.2590 - p_acc: 0.4904 - val_loss: 1.3184 - val_p_acc: 0.3269\n",
      "Epoch 114/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.1883 - p_acc: 0.5345 - val_loss: 1.3182 - val_p_acc: 0.3622\n",
      "Epoch 115/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2144 - p_acc: 0.4351 - val_loss: 1.3173 - val_p_acc: 0.3798\n",
      "Epoch 116/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.2085 - p_acc: 0.4816 - val_loss: 1.3172 - val_p_acc: 0.3446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.2123 - p_acc: 0.4591 - val_loss: 1.3158 - val_p_acc: 0.3446\n",
      "Epoch 118/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.2266 - p_acc: 0.4054 - val_loss: 1.3149 - val_p_acc: 0.3974\n",
      "Epoch 119/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2542 - p_acc: 0.4415 - val_loss: 1.3144 - val_p_acc: 0.4151\n",
      "Epoch 120/5000\n",
      "85/85 [==============================] - 0s 633us/sample - loss: 1.2344 - p_acc: 0.4992 - val_loss: 1.3128 - val_p_acc: 0.3622\n",
      "Epoch 121/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2367 - p_acc: 0.3774 - val_loss: 1.3122 - val_p_acc: 0.3622\n",
      "Epoch 122/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.2305 - p_acc: 0.5393 - val_loss: 1.3118 - val_p_acc: 0.4535\n",
      "Epoch 123/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2114 - p_acc: 0.4295 - val_loss: 1.3112 - val_p_acc: 0.4359\n",
      "Epoch 124/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.2364 - p_acc: 0.5481 - val_loss: 1.3114 - val_p_acc: 0.4359\n",
      "Epoch 125/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2635 - p_acc: 0.3566 - val_loss: 1.3105 - val_p_acc: 0.3830\n",
      "Epoch 126/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.2428 - p_acc: 0.4960 - val_loss: 1.3111 - val_p_acc: 0.4006\n",
      "Epoch 127/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.1890 - p_acc: 0.4696 - val_loss: 1.3115 - val_p_acc: 0.3478\n",
      "Epoch 128/5000\n",
      "85/85 [==============================] - 0s 646us/sample - loss: 1.1994 - p_acc: 0.4712 - val_loss: 1.3122 - val_p_acc: 0.4359\n",
      "Epoch 129/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.2375 - p_acc: 0.4471 - val_loss: 1.3114 - val_p_acc: 0.3830\n",
      "Epoch 130/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2086 - p_acc: 0.4263 - val_loss: 1.3118 - val_p_acc: 0.3478\n",
      "Epoch 131/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.1746 - p_acc: 0.5393 - val_loss: 1.3123 - val_p_acc: 0.4006\n",
      "Epoch 132/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.2945 - p_acc: 0.3966 - val_loss: 1.3111 - val_p_acc: 0.3654\n",
      "Epoch 133/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.1509 - p_acc: 0.4816 - val_loss: 1.3112 - val_p_acc: 0.4006\n",
      "Epoch 134/5000\n",
      "85/85 [==============================] - 0s 645us/sample - loss: 1.1944 - p_acc: 0.4311 - val_loss: 1.3116 - val_p_acc: 0.4359\n",
      "Epoch 135/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.2314 - p_acc: 0.4679 - val_loss: 1.3113 - val_p_acc: 0.3654\n",
      "Epoch 136/5000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.2311 - p_acc: 0.4744 - val_loss: 1.3109 - val_p_acc: 0.4183\n",
      "Epoch 137/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1794 - p_acc: 0.5112 - val_loss: 1.3105 - val_p_acc: 0.4391\n",
      "Epoch 138/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.1967 - p_acc: 0.4696 - val_loss: 1.3105 - val_p_acc: 0.4391\n",
      "Epoch 139/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2281 - p_acc: 0.4311 - val_loss: 1.3092 - val_p_acc: 0.4391\n",
      "Epoch 140/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 1.2626 - p_acc: 0.5008 - val_loss: 1.3084 - val_p_acc: 0.4391\n",
      "Epoch 141/5000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.2373 - p_acc: 0.4383 - val_loss: 1.3076 - val_p_acc: 0.4391\n",
      "Epoch 142/5000\n",
      "85/85 [==============================] - 0s 658us/sample - loss: 1.2369 - p_acc: 0.4607 - val_loss: 1.3071 - val_p_acc: 0.4006\n",
      "Epoch 143/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.1592 - p_acc: 0.5080 - val_loss: 1.3075 - val_p_acc: 0.4183\n",
      "Epoch 144/5000\n",
      "85/85 [==============================] - 0s 656us/sample - loss: 1.2332 - p_acc: 0.4872 - val_loss: 1.3057 - val_p_acc: 0.3654\n",
      "Epoch 145/5000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.1972 - p_acc: 0.4992 - val_loss: 1.3068 - val_p_acc: 0.3830\n",
      "Epoch 146/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.1684 - p_acc: 0.4119 - val_loss: 1.3068 - val_p_acc: 0.4183\n",
      "Epoch 147/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1370 - p_acc: 0.6018 - val_loss: 1.3078 - val_p_acc: 0.4359\n",
      "Epoch 148/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.2504 - p_acc: 0.5617 - val_loss: 1.3071 - val_p_acc: 0.4038\n",
      "Epoch 149/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.1817 - p_acc: 0.4992 - val_loss: 1.3066 - val_p_acc: 0.4391\n",
      "Epoch 150/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.1917 - p_acc: 0.4415 - val_loss: 1.3056 - val_p_acc: 0.4359\n",
      "Epoch 151/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 1.2233 - p_acc: 0.5857 - val_loss: 1.3038 - val_p_acc: 0.4359\n",
      "Epoch 152/5000\n",
      "85/85 [==============================] - 0s 634us/sample - loss: 1.2424 - p_acc: 0.5216 - val_loss: 1.3029 - val_p_acc: 0.4712\n",
      "Epoch 153/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2076 - p_acc: 0.4207 - val_loss: 1.3034 - val_p_acc: 0.4006\n",
      "Epoch 154/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 1.1656 - p_acc: 0.5112 - val_loss: 1.3047 - val_p_acc: 0.4006\n",
      "Epoch 155/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.1813 - p_acc: 0.5409 - val_loss: 1.3040 - val_p_acc: 0.4535\n",
      "Epoch 156/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2476 - p_acc: 0.4663 - val_loss: 1.3034 - val_p_acc: 0.4006\n",
      "Epoch 157/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1782 - p_acc: 0.6386 - val_loss: 1.3021 - val_p_acc: 0.4391\n",
      "Epoch 158/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2068 - p_acc: 0.4367 - val_loss: 1.3024 - val_p_acc: 0.4391\n",
      "Epoch 159/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1663 - p_acc: 0.5841 - val_loss: 1.3018 - val_p_acc: 0.3862\n",
      "Epoch 160/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2582 - p_acc: 0.4696 - val_loss: 1.3010 - val_p_acc: 0.4215\n",
      "Epoch 161/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1328 - p_acc: 0.5304 - val_loss: 1.3001 - val_p_acc: 0.4391\n",
      "Epoch 162/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2126 - p_acc: 0.5040 - val_loss: 1.3000 - val_p_acc: 0.4744\n",
      "Epoch 163/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.2408 - p_acc: 0.5377 - val_loss: 1.3003 - val_p_acc: 0.4215\n",
      "Epoch 164/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 1.1859 - p_acc: 0.4639 - val_loss: 1.3004 - val_p_acc: 0.4215\n",
      "Epoch 165/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1819 - p_acc: 0.4888 - val_loss: 1.3001 - val_p_acc: 0.4038\n",
      "Epoch 166/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.2112 - p_acc: 0.5689 - val_loss: 1.2990 - val_p_acc: 0.4920\n",
      "Epoch 167/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.2010 - p_acc: 0.4503 - val_loss: 1.2992 - val_p_acc: 0.3862\n",
      "Epoch 168/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.2716 - p_acc: 0.5216 - val_loss: 1.2997 - val_p_acc: 0.4215\n",
      "Epoch 169/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2169 - p_acc: 0.4295 - val_loss: 1.3003 - val_p_acc: 0.4391\n",
      "Epoch 170/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2318 - p_acc: 0.5304 - val_loss: 1.3011 - val_p_acc: 0.4215\n",
      "Epoch 171/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1777 - p_acc: 0.5024 - val_loss: 1.3007 - val_p_acc: 0.4215\n",
      "Epoch 172/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2314 - p_acc: 0.4904 - val_loss: 1.2999 - val_p_acc: 0.4567\n",
      "Epoch 173/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2965 - p_acc: 0.4415 - val_loss: 1.2999 - val_p_acc: 0.4567\n",
      "Epoch 174/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2193 - p_acc: 0.5705 - val_loss: 1.2989 - val_p_acc: 0.4391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2000 - p_acc: 0.4663 - val_loss: 1.2989 - val_p_acc: 0.4744\n",
      "Epoch 176/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1919 - p_acc: 0.5617 - val_loss: 1.2981 - val_p_acc: 0.4567\n",
      "Epoch 177/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2052 - p_acc: 0.5112 - val_loss: 1.2962 - val_p_acc: 0.4038\n",
      "Epoch 178/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1955 - p_acc: 0.5897 - val_loss: 1.2959 - val_p_acc: 0.4038\n",
      "Epoch 179/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2602 - p_acc: 0.4696 - val_loss: 1.2949 - val_p_acc: 0.3862\n",
      "Epoch 180/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1429 - p_acc: 0.5144 - val_loss: 1.2964 - val_p_acc: 0.4006\n",
      "Epoch 181/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1596 - p_acc: 0.5112 - val_loss: 1.2970 - val_p_acc: 0.4006\n",
      "Epoch 182/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1722 - p_acc: 0.4575 - val_loss: 1.2975 - val_p_acc: 0.4006\n",
      "Epoch 183/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1665 - p_acc: 0.4904 - val_loss: 1.2964 - val_p_acc: 0.4183\n",
      "Epoch 184/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1500 - p_acc: 0.5425 - val_loss: 1.2944 - val_p_acc: 0.4359\n",
      "Epoch 185/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1971 - p_acc: 0.4591 - val_loss: 1.2942 - val_p_acc: 0.4183\n",
      "Epoch 186/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1952 - p_acc: 0.4135 - val_loss: 1.2939 - val_p_acc: 0.4183\n",
      "Epoch 187/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1537 - p_acc: 0.5425 - val_loss: 1.2954 - val_p_acc: 0.3654\n",
      "Epoch 188/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1376 - p_acc: 0.5304 - val_loss: 1.2953 - val_p_acc: 0.4183\n",
      "Epoch 189/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1832 - p_acc: 0.5216 - val_loss: 1.2949 - val_p_acc: 0.4183\n",
      "Epoch 190/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1980 - p_acc: 0.5080 - val_loss: 1.2945 - val_p_acc: 0.3830\n",
      "Epoch 191/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1122 - p_acc: 0.5409 - val_loss: 1.2950 - val_p_acc: 0.4183\n",
      "Epoch 192/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2053 - p_acc: 0.5200 - val_loss: 1.2951 - val_p_acc: 0.3478\n",
      "Epoch 193/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1627 - p_acc: 0.4832 - val_loss: 1.2959 - val_p_acc: 0.4006\n",
      "Epoch 194/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1621 - p_acc: 0.5689 - val_loss: 1.2960 - val_p_acc: 0.4006\n",
      "Epoch 195/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2227 - p_acc: 0.5112 - val_loss: 1.2971 - val_p_acc: 0.3622\n",
      "Epoch 196/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.1771 - p_acc: 0.4696 - val_loss: 1.2958 - val_p_acc: 0.4183\n",
      "Epoch 197/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1221 - p_acc: 0.5304 - val_loss: 1.2954 - val_p_acc: 0.4006\n",
      "Epoch 198/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1980 - p_acc: 0.4800 - val_loss: 1.2946 - val_p_acc: 0.4359\n",
      "Epoch 199/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1726 - p_acc: 0.4415 - val_loss: 1.2951 - val_p_acc: 0.4359\n",
      "Epoch 200/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1865 - p_acc: 0.4191 - val_loss: 1.2942 - val_p_acc: 0.3654\n",
      "Epoch 201/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1830 - p_acc: 0.4832 - val_loss: 1.2946 - val_p_acc: 0.4359\n",
      "Epoch 202/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2132 - p_acc: 0.5409 - val_loss: 1.2931 - val_p_acc: 0.3830\n",
      "Epoch 203/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1602 - p_acc: 0.4800 - val_loss: 1.2917 - val_p_acc: 0.4183\n",
      "Epoch 204/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2070 - p_acc: 0.4848 - val_loss: 1.2915 - val_p_acc: 0.4006\n",
      "Epoch 205/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.2150 - p_acc: 0.4872 - val_loss: 1.2917 - val_p_acc: 0.3830\n",
      "Epoch 206/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.1709 - p_acc: 0.4728 - val_loss: 1.2925 - val_p_acc: 0.4183\n",
      "Epoch 207/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2190 - p_acc: 0.4712 - val_loss: 1.2922 - val_p_acc: 0.4006\n",
      "Epoch 208/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.1464 - p_acc: 0.5409 - val_loss: 1.2925 - val_p_acc: 0.4183\n",
      "Epoch 209/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1563 - p_acc: 0.6122 - val_loss: 1.2922 - val_p_acc: 0.4006\n",
      "Epoch 210/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1133 - p_acc: 0.5545 - val_loss: 1.2914 - val_p_acc: 0.4183\n",
      "Epoch 211/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.2438 - p_acc: 0.4623 - val_loss: 1.2921 - val_p_acc: 0.4006\n",
      "Epoch 212/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.2822 - p_acc: 0.3758 - val_loss: 1.2931 - val_p_acc: 0.4183\n",
      "Epoch 213/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1610 - p_acc: 0.5585 - val_loss: 1.2910 - val_p_acc: 0.4006\n",
      "Epoch 214/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2355 - p_acc: 0.5409 - val_loss: 1.2919 - val_p_acc: 0.4183\n",
      "Epoch 215/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2147 - p_acc: 0.5513 - val_loss: 1.2912 - val_p_acc: 0.3654\n",
      "Epoch 216/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1940 - p_acc: 0.5112 - val_loss: 1.2913 - val_p_acc: 0.4183\n",
      "Epoch 217/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1513 - p_acc: 0.6106 - val_loss: 1.2919 - val_p_acc: 0.4359\n",
      "Epoch 218/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1891 - p_acc: 0.5513 - val_loss: 1.2924 - val_p_acc: 0.3830\n",
      "Epoch 219/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2058 - p_acc: 0.5393 - val_loss: 1.2908 - val_p_acc: 0.4006\n",
      "Epoch 220/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2291 - p_acc: 0.4575 - val_loss: 1.2885 - val_p_acc: 0.4423\n",
      "Epoch 221/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1579 - p_acc: 0.4832 - val_loss: 1.2879 - val_p_acc: 0.4423\n",
      "Epoch 222/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1506 - p_acc: 0.5481 - val_loss: 1.2870 - val_p_acc: 0.4423\n",
      "Epoch 223/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.2265 - p_acc: 0.5184 - val_loss: 1.2873 - val_p_acc: 0.4776\n",
      "Epoch 224/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1749 - p_acc: 0.4471 - val_loss: 1.2874 - val_p_acc: 0.4599\n",
      "Epoch 225/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.2204 - p_acc: 0.4904 - val_loss: 1.2865 - val_p_acc: 0.4423\n",
      "Epoch 226/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1666 - p_acc: 0.4976 - val_loss: 1.2876 - val_p_acc: 0.4952\n",
      "Epoch 227/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1657 - p_acc: 0.5425 - val_loss: 1.2870 - val_p_acc: 0.4599\n",
      "Epoch 228/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.1985 - p_acc: 0.4784 - val_loss: 1.2877 - val_p_acc: 0.3830\n",
      "Epoch 229/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1752 - p_acc: 0.4816 - val_loss: 1.2873 - val_p_acc: 0.3830\n",
      "Epoch 230/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1555 - p_acc: 0.4952 - val_loss: 1.2875 - val_p_acc: 0.3830\n",
      "Epoch 231/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1534 - p_acc: 0.4816 - val_loss: 1.2874 - val_p_acc: 0.3654\n",
      "Epoch 232/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1476 - p_acc: 0.5216 - val_loss: 1.2868 - val_p_acc: 0.4215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1302 - p_acc: 0.5409 - val_loss: 1.2860 - val_p_acc: 0.4391\n",
      "Epoch 234/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1858 - p_acc: 0.5024 - val_loss: 1.2865 - val_p_acc: 0.4744\n",
      "Epoch 235/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1611 - p_acc: 0.4832 - val_loss: 1.2866 - val_p_acc: 0.4744\n",
      "Epoch 236/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1016 - p_acc: 0.5601 - val_loss: 1.2861 - val_p_acc: 0.4423\n",
      "Epoch 237/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1805 - p_acc: 0.6282 - val_loss: 1.2849 - val_p_acc: 0.4599\n",
      "Epoch 238/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1946 - p_acc: 0.5513 - val_loss: 1.2841 - val_p_acc: 0.4952\n",
      "Epoch 239/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1618 - p_acc: 0.5112 - val_loss: 1.2838 - val_p_acc: 0.4599\n",
      "Epoch 240/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1442 - p_acc: 0.4559 - val_loss: 1.2830 - val_p_acc: 0.4599\n",
      "Epoch 241/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1822 - p_acc: 0.5809 - val_loss: 1.2834 - val_p_acc: 0.4071\n",
      "Epoch 242/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2222 - p_acc: 0.4816 - val_loss: 1.2830 - val_p_acc: 0.4952\n",
      "Epoch 243/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2281 - p_acc: 0.5288 - val_loss: 1.2822 - val_p_acc: 0.4423\n",
      "Epoch 244/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2417 - p_acc: 0.4679 - val_loss: 1.2809 - val_p_acc: 0.4776\n",
      "Epoch 245/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2087 - p_acc: 0.4920 - val_loss: 1.2817 - val_p_acc: 0.4423\n",
      "Epoch 246/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1743 - p_acc: 0.5232 - val_loss: 1.2818 - val_p_acc: 0.4423\n",
      "Epoch 247/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1663 - p_acc: 0.4936 - val_loss: 1.2810 - val_p_acc: 0.4599\n",
      "Epoch 248/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.2445 - p_acc: 0.4207 - val_loss: 1.2807 - val_p_acc: 0.4423\n",
      "Epoch 249/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1765 - p_acc: 0.5465 - val_loss: 1.2804 - val_p_acc: 0.4776\n",
      "Epoch 250/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1625 - p_acc: 0.5393 - val_loss: 1.2814 - val_p_acc: 0.4038\n",
      "Epoch 251/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1915 - p_acc: 0.5425 - val_loss: 1.2811 - val_p_acc: 0.5096\n",
      "Epoch 252/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1859 - p_acc: 0.4992 - val_loss: 1.2804 - val_p_acc: 0.4567\n",
      "Epoch 253/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1263 - p_acc: 0.5809 - val_loss: 1.2804 - val_p_acc: 0.4215\n",
      "Epoch 254/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2003 - p_acc: 0.4191 - val_loss: 1.2816 - val_p_acc: 0.4744\n",
      "Epoch 255/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2367 - p_acc: 0.4992 - val_loss: 1.2832 - val_p_acc: 0.4215\n",
      "Epoch 256/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1626 - p_acc: 0.5841 - val_loss: 1.2835 - val_p_acc: 0.4215\n",
      "Epoch 257/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2149 - p_acc: 0.4904 - val_loss: 1.2827 - val_p_acc: 0.4215\n",
      "Epoch 258/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2037 - p_acc: 0.4519 - val_loss: 1.2807 - val_p_acc: 0.3862\n",
      "Epoch 259/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1447 - p_acc: 0.5024 - val_loss: 1.2804 - val_p_acc: 0.3510\n",
      "Epoch 260/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1833 - p_acc: 0.4519 - val_loss: 1.2800 - val_p_acc: 0.4391\n",
      "Epoch 261/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2081 - p_acc: 0.4712 - val_loss: 1.2807 - val_p_acc: 0.4391\n",
      "Epoch 262/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1423 - p_acc: 0.4816 - val_loss: 1.2806 - val_p_acc: 0.4038\n",
      "Epoch 263/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1487 - p_acc: 0.5024 - val_loss: 1.2795 - val_p_acc: 0.4215\n",
      "Epoch 264/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.2025 - p_acc: 0.4679 - val_loss: 1.2789 - val_p_acc: 0.4776\n",
      "Epoch 265/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1072 - p_acc: 0.6138 - val_loss: 1.2780 - val_p_acc: 0.4423\n",
      "Epoch 266/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1401 - p_acc: 0.4816 - val_loss: 1.2775 - val_p_acc: 0.4423\n",
      "Epoch 267/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1656 - p_acc: 0.5497 - val_loss: 1.2771 - val_p_acc: 0.4599\n",
      "Epoch 268/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.1312 - p_acc: 0.5601 - val_loss: 1.2783 - val_p_acc: 0.4776\n",
      "Epoch 269/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1717 - p_acc: 0.5553 - val_loss: 1.2783 - val_p_acc: 0.4599\n",
      "Epoch 270/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1497 - p_acc: 0.5393 - val_loss: 1.2775 - val_p_acc: 0.4776\n",
      "Epoch 271/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1913 - p_acc: 0.4487 - val_loss: 1.2768 - val_p_acc: 0.4071\n",
      "Epoch 272/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1414 - p_acc: 0.4888 - val_loss: 1.2786 - val_p_acc: 0.4599\n",
      "Epoch 273/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.2231 - p_acc: 0.4519 - val_loss: 1.2783 - val_p_acc: 0.4071\n",
      "Epoch 274/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1857 - p_acc: 0.5721 - val_loss: 1.2777 - val_p_acc: 0.4599\n",
      "Epoch 275/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1266 - p_acc: 0.4471 - val_loss: 1.2786 - val_p_acc: 0.4776\n",
      "Epoch 276/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1136 - p_acc: 0.4936 - val_loss: 1.2789 - val_p_acc: 0.4071\n",
      "Epoch 277/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1801 - p_acc: 0.5112 - val_loss: 1.2789 - val_p_acc: 0.4776\n",
      "Epoch 278/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1039 - p_acc: 0.4936 - val_loss: 1.2781 - val_p_acc: 0.4423\n",
      "Epoch 279/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.1583 - p_acc: 0.5216 - val_loss: 1.2784 - val_p_acc: 0.4599\n",
      "Epoch 280/5000\n",
      "85/85 [==============================] - 0s 709us/sample - loss: 1.1852 - p_acc: 0.4295 - val_loss: 1.2788 - val_p_acc: 0.4776\n",
      "Epoch 281/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1169 - p_acc: 0.5425 - val_loss: 1.2783 - val_p_acc: 0.4599\n",
      "Epoch 282/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2395 - p_acc: 0.4503 - val_loss: 1.2775 - val_p_acc: 0.5128\n",
      "Epoch 283/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1251 - p_acc: 0.5112 - val_loss: 1.2779 - val_p_acc: 0.4952\n",
      "Epoch 284/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1573 - p_acc: 0.4872 - val_loss: 1.2773 - val_p_acc: 0.5128\n",
      "Epoch 285/5000\n",
      "85/85 [==============================] - 0s 709us/sample - loss: 1.1435 - p_acc: 0.5288 - val_loss: 1.2773 - val_p_acc: 0.4247\n",
      "Epoch 286/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1691 - p_acc: 0.5288 - val_loss: 1.2769 - val_p_acc: 0.4776\n",
      "Epoch 287/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1636 - p_acc: 0.5112 - val_loss: 1.2763 - val_p_acc: 0.4776\n",
      "Epoch 288/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.2122 - p_acc: 0.5128 - val_loss: 1.2761 - val_p_acc: 0.4776\n",
      "Epoch 289/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1264 - p_acc: 0.5393 - val_loss: 1.2754 - val_p_acc: 0.4599\n",
      "Epoch 290/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1356 - p_acc: 0.5377 - val_loss: 1.2759 - val_p_acc: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1385 - p_acc: 0.4487 - val_loss: 1.2754 - val_p_acc: 0.4423\n",
      "Epoch 292/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1471 - p_acc: 0.6034 - val_loss: 1.2758 - val_p_acc: 0.4776\n",
      "Epoch 293/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1953 - p_acc: 0.4784 - val_loss: 1.2750 - val_p_acc: 0.4776\n",
      "Epoch 294/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1113 - p_acc: 0.4816 - val_loss: 1.2762 - val_p_acc: 0.4599\n",
      "Epoch 295/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.2275 - p_acc: 0.5513 - val_loss: 1.2750 - val_p_acc: 0.5304\n",
      "Epoch 296/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1563 - p_acc: 0.5377 - val_loss: 1.2736 - val_p_acc: 0.4071\n",
      "Epoch 297/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1505 - p_acc: 0.5897 - val_loss: 1.2718 - val_p_acc: 0.4776\n",
      "Epoch 298/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1910 - p_acc: 0.5096 - val_loss: 1.2708 - val_p_acc: 0.4423\n",
      "Epoch 299/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1502 - p_acc: 0.5272 - val_loss: 1.2696 - val_p_acc: 0.4776\n",
      "Epoch 300/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 1.2070 - p_acc: 0.4383 - val_loss: 1.2685 - val_p_acc: 0.5128\n",
      "Epoch 301/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1439 - p_acc: 0.4816 - val_loss: 1.2676 - val_p_acc: 0.4776\n",
      "Epoch 302/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1631 - p_acc: 0.5841 - val_loss: 1.2670 - val_p_acc: 0.4952\n",
      "Epoch 303/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1544 - p_acc: 0.4800 - val_loss: 1.2669 - val_p_acc: 0.4776\n",
      "Epoch 304/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1636 - p_acc: 0.5200 - val_loss: 1.2661 - val_p_acc: 0.4423\n",
      "Epoch 305/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1494 - p_acc: 0.5617 - val_loss: 1.2665 - val_p_acc: 0.4247\n",
      "Epoch 306/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0979 - p_acc: 0.5585 - val_loss: 1.2655 - val_p_acc: 0.4071\n",
      "Epoch 307/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1402 - p_acc: 0.5008 - val_loss: 1.2661 - val_p_acc: 0.4776\n",
      "Epoch 308/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1951 - p_acc: 0.5288 - val_loss: 1.2662 - val_p_acc: 0.4776\n",
      "Epoch 309/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1268 - p_acc: 0.5617 - val_loss: 1.2654 - val_p_acc: 0.4423\n",
      "Epoch 310/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1695 - p_acc: 0.4976 - val_loss: 1.2651 - val_p_acc: 0.4599\n",
      "Epoch 311/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1948 - p_acc: 0.4800 - val_loss: 1.2659 - val_p_acc: 0.4776\n",
      "Epoch 312/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1696 - p_acc: 0.5024 - val_loss: 1.2655 - val_p_acc: 0.4952\n",
      "Epoch 313/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1615 - p_acc: 0.4904 - val_loss: 1.2654 - val_p_acc: 0.4247\n",
      "Epoch 314/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0925 - p_acc: 0.5689 - val_loss: 1.2641 - val_p_acc: 0.4952\n",
      "Epoch 315/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1496 - p_acc: 0.5184 - val_loss: 1.2657 - val_p_acc: 0.4599\n",
      "Epoch 316/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1451 - p_acc: 0.5096 - val_loss: 1.2646 - val_p_acc: 0.4776\n",
      "Epoch 317/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1118 - p_acc: 0.6579 - val_loss: 1.2648 - val_p_acc: 0.4599\n",
      "Epoch 318/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1629 - p_acc: 0.5232 - val_loss: 1.2646 - val_p_acc: 0.4599\n",
      "Epoch 319/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 1.1545 - p_acc: 0.4888 - val_loss: 1.2648 - val_p_acc: 0.4599\n",
      "Epoch 320/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1129 - p_acc: 0.6090 - val_loss: 1.2648 - val_p_acc: 0.5128\n",
      "Epoch 321/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1488 - p_acc: 0.5633 - val_loss: 1.2652 - val_p_acc: 0.4776\n",
      "Epoch 322/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.2418 - p_acc: 0.4295 - val_loss: 1.2645 - val_p_acc: 0.4952\n",
      "Epoch 323/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1540 - p_acc: 0.5040 - val_loss: 1.2654 - val_p_acc: 0.4599\n",
      "Epoch 324/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1474 - p_acc: 0.4311 - val_loss: 1.2651 - val_p_acc: 0.4247\n",
      "Epoch 325/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1386 - p_acc: 0.4768 - val_loss: 1.2648 - val_p_acc: 0.4776\n",
      "Epoch 326/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1161 - p_acc: 0.5337 - val_loss: 1.2640 - val_p_acc: 0.4776\n",
      "Epoch 327/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1199 - p_acc: 0.5008 - val_loss: 1.2640 - val_p_acc: 0.4599\n",
      "Epoch 328/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1226 - p_acc: 0.5585 - val_loss: 1.2630 - val_p_acc: 0.4776\n",
      "Epoch 329/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1634 - p_acc: 0.4904 - val_loss: 1.2626 - val_p_acc: 0.4423\n",
      "Epoch 330/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.2063 - p_acc: 0.4784 - val_loss: 1.2613 - val_p_acc: 0.4247\n",
      "Epoch 331/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1435 - p_acc: 0.5304 - val_loss: 1.2604 - val_p_acc: 0.4599\n",
      "Epoch 332/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.2459 - p_acc: 0.5128 - val_loss: 1.2593 - val_p_acc: 0.4599\n",
      "Epoch 333/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1376 - p_acc: 0.4784 - val_loss: 1.2590 - val_p_acc: 0.4776\n",
      "Epoch 334/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1574 - p_acc: 0.5200 - val_loss: 1.2579 - val_p_acc: 0.4247\n",
      "Epoch 335/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1502 - p_acc: 0.4471 - val_loss: 1.2570 - val_p_acc: 0.4776\n",
      "Epoch 336/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1664 - p_acc: 0.4904 - val_loss: 1.2572 - val_p_acc: 0.5128\n",
      "Epoch 337/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1105 - p_acc: 0.5913 - val_loss: 1.2576 - val_p_acc: 0.4952\n",
      "Epoch 338/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.2170 - p_acc: 0.5080 - val_loss: 1.2586 - val_p_acc: 0.4599\n",
      "Epoch 339/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1187 - p_acc: 0.5008 - val_loss: 1.2597 - val_p_acc: 0.4247\n",
      "Epoch 340/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1820 - p_acc: 0.4311 - val_loss: 1.2595 - val_p_acc: 0.4247\n",
      "Epoch 341/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1686 - p_acc: 0.5617 - val_loss: 1.2581 - val_p_acc: 0.4599\n",
      "Epoch 342/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2287 - p_acc: 0.5216 - val_loss: 1.2581 - val_p_acc: 0.5304\n",
      "Epoch 343/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1784 - p_acc: 0.5096 - val_loss: 1.2573 - val_p_acc: 0.4423\n",
      "Epoch 344/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1263 - p_acc: 0.4904 - val_loss: 1.2560 - val_p_acc: 0.4952\n",
      "Epoch 345/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0973 - p_acc: 0.5008 - val_loss: 1.2554 - val_p_acc: 0.4599\n",
      "Epoch 346/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1916 - p_acc: 0.5545 - val_loss: 1.2557 - val_p_acc: 0.4599\n",
      "Epoch 347/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1116 - p_acc: 0.5809 - val_loss: 1.2548 - val_p_acc: 0.4776\n",
      "Epoch 348/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1477 - p_acc: 0.5409 - val_loss: 1.2539 - val_p_acc: 0.4952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1066 - p_acc: 0.5705 - val_loss: 1.2528 - val_p_acc: 0.4776\n",
      "Epoch 350/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1444 - p_acc: 0.5481 - val_loss: 1.2535 - val_p_acc: 0.4599\n",
      "Epoch 351/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1429 - p_acc: 0.5128 - val_loss: 1.2534 - val_p_acc: 0.4423\n",
      "Epoch 352/5000\n",
      "85/85 [==============================] - 0s 682us/sample - loss: 1.1771 - p_acc: 0.4487 - val_loss: 1.2536 - val_p_acc: 0.4599\n",
      "Epoch 353/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1814 - p_acc: 0.4503 - val_loss: 1.2526 - val_p_acc: 0.4599\n",
      "Epoch 354/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1965 - p_acc: 0.5529 - val_loss: 1.2525 - val_p_acc: 0.4952\n",
      "Epoch 355/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1590 - p_acc: 0.5216 - val_loss: 1.2531 - val_p_acc: 0.4776\n",
      "Epoch 356/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1566 - p_acc: 0.5112 - val_loss: 1.2529 - val_p_acc: 0.4599\n",
      "Epoch 357/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1627 - p_acc: 0.4904 - val_loss: 1.2538 - val_p_acc: 0.4952\n",
      "Epoch 358/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1497 - p_acc: 0.5008 - val_loss: 1.2534 - val_p_acc: 0.4776\n",
      "Epoch 359/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1153 - p_acc: 0.5721 - val_loss: 1.2535 - val_p_acc: 0.4599\n",
      "Epoch 360/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.2347 - p_acc: 0.5601 - val_loss: 1.2535 - val_p_acc: 0.4247\n",
      "Epoch 361/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1742 - p_acc: 0.4103 - val_loss: 1.2538 - val_p_acc: 0.4776\n",
      "Epoch 362/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1510 - p_acc: 0.5040 - val_loss: 1.2549 - val_p_acc: 0.4952\n",
      "Epoch 363/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0789 - p_acc: 0.6018 - val_loss: 1.2556 - val_p_acc: 0.4423\n",
      "Epoch 364/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1014 - p_acc: 0.5024 - val_loss: 1.2559 - val_p_acc: 0.4247\n",
      "Epoch 365/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1765 - p_acc: 0.5008 - val_loss: 1.2557 - val_p_acc: 0.4423\n",
      "Epoch 366/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1272 - p_acc: 0.5200 - val_loss: 1.2556 - val_p_acc: 0.4423\n",
      "Epoch 367/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1762 - p_acc: 0.4768 - val_loss: 1.2555 - val_p_acc: 0.4776\n",
      "Epoch 368/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1918 - p_acc: 0.4679 - val_loss: 1.2557 - val_p_acc: 0.4247\n",
      "Epoch 369/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1367 - p_acc: 0.4976 - val_loss: 1.2544 - val_p_acc: 0.4599\n",
      "Epoch 370/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1647 - p_acc: 0.4607 - val_loss: 1.2546 - val_p_acc: 0.4599\n",
      "Epoch 371/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.2065 - p_acc: 0.4968 - val_loss: 1.2535 - val_p_acc: 0.4423\n",
      "Epoch 372/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1286 - p_acc: 0.4992 - val_loss: 1.2535 - val_p_acc: 0.4423\n",
      "Epoch 373/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1778 - p_acc: 0.5321 - val_loss: 1.2531 - val_p_acc: 0.4599\n",
      "Epoch 374/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1497 - p_acc: 0.4904 - val_loss: 1.2534 - val_p_acc: 0.4247\n",
      "Epoch 375/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1369 - p_acc: 0.5024 - val_loss: 1.2533 - val_p_acc: 0.4423\n",
      "Epoch 376/5000\n",
      "85/85 [==============================] - 0s 687us/sample - loss: 1.1519 - p_acc: 0.5857 - val_loss: 1.2530 - val_p_acc: 0.4423\n",
      "Epoch 377/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1380 - p_acc: 0.5409 - val_loss: 1.2520 - val_p_acc: 0.4423\n",
      "Epoch 378/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1282 - p_acc: 0.4431 - val_loss: 1.2511 - val_p_acc: 0.5128\n",
      "Epoch 379/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1296 - p_acc: 0.5497 - val_loss: 1.2499 - val_p_acc: 0.5128\n",
      "Epoch 380/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.1420 - p_acc: 0.5809 - val_loss: 1.2492 - val_p_acc: 0.5128\n",
      "Epoch 381/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0974 - p_acc: 0.5601 - val_loss: 1.2504 - val_p_acc: 0.4247\n",
      "Epoch 382/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1727 - p_acc: 0.5184 - val_loss: 1.2498 - val_p_acc: 0.4952\n",
      "Epoch 383/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1795 - p_acc: 0.4383 - val_loss: 1.2500 - val_p_acc: 0.4423\n",
      "Epoch 384/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1640 - p_acc: 0.4872 - val_loss: 1.2507 - val_p_acc: 0.4776\n",
      "Epoch 385/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.2011 - p_acc: 0.4591 - val_loss: 1.2506 - val_p_acc: 0.4599\n",
      "Epoch 386/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1373 - p_acc: 0.5304 - val_loss: 1.2491 - val_p_acc: 0.4776\n",
      "Epoch 387/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0900 - p_acc: 0.6138 - val_loss: 1.2476 - val_p_acc: 0.4776\n",
      "Epoch 388/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.1056 - p_acc: 0.4816 - val_loss: 1.2465 - val_p_acc: 0.4599\n",
      "Epoch 389/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1005 - p_acc: 0.4728 - val_loss: 1.2454 - val_p_acc: 0.4952\n",
      "Epoch 390/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1426 - p_acc: 0.4087 - val_loss: 1.2456 - val_p_acc: 0.4599\n",
      "Epoch 391/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1397 - p_acc: 0.5825 - val_loss: 1.2450 - val_p_acc: 0.4423\n",
      "Epoch 392/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1409 - p_acc: 0.5913 - val_loss: 1.2435 - val_p_acc: 0.4423\n",
      "Epoch 393/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1958 - p_acc: 0.4976 - val_loss: 1.2437 - val_p_acc: 0.4776\n",
      "Epoch 394/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1673 - p_acc: 0.5601 - val_loss: 1.2431 - val_p_acc: 0.4599\n",
      "Epoch 395/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1340 - p_acc: 0.5497 - val_loss: 1.2416 - val_p_acc: 0.4776\n",
      "Epoch 396/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1172 - p_acc: 0.5705 - val_loss: 1.2423 - val_p_acc: 0.4599\n",
      "Epoch 397/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1156 - p_acc: 0.6018 - val_loss: 1.2429 - val_p_acc: 0.4776\n",
      "Epoch 398/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0736 - p_acc: 0.4607 - val_loss: 1.2424 - val_p_acc: 0.4423\n",
      "Epoch 399/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1378 - p_acc: 0.5513 - val_loss: 1.2419 - val_p_acc: 0.4599\n",
      "Epoch 400/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1143 - p_acc: 0.5825 - val_loss: 1.2412 - val_p_acc: 0.4423\n",
      "Epoch 401/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1593 - p_acc: 0.5216 - val_loss: 1.2402 - val_p_acc: 0.4247\n",
      "Epoch 402/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1953 - p_acc: 0.5232 - val_loss: 1.2398 - val_p_acc: 0.4952\n",
      "Epoch 403/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1363 - p_acc: 0.5425 - val_loss: 1.2407 - val_p_acc: 0.4952\n",
      "Epoch 404/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1637 - p_acc: 0.5216 - val_loss: 1.2389 - val_p_acc: 0.4776\n",
      "Epoch 405/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0726 - p_acc: 0.5809 - val_loss: 1.2382 - val_p_acc: 0.5128\n",
      "Epoch 406/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1386 - p_acc: 0.4696 - val_loss: 1.2383 - val_p_acc: 0.4423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1218 - p_acc: 0.5200 - val_loss: 1.2381 - val_p_acc: 0.4599\n",
      "Epoch 408/5000\n",
      "85/85 [==============================] - 0s 685us/sample - loss: 1.1788 - p_acc: 0.4888 - val_loss: 1.2384 - val_p_acc: 0.4599\n",
      "Epoch 409/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1508 - p_acc: 0.5304 - val_loss: 1.2373 - val_p_acc: 0.4599\n",
      "Epoch 410/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1959 - p_acc: 0.5080 - val_loss: 1.2372 - val_p_acc: 0.3894\n",
      "Epoch 411/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0932 - p_acc: 0.5809 - val_loss: 1.2382 - val_p_acc: 0.4423\n",
      "Epoch 412/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0720 - p_acc: 0.5425 - val_loss: 1.2374 - val_p_acc: 0.4776\n",
      "Epoch 413/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.1599 - p_acc: 0.5248 - val_loss: 1.2365 - val_p_acc: 0.4776\n",
      "Epoch 414/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1874 - p_acc: 0.5096 - val_loss: 1.2362 - val_p_acc: 0.4599\n",
      "Epoch 415/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1650 - p_acc: 0.4936 - val_loss: 1.2355 - val_p_acc: 0.4599\n",
      "Epoch 416/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1039 - p_acc: 0.5304 - val_loss: 1.2355 - val_p_acc: 0.4599\n",
      "Epoch 417/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0973 - p_acc: 0.5689 - val_loss: 1.2345 - val_p_acc: 0.4776\n",
      "Epoch 418/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1283 - p_acc: 0.4816 - val_loss: 1.2349 - val_p_acc: 0.4599\n",
      "Epoch 419/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1205 - p_acc: 0.4679 - val_loss: 1.2347 - val_p_acc: 0.4247\n",
      "Epoch 420/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1762 - p_acc: 0.5288 - val_loss: 1.2352 - val_p_acc: 0.4423\n",
      "Epoch 421/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1058 - p_acc: 0.5601 - val_loss: 1.2359 - val_p_acc: 0.4423\n",
      "Epoch 422/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1289 - p_acc: 0.4992 - val_loss: 1.2363 - val_p_acc: 0.4776\n",
      "Epoch 423/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0920 - p_acc: 0.5946 - val_loss: 1.2361 - val_p_acc: 0.4776\n",
      "Epoch 424/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0998 - p_acc: 0.5409 - val_loss: 1.2368 - val_p_acc: 0.4776\n",
      "Epoch 425/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0971 - p_acc: 0.5721 - val_loss: 1.2383 - val_p_acc: 0.4952\n",
      "Epoch 426/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1176 - p_acc: 0.5409 - val_loss: 1.2385 - val_p_acc: 0.4599\n",
      "Epoch 427/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1914 - p_acc: 0.4800 - val_loss: 1.2401 - val_p_acc: 0.4776\n",
      "Epoch 428/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1769 - p_acc: 0.5096 - val_loss: 1.2392 - val_p_acc: 0.4071\n",
      "Epoch 429/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1157 - p_acc: 0.4383 - val_loss: 1.2391 - val_p_acc: 0.4776\n",
      "Epoch 430/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1001 - p_acc: 0.5529 - val_loss: 1.2389 - val_p_acc: 0.4776\n",
      "Epoch 431/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1427 - p_acc: 0.5200 - val_loss: 1.2385 - val_p_acc: 0.4776\n",
      "Epoch 432/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0918 - p_acc: 0.5144 - val_loss: 1.2367 - val_p_acc: 0.4599\n",
      "Epoch 433/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1196 - p_acc: 0.4864 - val_loss: 1.2375 - val_p_acc: 0.4423\n",
      "Epoch 434/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1814 - p_acc: 0.5200 - val_loss: 1.2381 - val_p_acc: 0.4776\n",
      "Epoch 435/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1379 - p_acc: 0.4920 - val_loss: 1.2371 - val_p_acc: 0.4776\n",
      "Epoch 436/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1194 - p_acc: 0.5497 - val_loss: 1.2370 - val_p_acc: 0.4423\n",
      "Epoch 437/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.1260 - p_acc: 0.4816 - val_loss: 1.2368 - val_p_acc: 0.5128\n",
      "Epoch 438/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1458 - p_acc: 0.5337 - val_loss: 1.2363 - val_p_acc: 0.4071\n",
      "Epoch 439/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1001 - p_acc: 0.5497 - val_loss: 1.2361 - val_p_acc: 0.4776\n",
      "Epoch 440/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1290 - p_acc: 0.4696 - val_loss: 1.2368 - val_p_acc: 0.4599\n",
      "Epoch 441/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0757 - p_acc: 0.6138 - val_loss: 1.2378 - val_p_acc: 0.4599\n",
      "Epoch 442/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1346 - p_acc: 0.5809 - val_loss: 1.2389 - val_p_acc: 0.4776\n",
      "Epoch 443/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0844 - p_acc: 0.5112 - val_loss: 1.2382 - val_p_acc: 0.4599\n",
      "Epoch 444/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1350 - p_acc: 0.5481 - val_loss: 1.2385 - val_p_acc: 0.4776\n",
      "Epoch 445/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.1315 - p_acc: 0.5705 - val_loss: 1.2382 - val_p_acc: 0.4247\n",
      "Epoch 446/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1625 - p_acc: 0.5024 - val_loss: 1.2372 - val_p_acc: 0.4599\n",
      "Epoch 447/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1265 - p_acc: 0.4383 - val_loss: 1.2376 - val_p_acc: 0.4599\n",
      "Epoch 448/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0633 - p_acc: 0.5232 - val_loss: 1.2366 - val_p_acc: 0.4247\n",
      "Epoch 449/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0900 - p_acc: 0.5200 - val_loss: 1.2371 - val_p_acc: 0.4423\n",
      "Epoch 450/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0633 - p_acc: 0.6194 - val_loss: 1.2359 - val_p_acc: 0.4776\n",
      "Epoch 451/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1582 - p_acc: 0.5112 - val_loss: 1.2352 - val_p_acc: 0.4247\n",
      "Epoch 452/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1602 - p_acc: 0.4503 - val_loss: 1.2355 - val_p_acc: 0.4423\n",
      "Epoch 453/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1390 - p_acc: 0.5689 - val_loss: 1.2352 - val_p_acc: 0.4423\n",
      "Epoch 454/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1829 - p_acc: 0.4888 - val_loss: 1.2350 - val_p_acc: 0.5128\n",
      "Epoch 455/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1331 - p_acc: 0.5513 - val_loss: 1.2355 - val_p_acc: 0.4952\n",
      "Epoch 456/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0752 - p_acc: 0.5272 - val_loss: 1.2369 - val_p_acc: 0.4423\n",
      "Epoch 457/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0864 - p_acc: 0.5377 - val_loss: 1.2371 - val_p_acc: 0.4776\n",
      "Epoch 458/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1071 - p_acc: 0.4760 - val_loss: 1.2376 - val_p_acc: 0.4776\n",
      "Epoch 459/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.1975 - p_acc: 0.4503 - val_loss: 1.2374 - val_p_acc: 0.4776\n",
      "Epoch 460/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0863 - p_acc: 0.4575 - val_loss: 1.2367 - val_p_acc: 0.4247\n",
      "Epoch 461/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1415 - p_acc: 0.5513 - val_loss: 1.2367 - val_p_acc: 0.4776\n",
      "Epoch 462/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0617 - p_acc: 0.6106 - val_loss: 1.2352 - val_p_acc: 0.4776\n",
      "Epoch 463/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1049 - p_acc: 0.5024 - val_loss: 1.2338 - val_p_acc: 0.4776\n",
      "Epoch 464/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1625 - p_acc: 0.5481 - val_loss: 1.2338 - val_p_acc: 0.4952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0609 - p_acc: 0.6194 - val_loss: 1.2338 - val_p_acc: 0.4423\n",
      "Epoch 466/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.0869 - p_acc: 0.5777 - val_loss: 1.2332 - val_p_acc: 0.4776\n",
      "Epoch 467/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1525 - p_acc: 0.5256 - val_loss: 1.2331 - val_p_acc: 0.4071\n",
      "Epoch 468/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1429 - p_acc: 0.4591 - val_loss: 1.2328 - val_p_acc: 0.4423\n",
      "Epoch 469/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0882 - p_acc: 0.6106 - val_loss: 1.2335 - val_p_acc: 0.4599\n",
      "Epoch 470/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1071 - p_acc: 0.6018 - val_loss: 1.2343 - val_p_acc: 0.4247\n",
      "Epoch 471/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1359 - p_acc: 0.5096 - val_loss: 1.2344 - val_p_acc: 0.4599\n",
      "Epoch 472/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1113 - p_acc: 0.6002 - val_loss: 1.2347 - val_p_acc: 0.4776\n",
      "Epoch 473/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1093 - p_acc: 0.5481 - val_loss: 1.2347 - val_p_acc: 0.4952\n",
      "Epoch 474/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0675 - p_acc: 0.5809 - val_loss: 1.2338 - val_p_acc: 0.4599\n",
      "Epoch 475/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0817 - p_acc: 0.5112 - val_loss: 1.2345 - val_p_acc: 0.5304\n",
      "Epoch 476/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.0631 - p_acc: 0.5112 - val_loss: 1.2360 - val_p_acc: 0.5128\n",
      "Epoch 477/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1227 - p_acc: 0.5529 - val_loss: 1.2358 - val_p_acc: 0.4776\n",
      "Epoch 478/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1210 - p_acc: 0.6210 - val_loss: 1.2360 - val_p_acc: 0.4952\n",
      "Epoch 479/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1197 - p_acc: 0.5216 - val_loss: 1.2352 - val_p_acc: 0.4599\n",
      "Epoch 480/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0873 - p_acc: 0.4623 - val_loss: 1.2349 - val_p_acc: 0.4599\n",
      "Epoch 481/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1145 - p_acc: 0.5321 - val_loss: 1.2327 - val_p_acc: 0.5128\n",
      "Epoch 482/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1050 - p_acc: 0.5377 - val_loss: 1.2317 - val_p_acc: 0.4423\n",
      "Epoch 483/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0766 - p_acc: 0.5497 - val_loss: 1.2308 - val_p_acc: 0.4599\n",
      "Epoch 484/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1133 - p_acc: 0.5200 - val_loss: 1.2316 - val_p_acc: 0.4423\n",
      "Epoch 485/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0964 - p_acc: 0.6226 - val_loss: 1.2316 - val_p_acc: 0.4952\n",
      "Epoch 486/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0971 - p_acc: 0.5793 - val_loss: 1.2303 - val_p_acc: 0.4776\n",
      "Epoch 487/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1329 - p_acc: 0.5929 - val_loss: 1.2304 - val_p_acc: 0.4423\n",
      "Epoch 488/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1291 - p_acc: 0.4728 - val_loss: 1.2302 - val_p_acc: 0.4423\n",
      "Epoch 489/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0679 - p_acc: 0.5585 - val_loss: 1.2298 - val_p_acc: 0.4599\n",
      "Epoch 490/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1037 - p_acc: 0.5040 - val_loss: 1.2289 - val_p_acc: 0.4599\n",
      "Epoch 491/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0677 - p_acc: 0.6627 - val_loss: 1.2283 - val_p_acc: 0.4599\n",
      "Epoch 492/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.0336 - p_acc: 0.6314 - val_loss: 1.2281 - val_p_acc: 0.4423\n",
      "Epoch 493/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0909 - p_acc: 0.4992 - val_loss: 1.2278 - val_p_acc: 0.4423\n",
      "Epoch 494/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1203 - p_acc: 0.4832 - val_loss: 1.2266 - val_p_acc: 0.4599\n",
      "Epoch 495/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1653 - p_acc: 0.4503 - val_loss: 1.2271 - val_p_acc: 0.4599\n",
      "Epoch 496/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0736 - p_acc: 0.4816 - val_loss: 1.2256 - val_p_acc: 0.4423\n",
      "Epoch 497/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0951 - p_acc: 0.5216 - val_loss: 1.2255 - val_p_acc: 0.5128\n",
      "Epoch 498/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1962 - p_acc: 0.5272 - val_loss: 1.2249 - val_p_acc: 0.4776\n",
      "Epoch 499/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0636 - p_acc: 0.4936 - val_loss: 1.2246 - val_p_acc: 0.4423\n",
      "Epoch 500/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0508 - p_acc: 0.5232 - val_loss: 1.2244 - val_p_acc: 0.4247\n",
      "Epoch 501/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0549 - p_acc: 0.5913 - val_loss: 1.2233 - val_p_acc: 0.5128\n",
      "Epoch 502/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1071 - p_acc: 0.5200 - val_loss: 1.2229 - val_p_acc: 0.4776\n",
      "Epoch 503/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0739 - p_acc: 0.5721 - val_loss: 1.2237 - val_p_acc: 0.4599\n",
      "Epoch 504/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0678 - p_acc: 0.6611 - val_loss: 1.2236 - val_p_acc: 0.4776\n",
      "Epoch 505/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1384 - p_acc: 0.4503 - val_loss: 1.2231 - val_p_acc: 0.5128\n",
      "Epoch 506/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1056 - p_acc: 0.5465 - val_loss: 1.2218 - val_p_acc: 0.4599\n",
      "Epoch 507/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1129 - p_acc: 0.5216 - val_loss: 1.2207 - val_p_acc: 0.4952\n",
      "Epoch 508/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0823 - p_acc: 0.5513 - val_loss: 1.2197 - val_p_acc: 0.4423\n",
      "Epoch 509/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1056 - p_acc: 0.5184 - val_loss: 1.2193 - val_p_acc: 0.4247\n",
      "Epoch 510/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0761 - p_acc: 0.6210 - val_loss: 1.2191 - val_p_acc: 0.4776\n",
      "Epoch 511/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1094 - p_acc: 0.5601 - val_loss: 1.2183 - val_p_acc: 0.4599\n",
      "Epoch 512/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.0785 - p_acc: 0.5337 - val_loss: 1.2177 - val_p_acc: 0.4071\n",
      "Epoch 513/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1295 - p_acc: 0.4752 - val_loss: 1.2172 - val_p_acc: 0.3894\n",
      "Epoch 514/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1298 - p_acc: 0.5216 - val_loss: 1.2176 - val_p_acc: 0.4776\n",
      "Epoch 515/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0727 - p_acc: 0.5096 - val_loss: 1.2175 - val_p_acc: 0.4952\n",
      "Epoch 516/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1105 - p_acc: 0.5617 - val_loss: 1.2181 - val_p_acc: 0.4599\n",
      "Epoch 517/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1423 - p_acc: 0.5184 - val_loss: 1.2196 - val_p_acc: 0.4952\n",
      "Epoch 518/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0379 - p_acc: 0.5617 - val_loss: 1.2192 - val_p_acc: 0.4599\n",
      "Epoch 519/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0823 - p_acc: 0.4992 - val_loss: 1.2192 - val_p_acc: 0.4599\n",
      "Epoch 520/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0734 - p_acc: 0.5649 - val_loss: 1.2212 - val_p_acc: 0.4599\n",
      "Epoch 521/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1298 - p_acc: 0.5633 - val_loss: 1.2215 - val_p_acc: 0.4599\n",
      "Epoch 522/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0635 - p_acc: 0.5144 - val_loss: 1.2214 - val_p_acc: 0.4599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 523/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0946 - p_acc: 0.5897 - val_loss: 1.2223 - val_p_acc: 0.4776\n",
      "Epoch 524/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1309 - p_acc: 0.4936 - val_loss: 1.2224 - val_p_acc: 0.4952\n",
      "Epoch 525/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1213 - p_acc: 0.5096 - val_loss: 1.2214 - val_p_acc: 0.4599\n",
      "Epoch 526/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1184 - p_acc: 0.5393 - val_loss: 1.2205 - val_p_acc: 0.5128\n",
      "Epoch 527/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0429 - p_acc: 0.6474 - val_loss: 1.2206 - val_p_acc: 0.4599\n",
      "Epoch 528/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.1600 - p_acc: 0.5200 - val_loss: 1.2191 - val_p_acc: 0.4599\n",
      "Epoch 529/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.0461 - p_acc: 0.6434 - val_loss: 1.2200 - val_p_acc: 0.4599\n",
      "Epoch 530/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0393 - p_acc: 0.6122 - val_loss: 1.2195 - val_p_acc: 0.4599\n",
      "Epoch 531/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.0810 - p_acc: 0.5064 - val_loss: 1.2186 - val_p_acc: 0.4599\n",
      "Epoch 532/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1230 - p_acc: 0.4800 - val_loss: 1.2179 - val_p_acc: 0.4423\n",
      "Epoch 533/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0710 - p_acc: 0.4832 - val_loss: 1.2178 - val_p_acc: 0.4952\n",
      "Epoch 534/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0665 - p_acc: 0.5184 - val_loss: 1.2180 - val_p_acc: 0.4423\n",
      "Epoch 535/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1047 - p_acc: 0.5721 - val_loss: 1.2177 - val_p_acc: 0.4776\n",
      "Epoch 536/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1258 - p_acc: 0.5513 - val_loss: 1.2187 - val_p_acc: 0.4599\n",
      "Epoch 537/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0985 - p_acc: 0.5617 - val_loss: 1.2200 - val_p_acc: 0.4599\n",
      "Epoch 538/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0668 - p_acc: 0.5096 - val_loss: 1.2201 - val_p_acc: 0.4247\n",
      "Epoch 539/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1050 - p_acc: 0.5897 - val_loss: 1.2204 - val_p_acc: 0.4599\n",
      "Epoch 540/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0942 - p_acc: 0.5393 - val_loss: 1.2211 - val_p_acc: 0.4776\n",
      "Epoch 541/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0524 - p_acc: 0.6090 - val_loss: 1.2202 - val_p_acc: 0.4071\n",
      "Epoch 542/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0759 - p_acc: 0.6002 - val_loss: 1.2194 - val_p_acc: 0.4952\n",
      "Epoch 543/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0898 - p_acc: 0.4503 - val_loss: 1.2188 - val_p_acc: 0.4247\n",
      "Epoch 544/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.1240 - p_acc: 0.5040 - val_loss: 1.2189 - val_p_acc: 0.4776\n",
      "Epoch 545/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1016 - p_acc: 0.5545 - val_loss: 1.2190 - val_p_acc: 0.3894\n",
      "Epoch 546/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 1.0920 - p_acc: 0.5288 - val_loss: 1.2179 - val_p_acc: 0.4952\n",
      "Epoch 547/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.0938 - p_acc: 0.5321 - val_loss: 1.2190 - val_p_acc: 0.4423\n",
      "Epoch 548/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.1520 - p_acc: 0.4744 - val_loss: 1.2203 - val_p_acc: 0.4808\n",
      "Epoch 549/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1204 - p_acc: 0.5024 - val_loss: 1.2204 - val_p_acc: 0.4455\n",
      "Epoch 550/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1173 - p_acc: 0.5481 - val_loss: 1.2197 - val_p_acc: 0.4631\n",
      "Epoch 551/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.1470 - p_acc: 0.4327 - val_loss: 1.2201 - val_p_acc: 0.4984\n",
      "Epoch 552/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0592 - p_acc: 0.5793 - val_loss: 1.2197 - val_p_acc: 0.4247\n",
      "Epoch 553/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.0518 - p_acc: 0.6314 - val_loss: 1.2183 - val_p_acc: 0.4423\n",
      "Epoch 554/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1277 - p_acc: 0.5304 - val_loss: 1.2179 - val_p_acc: 0.4952\n",
      "Epoch 555/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1641 - p_acc: 0.4744 - val_loss: 1.2169 - val_p_acc: 0.4423\n",
      "Epoch 556/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0830 - p_acc: 0.4888 - val_loss: 1.2151 - val_p_acc: 0.4423\n",
      "Epoch 557/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0538 - p_acc: 0.5008 - val_loss: 1.2156 - val_p_acc: 0.4776\n",
      "Epoch 558/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1358 - p_acc: 0.5200 - val_loss: 1.2150 - val_p_acc: 0.4599\n",
      "Epoch 559/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0431 - p_acc: 0.5617 - val_loss: 1.2148 - val_p_acc: 0.4247\n",
      "Epoch 560/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0449 - p_acc: 0.6402 - val_loss: 1.2145 - val_p_acc: 0.4776\n",
      "Epoch 561/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1138 - p_acc: 0.5216 - val_loss: 1.2144 - val_p_acc: 0.4423\n",
      "Epoch 562/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.1375 - p_acc: 0.6018 - val_loss: 1.2135 - val_p_acc: 0.4599\n",
      "Epoch 563/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1267 - p_acc: 0.4992 - val_loss: 1.2134 - val_p_acc: 0.4247\n",
      "Epoch 564/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1150 - p_acc: 0.6122 - val_loss: 1.2138 - val_p_acc: 0.4599\n",
      "Epoch 565/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.1641 - p_acc: 0.5184 - val_loss: 1.2129 - val_p_acc: 0.4599\n",
      "Epoch 566/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0906 - p_acc: 0.5529 - val_loss: 1.2132 - val_p_acc: 0.4952\n",
      "Epoch 567/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.1025 - p_acc: 0.4888 - val_loss: 1.2124 - val_p_acc: 0.4952\n",
      "Epoch 568/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0703 - p_acc: 0.5321 - val_loss: 1.2119 - val_p_acc: 0.4247\n",
      "Epoch 569/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1279 - p_acc: 0.5008 - val_loss: 1.2103 - val_p_acc: 0.4952\n",
      "Epoch 570/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0756 - p_acc: 0.5409 - val_loss: 1.2103 - val_p_acc: 0.4071\n",
      "Epoch 571/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.1202 - p_acc: 0.5232 - val_loss: 1.2100 - val_p_acc: 0.4423\n",
      "Epoch 572/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.1030 - p_acc: 0.4920 - val_loss: 1.2080 - val_p_acc: 0.4247\n",
      "Epoch 573/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.1497 - p_acc: 0.5689 - val_loss: 1.2086 - val_p_acc: 0.4247\n",
      "Epoch 574/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0700 - p_acc: 0.5112 - val_loss: 1.2089 - val_p_acc: 0.4423\n",
      "Epoch 575/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0093 - p_acc: 0.6210 - val_loss: 1.2088 - val_p_acc: 0.4952\n",
      "Epoch 576/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 1.0554 - p_acc: 0.5897 - val_loss: 1.2089 - val_p_acc: 0.4776\n",
      "Epoch 577/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.1027 - p_acc: 0.5080 - val_loss: 1.2083 - val_p_acc: 0.4071\n",
      "Epoch 578/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.1025 - p_acc: 0.5112 - val_loss: 1.2101 - val_p_acc: 0.4599\n",
      "Epoch 579/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.1532 - p_acc: 0.4920 - val_loss: 1.2107 - val_p_acc: 0.4952\n",
      "Epoch 580/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 1.0696 - p_acc: 0.6106 - val_loss: 1.2101 - val_p_acc: 0.4599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581/5000\n",
      "85/85 [==============================] - 0s 844us/sample - loss: 1.0770 - p_acc: 0.5633 - val_loss: 1.2097 - val_p_acc: 0.4776\n",
      "Epoch 582/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0851 - p_acc: 0.4904 - val_loss: 1.2104 - val_p_acc: 0.4247\n",
      "Epoch 583/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0479 - p_acc: 0.6538 - val_loss: 1.2098 - val_p_acc: 0.4599\n",
      "Epoch 584/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 1.0559 - p_acc: 0.5809 - val_loss: 1.2103 - val_p_acc: 0.4247\n",
      "Epoch 585/5000\n",
      "85/85 [==============================] - 0s 844us/sample - loss: 1.0339 - p_acc: 0.6018 - val_loss: 1.2112 - val_p_acc: 0.4247\n",
      "Epoch 586/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0656 - p_acc: 0.5825 - val_loss: 1.2096 - val_p_acc: 0.4776\n",
      "Epoch 587/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.1454 - p_acc: 0.5096 - val_loss: 1.2077 - val_p_acc: 0.4599\n",
      "Epoch 588/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0104 - p_acc: 0.6138 - val_loss: 1.2060 - val_p_acc: 0.4599\n",
      "Epoch 589/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.1075 - p_acc: 0.5897 - val_loss: 1.2062 - val_p_acc: 0.4952\n",
      "Epoch 590/5000\n",
      "85/85 [==============================] - 0s 856us/sample - loss: 1.1202 - p_acc: 0.5721 - val_loss: 1.2052 - val_p_acc: 0.4599\n",
      "Epoch 591/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 1.1620 - p_acc: 0.4800 - val_loss: 1.2061 - val_p_acc: 0.4776\n",
      "Epoch 592/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.1116 - p_acc: 0.4712 - val_loss: 1.2071 - val_p_acc: 0.4631\n",
      "Epoch 593/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 1.1183 - p_acc: 0.5200 - val_loss: 1.2073 - val_p_acc: 0.4599\n",
      "Epoch 594/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0538 - p_acc: 0.5441 - val_loss: 1.2070 - val_p_acc: 0.5337\n",
      "Epoch 595/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.0921 - p_acc: 0.5529 - val_loss: 1.2068 - val_p_acc: 0.4984\n",
      "Epoch 596/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0652 - p_acc: 0.5497 - val_loss: 1.2060 - val_p_acc: 0.4808\n",
      "Epoch 597/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0478 - p_acc: 0.5601 - val_loss: 1.2068 - val_p_acc: 0.4631\n",
      "Epoch 598/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.0542 - p_acc: 0.5705 - val_loss: 1.2058 - val_p_acc: 0.5160\n",
      "Epoch 599/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 1.0461 - p_acc: 0.6002 - val_loss: 1.2059 - val_p_acc: 0.4279\n",
      "Epoch 600/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 1.1215 - p_acc: 0.6106 - val_loss: 1.2056 - val_p_acc: 0.4984\n",
      "Epoch 601/5000\n",
      "85/85 [==============================] - 0s 869us/sample - loss: 1.0614 - p_acc: 0.5601 - val_loss: 1.2051 - val_p_acc: 0.4808\n",
      "Epoch 602/5000\n",
      "85/85 [==============================] - 0s 869us/sample - loss: 1.0817 - p_acc: 0.5809 - val_loss: 1.2039 - val_p_acc: 0.4984\n",
      "Epoch 603/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0757 - p_acc: 0.5425 - val_loss: 1.2050 - val_p_acc: 0.4984\n",
      "Epoch 604/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 1.0935 - p_acc: 0.4904 - val_loss: 1.2054 - val_p_acc: 0.4984\n",
      "Epoch 605/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0566 - p_acc: 0.5825 - val_loss: 1.2053 - val_p_acc: 0.4984\n",
      "Epoch 606/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.0903 - p_acc: 0.5513 - val_loss: 1.2057 - val_p_acc: 0.4631\n",
      "Epoch 607/5000\n",
      "85/85 [==============================] - 0s 834us/sample - loss: 1.1434 - p_acc: 0.5497 - val_loss: 1.2044 - val_p_acc: 0.4455\n",
      "Epoch 608/5000\n",
      "85/85 [==============================] - 0s 869us/sample - loss: 1.0479 - p_acc: 0.6242 - val_loss: 1.2028 - val_p_acc: 0.4808\n",
      "Epoch 609/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0506 - p_acc: 0.5689 - val_loss: 1.2021 - val_p_acc: 0.4984\n",
      "Epoch 610/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0974 - p_acc: 0.5393 - val_loss: 1.2024 - val_p_acc: 0.4279\n",
      "Epoch 611/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.1162 - p_acc: 0.4904 - val_loss: 1.2020 - val_p_acc: 0.4984\n",
      "Epoch 612/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.1206 - p_acc: 0.4519 - val_loss: 1.2013 - val_p_acc: 0.4984\n",
      "Epoch 613/5000\n",
      "85/85 [==============================] - 0s 856us/sample - loss: 1.1660 - p_acc: 0.4311 - val_loss: 1.2015 - val_p_acc: 0.5337\n",
      "Epoch 614/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0787 - p_acc: 0.4904 - val_loss: 1.2007 - val_p_acc: 0.4984\n",
      "Epoch 615/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.1207 - p_acc: 0.5617 - val_loss: 1.2003 - val_p_acc: 0.4599\n",
      "Epoch 616/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.1112 - p_acc: 0.5304 - val_loss: 1.2003 - val_p_acc: 0.4247\n",
      "Epoch 617/5000\n",
      "85/85 [==============================] - 0s 844us/sample - loss: 1.0445 - p_acc: 0.6298 - val_loss: 1.2002 - val_p_acc: 0.4423\n",
      "Epoch 618/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 1.0147 - p_acc: 0.6178 - val_loss: 1.1988 - val_p_acc: 0.5160\n",
      "Epoch 619/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 1.0552 - p_acc: 0.5617 - val_loss: 1.1978 - val_p_acc: 0.4808\n",
      "Epoch 620/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 1.0634 - p_acc: 0.5705 - val_loss: 1.1978 - val_p_acc: 0.5128\n",
      "Epoch 621/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 1.0582 - p_acc: 0.5216 - val_loss: 1.1988 - val_p_acc: 0.4776\n",
      "Epoch 622/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 1.1254 - p_acc: 0.5545 - val_loss: 1.1995 - val_p_acc: 0.4984\n",
      "Epoch 623/5000\n",
      "85/85 [==============================] - 0s 848us/sample - loss: 1.0626 - p_acc: 0.5825 - val_loss: 1.1991 - val_p_acc: 0.4808\n",
      "Epoch 624/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.0648 - p_acc: 0.5809 - val_loss: 1.1994 - val_p_acc: 0.4631\n",
      "Epoch 625/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.1068 - p_acc: 0.4904 - val_loss: 1.1989 - val_p_acc: 0.4984\n",
      "Epoch 626/5000\n",
      "85/85 [==============================] - 0s 822us/sample - loss: 1.1034 - p_acc: 0.4800 - val_loss: 1.1980 - val_p_acc: 0.4631\n",
      "Epoch 627/5000\n",
      "85/85 [==============================] - 0s 856us/sample - loss: 1.0454 - p_acc: 0.5737 - val_loss: 1.1976 - val_p_acc: 0.4808\n",
      "Epoch 628/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 1.1145 - p_acc: 0.4503 - val_loss: 1.1967 - val_p_acc: 0.4984\n",
      "Epoch 629/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 1.0624 - p_acc: 0.5321 - val_loss: 1.1964 - val_p_acc: 0.4808\n",
      "Epoch 630/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.1006 - p_acc: 0.5569 - val_loss: 1.1955 - val_p_acc: 0.4808\n",
      "Epoch 631/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.1509 - p_acc: 0.4119 - val_loss: 1.1962 - val_p_acc: 0.4631\n",
      "Epoch 632/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0785 - p_acc: 0.5649 - val_loss: 1.1962 - val_p_acc: 0.4808\n",
      "Epoch 633/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0998 - p_acc: 0.5008 - val_loss: 1.1965 - val_p_acc: 0.4984\n",
      "Epoch 634/5000\n",
      "85/85 [==============================] - 0s 762us/sample - loss: 1.0783 - p_acc: 0.5809 - val_loss: 1.1965 - val_p_acc: 0.4808\n",
      "Epoch 635/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0898 - p_acc: 0.5321 - val_loss: 1.1960 - val_p_acc: 0.4808\n",
      "Epoch 636/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0766 - p_acc: 0.5585 - val_loss: 1.1947 - val_p_acc: 0.4808\n",
      "Epoch 637/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0854 - p_acc: 0.4607 - val_loss: 1.1939 - val_p_acc: 0.4631\n",
      "Epoch 638/5000\n",
      "85/85 [==============================] - 0s 732us/sample - loss: 1.0410 - p_acc: 0.4728 - val_loss: 1.1939 - val_p_acc: 0.4984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.0831 - p_acc: 0.5737 - val_loss: 1.1937 - val_p_acc: 0.4808\n",
      "Epoch 640/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 1.0763 - p_acc: 0.5601 - val_loss: 1.1929 - val_p_acc: 0.4631\n",
      "Epoch 641/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0847 - p_acc: 0.5497 - val_loss: 1.1922 - val_p_acc: 0.4631\n",
      "Epoch 642/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.0779 - p_acc: 0.5337 - val_loss: 1.1917 - val_p_acc: 0.4984\n",
      "Epoch 643/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.1067 - p_acc: 0.5449 - val_loss: 1.1918 - val_p_acc: 0.4808\n",
      "Epoch 644/5000\n",
      "85/85 [==============================] - 0s 869us/sample - loss: 0.9954 - p_acc: 0.5929 - val_loss: 1.1917 - val_p_acc: 0.4984\n",
      "Epoch 645/5000\n",
      "85/85 [==============================] - 0s 869us/sample - loss: 1.0624 - p_acc: 0.5393 - val_loss: 1.1905 - val_p_acc: 0.4808\n",
      "Epoch 646/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 1.1227 - p_acc: 0.5393 - val_loss: 1.1917 - val_p_acc: 0.5337\n",
      "Epoch 647/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.0555 - p_acc: 0.5216 - val_loss: 1.1915 - val_p_acc: 0.4808\n",
      "Epoch 648/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 1.1474 - p_acc: 0.4519 - val_loss: 1.1933 - val_p_acc: 0.5160\n",
      "Epoch 649/5000\n",
      "85/85 [==============================] - 0s 822us/sample - loss: 1.1220 - p_acc: 0.5825 - val_loss: 1.1937 - val_p_acc: 0.5160\n",
      "Epoch 650/5000\n",
      "85/85 [==============================] - 0s 834us/sample - loss: 1.0950 - p_acc: 0.6194 - val_loss: 1.1938 - val_p_acc: 0.4808\n",
      "Epoch 651/5000\n",
      "85/85 [==============================] - 0s 881us/sample - loss: 1.0195 - p_acc: 0.5321 - val_loss: 1.1946 - val_p_acc: 0.4984\n",
      "Epoch 652/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.1422 - p_acc: 0.5425 - val_loss: 1.1946 - val_p_acc: 0.4631\n",
      "Epoch 653/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.1098 - p_acc: 0.5929 - val_loss: 1.1942 - val_p_acc: 0.5160\n",
      "Epoch 654/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0672 - p_acc: 0.5689 - val_loss: 1.1939 - val_p_acc: 0.4808\n",
      "Epoch 655/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 1.0686 - p_acc: 0.5841 - val_loss: 1.1926 - val_p_acc: 0.5160\n",
      "Epoch 656/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 1.0842 - p_acc: 0.5617 - val_loss: 1.1922 - val_p_acc: 0.4423\n",
      "Epoch 657/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 1.0970 - p_acc: 0.5465 - val_loss: 1.1931 - val_p_acc: 0.4599\n",
      "Epoch 658/5000\n",
      "85/85 [==============================] - 0s 834us/sample - loss: 1.1020 - p_acc: 0.5529 - val_loss: 1.1924 - val_p_acc: 0.4808\n",
      "Epoch 659/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 1.0479 - p_acc: 0.5601 - val_loss: 1.1916 - val_p_acc: 0.4247\n",
      "Epoch 660/5000\n",
      "85/85 [==============================] - 0s 844us/sample - loss: 1.0913 - p_acc: 0.4639 - val_loss: 1.1915 - val_p_acc: 0.4599\n",
      "Epoch 661/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 1.0989 - p_acc: 0.5409 - val_loss: 1.1906 - val_p_acc: 0.4599\n",
      "Epoch 662/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0709 - p_acc: 0.5617 - val_loss: 1.1904 - val_p_acc: 0.4599\n",
      "Epoch 663/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0320 - p_acc: 0.5881 - val_loss: 1.1902 - val_p_acc: 0.4776\n",
      "Epoch 664/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.0524 - p_acc: 0.5481 - val_loss: 1.1900 - val_p_acc: 0.4776\n",
      "Epoch 665/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0958 - p_acc: 0.6034 - val_loss: 1.1887 - val_p_acc: 0.4071\n",
      "Epoch 666/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 1.0111 - p_acc: 0.5216 - val_loss: 1.1874 - val_p_acc: 0.4423\n",
      "Epoch 667/5000\n",
      "85/85 [==============================] - 0s 736us/sample - loss: 1.0616 - p_acc: 0.5705 - val_loss: 1.1869 - val_p_acc: 0.4071\n",
      "Epoch 668/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.1102 - p_acc: 0.5393 - val_loss: 1.1872 - val_p_acc: 0.4776\n",
      "Epoch 669/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0541 - p_acc: 0.4976 - val_loss: 1.1876 - val_p_acc: 0.4984\n",
      "Epoch 670/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 1.0074 - p_acc: 0.5913 - val_loss: 1.1864 - val_p_acc: 0.4808\n",
      "Epoch 671/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 1.0790 - p_acc: 0.5425 - val_loss: 1.1859 - val_p_acc: 0.5160\n",
      "Epoch 672/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 1.0346 - p_acc: 0.5881 - val_loss: 1.1855 - val_p_acc: 0.4808\n",
      "Epoch 673/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0770 - p_acc: 0.5024 - val_loss: 1.1856 - val_p_acc: 0.4631\n",
      "Epoch 674/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.1104 - p_acc: 0.6210 - val_loss: 1.1852 - val_p_acc: 0.4808\n",
      "Epoch 675/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.1069 - p_acc: 0.4904 - val_loss: 1.1865 - val_p_acc: 0.4808\n",
      "Epoch 676/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0638 - p_acc: 0.6018 - val_loss: 1.1865 - val_p_acc: 0.4279\n",
      "Epoch 677/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 1.0864 - p_acc: 0.5897 - val_loss: 1.1864 - val_p_acc: 0.4631\n",
      "Epoch 678/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0370 - p_acc: 0.5825 - val_loss: 1.1848 - val_p_acc: 0.4984\n",
      "Epoch 679/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0475 - p_acc: 0.5841 - val_loss: 1.1847 - val_p_acc: 0.4984\n",
      "Epoch 680/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.0676 - p_acc: 0.5545 - val_loss: 1.1837 - val_p_acc: 0.4455\n",
      "Epoch 681/5000\n",
      "85/85 [==============================] - 0s 797us/sample - loss: 1.0035 - p_acc: 0.5513 - val_loss: 1.1839 - val_p_acc: 0.4808\n",
      "Epoch 682/5000\n",
      "85/85 [==============================] - 0s 834us/sample - loss: 1.0304 - p_acc: 0.5633 - val_loss: 1.1834 - val_p_acc: 0.5160\n",
      "Epoch 683/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.1088 - p_acc: 0.5497 - val_loss: 1.1836 - val_p_acc: 0.4984\n",
      "Epoch 684/5000\n",
      "85/85 [==============================] - 0s 856us/sample - loss: 1.0928 - p_acc: 0.4904 - val_loss: 1.1837 - val_p_acc: 0.4808\n",
      "Epoch 685/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 1.0750 - p_acc: 0.5441 - val_loss: 1.1838 - val_p_acc: 0.4984\n",
      "Epoch 686/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0899 - p_acc: 0.5248 - val_loss: 1.1848 - val_p_acc: 0.4808\n",
      "Epoch 687/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0908 - p_acc: 0.5008 - val_loss: 1.1844 - val_p_acc: 0.5337\n",
      "Epoch 688/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 1.0542 - p_acc: 0.5096 - val_loss: 1.1841 - val_p_acc: 0.5337\n",
      "Epoch 689/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.0019 - p_acc: 0.5929 - val_loss: 1.1830 - val_p_acc: 0.4455\n",
      "Epoch 690/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 1.0040 - p_acc: 0.6242 - val_loss: 1.1829 - val_p_acc: 0.4455\n",
      "Epoch 691/5000\n",
      "85/85 [==============================] - 0s 844us/sample - loss: 1.0516 - p_acc: 0.5881 - val_loss: 1.1836 - val_p_acc: 0.4631\n",
      "Epoch 692/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0337 - p_acc: 0.5441 - val_loss: 1.1834 - val_p_acc: 0.4808\n",
      "Epoch 693/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.0492 - p_acc: 0.5705 - val_loss: 1.1831 - val_p_acc: 0.4984\n",
      "Epoch 694/5000\n",
      "85/85 [==============================] - 0s 834us/sample - loss: 1.0827 - p_acc: 0.5393 - val_loss: 1.1820 - val_p_acc: 0.4984\n",
      "Epoch 695/5000\n",
      "85/85 [==============================] - 0s 822us/sample - loss: 1.0640 - p_acc: 0.5825 - val_loss: 1.1829 - val_p_acc: 0.4808\n",
      "Epoch 696/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 1.0409 - p_acc: 0.5481 - val_loss: 1.1845 - val_p_acc: 0.4808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 697/5000\n",
      "85/85 [==============================] - 0s 785us/sample - loss: 1.0906 - p_acc: 0.5793 - val_loss: 1.1846 - val_p_acc: 0.5160\n",
      "Epoch 698/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 1.0291 - p_acc: 0.6018 - val_loss: 1.1851 - val_p_acc: 0.5337\n",
      "Epoch 699/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0628 - p_acc: 0.5321 - val_loss: 1.1831 - val_p_acc: 0.4808\n",
      "Epoch 700/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0803 - p_acc: 0.6002 - val_loss: 1.1838 - val_p_acc: 0.5337\n",
      "Epoch 701/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0341 - p_acc: 0.5737 - val_loss: 1.1831 - val_p_acc: 0.4808\n",
      "Epoch 702/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0511 - p_acc: 0.5617 - val_loss: 1.1823 - val_p_acc: 0.5160\n",
      "Epoch 703/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0344 - p_acc: 0.6450 - val_loss: 1.1832 - val_p_acc: 0.4808\n",
      "Epoch 704/5000\n",
      "85/85 [==============================] - 0s 738us/sample - loss: 1.1088 - p_acc: 0.5409 - val_loss: 1.1828 - val_p_acc: 0.5160\n",
      "Epoch 705/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0837 - p_acc: 0.4295 - val_loss: 1.1824 - val_p_acc: 0.4455\n",
      "Epoch 706/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0372 - p_acc: 0.5721 - val_loss: 1.1811 - val_p_acc: 0.4984\n",
      "Epoch 707/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.0251 - p_acc: 0.5288 - val_loss: 1.1824 - val_p_acc: 0.4808\n",
      "Epoch 708/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0499 - p_acc: 0.5705 - val_loss: 1.1817 - val_p_acc: 0.5160\n",
      "Epoch 709/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0351 - p_acc: 0.5409 - val_loss: 1.1822 - val_p_acc: 0.4455\n",
      "Epoch 710/5000\n",
      "85/85 [==============================] - 0s 809us/sample - loss: 1.0553 - p_acc: 0.5377 - val_loss: 1.1814 - val_p_acc: 0.4808\n",
      "Epoch 711/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 1.0587 - p_acc: 0.5393 - val_loss: 1.1822 - val_p_acc: 0.4984\n",
      "Epoch 712/5000\n",
      "85/85 [==============================] - 0s 722us/sample - loss: 1.0474 - p_acc: 0.6370 - val_loss: 1.1822 - val_p_acc: 0.4279\n",
      "Epoch 713/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0317 - p_acc: 0.4992 - val_loss: 1.1819 - val_p_acc: 0.4808\n",
      "Epoch 714/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0041 - p_acc: 0.6122 - val_loss: 1.1822 - val_p_acc: 0.4984\n",
      "Epoch 715/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 1.0665 - p_acc: 0.5040 - val_loss: 1.1812 - val_p_acc: 0.5160\n",
      "Epoch 716/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0212 - p_acc: 0.5633 - val_loss: 1.1792 - val_p_acc: 0.4808\n",
      "Epoch 717/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9976 - p_acc: 0.6106 - val_loss: 1.1797 - val_p_acc: 0.4808\n",
      "Epoch 718/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9824 - p_acc: 0.5705 - val_loss: 1.1782 - val_p_acc: 0.4279\n",
      "Epoch 719/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1120 - p_acc: 0.5321 - val_loss: 1.1775 - val_p_acc: 0.4455\n",
      "Epoch 720/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 1.0080 - p_acc: 0.5321 - val_loss: 1.1759 - val_p_acc: 0.4984\n",
      "Epoch 721/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0484 - p_acc: 0.5160 - val_loss: 1.1759 - val_p_acc: 0.4631\n",
      "Epoch 722/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0637 - p_acc: 0.5705 - val_loss: 1.1749 - val_p_acc: 0.4808\n",
      "Epoch 723/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.0481 - p_acc: 0.5272 - val_loss: 1.1749 - val_p_acc: 0.4808\n",
      "Epoch 724/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.1671 - p_acc: 0.4800 - val_loss: 1.1756 - val_p_acc: 0.4631\n",
      "Epoch 725/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0929 - p_acc: 0.5232 - val_loss: 1.1749 - val_p_acc: 0.4279\n",
      "Epoch 726/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0446 - p_acc: 0.6138 - val_loss: 1.1731 - val_p_acc: 0.4984\n",
      "Epoch 727/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0067 - p_acc: 0.5617 - val_loss: 1.1738 - val_p_acc: 0.4808\n",
      "Epoch 728/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0617 - p_acc: 0.5304 - val_loss: 1.1733 - val_p_acc: 0.4279\n",
      "Epoch 729/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.1191 - p_acc: 0.5304 - val_loss: 1.1722 - val_p_acc: 0.4808\n",
      "Epoch 730/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0201 - p_acc: 0.6034 - val_loss: 1.1720 - val_p_acc: 0.4984\n",
      "Epoch 731/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 1.0186 - p_acc: 0.6370 - val_loss: 1.1718 - val_p_acc: 0.4984\n",
      "Epoch 732/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 1.0813 - p_acc: 0.5008 - val_loss: 1.1714 - val_p_acc: 0.4984\n",
      "Epoch 733/5000\n",
      "85/85 [==============================] - 0s 742us/sample - loss: 1.0663 - p_acc: 0.5841 - val_loss: 1.1716 - val_p_acc: 0.4984\n",
      "Epoch 734/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0791 - p_acc: 0.5633 - val_loss: 1.1719 - val_p_acc: 0.5160\n",
      "Epoch 735/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.1041 - p_acc: 0.5184 - val_loss: 1.1708 - val_p_acc: 0.4631\n",
      "Epoch 736/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.1049 - p_acc: 0.5112 - val_loss: 1.1708 - val_p_acc: 0.4631\n",
      "Epoch 737/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.1118 - p_acc: 0.5633 - val_loss: 1.1719 - val_p_acc: 0.4808\n",
      "Epoch 738/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0245 - p_acc: 0.5913 - val_loss: 1.1728 - val_p_acc: 0.4631\n",
      "Epoch 739/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0685 - p_acc: 0.5793 - val_loss: 1.1730 - val_p_acc: 0.4631\n",
      "Epoch 740/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0974 - p_acc: 0.5248 - val_loss: 1.1729 - val_p_acc: 0.5160\n",
      "Epoch 741/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0373 - p_acc: 0.5128 - val_loss: 1.1733 - val_p_acc: 0.5160\n",
      "Epoch 742/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 1.0278 - p_acc: 0.6106 - val_loss: 1.1735 - val_p_acc: 0.4808\n",
      "Epoch 743/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.1485 - p_acc: 0.4367 - val_loss: 1.1734 - val_p_acc: 0.4808\n",
      "Epoch 744/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0872 - p_acc: 0.5705 - val_loss: 1.1732 - val_p_acc: 0.4984\n",
      "Epoch 745/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0171 - p_acc: 0.5897 - val_loss: 1.1727 - val_p_acc: 0.4984\n",
      "Epoch 746/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0792 - p_acc: 0.5096 - val_loss: 1.1733 - val_p_acc: 0.4279\n",
      "Epoch 747/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0741 - p_acc: 0.4607 - val_loss: 1.1730 - val_p_acc: 0.4808\n",
      "Epoch 748/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 1.0631 - p_acc: 0.6018 - val_loss: 1.1733 - val_p_acc: 0.4631\n",
      "Epoch 749/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0220 - p_acc: 0.5897 - val_loss: 1.1732 - val_p_acc: 0.4631\n",
      "Epoch 750/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 1.0700 - p_acc: 0.5024 - val_loss: 1.1730 - val_p_acc: 0.4984\n",
      "Epoch 751/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 1.0585 - p_acc: 0.5633 - val_loss: 1.1734 - val_p_acc: 0.4984\n",
      "Epoch 752/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 1.0735 - p_acc: 0.5465 - val_loss: 1.1733 - val_p_acc: 0.4808\n",
      "Epoch 753/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 1.0374 - p_acc: 0.6402 - val_loss: 1.1733 - val_p_acc: 0.5160\n",
      "Epoch 754/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0136 - p_acc: 0.6386 - val_loss: 1.1733 - val_p_acc: 0.5337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 755/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0782 - p_acc: 0.5425 - val_loss: 1.1723 - val_p_acc: 0.4279\n",
      "Epoch 756/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0756 - p_acc: 0.4904 - val_loss: 1.1714 - val_p_acc: 0.4808\n",
      "Epoch 757/5000\n",
      "85/85 [==============================] - 0s 738us/sample - loss: 1.0279 - p_acc: 0.5321 - val_loss: 1.1716 - val_p_acc: 0.4984\n",
      "Epoch 758/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0590 - p_acc: 0.5929 - val_loss: 1.1713 - val_p_acc: 0.5160\n",
      "Epoch 759/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0453 - p_acc: 0.5825 - val_loss: 1.1722 - val_p_acc: 0.4984\n",
      "Epoch 760/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0330 - p_acc: 0.5881 - val_loss: 1.1720 - val_p_acc: 0.4455\n",
      "Epoch 761/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.1047 - p_acc: 0.5617 - val_loss: 1.1712 - val_p_acc: 0.4808\n",
      "Epoch 762/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0358 - p_acc: 0.5497 - val_loss: 1.1720 - val_p_acc: 0.4984\n",
      "Epoch 763/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0626 - p_acc: 0.5601 - val_loss: 1.1722 - val_p_acc: 0.4455\n",
      "Epoch 764/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0722 - p_acc: 0.5809 - val_loss: 1.1730 - val_p_acc: 0.5337\n",
      "Epoch 765/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9703 - p_acc: 0.6298 - val_loss: 1.1741 - val_p_acc: 0.4631\n",
      "Epoch 766/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0944 - p_acc: 0.5216 - val_loss: 1.1735 - val_p_acc: 0.4984\n",
      "Epoch 767/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0905 - p_acc: 0.4920 - val_loss: 1.1726 - val_p_acc: 0.4808\n",
      "Epoch 768/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.1044 - p_acc: 0.5986 - val_loss: 1.1725 - val_p_acc: 0.5160\n",
      "Epoch 769/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0610 - p_acc: 0.5200 - val_loss: 1.1714 - val_p_acc: 0.4808\n",
      "Epoch 770/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0242 - p_acc: 0.5705 - val_loss: 1.1719 - val_p_acc: 0.5160\n",
      "Epoch 771/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0659 - p_acc: 0.5321 - val_loss: 1.1725 - val_p_acc: 0.4808\n",
      "Epoch 772/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9561 - p_acc: 0.6138 - val_loss: 1.1738 - val_p_acc: 0.4808\n",
      "Epoch 773/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0402 - p_acc: 0.5633 - val_loss: 1.1738 - val_p_acc: 0.4984\n",
      "Epoch 774/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0282 - p_acc: 0.6434 - val_loss: 1.1726 - val_p_acc: 0.4808\n",
      "Epoch 775/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0508 - p_acc: 0.5200 - val_loss: 1.1731 - val_p_acc: 0.4631\n",
      "Epoch 776/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0116 - p_acc: 0.5096 - val_loss: 1.1727 - val_p_acc: 0.5160\n",
      "Epoch 777/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0492 - p_acc: 0.4816 - val_loss: 1.1718 - val_p_acc: 0.4808\n",
      "Epoch 778/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0303 - p_acc: 0.5409 - val_loss: 1.1713 - val_p_acc: 0.4455\n",
      "Epoch 779/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 1.0885 - p_acc: 0.4679 - val_loss: 1.1709 - val_p_acc: 0.4984\n",
      "Epoch 780/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.9931 - p_acc: 0.6803 - val_loss: 1.1708 - val_p_acc: 0.5160\n",
      "Epoch 781/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.9929 - p_acc: 0.5633 - val_loss: 1.1707 - val_p_acc: 0.5160\n",
      "Epoch 782/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0073 - p_acc: 0.5441 - val_loss: 1.1708 - val_p_acc: 0.4984\n",
      "Epoch 783/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0992 - p_acc: 0.5056 - val_loss: 1.1710 - val_p_acc: 0.4455\n",
      "Epoch 784/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0999 - p_acc: 0.6034 - val_loss: 1.1715 - val_p_acc: 0.4631\n",
      "Epoch 785/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0687 - p_acc: 0.5497 - val_loss: 1.1705 - val_p_acc: 0.4631\n",
      "Epoch 786/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0675 - p_acc: 0.5216 - val_loss: 1.1701 - val_p_acc: 0.4631\n",
      "Epoch 787/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0417 - p_acc: 0.5689 - val_loss: 1.1693 - val_p_acc: 0.4455\n",
      "Epoch 788/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0072 - p_acc: 0.6522 - val_loss: 1.1680 - val_p_acc: 0.4631\n",
      "Epoch 789/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0234 - p_acc: 0.6090 - val_loss: 1.1680 - val_p_acc: 0.4808\n",
      "Epoch 790/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9900 - p_acc: 0.5561 - val_loss: 1.1673 - val_p_acc: 0.4808\n",
      "Epoch 791/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0097 - p_acc: 0.5216 - val_loss: 1.1668 - val_p_acc: 0.5160\n",
      "Epoch 792/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 1.0467 - p_acc: 0.5425 - val_loss: 1.1658 - val_p_acc: 0.4631\n",
      "Epoch 793/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0434 - p_acc: 0.6034 - val_loss: 1.1659 - val_p_acc: 0.4984\n",
      "Epoch 794/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0199 - p_acc: 0.5825 - val_loss: 1.1658 - val_p_acc: 0.5337\n",
      "Epoch 795/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0772 - p_acc: 0.4816 - val_loss: 1.1653 - val_p_acc: 0.4631\n",
      "Epoch 796/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.1108 - p_acc: 0.4383 - val_loss: 1.1652 - val_p_acc: 0.4808\n",
      "Epoch 797/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0654 - p_acc: 0.5617 - val_loss: 1.1647 - val_p_acc: 0.4455\n",
      "Epoch 798/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0368 - p_acc: 0.5393 - val_loss: 1.1645 - val_p_acc: 0.4808\n",
      "Epoch 799/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 1.0138 - p_acc: 0.6298 - val_loss: 1.1641 - val_p_acc: 0.4984\n",
      "Epoch 800/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0223 - p_acc: 0.5841 - val_loss: 1.1636 - val_p_acc: 0.5160\n",
      "Epoch 801/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.9841 - p_acc: 0.5897 - val_loss: 1.1641 - val_p_acc: 0.4984\n",
      "Epoch 802/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 1.0635 - p_acc: 0.5409 - val_loss: 1.1649 - val_p_acc: 0.4984\n",
      "Epoch 803/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0607 - p_acc: 0.5793 - val_loss: 1.1668 - val_p_acc: 0.4808\n",
      "Epoch 804/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.1017 - p_acc: 0.5441 - val_loss: 1.1663 - val_p_acc: 0.5160\n",
      "Epoch 805/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0274 - p_acc: 0.5321 - val_loss: 1.1656 - val_p_acc: 0.4808\n",
      "Epoch 806/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.1122 - p_acc: 0.5200 - val_loss: 1.1656 - val_p_acc: 0.4808\n",
      "Epoch 807/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.1073 - p_acc: 0.5425 - val_loss: 1.1658 - val_p_acc: 0.4808\n",
      "Epoch 808/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0348 - p_acc: 0.5200 - val_loss: 1.1648 - val_p_acc: 0.4631\n",
      "Epoch 809/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0450 - p_acc: 0.6122 - val_loss: 1.1644 - val_p_acc: 0.4808\n",
      "Epoch 810/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0351 - p_acc: 0.6106 - val_loss: 1.1654 - val_p_acc: 0.4631\n",
      "Epoch 811/5000\n",
      "85/85 [==============================] - 0s 822us/sample - loss: 1.0725 - p_acc: 0.4679 - val_loss: 1.1652 - val_p_acc: 0.4808\n",
      "Epoch 812/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.1219 - p_acc: 0.4519 - val_loss: 1.1656 - val_p_acc: 0.4984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 813/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0254 - p_acc: 0.5881 - val_loss: 1.1653 - val_p_acc: 0.4984\n",
      "Epoch 814/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0440 - p_acc: 0.6194 - val_loss: 1.1653 - val_p_acc: 0.4631\n",
      "Epoch 815/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0750 - p_acc: 0.5353 - val_loss: 1.1636 - val_p_acc: 0.4808\n",
      "Epoch 816/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0432 - p_acc: 0.5633 - val_loss: 1.1636 - val_p_acc: 0.4631\n",
      "Epoch 817/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0413 - p_acc: 0.5080 - val_loss: 1.1628 - val_p_acc: 0.5160\n",
      "Epoch 818/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 1.0949 - p_acc: 0.5425 - val_loss: 1.1619 - val_p_acc: 0.4631\n",
      "Epoch 819/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9696 - p_acc: 0.6522 - val_loss: 1.1623 - val_p_acc: 0.4631\n",
      "Epoch 820/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 1.0186 - p_acc: 0.5689 - val_loss: 1.1624 - val_p_acc: 0.4984\n",
      "Epoch 821/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9672 - p_acc: 0.5962 - val_loss: 1.1614 - val_p_acc: 0.4984\n",
      "Epoch 822/5000\n",
      "85/85 [==============================] - 0s 717us/sample - loss: 0.9805 - p_acc: 0.6050 - val_loss: 1.1615 - val_p_acc: 0.4984\n",
      "Epoch 823/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0335 - p_acc: 0.6034 - val_loss: 1.1621 - val_p_acc: 0.4808\n",
      "Epoch 824/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0864 - p_acc: 0.5825 - val_loss: 1.1600 - val_p_acc: 0.4631\n",
      "Epoch 825/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0982 - p_acc: 0.5881 - val_loss: 1.1614 - val_p_acc: 0.4984\n",
      "Epoch 826/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0223 - p_acc: 0.5409 - val_loss: 1.1623 - val_p_acc: 0.4808\n",
      "Epoch 827/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0128 - p_acc: 0.5825 - val_loss: 1.1627 - val_p_acc: 0.5337\n",
      "Epoch 828/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.1011 - p_acc: 0.4263 - val_loss: 1.1618 - val_p_acc: 0.4984\n",
      "Epoch 829/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0387 - p_acc: 0.5425 - val_loss: 1.1634 - val_p_acc: 0.4631\n",
      "Epoch 830/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.0135 - p_acc: 0.6194 - val_loss: 1.1629 - val_p_acc: 0.4984\n",
      "Epoch 831/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0350 - p_acc: 0.6226 - val_loss: 1.1631 - val_p_acc: 0.4984\n",
      "Epoch 832/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0767 - p_acc: 0.5361 - val_loss: 1.1632 - val_p_acc: 0.4631\n",
      "Epoch 833/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0756 - p_acc: 0.6002 - val_loss: 1.1625 - val_p_acc: 0.4984\n",
      "Epoch 834/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0388 - p_acc: 0.5809 - val_loss: 1.1624 - val_p_acc: 0.4455\n",
      "Epoch 835/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0924 - p_acc: 0.6538 - val_loss: 1.1627 - val_p_acc: 0.4984\n",
      "Epoch 836/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.1270 - p_acc: 0.4768 - val_loss: 1.1624 - val_p_acc: 0.4279\n",
      "Epoch 837/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0910 - p_acc: 0.4399 - val_loss: 1.1628 - val_p_acc: 0.5160\n",
      "Epoch 838/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0889 - p_acc: 0.5513 - val_loss: 1.1640 - val_p_acc: 0.5513\n",
      "Epoch 839/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0699 - p_acc: 0.5705 - val_loss: 1.1636 - val_p_acc: 0.4808\n",
      "Epoch 840/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0944 - p_acc: 0.4904 - val_loss: 1.1647 - val_p_acc: 0.5337\n",
      "Epoch 841/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0191 - p_acc: 0.5897 - val_loss: 1.1652 - val_p_acc: 0.4631\n",
      "Epoch 842/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0751 - p_acc: 0.5793 - val_loss: 1.1650 - val_p_acc: 0.5160\n",
      "Epoch 843/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0006 - p_acc: 0.6538 - val_loss: 1.1648 - val_p_acc: 0.4631\n",
      "Epoch 844/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.1087 - p_acc: 0.5393 - val_loss: 1.1646 - val_p_acc: 0.4808\n",
      "Epoch 845/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0463 - p_acc: 0.5913 - val_loss: 1.1644 - val_p_acc: 0.4808\n",
      "Epoch 846/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0056 - p_acc: 0.7252 - val_loss: 1.1645 - val_p_acc: 0.4984\n",
      "Epoch 847/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0414 - p_acc: 0.5929 - val_loss: 1.1632 - val_p_acc: 0.4984\n",
      "Epoch 848/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0706 - p_acc: 0.5825 - val_loss: 1.1631 - val_p_acc: 0.4808\n",
      "Epoch 849/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 1.0415 - p_acc: 0.6034 - val_loss: 1.1640 - val_p_acc: 0.4984\n",
      "Epoch 850/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0087 - p_acc: 0.4832 - val_loss: 1.1635 - val_p_acc: 0.4631\n",
      "Epoch 851/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9923 - p_acc: 0.6002 - val_loss: 1.1639 - val_p_acc: 0.4455\n",
      "Epoch 852/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9935 - p_acc: 0.6154 - val_loss: 1.1623 - val_p_acc: 0.4631\n",
      "Epoch 853/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 1.0632 - p_acc: 0.5425 - val_loss: 1.1612 - val_p_acc: 0.5160\n",
      "Epoch 854/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0152 - p_acc: 0.6242 - val_loss: 1.1596 - val_p_acc: 0.4631\n",
      "Epoch 855/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0193 - p_acc: 0.6226 - val_loss: 1.1596 - val_p_acc: 0.4808\n",
      "Epoch 856/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9968 - p_acc: 0.5793 - val_loss: 1.1601 - val_p_acc: 0.4808\n",
      "Epoch 857/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0654 - p_acc: 0.5337 - val_loss: 1.1610 - val_p_acc: 0.4455\n",
      "Epoch 858/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0912 - p_acc: 0.4728 - val_loss: 1.1616 - val_p_acc: 0.4808\n",
      "Epoch 859/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9468 - p_acc: 0.6314 - val_loss: 1.1610 - val_p_acc: 0.5160\n",
      "Epoch 860/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 1.0205 - p_acc: 0.4936 - val_loss: 1.1596 - val_p_acc: 0.4455\n",
      "Epoch 861/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 1.0325 - p_acc: 0.5497 - val_loss: 1.1602 - val_p_acc: 0.4455\n",
      "Epoch 862/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0283 - p_acc: 0.5529 - val_loss: 1.1608 - val_p_acc: 0.4984\n",
      "Epoch 863/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.9990 - p_acc: 0.6226 - val_loss: 1.1601 - val_p_acc: 0.5160\n",
      "Epoch 864/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0115 - p_acc: 0.5841 - val_loss: 1.1604 - val_p_acc: 0.4631\n",
      "Epoch 865/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0746 - p_acc: 0.5617 - val_loss: 1.1626 - val_p_acc: 0.4631\n",
      "Epoch 866/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0224 - p_acc: 0.5913 - val_loss: 1.1626 - val_p_acc: 0.4984\n",
      "Epoch 867/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0842 - p_acc: 0.5304 - val_loss: 1.1630 - val_p_acc: 0.4984\n",
      "Epoch 868/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9922 - p_acc: 0.6474 - val_loss: 1.1629 - val_p_acc: 0.4631\n",
      "Epoch 869/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0324 - p_acc: 0.5425 - val_loss: 1.1625 - val_p_acc: 0.4808\n",
      "Epoch 870/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 1.0501 - p_acc: 0.5409 - val_loss: 1.1633 - val_p_acc: 0.5337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 871/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.9824 - p_acc: 0.6018 - val_loss: 1.1632 - val_p_acc: 0.4455\n",
      "Epoch 872/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9865 - p_acc: 0.5929 - val_loss: 1.1625 - val_p_acc: 0.4631\n",
      "Epoch 873/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0407 - p_acc: 0.5304 - val_loss: 1.1623 - val_p_acc: 0.5160\n",
      "Epoch 874/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9935 - p_acc: 0.5841 - val_loss: 1.1624 - val_p_acc: 0.4631\n",
      "Epoch 875/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0051 - p_acc: 0.4696 - val_loss: 1.1624 - val_p_acc: 0.5160\n",
      "Epoch 876/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9874 - p_acc: 0.6659 - val_loss: 1.1614 - val_p_acc: 0.4631\n",
      "Epoch 877/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0722 - p_acc: 0.5272 - val_loss: 1.1614 - val_p_acc: 0.4984\n",
      "Epoch 878/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0320 - p_acc: 0.5809 - val_loss: 1.1618 - val_p_acc: 0.4631\n",
      "Epoch 879/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9836 - p_acc: 0.5321 - val_loss: 1.1609 - val_p_acc: 0.4808\n",
      "Epoch 880/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.9461 - p_acc: 0.6627 - val_loss: 1.1615 - val_p_acc: 0.4808\n",
      "Epoch 881/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0165 - p_acc: 0.5304 - val_loss: 1.1623 - val_p_acc: 0.4808\n",
      "Epoch 882/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0241 - p_acc: 0.5721 - val_loss: 1.1623 - val_p_acc: 0.4984\n",
      "Epoch 883/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.1212 - p_acc: 0.5881 - val_loss: 1.1627 - val_p_acc: 0.4808\n",
      "Epoch 884/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0058 - p_acc: 0.5721 - val_loss: 1.1631 - val_p_acc: 0.4984\n",
      "Epoch 885/5000\n",
      "85/85 [==============================] - 0s 762us/sample - loss: 1.0174 - p_acc: 0.5633 - val_loss: 1.1632 - val_p_acc: 0.4631\n",
      "Epoch 886/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9951 - p_acc: 0.5793 - val_loss: 1.1637 - val_p_acc: 0.5337\n",
      "Epoch 887/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0274 - p_acc: 0.5705 - val_loss: 1.1623 - val_p_acc: 0.4808\n",
      "Epoch 888/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0092 - p_acc: 0.5737 - val_loss: 1.1619 - val_p_acc: 0.4455\n",
      "Epoch 889/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0215 - p_acc: 0.5705 - val_loss: 1.1626 - val_p_acc: 0.4808\n",
      "Epoch 890/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 1.0233 - p_acc: 0.5393 - val_loss: 1.1622 - val_p_acc: 0.4808\n",
      "Epoch 891/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0182 - p_acc: 0.5321 - val_loss: 1.1629 - val_p_acc: 0.5513\n",
      "Epoch 892/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 1.0965 - p_acc: 0.4575 - val_loss: 1.1634 - val_p_acc: 0.4984\n",
      "Epoch 893/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0454 - p_acc: 0.5056 - val_loss: 1.1620 - val_p_acc: 0.4631\n",
      "Epoch 894/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9826 - p_acc: 0.6330 - val_loss: 1.1612 - val_p_acc: 0.4808\n",
      "Epoch 895/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9623 - p_acc: 0.5825 - val_loss: 1.1606 - val_p_acc: 0.4808\n",
      "Epoch 896/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9409 - p_acc: 0.6362 - val_loss: 1.1609 - val_p_acc: 0.4808\n",
      "Epoch 897/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.9617 - p_acc: 0.6434 - val_loss: 1.1606 - val_p_acc: 0.5160\n",
      "Epoch 898/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0155 - p_acc: 0.5689 - val_loss: 1.1603 - val_p_acc: 0.4279\n",
      "Epoch 899/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0963 - p_acc: 0.5513 - val_loss: 1.1598 - val_p_acc: 0.5160\n",
      "Epoch 900/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0025 - p_acc: 0.6090 - val_loss: 1.1602 - val_p_acc: 0.5160\n",
      "Epoch 901/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0410 - p_acc: 0.5569 - val_loss: 1.1585 - val_p_acc: 0.4808\n",
      "Epoch 902/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0991 - p_acc: 0.5569 - val_loss: 1.1585 - val_p_acc: 0.4808\n",
      "Epoch 903/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0412 - p_acc: 0.5793 - val_loss: 1.1580 - val_p_acc: 0.4808\n",
      "Epoch 904/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0014 - p_acc: 0.5393 - val_loss: 1.1580 - val_p_acc: 0.4984\n",
      "Epoch 905/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9619 - p_acc: 0.6402 - val_loss: 1.1584 - val_p_acc: 0.4808\n",
      "Epoch 906/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 1.0100 - p_acc: 0.5304 - val_loss: 1.1569 - val_p_acc: 0.4808\n",
      "Epoch 907/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.0344 - p_acc: 0.6715 - val_loss: 1.1566 - val_p_acc: 0.4808\n",
      "Epoch 908/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0329 - p_acc: 0.5809 - val_loss: 1.1562 - val_p_acc: 0.5160\n",
      "Epoch 909/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0593 - p_acc: 0.5545 - val_loss: 1.1547 - val_p_acc: 0.5160\n",
      "Epoch 910/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0148 - p_acc: 0.5409 - val_loss: 1.1540 - val_p_acc: 0.4984\n",
      "Epoch 911/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0077 - p_acc: 0.5970 - val_loss: 1.1546 - val_p_acc: 0.4631\n",
      "Epoch 912/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0891 - p_acc: 0.4575 - val_loss: 1.1538 - val_p_acc: 0.5160\n",
      "Epoch 913/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0687 - p_acc: 0.5617 - val_loss: 1.1541 - val_p_acc: 0.4984\n",
      "Epoch 914/5000\n",
      "85/85 [==============================] - 0s 738us/sample - loss: 1.0574 - p_acc: 0.5809 - val_loss: 1.1546 - val_p_acc: 0.4808\n",
      "Epoch 915/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9727 - p_acc: 0.6194 - val_loss: 1.1547 - val_p_acc: 0.5337\n",
      "Epoch 916/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.0456 - p_acc: 0.6122 - val_loss: 1.1561 - val_p_acc: 0.4455\n",
      "Epoch 917/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 1.0336 - p_acc: 0.5321 - val_loss: 1.1555 - val_p_acc: 0.4631\n",
      "Epoch 918/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 1.0624 - p_acc: 0.5561 - val_loss: 1.1554 - val_p_acc: 0.5337\n",
      "Epoch 919/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9856 - p_acc: 0.6210 - val_loss: 1.1569 - val_p_acc: 0.4808\n",
      "Epoch 920/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9491 - p_acc: 0.6170 - val_loss: 1.1573 - val_p_acc: 0.5160\n",
      "Epoch 921/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 1.0334 - p_acc: 0.6386 - val_loss: 1.1576 - val_p_acc: 0.5337\n",
      "Epoch 922/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9701 - p_acc: 0.5809 - val_loss: 1.1574 - val_p_acc: 0.4984\n",
      "Epoch 923/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9903 - p_acc: 0.6154 - val_loss: 1.1569 - val_p_acc: 0.4808\n",
      "Epoch 924/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0662 - p_acc: 0.5601 - val_loss: 1.1567 - val_p_acc: 0.5160\n",
      "Epoch 925/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9981 - p_acc: 0.5529 - val_loss: 1.1562 - val_p_acc: 0.4808\n",
      "Epoch 926/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0946 - p_acc: 0.5008 - val_loss: 1.1563 - val_p_acc: 0.4808\n",
      "Epoch 927/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0541 - p_acc: 0.5561 - val_loss: 1.1562 - val_p_acc: 0.4631\n",
      "Epoch 928/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9853 - p_acc: 0.6314 - val_loss: 1.1559 - val_p_acc: 0.4455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 929/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0498 - p_acc: 0.5913 - val_loss: 1.1556 - val_p_acc: 0.4631\n",
      "Epoch 930/5000\n",
      "85/85 [==============================] - 0s 762us/sample - loss: 1.0396 - p_acc: 0.5569 - val_loss: 1.1552 - val_p_acc: 0.4808\n",
      "Epoch 931/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.9746 - p_acc: 0.6274 - val_loss: 1.1546 - val_p_acc: 0.4631\n",
      "Epoch 932/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9993 - p_acc: 0.5529 - val_loss: 1.1531 - val_p_acc: 0.4808\n",
      "Epoch 933/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0403 - p_acc: 0.6002 - val_loss: 1.1527 - val_p_acc: 0.4984\n",
      "Epoch 934/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9787 - p_acc: 0.5753 - val_loss: 1.1527 - val_p_acc: 0.4631\n",
      "Epoch 935/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0014 - p_acc: 0.5649 - val_loss: 1.1520 - val_p_acc: 0.4984\n",
      "Epoch 936/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 1.0821 - p_acc: 0.5913 - val_loss: 1.1516 - val_p_acc: 0.4984\n",
      "Epoch 937/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 1.0258 - p_acc: 0.5809 - val_loss: 1.1514 - val_p_acc: 0.4808\n",
      "Epoch 938/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0093 - p_acc: 0.6090 - val_loss: 1.1519 - val_p_acc: 0.4455\n",
      "Epoch 939/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0184 - p_acc: 0.6018 - val_loss: 1.1510 - val_p_acc: 0.4455\n",
      "Epoch 940/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0242 - p_acc: 0.5825 - val_loss: 1.1503 - val_p_acc: 0.4808\n",
      "Epoch 941/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9563 - p_acc: 0.6522 - val_loss: 1.1514 - val_p_acc: 0.4631\n",
      "Epoch 942/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0322 - p_acc: 0.5465 - val_loss: 1.1517 - val_p_acc: 0.5337\n",
      "Epoch 943/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0524 - p_acc: 0.5321 - val_loss: 1.1523 - val_p_acc: 0.4631\n",
      "Epoch 944/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9892 - p_acc: 0.6226 - val_loss: 1.1518 - val_p_acc: 0.4808\n",
      "Epoch 945/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9944 - p_acc: 0.5946 - val_loss: 1.1516 - val_p_acc: 0.4631\n",
      "Epoch 946/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9827 - p_acc: 0.5929 - val_loss: 1.1516 - val_p_acc: 0.5160\n",
      "Epoch 947/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0266 - p_acc: 0.5721 - val_loss: 1.1509 - val_p_acc: 0.4808\n",
      "Epoch 948/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0397 - p_acc: 0.5008 - val_loss: 1.1506 - val_p_acc: 0.5160\n",
      "Epoch 949/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9557 - p_acc: 0.5825 - val_loss: 1.1503 - val_p_acc: 0.4808\n",
      "Epoch 950/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0278 - p_acc: 0.5409 - val_loss: 1.1492 - val_p_acc: 0.4984\n",
      "Epoch 951/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9266 - p_acc: 0.5633 - val_loss: 1.1480 - val_p_acc: 0.4984\n",
      "Epoch 952/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9800 - p_acc: 0.6995 - val_loss: 1.1469 - val_p_acc: 0.4808\n",
      "Epoch 953/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0832 - p_acc: 0.4728 - val_loss: 1.1479 - val_p_acc: 0.4455\n",
      "Epoch 954/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0023 - p_acc: 0.5793 - val_loss: 1.1480 - val_p_acc: 0.4631\n",
      "Epoch 955/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9888 - p_acc: 0.5649 - val_loss: 1.1487 - val_p_acc: 0.4631\n",
      "Epoch 956/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 1.0225 - p_acc: 0.5288 - val_loss: 1.1497 - val_p_acc: 0.4984\n",
      "Epoch 957/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0489 - p_acc: 0.4936 - val_loss: 1.1492 - val_p_acc: 0.4808\n",
      "Epoch 958/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0055 - p_acc: 0.5441 - val_loss: 1.1489 - val_p_acc: 0.4984\n",
      "Epoch 959/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0605 - p_acc: 0.5633 - val_loss: 1.1498 - val_p_acc: 0.4984\n",
      "Epoch 960/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.0813 - p_acc: 0.5809 - val_loss: 1.1497 - val_p_acc: 0.4808\n",
      "Epoch 961/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0360 - p_acc: 0.5337 - val_loss: 1.1500 - val_p_acc: 0.4808\n",
      "Epoch 962/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9933 - p_acc: 0.5913 - val_loss: 1.1504 - val_p_acc: 0.4808\n",
      "Epoch 963/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.9981 - p_acc: 0.5689 - val_loss: 1.1515 - val_p_acc: 0.5160\n",
      "Epoch 964/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0154 - p_acc: 0.5617 - val_loss: 1.1500 - val_p_acc: 0.4631\n",
      "Epoch 965/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9623 - p_acc: 0.6226 - val_loss: 1.1499 - val_p_acc: 0.4808\n",
      "Epoch 966/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9285 - p_acc: 0.5946 - val_loss: 1.1500 - val_p_acc: 0.5337\n",
      "Epoch 967/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0540 - p_acc: 0.6210 - val_loss: 1.1493 - val_p_acc: 0.4984\n",
      "Epoch 968/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.1286 - p_acc: 0.5216 - val_loss: 1.1497 - val_p_acc: 0.4984\n",
      "Epoch 969/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0921 - p_acc: 0.5425 - val_loss: 1.1503 - val_p_acc: 0.5160\n",
      "Epoch 970/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9426 - p_acc: 0.5112 - val_loss: 1.1503 - val_p_acc: 0.4984\n",
      "Epoch 971/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0694 - p_acc: 0.5585 - val_loss: 1.1509 - val_p_acc: 0.4984\n",
      "Epoch 972/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9836 - p_acc: 0.6210 - val_loss: 1.1514 - val_p_acc: 0.4808\n",
      "Epoch 973/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0134 - p_acc: 0.5897 - val_loss: 1.1524 - val_p_acc: 0.4808\n",
      "Epoch 974/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9206 - p_acc: 0.5617 - val_loss: 1.1512 - val_p_acc: 0.4984\n",
      "Epoch 975/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0069 - p_acc: 0.6819 - val_loss: 1.1507 - val_p_acc: 0.4808\n",
      "Epoch 976/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9707 - p_acc: 0.5561 - val_loss: 1.1505 - val_p_acc: 0.5160\n",
      "Epoch 977/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0715 - p_acc: 0.5216 - val_loss: 1.1500 - val_p_acc: 0.4808\n",
      "Epoch 978/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0004 - p_acc: 0.5529 - val_loss: 1.1501 - val_p_acc: 0.4455\n",
      "Epoch 979/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0021 - p_acc: 0.5601 - val_loss: 1.1512 - val_p_acc: 0.5513\n",
      "Epoch 980/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9541 - p_acc: 0.6715 - val_loss: 1.1505 - val_p_acc: 0.4808\n",
      "Epoch 981/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9903 - p_acc: 0.6034 - val_loss: 1.1498 - val_p_acc: 0.5337\n",
      "Epoch 982/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0054 - p_acc: 0.5929 - val_loss: 1.1498 - val_p_acc: 0.4984\n",
      "Epoch 983/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0587 - p_acc: 0.5425 - val_loss: 1.1487 - val_p_acc: 0.4984\n",
      "Epoch 984/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9204 - p_acc: 0.6050 - val_loss: 1.1476 - val_p_acc: 0.5160\n",
      "Epoch 985/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9725 - p_acc: 0.5128 - val_loss: 1.1465 - val_p_acc: 0.4631\n",
      "Epoch 986/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0378 - p_acc: 0.5689 - val_loss: 1.1479 - val_p_acc: 0.4984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 987/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9916 - p_acc: 0.5601 - val_loss: 1.1484 - val_p_acc: 0.5160\n",
      "Epoch 988/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0280 - p_acc: 0.5096 - val_loss: 1.1483 - val_p_acc: 0.4808\n",
      "Epoch 989/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0133 - p_acc: 0.6018 - val_loss: 1.1482 - val_p_acc: 0.4631\n",
      "Epoch 990/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9248 - p_acc: 0.6090 - val_loss: 1.1480 - val_p_acc: 0.5160\n",
      "Epoch 991/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9898 - p_acc: 0.5617 - val_loss: 1.1480 - val_p_acc: 0.5160\n",
      "Epoch 992/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0364 - p_acc: 0.5649 - val_loss: 1.1478 - val_p_acc: 0.5337\n",
      "Epoch 993/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0316 - p_acc: 0.4904 - val_loss: 1.1462 - val_p_acc: 0.4984\n",
      "Epoch 994/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0242 - p_acc: 0.6018 - val_loss: 1.1465 - val_p_acc: 0.4984\n",
      "Epoch 995/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9360 - p_acc: 0.6210 - val_loss: 1.1473 - val_p_acc: 0.4984\n",
      "Epoch 996/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0536 - p_acc: 0.5200 - val_loss: 1.1474 - val_p_acc: 0.4455\n",
      "Epoch 997/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0274 - p_acc: 0.5753 - val_loss: 1.1464 - val_p_acc: 0.4631\n",
      "Epoch 998/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9722 - p_acc: 0.6314 - val_loss: 1.1452 - val_p_acc: 0.4984\n",
      "Epoch 999/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9964 - p_acc: 0.5809 - val_loss: 1.1436 - val_p_acc: 0.4631\n",
      "Epoch 1000/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0271 - p_acc: 0.5793 - val_loss: 1.1443 - val_p_acc: 0.4808\n",
      "Epoch 1001/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0691 - p_acc: 0.5737 - val_loss: 1.1455 - val_p_acc: 0.4984\n",
      "Epoch 1002/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9837 - p_acc: 0.6226 - val_loss: 1.1461 - val_p_acc: 0.4984\n",
      "Epoch 1003/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0814 - p_acc: 0.5321 - val_loss: 1.1468 - val_p_acc: 0.4631\n",
      "Epoch 1004/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9590 - p_acc: 0.6819 - val_loss: 1.1463 - val_p_acc: 0.5160\n",
      "Epoch 1005/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0043 - p_acc: 0.5689 - val_loss: 1.1462 - val_p_acc: 0.4631\n",
      "Epoch 1006/5000\n",
      "85/85 [==============================] - 0s 709us/sample - loss: 1.0418 - p_acc: 0.5841 - val_loss: 1.1464 - val_p_acc: 0.4808\n",
      "Epoch 1007/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0585 - p_acc: 0.5321 - val_loss: 1.1459 - val_p_acc: 0.4984\n",
      "Epoch 1008/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0388 - p_acc: 0.5777 - val_loss: 1.1461 - val_p_acc: 0.4984\n",
      "Epoch 1009/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0396 - p_acc: 0.4992 - val_loss: 1.1472 - val_p_acc: 0.5160\n",
      "Epoch 1010/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0066 - p_acc: 0.5529 - val_loss: 1.1469 - val_p_acc: 0.5160\n",
      "Epoch 1011/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0917 - p_acc: 0.5216 - val_loss: 1.1456 - val_p_acc: 0.4631\n",
      "Epoch 1012/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0173 - p_acc: 0.5513 - val_loss: 1.1453 - val_p_acc: 0.4631\n",
      "Epoch 1013/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0296 - p_acc: 0.5513 - val_loss: 1.1451 - val_p_acc: 0.5160\n",
      "Epoch 1014/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0039 - p_acc: 0.5425 - val_loss: 1.1445 - val_p_acc: 0.5160\n",
      "Epoch 1015/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9741 - p_acc: 0.5441 - val_loss: 1.1438 - val_p_acc: 0.4984\n",
      "Epoch 1016/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9721 - p_acc: 0.6330 - val_loss: 1.1423 - val_p_acc: 0.4808\n",
      "Epoch 1017/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0466 - p_acc: 0.5425 - val_loss: 1.1418 - val_p_acc: 0.5160\n",
      "Epoch 1018/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0412 - p_acc: 0.6506 - val_loss: 1.1410 - val_p_acc: 0.5160\n",
      "Epoch 1019/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9476 - p_acc: 0.5946 - val_loss: 1.1405 - val_p_acc: 0.4808\n",
      "Epoch 1020/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.0427 - p_acc: 0.5913 - val_loss: 1.1405 - val_p_acc: 0.5337\n",
      "Epoch 1021/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9998 - p_acc: 0.5705 - val_loss: 1.1403 - val_p_acc: 0.4631\n",
      "Epoch 1022/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0471 - p_acc: 0.5761 - val_loss: 1.1394 - val_p_acc: 0.4631\n",
      "Epoch 1023/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0063 - p_acc: 0.6418 - val_loss: 1.1391 - val_p_acc: 0.5160\n",
      "Epoch 1024/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0228 - p_acc: 0.5649 - val_loss: 1.1399 - val_p_acc: 0.5160\n",
      "Epoch 1025/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0194 - p_acc: 0.5721 - val_loss: 1.1396 - val_p_acc: 0.4631\n",
      "Epoch 1026/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9774 - p_acc: 0.5857 - val_loss: 1.1407 - val_p_acc: 0.5160\n",
      "Epoch 1027/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9673 - p_acc: 0.6018 - val_loss: 1.1402 - val_p_acc: 0.4455\n",
      "Epoch 1028/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0121 - p_acc: 0.5545 - val_loss: 1.1399 - val_p_acc: 0.4455\n",
      "Epoch 1029/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0087 - p_acc: 0.5705 - val_loss: 1.1396 - val_p_acc: 0.5160\n",
      "Epoch 1030/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9623 - p_acc: 0.5545 - val_loss: 1.1388 - val_p_acc: 0.4631\n",
      "Epoch 1031/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9734 - p_acc: 0.5721 - val_loss: 1.1394 - val_p_acc: 0.4984\n",
      "Epoch 1032/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0531 - p_acc: 0.5633 - val_loss: 1.1391 - val_p_acc: 0.4631\n",
      "Epoch 1033/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0190 - p_acc: 0.5008 - val_loss: 1.1396 - val_p_acc: 0.4808\n",
      "Epoch 1034/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9817 - p_acc: 0.6418 - val_loss: 1.1400 - val_p_acc: 0.4984\n",
      "Epoch 1035/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0102 - p_acc: 0.5721 - val_loss: 1.1405 - val_p_acc: 0.5337\n",
      "Epoch 1036/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9817 - p_acc: 0.5441 - val_loss: 1.1406 - val_p_acc: 0.4984\n",
      "Epoch 1037/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0409 - p_acc: 0.6122 - val_loss: 1.1412 - val_p_acc: 0.4631\n",
      "Epoch 1038/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9521 - p_acc: 0.6002 - val_loss: 1.1418 - val_p_acc: 0.4984\n",
      "Epoch 1039/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0275 - p_acc: 0.5561 - val_loss: 1.1414 - val_p_acc: 0.4984\n",
      "Epoch 1040/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0213 - p_acc: 0.5705 - val_loss: 1.1424 - val_p_acc: 0.5160\n",
      "Epoch 1041/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9992 - p_acc: 0.6002 - val_loss: 1.1411 - val_p_acc: 0.4984\n",
      "Epoch 1042/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0074 - p_acc: 0.5929 - val_loss: 1.1413 - val_p_acc: 0.4984\n",
      "Epoch 1043/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9808 - p_acc: 0.5248 - val_loss: 1.1407 - val_p_acc: 0.4279\n",
      "Epoch 1044/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9872 - p_acc: 0.5841 - val_loss: 1.1404 - val_p_acc: 0.4455\n",
      "Epoch 1045/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9701 - p_acc: 0.6314 - val_loss: 1.1400 - val_p_acc: 0.4455\n",
      "Epoch 1046/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9845 - p_acc: 0.5793 - val_loss: 1.1403 - val_p_acc: 0.4984\n",
      "Epoch 1047/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9269 - p_acc: 0.6803 - val_loss: 1.1398 - val_p_acc: 0.4984\n",
      "Epoch 1048/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0526 - p_acc: 0.5321 - val_loss: 1.1392 - val_p_acc: 0.5160\n",
      "Epoch 1049/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0810 - p_acc: 0.6314 - val_loss: 1.1382 - val_p_acc: 0.4808\n",
      "Epoch 1050/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0527 - p_acc: 0.5897 - val_loss: 1.1363 - val_p_acc: 0.4808\n",
      "Epoch 1051/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0403 - p_acc: 0.5184 - val_loss: 1.1365 - val_p_acc: 0.4631\n",
      "Epoch 1052/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9442 - p_acc: 0.5809 - val_loss: 1.1356 - val_p_acc: 0.4808\n",
      "Epoch 1053/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9946 - p_acc: 0.5617 - val_loss: 1.1352 - val_p_acc: 0.4984\n",
      "Epoch 1054/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.0499 - p_acc: 0.5425 - val_loss: 1.1350 - val_p_acc: 0.4808\n",
      "Epoch 1055/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9622 - p_acc: 0.5913 - val_loss: 1.1352 - val_p_acc: 0.5160\n",
      "Epoch 1056/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0204 - p_acc: 0.5513 - val_loss: 1.1360 - val_p_acc: 0.4631\n",
      "Epoch 1057/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9610 - p_acc: 0.5946 - val_loss: 1.1345 - val_p_acc: 0.4808\n",
      "Epoch 1058/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0121 - p_acc: 0.5897 - val_loss: 1.1353 - val_p_acc: 0.5160\n",
      "Epoch 1059/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0127 - p_acc: 0.5200 - val_loss: 1.1350 - val_p_acc: 0.4808\n",
      "Epoch 1060/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0769 - p_acc: 0.4976 - val_loss: 1.1355 - val_p_acc: 0.5337\n",
      "Epoch 1061/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0191 - p_acc: 0.4992 - val_loss: 1.1354 - val_p_acc: 0.4984\n",
      "Epoch 1062/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9021 - p_acc: 0.6138 - val_loss: 1.1352 - val_p_acc: 0.4984\n",
      "Epoch 1063/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9974 - p_acc: 0.6122 - val_loss: 1.1345 - val_p_acc: 0.4103\n",
      "Epoch 1064/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9938 - p_acc: 0.5513 - val_loss: 1.1361 - val_p_acc: 0.4808\n",
      "Epoch 1065/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9280 - p_acc: 0.5673 - val_loss: 1.1350 - val_p_acc: 0.4631\n",
      "Epoch 1066/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.0620 - p_acc: 0.5986 - val_loss: 1.1339 - val_p_acc: 0.5513\n",
      "Epoch 1067/5000\n",
      "85/85 [==============================] - 0s 710us/sample - loss: 0.9458 - p_acc: 0.6018 - val_loss: 1.1324 - val_p_acc: 0.5160\n",
      "Epoch 1068/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8962 - p_acc: 0.6034 - val_loss: 1.1331 - val_p_acc: 0.4808\n",
      "Epoch 1069/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9645 - p_acc: 0.5793 - val_loss: 1.1333 - val_p_acc: 0.4984\n",
      "Epoch 1070/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0155 - p_acc: 0.6138 - val_loss: 1.1331 - val_p_acc: 0.5160\n",
      "Epoch 1071/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9195 - p_acc: 0.6522 - val_loss: 1.1326 - val_p_acc: 0.5160\n",
      "Epoch 1072/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9618 - p_acc: 0.6106 - val_loss: 1.1315 - val_p_acc: 0.4984\n",
      "Epoch 1073/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9524 - p_acc: 0.5321 - val_loss: 1.1318 - val_p_acc: 0.4808\n",
      "Epoch 1074/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9988 - p_acc: 0.6106 - val_loss: 1.1315 - val_p_acc: 0.4455\n",
      "Epoch 1075/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9348 - p_acc: 0.6122 - val_loss: 1.1309 - val_p_acc: 0.4808\n",
      "Epoch 1076/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0365 - p_acc: 0.5825 - val_loss: 1.1310 - val_p_acc: 0.4808\n",
      "Epoch 1077/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0032 - p_acc: 0.5497 - val_loss: 1.1316 - val_p_acc: 0.4808\n",
      "Epoch 1078/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0990 - p_acc: 0.4712 - val_loss: 1.1313 - val_p_acc: 0.4808\n",
      "Epoch 1079/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9701 - p_acc: 0.6330 - val_loss: 1.1315 - val_p_acc: 0.5160\n",
      "Epoch 1080/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0173 - p_acc: 0.6330 - val_loss: 1.1328 - val_p_acc: 0.4808\n",
      "Epoch 1081/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9492 - p_acc: 0.5897 - val_loss: 1.1324 - val_p_acc: 0.4984\n",
      "Epoch 1082/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0277 - p_acc: 0.6106 - val_loss: 1.1322 - val_p_acc: 0.4279\n",
      "Epoch 1083/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.0182 - p_acc: 0.5232 - val_loss: 1.1320 - val_p_acc: 0.4984\n",
      "Epoch 1084/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0754 - p_acc: 0.5633 - val_loss: 1.1327 - val_p_acc: 0.4984\n",
      "Epoch 1085/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0252 - p_acc: 0.6018 - val_loss: 1.1326 - val_p_acc: 0.4808\n",
      "Epoch 1086/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9901 - p_acc: 0.5809 - val_loss: 1.1330 - val_p_acc: 0.4808\n",
      "Epoch 1087/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9378 - p_acc: 0.6082 - val_loss: 1.1342 - val_p_acc: 0.4455\n",
      "Epoch 1088/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0580 - p_acc: 0.6298 - val_loss: 1.1345 - val_p_acc: 0.5160\n",
      "Epoch 1089/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9634 - p_acc: 0.6418 - val_loss: 1.1353 - val_p_acc: 0.4984\n",
      "Epoch 1090/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 1.0222 - p_acc: 0.5633 - val_loss: 1.1336 - val_p_acc: 0.4984\n",
      "Epoch 1091/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9723 - p_acc: 0.5986 - val_loss: 1.1348 - val_p_acc: 0.5160\n",
      "Epoch 1092/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0505 - p_acc: 0.5425 - val_loss: 1.1351 - val_p_acc: 0.4455\n",
      "Epoch 1093/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0093 - p_acc: 0.6034 - val_loss: 1.1348 - val_p_acc: 0.4984\n",
      "Epoch 1094/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0137 - p_acc: 0.4936 - val_loss: 1.1349 - val_p_acc: 0.5160\n",
      "Epoch 1095/5000\n",
      "85/85 [==============================] - 0s 709us/sample - loss: 1.0417 - p_acc: 0.6226 - val_loss: 1.1354 - val_p_acc: 0.5337\n",
      "Epoch 1096/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.1307 - p_acc: 0.4487 - val_loss: 1.1356 - val_p_acc: 0.4808\n",
      "Epoch 1097/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9630 - p_acc: 0.5809 - val_loss: 1.1359 - val_p_acc: 0.4631\n",
      "Epoch 1098/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9516 - p_acc: 0.6050 - val_loss: 1.1353 - val_p_acc: 0.4808\n",
      "Epoch 1099/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0058 - p_acc: 0.6226 - val_loss: 1.1358 - val_p_acc: 0.4808\n",
      "Epoch 1100/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9791 - p_acc: 0.5321 - val_loss: 1.1360 - val_p_acc: 0.4631\n",
      "Epoch 1101/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9893 - p_acc: 0.6506 - val_loss: 1.1371 - val_p_acc: 0.4631\n",
      "Epoch 1102/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0353 - p_acc: 0.5409 - val_loss: 1.1372 - val_p_acc: 0.4631\n",
      "Epoch 1103/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 0.9934 - p_acc: 0.5601 - val_loss: 1.1381 - val_p_acc: 0.4984\n",
      "Epoch 1104/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 1.0693 - p_acc: 0.6538 - val_loss: 1.1383 - val_p_acc: 0.4631\n",
      "Epoch 1105/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9624 - p_acc: 0.5497 - val_loss: 1.1374 - val_p_acc: 0.4631\n",
      "Epoch 1106/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0466 - p_acc: 0.5232 - val_loss: 1.1380 - val_p_acc: 0.5337\n",
      "Epoch 1107/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9975 - p_acc: 0.5232 - val_loss: 1.1377 - val_p_acc: 0.4984\n",
      "Epoch 1108/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9915 - p_acc: 0.5601 - val_loss: 1.1368 - val_p_acc: 0.4808\n",
      "Epoch 1109/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9413 - p_acc: 0.5232 - val_loss: 1.1355 - val_p_acc: 0.4984\n",
      "Epoch 1110/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0412 - p_acc: 0.5633 - val_loss: 1.1350 - val_p_acc: 0.4808\n",
      "Epoch 1111/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9119 - p_acc: 0.6034 - val_loss: 1.1342 - val_p_acc: 0.5513\n",
      "Epoch 1112/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0184 - p_acc: 0.5441 - val_loss: 1.1340 - val_p_acc: 0.4455\n",
      "Epoch 1113/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9726 - p_acc: 0.6090 - val_loss: 1.1330 - val_p_acc: 0.4808\n",
      "Epoch 1114/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9237 - p_acc: 0.5633 - val_loss: 1.1324 - val_p_acc: 0.5160\n",
      "Epoch 1115/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9187 - p_acc: 0.5946 - val_loss: 1.1319 - val_p_acc: 0.4808\n",
      "Epoch 1116/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9337 - p_acc: 0.5737 - val_loss: 1.1313 - val_p_acc: 0.4984\n",
      "Epoch 1117/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0138 - p_acc: 0.5809 - val_loss: 1.1306 - val_p_acc: 0.4808\n",
      "Epoch 1118/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0181 - p_acc: 0.5321 - val_loss: 1.1310 - val_p_acc: 0.4984\n",
      "Epoch 1119/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9679 - p_acc: 0.5513 - val_loss: 1.1313 - val_p_acc: 0.4808\n",
      "Epoch 1120/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9755 - p_acc: 0.6434 - val_loss: 1.1317 - val_p_acc: 0.4808\n",
      "Epoch 1121/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0678 - p_acc: 0.4311 - val_loss: 1.1319 - val_p_acc: 0.4808\n",
      "Epoch 1122/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0580 - p_acc: 0.5897 - val_loss: 1.1305 - val_p_acc: 0.4808\n",
      "Epoch 1123/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9716 - p_acc: 0.5689 - val_loss: 1.1301 - val_p_acc: 0.4984\n",
      "Epoch 1124/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0345 - p_acc: 0.6314 - val_loss: 1.1298 - val_p_acc: 0.4631\n",
      "Epoch 1125/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0591 - p_acc: 0.5601 - val_loss: 1.1298 - val_p_acc: 0.4631\n",
      "Epoch 1126/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.9528 - p_acc: 0.6138 - val_loss: 1.1289 - val_p_acc: 0.5160\n",
      "Epoch 1127/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0363 - p_acc: 0.5248 - val_loss: 1.1294 - val_p_acc: 0.5337\n",
      "Epoch 1128/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0531 - p_acc: 0.5946 - val_loss: 1.1299 - val_p_acc: 0.4455\n",
      "Epoch 1129/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9925 - p_acc: 0.5617 - val_loss: 1.1280 - val_p_acc: 0.4984\n",
      "Epoch 1130/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9689 - p_acc: 0.6154 - val_loss: 1.1265 - val_p_acc: 0.4984\n",
      "Epoch 1131/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9467 - p_acc: 0.6138 - val_loss: 1.1264 - val_p_acc: 0.5337\n",
      "Epoch 1132/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9764 - p_acc: 0.5721 - val_loss: 1.1265 - val_p_acc: 0.4984\n",
      "Epoch 1133/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9992 - p_acc: 0.5513 - val_loss: 1.1263 - val_p_acc: 0.5160\n",
      "Epoch 1134/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0088 - p_acc: 0.5793 - val_loss: 1.1262 - val_p_acc: 0.4631\n",
      "Epoch 1135/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0337 - p_acc: 0.5425 - val_loss: 1.1257 - val_p_acc: 0.4984\n",
      "Epoch 1136/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9979 - p_acc: 0.6018 - val_loss: 1.1251 - val_p_acc: 0.4984\n",
      "Epoch 1137/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0513 - p_acc: 0.6194 - val_loss: 1.1249 - val_p_acc: 0.4103\n",
      "Epoch 1138/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0430 - p_acc: 0.5216 - val_loss: 1.1244 - val_p_acc: 0.4455\n",
      "Epoch 1139/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0021 - p_acc: 0.5689 - val_loss: 1.1243 - val_p_acc: 0.4631\n",
      "Epoch 1140/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9524 - p_acc: 0.5721 - val_loss: 1.1241 - val_p_acc: 0.4808\n",
      "Epoch 1141/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9324 - p_acc: 0.7043 - val_loss: 1.1245 - val_p_acc: 0.4631\n",
      "Epoch 1142/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0465 - p_acc: 0.5617 - val_loss: 1.1230 - val_p_acc: 0.4984\n",
      "Epoch 1143/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0484 - p_acc: 0.5497 - val_loss: 1.1216 - val_p_acc: 0.4808\n",
      "Epoch 1144/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9499 - p_acc: 0.5721 - val_loss: 1.1220 - val_p_acc: 0.4808\n",
      "Epoch 1145/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 1.0030 - p_acc: 0.5024 - val_loss: 1.1215 - val_p_acc: 0.4631\n",
      "Epoch 1146/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9989 - p_acc: 0.5529 - val_loss: 1.1213 - val_p_acc: 0.4808\n",
      "Epoch 1147/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9614 - p_acc: 0.6418 - val_loss: 1.1208 - val_p_acc: 0.4808\n",
      "Epoch 1148/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9499 - p_acc: 0.6298 - val_loss: 1.1216 - val_p_acc: 0.5160\n",
      "Epoch 1149/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9907 - p_acc: 0.5513 - val_loss: 1.1230 - val_p_acc: 0.4808\n",
      "Epoch 1150/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9787 - p_acc: 0.6298 - val_loss: 1.1225 - val_p_acc: 0.4631\n",
      "Epoch 1151/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9141 - p_acc: 0.6627 - val_loss: 1.1213 - val_p_acc: 0.4984\n",
      "Epoch 1152/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9542 - p_acc: 0.6138 - val_loss: 1.1217 - val_p_acc: 0.4631\n",
      "Epoch 1153/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9968 - p_acc: 0.6699 - val_loss: 1.1228 - val_p_acc: 0.4808\n",
      "Epoch 1154/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0164 - p_acc: 0.5721 - val_loss: 1.1231 - val_p_acc: 0.4631\n",
      "Epoch 1155/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0280 - p_acc: 0.5913 - val_loss: 1.1235 - val_p_acc: 0.4984\n",
      "Epoch 1156/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0235 - p_acc: 0.6122 - val_loss: 1.1233 - val_p_acc: 0.5337\n",
      "Epoch 1157/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0236 - p_acc: 0.5497 - val_loss: 1.1239 - val_p_acc: 0.4631\n",
      "Epoch 1158/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0074 - p_acc: 0.5288 - val_loss: 1.1241 - val_p_acc: 0.4984\n",
      "Epoch 1159/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0006 - p_acc: 0.5913 - val_loss: 1.1233 - val_p_acc: 0.4808\n",
      "Epoch 1160/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0362 - p_acc: 0.6226 - val_loss: 1.1240 - val_p_acc: 0.5337\n",
      "Epoch 1161/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9666 - p_acc: 0.5913 - val_loss: 1.1229 - val_p_acc: 0.5160\n",
      "Epoch 1162/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0129 - p_acc: 0.5144 - val_loss: 1.1231 - val_p_acc: 0.4984\n",
      "Epoch 1163/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9422 - p_acc: 0.5705 - val_loss: 1.1223 - val_p_acc: 0.5337\n",
      "Epoch 1164/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9723 - p_acc: 0.5825 - val_loss: 1.1230 - val_p_acc: 0.4808\n",
      "Epoch 1165/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9237 - p_acc: 0.5617 - val_loss: 1.1226 - val_p_acc: 0.4631\n",
      "Epoch 1166/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9732 - p_acc: 0.5409 - val_loss: 1.1218 - val_p_acc: 0.4631\n",
      "Epoch 1167/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9630 - p_acc: 0.5377 - val_loss: 1.1223 - val_p_acc: 0.4808\n",
      "Epoch 1168/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8496 - p_acc: 0.6450 - val_loss: 1.1234 - val_p_acc: 0.5513\n",
      "Epoch 1169/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0784 - p_acc: 0.5409 - val_loss: 1.1255 - val_p_acc: 0.5160\n",
      "Epoch 1170/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0182 - p_acc: 0.6242 - val_loss: 1.1264 - val_p_acc: 0.4808\n",
      "Epoch 1171/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0250 - p_acc: 0.6611 - val_loss: 1.1275 - val_p_acc: 0.4808\n",
      "Epoch 1172/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9320 - p_acc: 0.6138 - val_loss: 1.1272 - val_p_acc: 0.4808\n",
      "Epoch 1173/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9532 - p_acc: 0.5897 - val_loss: 1.1261 - val_p_acc: 0.4808\n",
      "Epoch 1174/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9623 - p_acc: 0.6210 - val_loss: 1.1267 - val_p_acc: 0.5160\n",
      "Epoch 1175/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0051 - p_acc: 0.5128 - val_loss: 1.1266 - val_p_acc: 0.4984\n",
      "Epoch 1176/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9599 - p_acc: 0.5425 - val_loss: 1.1255 - val_p_acc: 0.4984\n",
      "Epoch 1177/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9599 - p_acc: 0.6450 - val_loss: 1.1249 - val_p_acc: 0.4984\n",
      "Epoch 1178/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9364 - p_acc: 0.6434 - val_loss: 1.1241 - val_p_acc: 0.4984\n",
      "Epoch 1179/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0358 - p_acc: 0.5304 - val_loss: 1.1243 - val_p_acc: 0.4984\n",
      "Epoch 1180/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9511 - p_acc: 0.6242 - val_loss: 1.1256 - val_p_acc: 0.4808\n",
      "Epoch 1181/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9346 - p_acc: 0.6891 - val_loss: 1.1253 - val_p_acc: 0.4279\n",
      "Epoch 1182/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9982 - p_acc: 0.5545 - val_loss: 1.1251 - val_p_acc: 0.4631\n",
      "Epoch 1183/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9812 - p_acc: 0.6226 - val_loss: 1.1243 - val_p_acc: 0.4984\n",
      "Epoch 1184/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9820 - p_acc: 0.5353 - val_loss: 1.1249 - val_p_acc: 0.4631\n",
      "Epoch 1185/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9835 - p_acc: 0.5689 - val_loss: 1.1246 - val_p_acc: 0.4631\n",
      "Epoch 1186/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9907 - p_acc: 0.6715 - val_loss: 1.1250 - val_p_acc: 0.5337\n",
      "Epoch 1187/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9451 - p_acc: 0.5809 - val_loss: 1.1244 - val_p_acc: 0.5160\n",
      "Epoch 1188/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9493 - p_acc: 0.6314 - val_loss: 1.1244 - val_p_acc: 0.5337\n",
      "Epoch 1189/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9137 - p_acc: 0.6122 - val_loss: 1.1245 - val_p_acc: 0.5337\n",
      "Epoch 1190/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9812 - p_acc: 0.5913 - val_loss: 1.1238 - val_p_acc: 0.4455\n",
      "Epoch 1191/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9494 - p_acc: 0.6138 - val_loss: 1.1237 - val_p_acc: 0.4984\n",
      "Epoch 1192/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9764 - p_acc: 0.5689 - val_loss: 1.1249 - val_p_acc: 0.4631\n",
      "Epoch 1193/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0005 - p_acc: 0.6434 - val_loss: 1.1243 - val_p_acc: 0.4984\n",
      "Epoch 1194/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9641 - p_acc: 0.6386 - val_loss: 1.1253 - val_p_acc: 0.5337\n",
      "Epoch 1195/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9793 - p_acc: 0.5721 - val_loss: 1.1241 - val_p_acc: 0.5337\n",
      "Epoch 1196/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9528 - p_acc: 0.5809 - val_loss: 1.1244 - val_p_acc: 0.4455\n",
      "Epoch 1197/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9899 - p_acc: 0.5737 - val_loss: 1.1241 - val_p_acc: 0.4631\n",
      "Epoch 1198/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9355 - p_acc: 0.5946 - val_loss: 1.1244 - val_p_acc: 0.5160\n",
      "Epoch 1199/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0653 - p_acc: 0.4784 - val_loss: 1.1250 - val_p_acc: 0.4455\n",
      "Epoch 1200/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9525 - p_acc: 0.5737 - val_loss: 1.1250 - val_p_acc: 0.5160\n",
      "Epoch 1201/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9312 - p_acc: 0.5946 - val_loss: 1.1258 - val_p_acc: 0.4455\n",
      "Epoch 1202/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9545 - p_acc: 0.5825 - val_loss: 1.1250 - val_p_acc: 0.4808\n",
      "Epoch 1203/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9742 - p_acc: 0.6611 - val_loss: 1.1250 - val_p_acc: 0.5160\n",
      "Epoch 1204/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9711 - p_acc: 0.5970 - val_loss: 1.1250 - val_p_acc: 0.4455\n",
      "Epoch 1205/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0090 - p_acc: 0.5441 - val_loss: 1.1259 - val_p_acc: 0.4984\n",
      "Epoch 1206/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9780 - p_acc: 0.6138 - val_loss: 1.1257 - val_p_acc: 0.5160\n",
      "Epoch 1207/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9945 - p_acc: 0.5753 - val_loss: 1.1260 - val_p_acc: 0.4631\n",
      "Epoch 1208/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9413 - p_acc: 0.6122 - val_loss: 1.1255 - val_p_acc: 0.4631\n",
      "Epoch 1209/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9793 - p_acc: 0.5513 - val_loss: 1.1256 - val_p_acc: 0.4808\n",
      "Epoch 1210/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0151 - p_acc: 0.5617 - val_loss: 1.1261 - val_p_acc: 0.4984\n",
      "Epoch 1211/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9309 - p_acc: 0.6418 - val_loss: 1.1268 - val_p_acc: 0.5160\n",
      "Epoch 1212/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9839 - p_acc: 0.5705 - val_loss: 1.1270 - val_p_acc: 0.5160\n",
      "Epoch 1213/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9609 - p_acc: 0.5753 - val_loss: 1.1297 - val_p_acc: 0.4808\n",
      "Epoch 1214/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9927 - p_acc: 0.5705 - val_loss: 1.1312 - val_p_acc: 0.4808\n",
      "Epoch 1215/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9147 - p_acc: 0.6522 - val_loss: 1.1313 - val_p_acc: 0.5160\n",
      "Epoch 1216/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9828 - p_acc: 0.5633 - val_loss: 1.1315 - val_p_acc: 0.4984\n",
      "Epoch 1217/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9707 - p_acc: 0.6226 - val_loss: 1.1309 - val_p_acc: 0.4808\n",
      "Epoch 1218/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0647 - p_acc: 0.4728 - val_loss: 1.1304 - val_p_acc: 0.4984\n",
      "Epoch 1219/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9553 - p_acc: 0.5929 - val_loss: 1.1299 - val_p_acc: 0.4808\n",
      "Epoch 1220/5000\n",
      "85/85 [==============================] - 0s 701us/sample - loss: 1.0048 - p_acc: 0.5737 - val_loss: 1.1294 - val_p_acc: 0.4631\n",
      "Epoch 1221/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9462 - p_acc: 0.6018 - val_loss: 1.1296 - val_p_acc: 0.4455\n",
      "Epoch 1222/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9351 - p_acc: 0.6018 - val_loss: 1.1302 - val_p_acc: 0.4984\n",
      "Epoch 1223/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9114 - p_acc: 0.6226 - val_loss: 1.1311 - val_p_acc: 0.4455\n",
      "Epoch 1224/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 1.0136 - p_acc: 0.6290 - val_loss: 1.1316 - val_p_acc: 0.4455\n",
      "Epoch 1225/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8940 - p_acc: 0.6226 - val_loss: 1.1323 - val_p_acc: 0.4631\n",
      "Epoch 1226/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9267 - p_acc: 0.5913 - val_loss: 1.1328 - val_p_acc: 0.4455\n",
      "Epoch 1227/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0139 - p_acc: 0.5809 - val_loss: 1.1314 - val_p_acc: 0.4808\n",
      "Epoch 1228/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0712 - p_acc: 0.5529 - val_loss: 1.1301 - val_p_acc: 0.4631\n",
      "Epoch 1229/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9789 - p_acc: 0.5128 - val_loss: 1.1300 - val_p_acc: 0.4279\n",
      "Epoch 1230/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9818 - p_acc: 0.5288 - val_loss: 1.1298 - val_p_acc: 0.4808\n",
      "Epoch 1231/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9398 - p_acc: 0.6715 - val_loss: 1.1286 - val_p_acc: 0.4631\n",
      "Epoch 1232/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0188 - p_acc: 0.4816 - val_loss: 1.1274 - val_p_acc: 0.5160\n",
      "Epoch 1233/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9812 - p_acc: 0.6715 - val_loss: 1.1267 - val_p_acc: 0.4279\n",
      "Epoch 1234/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9118 - p_acc: 0.6418 - val_loss: 1.1275 - val_p_acc: 0.4631\n",
      "Epoch 1235/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9816 - p_acc: 0.5112 - val_loss: 1.1274 - val_p_acc: 0.4984\n",
      "Epoch 1236/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.0020 - p_acc: 0.5929 - val_loss: 1.1275 - val_p_acc: 0.4984\n",
      "Epoch 1237/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9841 - p_acc: 0.5986 - val_loss: 1.1269 - val_p_acc: 0.4631\n",
      "Epoch 1238/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0032 - p_acc: 0.5721 - val_loss: 1.1266 - val_p_acc: 0.5160\n",
      "Epoch 1239/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9299 - p_acc: 0.6538 - val_loss: 1.1279 - val_p_acc: 0.4984\n",
      "Epoch 1240/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0139 - p_acc: 0.5112 - val_loss: 1.1274 - val_p_acc: 0.5160\n",
      "Epoch 1241/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9486 - p_acc: 0.6402 - val_loss: 1.1270 - val_p_acc: 0.4455\n",
      "Epoch 1242/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9237 - p_acc: 0.6314 - val_loss: 1.1260 - val_p_acc: 0.4808\n",
      "Epoch 1243/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9172 - p_acc: 0.6330 - val_loss: 1.1260 - val_p_acc: 0.4984\n",
      "Epoch 1244/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0054 - p_acc: 0.5529 - val_loss: 1.1261 - val_p_acc: 0.4984\n",
      "Epoch 1245/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9308 - p_acc: 0.6346 - val_loss: 1.1257 - val_p_acc: 0.4631\n",
      "Epoch 1246/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9717 - p_acc: 0.5601 - val_loss: 1.1266 - val_p_acc: 0.4631\n",
      "Epoch 1247/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9656 - p_acc: 0.5897 - val_loss: 1.1248 - val_p_acc: 0.5160\n",
      "Epoch 1248/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9569 - p_acc: 0.5457 - val_loss: 1.1253 - val_p_acc: 0.4631\n",
      "Epoch 1249/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9495 - p_acc: 0.4992 - val_loss: 1.1251 - val_p_acc: 0.4984\n",
      "Epoch 1250/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9614 - p_acc: 0.6434 - val_loss: 1.1245 - val_p_acc: 0.4631\n",
      "Epoch 1251/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9748 - p_acc: 0.5777 - val_loss: 1.1240 - val_p_acc: 0.4808\n",
      "Epoch 1252/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9599 - p_acc: 0.5425 - val_loss: 1.1239 - val_p_acc: 0.5160\n",
      "Epoch 1253/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9448 - p_acc: 0.5825 - val_loss: 1.1225 - val_p_acc: 0.4279\n",
      "Epoch 1254/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9322 - p_acc: 0.5962 - val_loss: 1.1216 - val_p_acc: 0.4631\n",
      "Epoch 1255/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0176 - p_acc: 0.6050 - val_loss: 1.1207 - val_p_acc: 0.4631\n",
      "Epoch 1256/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9439 - p_acc: 0.5096 - val_loss: 1.1213 - val_p_acc: 0.4455\n",
      "Epoch 1257/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9800 - p_acc: 0.5857 - val_loss: 1.1211 - val_p_acc: 0.4984\n",
      "Epoch 1258/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9281 - p_acc: 0.5705 - val_loss: 1.1197 - val_p_acc: 0.4984\n",
      "Epoch 1259/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0102 - p_acc: 0.5529 - val_loss: 1.1201 - val_p_acc: 0.4455\n",
      "Epoch 1260/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9961 - p_acc: 0.6194 - val_loss: 1.1201 - val_p_acc: 0.4455\n",
      "Epoch 1261/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8958 - p_acc: 0.6106 - val_loss: 1.1212 - val_p_acc: 0.5337\n",
      "Epoch 1262/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9295 - p_acc: 0.6106 - val_loss: 1.1226 - val_p_acc: 0.4808\n",
      "Epoch 1263/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9427 - p_acc: 0.6659 - val_loss: 1.1227 - val_p_acc: 0.4455\n",
      "Epoch 1264/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0146 - p_acc: 0.5337 - val_loss: 1.1231 - val_p_acc: 0.4984\n",
      "Epoch 1265/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0056 - p_acc: 0.6226 - val_loss: 1.1242 - val_p_acc: 0.4984\n",
      "Epoch 1266/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9850 - p_acc: 0.5617 - val_loss: 1.1249 - val_p_acc: 0.4984\n",
      "Epoch 1267/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9723 - p_acc: 0.5825 - val_loss: 1.1259 - val_p_acc: 0.4631\n",
      "Epoch 1268/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9435 - p_acc: 0.5721 - val_loss: 1.1256 - val_p_acc: 0.4455\n",
      "Epoch 1269/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9774 - p_acc: 0.6122 - val_loss: 1.1249 - val_p_acc: 0.4455\n",
      "Epoch 1270/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9969 - p_acc: 0.4848 - val_loss: 1.1247 - val_p_acc: 0.4279\n",
      "Epoch 1271/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9663 - p_acc: 0.5913 - val_loss: 1.1238 - val_p_acc: 0.4984\n",
      "Epoch 1272/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9592 - p_acc: 0.5649 - val_loss: 1.1236 - val_p_acc: 0.4808\n",
      "Epoch 1273/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9900 - p_acc: 0.5929 - val_loss: 1.1236 - val_p_acc: 0.4103\n",
      "Epoch 1274/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9141 - p_acc: 0.6330 - val_loss: 1.1246 - val_p_acc: 0.5160\n",
      "Epoch 1275/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9591 - p_acc: 0.5929 - val_loss: 1.1248 - val_p_acc: 0.4455\n",
      "Epoch 1276/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9313 - p_acc: 0.6330 - val_loss: 1.1248 - val_p_acc: 0.4984\n",
      "Epoch 1277/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9839 - p_acc: 0.5929 - val_loss: 1.1242 - val_p_acc: 0.4808\n",
      "Epoch 1278/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9527 - p_acc: 0.6178 - val_loss: 1.1239 - val_p_acc: 0.4631\n",
      "Epoch 1279/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9536 - p_acc: 0.5529 - val_loss: 1.1228 - val_p_acc: 0.4808\n",
      "Epoch 1280/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9315 - p_acc: 0.5913 - val_loss: 1.1240 - val_p_acc: 0.5337\n",
      "Epoch 1281/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9692 - p_acc: 0.5962 - val_loss: 1.1238 - val_p_acc: 0.5160\n",
      "Epoch 1282/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9607 - p_acc: 0.5601 - val_loss: 1.1235 - val_p_acc: 0.5160\n",
      "Epoch 1283/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9911 - p_acc: 0.5737 - val_loss: 1.1222 - val_p_acc: 0.4808\n",
      "Epoch 1284/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9838 - p_acc: 0.5633 - val_loss: 1.1217 - val_p_acc: 0.4631\n",
      "Epoch 1285/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9537 - p_acc: 0.7011 - val_loss: 1.1213 - val_p_acc: 0.5160\n",
      "Epoch 1286/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9886 - p_acc: 0.5232 - val_loss: 1.1206 - val_p_acc: 0.4631\n",
      "Epoch 1287/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9344 - p_acc: 0.5513 - val_loss: 1.1207 - val_p_acc: 0.5337\n",
      "Epoch 1288/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9579 - p_acc: 0.5601 - val_loss: 1.1203 - val_p_acc: 0.5160\n",
      "Epoch 1289/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9039 - p_acc: 0.6090 - val_loss: 1.1201 - val_p_acc: 0.5160\n",
      "Epoch 1290/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9104 - p_acc: 0.6314 - val_loss: 1.1189 - val_p_acc: 0.4279\n",
      "Epoch 1291/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9577 - p_acc: 0.5128 - val_loss: 1.1181 - val_p_acc: 0.5160\n",
      "Epoch 1292/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9658 - p_acc: 0.5601 - val_loss: 1.1171 - val_p_acc: 0.4631\n",
      "Epoch 1293/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9661 - p_acc: 0.5689 - val_loss: 1.1179 - val_p_acc: 0.4631\n",
      "Epoch 1294/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9856 - p_acc: 0.5497 - val_loss: 1.1181 - val_p_acc: 0.4631\n",
      "Epoch 1295/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9448 - p_acc: 0.5809 - val_loss: 1.1170 - val_p_acc: 0.4808\n",
      "Epoch 1296/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9762 - p_acc: 0.5545 - val_loss: 1.1158 - val_p_acc: 0.4984\n",
      "Epoch 1297/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9557 - p_acc: 0.5497 - val_loss: 1.1150 - val_p_acc: 0.4808\n",
      "Epoch 1298/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9564 - p_acc: 0.5040 - val_loss: 1.1146 - val_p_acc: 0.4984\n",
      "Epoch 1299/5000\n",
      "85/85 [==============================] - 0s 713us/sample - loss: 1.0484 - p_acc: 0.5705 - val_loss: 1.1156 - val_p_acc: 0.4631\n",
      "Epoch 1300/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9937 - p_acc: 0.5929 - val_loss: 1.1158 - val_p_acc: 0.4984\n",
      "Epoch 1301/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9520 - p_acc: 0.6434 - val_loss: 1.1140 - val_p_acc: 0.4984\n",
      "Epoch 1302/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9445 - p_acc: 0.5689 - val_loss: 1.1140 - val_p_acc: 0.4808\n",
      "Epoch 1303/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9694 - p_acc: 0.5633 - val_loss: 1.1138 - val_p_acc: 0.4984\n",
      "Epoch 1304/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9743 - p_acc: 0.5897 - val_loss: 1.1139 - val_p_acc: 0.4984\n",
      "Epoch 1305/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0606 - p_acc: 0.5200 - val_loss: 1.1124 - val_p_acc: 0.4631\n",
      "Epoch 1306/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 1.0040 - p_acc: 0.5737 - val_loss: 1.1126 - val_p_acc: 0.4984\n",
      "Epoch 1307/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9342 - p_acc: 0.5737 - val_loss: 1.1134 - val_p_acc: 0.4631\n",
      "Epoch 1308/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9123 - p_acc: 0.6314 - val_loss: 1.1133 - val_p_acc: 0.5160\n",
      "Epoch 1309/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9330 - p_acc: 0.6434 - val_loss: 1.1136 - val_p_acc: 0.4984\n",
      "Epoch 1310/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0109 - p_acc: 0.5337 - val_loss: 1.1134 - val_p_acc: 0.4984\n",
      "Epoch 1311/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0053 - p_acc: 0.6122 - val_loss: 1.1116 - val_p_acc: 0.4631\n",
      "Epoch 1312/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9216 - p_acc: 0.6122 - val_loss: 1.1107 - val_p_acc: 0.4808\n",
      "Epoch 1313/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0442 - p_acc: 0.5409 - val_loss: 1.1094 - val_p_acc: 0.4631\n",
      "Epoch 1314/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8857 - p_acc: 0.5929 - val_loss: 1.1086 - val_p_acc: 0.4455\n",
      "Epoch 1315/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9042 - p_acc: 0.6210 - val_loss: 1.1089 - val_p_acc: 0.4808\n",
      "Epoch 1316/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9592 - p_acc: 0.6314 - val_loss: 1.1097 - val_p_acc: 0.4631\n",
      "Epoch 1317/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8915 - p_acc: 0.6210 - val_loss: 1.1106 - val_p_acc: 0.4631\n",
      "Epoch 1318/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9648 - p_acc: 0.6226 - val_loss: 1.1118 - val_p_acc: 0.4631\n",
      "Epoch 1319/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0351 - p_acc: 0.6090 - val_loss: 1.1118 - val_p_acc: 0.4808\n",
      "Epoch 1320/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9303 - p_acc: 0.6482 - val_loss: 1.1129 - val_p_acc: 0.4984\n",
      "Epoch 1321/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9098 - p_acc: 0.6418 - val_loss: 1.1146 - val_p_acc: 0.4984\n",
      "Epoch 1322/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9990 - p_acc: 0.5216 - val_loss: 1.1146 - val_p_acc: 0.4808\n",
      "Epoch 1323/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9992 - p_acc: 0.5040 - val_loss: 1.1136 - val_p_acc: 0.4631\n",
      "Epoch 1324/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9150 - p_acc: 0.6434 - val_loss: 1.1131 - val_p_acc: 0.5160\n",
      "Epoch 1325/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9317 - p_acc: 0.5809 - val_loss: 1.1121 - val_p_acc: 0.4808\n",
      "Epoch 1326/5000\n",
      "85/85 [==============================] - 0s 696us/sample - loss: 0.9025 - p_acc: 0.5721 - val_loss: 1.1128 - val_p_acc: 0.4631\n",
      "Epoch 1327/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9069 - p_acc: 0.6138 - val_loss: 1.1132 - val_p_acc: 0.5160\n",
      "Epoch 1328/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9312 - p_acc: 0.6018 - val_loss: 1.1131 - val_p_acc: 0.4984\n",
      "Epoch 1329/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 735us/sample - loss: 0.9619 - p_acc: 0.5962 - val_loss: 1.1134 - val_p_acc: 0.4984\n",
      "Epoch 1330/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9524 - p_acc: 0.6490 - val_loss: 1.1130 - val_p_acc: 0.4631\n",
      "Epoch 1331/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8647 - p_acc: 0.6314 - val_loss: 1.1131 - val_p_acc: 0.4631\n",
      "Epoch 1332/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9623 - p_acc: 0.5441 - val_loss: 1.1130 - val_p_acc: 0.4455\n",
      "Epoch 1333/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9168 - p_acc: 0.6106 - val_loss: 1.1125 - val_p_acc: 0.4984\n",
      "Epoch 1334/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9577 - p_acc: 0.5513 - val_loss: 1.1118 - val_p_acc: 0.4631\n",
      "Epoch 1335/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0646 - p_acc: 0.5513 - val_loss: 1.1125 - val_p_acc: 0.4984\n",
      "Epoch 1336/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9391 - p_acc: 0.5617 - val_loss: 1.1131 - val_p_acc: 0.5337\n",
      "Epoch 1337/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0036 - p_acc: 0.6226 - val_loss: 1.1138 - val_p_acc: 0.5160\n",
      "Epoch 1338/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9025 - p_acc: 0.5529 - val_loss: 1.1145 - val_p_acc: 0.4808\n",
      "Epoch 1339/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9504 - p_acc: 0.6595 - val_loss: 1.1152 - val_p_acc: 0.4808\n",
      "Epoch 1340/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9357 - p_acc: 0.6330 - val_loss: 1.1142 - val_p_acc: 0.4808\n",
      "Epoch 1341/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8828 - p_acc: 0.6747 - val_loss: 1.1152 - val_p_acc: 0.4631\n",
      "Epoch 1342/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0127 - p_acc: 0.4784 - val_loss: 1.1150 - val_p_acc: 0.4984\n",
      "Epoch 1343/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9936 - p_acc: 0.5929 - val_loss: 1.1155 - val_p_acc: 0.4984\n",
      "Epoch 1344/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9607 - p_acc: 0.6450 - val_loss: 1.1160 - val_p_acc: 0.4984\n",
      "Epoch 1345/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9428 - p_acc: 0.6034 - val_loss: 1.1156 - val_p_acc: 0.4455\n",
      "Epoch 1346/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9485 - p_acc: 0.6595 - val_loss: 1.1135 - val_p_acc: 0.4808\n",
      "Epoch 1347/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9354 - p_acc: 0.6194 - val_loss: 1.1138 - val_p_acc: 0.4808\n",
      "Epoch 1348/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9341 - p_acc: 0.5825 - val_loss: 1.1142 - val_p_acc: 0.4808\n",
      "Epoch 1349/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0229 - p_acc: 0.5200 - val_loss: 1.1136 - val_p_acc: 0.5160\n",
      "Epoch 1350/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9683 - p_acc: 0.4784 - val_loss: 1.1153 - val_p_acc: 0.4631\n",
      "Epoch 1351/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9013 - p_acc: 0.5321 - val_loss: 1.1157 - val_p_acc: 0.4808\n",
      "Epoch 1352/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9513 - p_acc: 0.5929 - val_loss: 1.1173 - val_p_acc: 0.4984\n",
      "Epoch 1353/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9283 - p_acc: 0.6386 - val_loss: 1.1176 - val_p_acc: 0.4631\n",
      "Epoch 1354/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9293 - p_acc: 0.6538 - val_loss: 1.1170 - val_p_acc: 0.5337\n",
      "Epoch 1355/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9315 - p_acc: 0.6018 - val_loss: 1.1152 - val_p_acc: 0.4455\n",
      "Epoch 1356/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9576 - p_acc: 0.5825 - val_loss: 1.1144 - val_p_acc: 0.4984\n",
      "Epoch 1357/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9187 - p_acc: 0.6346 - val_loss: 1.1145 - val_p_acc: 0.4631\n",
      "Epoch 1358/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8962 - p_acc: 0.6522 - val_loss: 1.1137 - val_p_acc: 0.4631\n",
      "Epoch 1359/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9679 - p_acc: 0.5825 - val_loss: 1.1137 - val_p_acc: 0.4808\n",
      "Epoch 1360/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9807 - p_acc: 0.5409 - val_loss: 1.1141 - val_p_acc: 0.4984\n",
      "Epoch 1361/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9280 - p_acc: 0.6611 - val_loss: 1.1145 - val_p_acc: 0.5160\n",
      "Epoch 1362/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9540 - p_acc: 0.5913 - val_loss: 1.1144 - val_p_acc: 0.5160\n",
      "Epoch 1363/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9375 - p_acc: 0.6018 - val_loss: 1.1139 - val_p_acc: 0.4455\n",
      "Epoch 1364/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9366 - p_acc: 0.5825 - val_loss: 1.1139 - val_p_acc: 0.5337\n",
      "Epoch 1365/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9210 - p_acc: 0.6018 - val_loss: 1.1140 - val_p_acc: 0.4631\n",
      "Epoch 1366/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9907 - p_acc: 0.6090 - val_loss: 1.1138 - val_p_acc: 0.4631\n",
      "Epoch 1367/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9656 - p_acc: 0.4936 - val_loss: 1.1145 - val_p_acc: 0.5160\n",
      "Epoch 1368/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9603 - p_acc: 0.5865 - val_loss: 1.1135 - val_p_acc: 0.4455\n",
      "Epoch 1369/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9406 - p_acc: 0.6210 - val_loss: 1.1138 - val_p_acc: 0.4808\n",
      "Epoch 1370/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0163 - p_acc: 0.4936 - val_loss: 1.1139 - val_p_acc: 0.4631\n",
      "Epoch 1371/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9863 - p_acc: 0.5601 - val_loss: 1.1142 - val_p_acc: 0.4984\n",
      "Epoch 1372/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9097 - p_acc: 0.5633 - val_loss: 1.1136 - val_p_acc: 0.4984\n",
      "Epoch 1373/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9622 - p_acc: 0.5096 - val_loss: 1.1129 - val_p_acc: 0.4808\n",
      "Epoch 1374/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9751 - p_acc: 0.6106 - val_loss: 1.1137 - val_p_acc: 0.5192\n",
      "Epoch 1375/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0799 - p_acc: 0.4832 - val_loss: 1.1134 - val_p_acc: 0.5545\n",
      "Epoch 1376/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8726 - p_acc: 0.6538 - val_loss: 1.1127 - val_p_acc: 0.5016\n",
      "Epoch 1377/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9118 - p_acc: 0.6106 - val_loss: 1.1128 - val_p_acc: 0.5016\n",
      "Epoch 1378/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9570 - p_acc: 0.5737 - val_loss: 1.1120 - val_p_acc: 0.4840\n",
      "Epoch 1379/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9523 - p_acc: 0.5809 - val_loss: 1.1121 - val_p_acc: 0.5016\n",
      "Epoch 1380/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9716 - p_acc: 0.6018 - val_loss: 1.1120 - val_p_acc: 0.4840\n",
      "Epoch 1381/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0020 - p_acc: 0.5144 - val_loss: 1.1115 - val_p_acc: 0.4840\n",
      "Epoch 1382/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9672 - p_acc: 0.6034 - val_loss: 1.1118 - val_p_acc: 0.5192\n",
      "Epoch 1383/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9219 - p_acc: 0.6034 - val_loss: 1.1129 - val_p_acc: 0.5016\n",
      "Epoch 1384/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9341 - p_acc: 0.6314 - val_loss: 1.1131 - val_p_acc: 0.5192\n",
      "Epoch 1385/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9372 - p_acc: 0.6819 - val_loss: 1.1143 - val_p_acc: 0.5192\n",
      "Epoch 1386/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9068 - p_acc: 0.5529 - val_loss: 1.1143 - val_p_acc: 0.5192\n",
      "Epoch 1387/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9420 - p_acc: 0.5393 - val_loss: 1.1131 - val_p_acc: 0.5369\n",
      "Epoch 1388/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9825 - p_acc: 0.6210 - val_loss: 1.1133 - val_p_acc: 0.5016\n",
      "Epoch 1389/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9701 - p_acc: 0.6627 - val_loss: 1.1143 - val_p_acc: 0.4840\n",
      "Epoch 1390/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0123 - p_acc: 0.6002 - val_loss: 1.1152 - val_p_acc: 0.5369\n",
      "Epoch 1391/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9959 - p_acc: 0.6538 - val_loss: 1.1154 - val_p_acc: 0.4663\n",
      "Epoch 1392/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0452 - p_acc: 0.5184 - val_loss: 1.1159 - val_p_acc: 0.5369\n",
      "Epoch 1393/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9944 - p_acc: 0.5913 - val_loss: 1.1169 - val_p_acc: 0.5192\n",
      "Epoch 1394/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9549 - p_acc: 0.5705 - val_loss: 1.1161 - val_p_acc: 0.5016\n",
      "Epoch 1395/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9575 - p_acc: 0.6034 - val_loss: 1.1149 - val_p_acc: 0.5369\n",
      "Epoch 1396/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9325 - p_acc: 0.5841 - val_loss: 1.1148 - val_p_acc: 0.5545\n",
      "Epoch 1397/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9134 - p_acc: 0.5913 - val_loss: 1.1143 - val_p_acc: 0.5016\n",
      "Epoch 1398/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8913 - p_acc: 0.5721 - val_loss: 1.1133 - val_p_acc: 0.5192\n",
      "Epoch 1399/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9781 - p_acc: 0.5096 - val_loss: 1.1142 - val_p_acc: 0.4663\n",
      "Epoch 1400/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9086 - p_acc: 0.5857 - val_loss: 1.1142 - val_p_acc: 0.5192\n",
      "Epoch 1401/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9446 - p_acc: 0.5857 - val_loss: 1.1136 - val_p_acc: 0.5369\n",
      "Epoch 1402/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8812 - p_acc: 0.6538 - val_loss: 1.1128 - val_p_acc: 0.5369\n",
      "Epoch 1403/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.9017 - p_acc: 0.6242 - val_loss: 1.1124 - val_p_acc: 0.4840\n",
      "Epoch 1404/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9391 - p_acc: 0.5409 - val_loss: 1.1123 - val_p_acc: 0.5192\n",
      "Epoch 1405/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9736 - p_acc: 0.5441 - val_loss: 1.1129 - val_p_acc: 0.4663\n",
      "Epoch 1406/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0031 - p_acc: 0.6106 - val_loss: 1.1130 - val_p_acc: 0.4840\n",
      "Epoch 1407/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9835 - p_acc: 0.5216 - val_loss: 1.1128 - val_p_acc: 0.5016\n",
      "Epoch 1408/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8431 - p_acc: 0.5721 - val_loss: 1.1126 - val_p_acc: 0.5016\n",
      "Epoch 1409/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9697 - p_acc: 0.5673 - val_loss: 1.1132 - val_p_acc: 0.4663\n",
      "Epoch 1410/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9521 - p_acc: 0.5112 - val_loss: 1.1128 - val_p_acc: 0.4663\n",
      "Epoch 1411/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9431 - p_acc: 0.5569 - val_loss: 1.1108 - val_p_acc: 0.5545\n",
      "Epoch 1412/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9524 - p_acc: 0.6194 - val_loss: 1.1098 - val_p_acc: 0.5369\n",
      "Epoch 1413/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9539 - p_acc: 0.6106 - val_loss: 1.1100 - val_p_acc: 0.5192\n",
      "Epoch 1414/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8894 - p_acc: 0.6138 - val_loss: 1.1101 - val_p_acc: 0.5192\n",
      "Epoch 1415/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8864 - p_acc: 0.6699 - val_loss: 1.1103 - val_p_acc: 0.4663\n",
      "Epoch 1416/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0663 - p_acc: 0.5441 - val_loss: 1.1097 - val_p_acc: 0.5192\n",
      "Epoch 1417/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8831 - p_acc: 0.5353 - val_loss: 1.1084 - val_p_acc: 0.5369\n",
      "Epoch 1418/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0013 - p_acc: 0.6194 - val_loss: 1.1077 - val_p_acc: 0.5192\n",
      "Epoch 1419/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9270 - p_acc: 0.6643 - val_loss: 1.1088 - val_p_acc: 0.4840\n",
      "Epoch 1420/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9133 - p_acc: 0.5986 - val_loss: 1.1083 - val_p_acc: 0.5369\n",
      "Epoch 1421/5000\n",
      "85/85 [==============================] - 0s 717us/sample - loss: 0.9717 - p_acc: 0.5986 - val_loss: 1.1082 - val_p_acc: 0.5369\n",
      "Epoch 1422/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9207 - p_acc: 0.6002 - val_loss: 1.1087 - val_p_acc: 0.5369\n",
      "Epoch 1423/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9506 - p_acc: 0.5497 - val_loss: 1.1089 - val_p_acc: 0.4840\n",
      "Epoch 1424/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9756 - p_acc: 0.6002 - val_loss: 1.1099 - val_p_acc: 0.5192\n",
      "Epoch 1425/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9158 - p_acc: 0.6314 - val_loss: 1.1102 - val_p_acc: 0.5369\n",
      "Epoch 1426/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9430 - p_acc: 0.6002 - val_loss: 1.1102 - val_p_acc: 0.5545\n",
      "Epoch 1427/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9520 - p_acc: 0.6418 - val_loss: 1.1121 - val_p_acc: 0.4311\n",
      "Epoch 1428/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9886 - p_acc: 0.5112 - val_loss: 1.1132 - val_p_acc: 0.5192\n",
      "Epoch 1429/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9560 - p_acc: 0.5128 - val_loss: 1.1127 - val_p_acc: 0.5016\n",
      "Epoch 1430/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9647 - p_acc: 0.5825 - val_loss: 1.1126 - val_p_acc: 0.5192\n",
      "Epoch 1431/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9710 - p_acc: 0.6122 - val_loss: 1.1136 - val_p_acc: 0.5192\n",
      "Epoch 1432/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9841 - p_acc: 0.6434 - val_loss: 1.1132 - val_p_acc: 0.5016\n",
      "Epoch 1433/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8897 - p_acc: 0.6258 - val_loss: 1.1133 - val_p_acc: 0.5192\n",
      "Epoch 1434/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9568 - p_acc: 0.6210 - val_loss: 1.1123 - val_p_acc: 0.5016\n",
      "Epoch 1435/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8151 - p_acc: 0.708 - 0s 692us/sample - loss: 0.9138 - p_acc: 0.6314 - val_loss: 1.1136 - val_p_acc: 0.4663\n",
      "Epoch 1436/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9816 - p_acc: 0.6554 - val_loss: 1.1138 - val_p_acc: 0.5192\n",
      "Epoch 1437/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9099 - p_acc: 0.6106 - val_loss: 1.1143 - val_p_acc: 0.5369\n",
      "Epoch 1438/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9101 - p_acc: 0.6434 - val_loss: 1.1146 - val_p_acc: 0.4663\n",
      "Epoch 1439/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9403 - p_acc: 0.5040 - val_loss: 1.1144 - val_p_acc: 0.5016\n",
      "Epoch 1440/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8973 - p_acc: 0.6018 - val_loss: 1.1146 - val_p_acc: 0.5192\n",
      "Epoch 1441/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9626 - p_acc: 0.5929 - val_loss: 1.1137 - val_p_acc: 0.5192\n",
      "Epoch 1442/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9881 - p_acc: 0.5513 - val_loss: 1.1136 - val_p_acc: 0.5016\n",
      "Epoch 1443/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9317 - p_acc: 0.6002 - val_loss: 1.1143 - val_p_acc: 0.5016\n",
      "Epoch 1444/5000\n",
      "85/85 [==============================] - 0s 689us/sample - loss: 0.9698 - p_acc: 0.5337 - val_loss: 1.1155 - val_p_acc: 0.4840\n",
      "Epoch 1445/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9098 - p_acc: 0.5809 - val_loss: 1.1153 - val_p_acc: 0.4840\n",
      "Epoch 1446/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9224 - p_acc: 0.6699 - val_loss: 1.1146 - val_p_acc: 0.5192\n",
      "Epoch 1447/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9747 - p_acc: 0.6923 - val_loss: 1.1143 - val_p_acc: 0.4487\n",
      "Epoch 1448/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8868 - p_acc: 0.6258 - val_loss: 1.1144 - val_p_acc: 0.5192\n",
      "Epoch 1449/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9532 - p_acc: 0.5617 - val_loss: 1.1146 - val_p_acc: 0.5192\n",
      "Epoch 1450/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9398 - p_acc: 0.5793 - val_loss: 1.1149 - val_p_acc: 0.5016\n",
      "Epoch 1451/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0507 - p_acc: 0.5200 - val_loss: 1.1137 - val_p_acc: 0.5016\n",
      "Epoch 1452/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0206 - p_acc: 0.5753 - val_loss: 1.1145 - val_p_acc: 0.4840\n",
      "Epoch 1453/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9234 - p_acc: 0.5304 - val_loss: 1.1144 - val_p_acc: 0.5721\n",
      "Epoch 1454/5000\n",
      "85/85 [==============================] - 0s 688us/sample - loss: 0.9038 - p_acc: 0.6194 - val_loss: 1.1140 - val_p_acc: 0.5369\n",
      "Epoch 1455/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9273 - p_acc: 0.6122 - val_loss: 1.1134 - val_p_acc: 0.5192\n",
      "Epoch 1456/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9131 - p_acc: 0.5633 - val_loss: 1.1130 - val_p_acc: 0.5016\n",
      "Epoch 1457/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9863 - p_acc: 0.5232 - val_loss: 1.1144 - val_p_acc: 0.4311\n",
      "Epoch 1458/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8870 - p_acc: 0.6018 - val_loss: 1.1151 - val_p_acc: 0.5192\n",
      "Epoch 1459/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9558 - p_acc: 0.6138 - val_loss: 1.1157 - val_p_acc: 0.5192\n",
      "Epoch 1460/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9022 - p_acc: 0.6282 - val_loss: 1.1165 - val_p_acc: 0.5369\n",
      "Epoch 1461/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9496 - p_acc: 0.5601 - val_loss: 1.1155 - val_p_acc: 0.5721\n",
      "Epoch 1462/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9037 - p_acc: 0.5962 - val_loss: 1.1162 - val_p_acc: 0.4840\n",
      "Epoch 1463/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9284 - p_acc: 0.5080 - val_loss: 1.1174 - val_p_acc: 0.5192\n",
      "Epoch 1464/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9848 - p_acc: 0.6242 - val_loss: 1.1169 - val_p_acc: 0.5192\n",
      "Epoch 1465/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9381 - p_acc: 0.5913 - val_loss: 1.1176 - val_p_acc: 0.4840\n",
      "Epoch 1466/5000\n",
      "85/85 [==============================] - 0s 709us/sample - loss: 0.9875 - p_acc: 0.5481 - val_loss: 1.1172 - val_p_acc: 0.4840\n",
      "Epoch 1467/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9934 - p_acc: 0.5753 - val_loss: 1.1179 - val_p_acc: 0.5369\n",
      "Epoch 1468/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8937 - p_acc: 0.6194 - val_loss: 1.1188 - val_p_acc: 0.5192\n",
      "Epoch 1469/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9484 - p_acc: 0.5513 - val_loss: 1.1185 - val_p_acc: 0.5545\n",
      "Epoch 1470/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9205 - p_acc: 0.6611 - val_loss: 1.1185 - val_p_acc: 0.5016\n",
      "Epoch 1471/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9317 - p_acc: 0.6538 - val_loss: 1.1184 - val_p_acc: 0.5369\n",
      "Epoch 1472/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9144 - p_acc: 0.6002 - val_loss: 1.1177 - val_p_acc: 0.5016\n",
      "Epoch 1473/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9436 - p_acc: 0.6330 - val_loss: 1.1174 - val_p_acc: 0.5369\n",
      "Epoch 1474/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9168 - p_acc: 0.5705 - val_loss: 1.1189 - val_p_acc: 0.5016\n",
      "Epoch 1475/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9711 - p_acc: 0.5232 - val_loss: 1.1195 - val_p_acc: 0.5192\n",
      "Epoch 1476/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9253 - p_acc: 0.6659 - val_loss: 1.1200 - val_p_acc: 0.5545\n",
      "Epoch 1477/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9028 - p_acc: 0.6627 - val_loss: 1.1212 - val_p_acc: 0.4840\n",
      "Epoch 1478/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8887 - p_acc: 0.6923 - val_loss: 1.1210 - val_p_acc: 0.5016\n",
      "Epoch 1479/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9786 - p_acc: 0.5545 - val_loss: 1.1219 - val_p_acc: 0.5016\n",
      "Epoch 1480/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9572 - p_acc: 0.5200 - val_loss: 1.1224 - val_p_acc: 0.4663\n",
      "Epoch 1481/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9899 - p_acc: 0.5946 - val_loss: 1.1227 - val_p_acc: 0.5545\n",
      "Epoch 1482/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9715 - p_acc: 0.6330 - val_loss: 1.1220 - val_p_acc: 0.5192\n",
      "Epoch 1483/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9946 - p_acc: 0.5497 - val_loss: 1.1219 - val_p_acc: 0.5016\n",
      "Epoch 1484/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9842 - p_acc: 0.5617 - val_loss: 1.1217 - val_p_acc: 0.5016\n",
      "Epoch 1485/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9372 - p_acc: 0.6715 - val_loss: 1.1216 - val_p_acc: 0.5192\n",
      "Epoch 1486/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8599 - p_acc: 0.6418 - val_loss: 1.1216 - val_p_acc: 0.5192\n",
      "Epoch 1487/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9456 - p_acc: 0.6002 - val_loss: 1.1202 - val_p_acc: 0.4840\n",
      "Epoch 1488/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8806 - p_acc: 0.6090 - val_loss: 1.1198 - val_p_acc: 0.5192\n",
      "Epoch 1489/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9284 - p_acc: 0.6138 - val_loss: 1.1196 - val_p_acc: 0.5721\n",
      "Epoch 1490/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9187 - p_acc: 0.6627 - val_loss: 1.1188 - val_p_acc: 0.5016\n",
      "Epoch 1491/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9737 - p_acc: 0.5857 - val_loss: 1.1186 - val_p_acc: 0.5721\n",
      "Epoch 1492/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8987 - p_acc: 0.5986 - val_loss: 1.1188 - val_p_acc: 0.5369\n",
      "Epoch 1493/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9553 - p_acc: 0.6050 - val_loss: 1.1189 - val_p_acc: 0.5016\n",
      "Epoch 1494/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9266 - p_acc: 0.5337 - val_loss: 1.1185 - val_p_acc: 0.5369\n",
      "Epoch 1495/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9840 - p_acc: 0.5825 - val_loss: 1.1178 - val_p_acc: 0.5545\n",
      "Epoch 1496/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9384 - p_acc: 0.6538 - val_loss: 1.1189 - val_p_acc: 0.5545\n",
      "Epoch 1497/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9026 - p_acc: 0.5665 - val_loss: 1.1197 - val_p_acc: 0.5545\n",
      "Epoch 1498/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9190 - p_acc: 0.5753 - val_loss: 1.1199 - val_p_acc: 0.4663\n",
      "Epoch 1499/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8931 - p_acc: 0.6418 - val_loss: 1.1198 - val_p_acc: 0.5192\n",
      "Epoch 1500/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9191 - p_acc: 0.6242 - val_loss: 1.1195 - val_p_acc: 0.4840\n",
      "Epoch 1501/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9533 - p_acc: 0.6314 - val_loss: 1.1183 - val_p_acc: 0.5016\n",
      "Epoch 1502/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.9280 - p_acc: 0.6522 - val_loss: 1.1191 - val_p_acc: 0.4840\n",
      "Epoch 1503/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8733 - p_acc: 0.6386 - val_loss: 1.1189 - val_p_acc: 0.4840\n",
      "Epoch 1504/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9305 - p_acc: 0.5841 - val_loss: 1.1196 - val_p_acc: 0.4840\n",
      "Epoch 1505/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9342 - p_acc: 0.5946 - val_loss: 1.1198 - val_p_acc: 0.4840\n",
      "Epoch 1506/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8923 - p_acc: 0.6611 - val_loss: 1.1188 - val_p_acc: 0.5192\n",
      "Epoch 1507/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9480 - p_acc: 0.5721 - val_loss: 1.1177 - val_p_acc: 0.5192\n",
      "Epoch 1508/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9502 - p_acc: 0.5633 - val_loss: 1.1178 - val_p_acc: 0.5192\n",
      "Epoch 1509/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9656 - p_acc: 0.6122 - val_loss: 1.1178 - val_p_acc: 0.5016\n",
      "Epoch 1510/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9438 - p_acc: 0.5481 - val_loss: 1.1173 - val_p_acc: 0.5369\n",
      "Epoch 1511/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9146 - p_acc: 0.5705 - val_loss: 1.1169 - val_p_acc: 0.5369\n",
      "Epoch 1512/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9561 - p_acc: 0.5545 - val_loss: 1.1172 - val_p_acc: 0.4840\n",
      "Epoch 1513/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9547 - p_acc: 0.5897 - val_loss: 1.1178 - val_p_acc: 0.5192\n",
      "Epoch 1514/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0189 - p_acc: 0.5304 - val_loss: 1.1182 - val_p_acc: 0.5192\n",
      "Epoch 1515/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9637 - p_acc: 0.6226 - val_loss: 1.1181 - val_p_acc: 0.4663\n",
      "Epoch 1516/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0287 - p_acc: 0.4832 - val_loss: 1.1179 - val_p_acc: 0.5369\n",
      "Epoch 1517/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9255 - p_acc: 0.6106 - val_loss: 1.1186 - val_p_acc: 0.5192\n",
      "Epoch 1518/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8849 - p_acc: 0.6034 - val_loss: 1.1179 - val_p_acc: 0.5369\n",
      "Epoch 1519/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9119 - p_acc: 0.6242 - val_loss: 1.1177 - val_p_acc: 0.4663\n",
      "Epoch 1520/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9302 - p_acc: 0.6138 - val_loss: 1.1187 - val_p_acc: 0.5016\n",
      "Epoch 1521/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 0.9510 - p_acc: 0.5425 - val_loss: 1.1186 - val_p_acc: 0.5545\n",
      "Epoch 1522/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9060 - p_acc: 0.6346 - val_loss: 1.1187 - val_p_acc: 0.5545\n",
      "Epoch 1523/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9472 - p_acc: 0.5545 - val_loss: 1.1175 - val_p_acc: 0.5192\n",
      "Epoch 1524/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9490 - p_acc: 0.6122 - val_loss: 1.1176 - val_p_acc: 0.5016\n",
      "Epoch 1525/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8588 - p_acc: 0.6330 - val_loss: 1.1188 - val_p_acc: 0.5721\n",
      "Epoch 1526/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9613 - p_acc: 0.6731 - val_loss: 1.1185 - val_p_acc: 0.5192\n",
      "Epoch 1527/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9292 - p_acc: 0.6194 - val_loss: 1.1181 - val_p_acc: 0.5192\n",
      "Epoch 1528/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8896 - p_acc: 0.6522 - val_loss: 1.1167 - val_p_acc: 0.4840\n",
      "Epoch 1529/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9219 - p_acc: 0.6034 - val_loss: 1.1172 - val_p_acc: 0.4487\n",
      "Epoch 1530/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9548 - p_acc: 0.5513 - val_loss: 1.1171 - val_p_acc: 0.5369\n",
      "Epoch 1531/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0474 - p_acc: 0.5809 - val_loss: 1.1166 - val_p_acc: 0.5369\n",
      "Epoch 1532/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9216 - p_acc: 0.6002 - val_loss: 1.1163 - val_p_acc: 0.5016\n",
      "Epoch 1533/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9740 - p_acc: 0.6154 - val_loss: 1.1162 - val_p_acc: 0.4840\n",
      "Epoch 1534/5000\n",
      "85/85 [==============================] - 0s 710us/sample - loss: 0.9106 - p_acc: 0.6018 - val_loss: 1.1150 - val_p_acc: 0.5369\n",
      "Epoch 1535/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9418 - p_acc: 0.6282 - val_loss: 1.1138 - val_p_acc: 0.5016\n",
      "Epoch 1536/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9978 - p_acc: 0.6018 - val_loss: 1.1130 - val_p_acc: 0.5016\n",
      "Epoch 1537/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9565 - p_acc: 0.5264 - val_loss: 1.1129 - val_p_acc: 0.5016\n",
      "Epoch 1538/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8669 - p_acc: 0.6122 - val_loss: 1.1126 - val_p_acc: 0.5016\n",
      "Epoch 1539/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9618 - p_acc: 0.6210 - val_loss: 1.1123 - val_p_acc: 0.5369\n",
      "Epoch 1540/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8610 - p_acc: 0.5721 - val_loss: 1.1141 - val_p_acc: 0.5369\n",
      "Epoch 1541/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8615 - p_acc: 0.5825 - val_loss: 1.1146 - val_p_acc: 0.5016\n",
      "Epoch 1542/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8664 - p_acc: 0.6138 - val_loss: 1.1152 - val_p_acc: 0.4487\n",
      "Epoch 1543/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9477 - p_acc: 0.6122 - val_loss: 1.1149 - val_p_acc: 0.5192\n",
      "Epoch 1544/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9550 - p_acc: 0.5705 - val_loss: 1.1161 - val_p_acc: 0.4840\n",
      "Epoch 1545/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9167 - p_acc: 0.6731 - val_loss: 1.1156 - val_p_acc: 0.5192\n",
      "Epoch 1546/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9785 - p_acc: 0.5633 - val_loss: 1.1168 - val_p_acc: 0.5192\n",
      "Epoch 1547/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9610 - p_acc: 0.5288 - val_loss: 1.1173 - val_p_acc: 0.4663\n",
      "Epoch 1548/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8558 - p_acc: 0.6731 - val_loss: 1.1170 - val_p_acc: 0.4840\n",
      "Epoch 1549/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9210 - p_acc: 0.6210 - val_loss: 1.1167 - val_p_acc: 0.5192\n",
      "Epoch 1550/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0020 - p_acc: 0.6210 - val_loss: 1.1169 - val_p_acc: 0.5016\n",
      "Epoch 1551/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9759 - p_acc: 0.6210 - val_loss: 1.1165 - val_p_acc: 0.5369\n",
      "Epoch 1552/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9674 - p_acc: 0.4832 - val_loss: 1.1168 - val_p_acc: 0.5192\n",
      "Epoch 1553/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8635 - p_acc: 0.583 - 0s 704us/sample - loss: 0.9104 - p_acc: 0.6402 - val_loss: 1.1165 - val_p_acc: 0.5192\n",
      "Epoch 1554/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8911 - p_acc: 0.7043 - val_loss: 1.1162 - val_p_acc: 0.5192\n",
      "Epoch 1555/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9163 - p_acc: 0.6210 - val_loss: 1.1160 - val_p_acc: 0.5016\n",
      "Epoch 1556/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9752 - p_acc: 0.5913 - val_loss: 1.1164 - val_p_acc: 0.4663\n",
      "Epoch 1557/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8589 - p_acc: 0.6907 - val_loss: 1.1153 - val_p_acc: 0.5016\n",
      "Epoch 1558/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9192 - p_acc: 0.5809 - val_loss: 1.1154 - val_p_acc: 0.4840\n",
      "Epoch 1559/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9614 - p_acc: 0.6298 - val_loss: 1.1157 - val_p_acc: 0.5192\n",
      "Epoch 1560/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9535 - p_acc: 0.5200 - val_loss: 1.1150 - val_p_acc: 0.5369\n",
      "Epoch 1561/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8983 - p_acc: 0.6418 - val_loss: 1.1148 - val_p_acc: 0.5192\n",
      "Epoch 1562/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8650 - p_acc: 0.7043 - val_loss: 1.1155 - val_p_acc: 0.4840\n",
      "Epoch 1563/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9020 - p_acc: 0.5929 - val_loss: 1.1142 - val_p_acc: 0.5016\n",
      "Epoch 1564/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9155 - p_acc: 0.6538 - val_loss: 1.1140 - val_p_acc: 0.5016\n",
      "Epoch 1565/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9393 - p_acc: 0.6314 - val_loss: 1.1141 - val_p_acc: 0.5016\n",
      "Epoch 1566/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9602 - p_acc: 0.6122 - val_loss: 1.1121 - val_p_acc: 0.5016\n",
      "Epoch 1567/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9321 - p_acc: 0.6002 - val_loss: 1.1110 - val_p_acc: 0.5545\n",
      "Epoch 1568/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9657 - p_acc: 0.5321 - val_loss: 1.1103 - val_p_acc: 0.5369\n",
      "Epoch 1569/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0340 - p_acc: 0.5705 - val_loss: 1.1113 - val_p_acc: 0.5016\n",
      "Epoch 1570/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9293 - p_acc: 0.5857 - val_loss: 1.1123 - val_p_acc: 0.5369\n",
      "Epoch 1571/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9428 - p_acc: 0.6627 - val_loss: 1.1128 - val_p_acc: 0.4487\n",
      "Epoch 1572/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9977 - p_acc: 0.4992 - val_loss: 1.1137 - val_p_acc: 0.5192\n",
      "Epoch 1573/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0095 - p_acc: 0.6330 - val_loss: 1.1149 - val_p_acc: 0.5545\n",
      "Epoch 1574/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9009 - p_acc: 0.6122 - val_loss: 1.1156 - val_p_acc: 0.5369\n",
      "Epoch 1575/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9487 - p_acc: 0.5705 - val_loss: 1.1167 - val_p_acc: 0.5016\n",
      "Epoch 1576/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9936 - p_acc: 0.5777 - val_loss: 1.1172 - val_p_acc: 0.5016\n",
      "Epoch 1577/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9932 - p_acc: 0.5617 - val_loss: 1.1160 - val_p_acc: 0.4487\n",
      "Epoch 1578/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9364 - p_acc: 0.5665 - val_loss: 1.1162 - val_p_acc: 0.5192\n",
      "Epoch 1579/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9759 - p_acc: 0.6675 - val_loss: 1.1173 - val_p_acc: 0.5192\n",
      "Epoch 1580/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0359 - p_acc: 0.5321 - val_loss: 1.1169 - val_p_acc: 0.5192\n",
      "Epoch 1581/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8853 - p_acc: 0.6090 - val_loss: 1.1164 - val_p_acc: 0.5369\n",
      "Epoch 1582/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9669 - p_acc: 0.6538 - val_loss: 1.1168 - val_p_acc: 0.5016\n",
      "Epoch 1583/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9258 - p_acc: 0.5929 - val_loss: 1.1175 - val_p_acc: 0.5545\n",
      "Epoch 1584/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9451 - p_acc: 0.6050 - val_loss: 1.1185 - val_p_acc: 0.5369\n",
      "Epoch 1585/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0104 - p_acc: 0.6803 - val_loss: 1.1196 - val_p_acc: 0.4840\n",
      "Epoch 1586/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9375 - p_acc: 0.6210 - val_loss: 1.1186 - val_p_acc: 0.5192\n",
      "Epoch 1587/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8752 - p_acc: 0.5897 - val_loss: 1.1181 - val_p_acc: 0.5369\n",
      "Epoch 1588/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9369 - p_acc: 0.5946 - val_loss: 1.1177 - val_p_acc: 0.4840\n",
      "Epoch 1589/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9216 - p_acc: 0.5913 - val_loss: 1.1170 - val_p_acc: 0.4840\n",
      "Epoch 1590/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0383 - p_acc: 0.5200 - val_loss: 1.1163 - val_p_acc: 0.5016\n",
      "Epoch 1591/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8852 - p_acc: 0.6538 - val_loss: 1.1162 - val_p_acc: 0.5545\n",
      "Epoch 1592/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9293 - p_acc: 0.6386 - val_loss: 1.1162 - val_p_acc: 0.5192\n",
      "Epoch 1593/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9970 - p_acc: 0.5793 - val_loss: 1.1158 - val_p_acc: 0.5192\n",
      "Epoch 1594/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9430 - p_acc: 0.6538 - val_loss: 1.1161 - val_p_acc: 0.4840\n",
      "Epoch 1595/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9548 - p_acc: 0.6611 - val_loss: 1.1160 - val_p_acc: 0.5192\n",
      "Epoch 1596/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9342 - p_acc: 0.5777 - val_loss: 1.1152 - val_p_acc: 0.5369\n",
      "Epoch 1597/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9659 - p_acc: 0.6018 - val_loss: 1.1136 - val_p_acc: 0.5192\n",
      "Epoch 1598/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8399 - p_acc: 0.7027 - val_loss: 1.1128 - val_p_acc: 0.5192\n",
      "Epoch 1599/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9265 - p_acc: 0.6242 - val_loss: 1.1136 - val_p_acc: 0.5192\n",
      "Epoch 1600/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9695 - p_acc: 0.5793 - val_loss: 1.1136 - val_p_acc: 0.4840\n",
      "Epoch 1601/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8746 - p_acc: 0.6242 - val_loss: 1.1137 - val_p_acc: 0.5369\n",
      "Epoch 1602/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9654 - p_acc: 0.6226 - val_loss: 1.1122 - val_p_acc: 0.5192\n",
      "Epoch 1603/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9740 - p_acc: 0.5689 - val_loss: 1.1135 - val_p_acc: 0.5192\n",
      "Epoch 1604/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8932 - p_acc: 0.5545 - val_loss: 1.1145 - val_p_acc: 0.5192\n",
      "Epoch 1605/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9256 - p_acc: 0.6210 - val_loss: 1.1148 - val_p_acc: 0.5192\n",
      "Epoch 1606/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9765 - p_acc: 0.5897 - val_loss: 1.1148 - val_p_acc: 0.5016\n",
      "Epoch 1607/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8804 - p_acc: 0.6506 - val_loss: 1.1152 - val_p_acc: 0.5016\n",
      "Epoch 1608/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8652 - p_acc: 0.6210 - val_loss: 1.1146 - val_p_acc: 0.5192\n",
      "Epoch 1609/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9150 - p_acc: 0.6106 - val_loss: 1.1146 - val_p_acc: 0.5721\n",
      "Epoch 1610/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9376 - p_acc: 0.5946 - val_loss: 1.1137 - val_p_acc: 0.4840\n",
      "Epoch 1611/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8968 - p_acc: 0.5529 - val_loss: 1.1135 - val_p_acc: 0.5016\n",
      "Epoch 1612/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9466 - p_acc: 0.6018 - val_loss: 1.1134 - val_p_acc: 0.4840\n",
      "Epoch 1613/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9143 - p_acc: 0.6298 - val_loss: 1.1142 - val_p_acc: 0.5192\n",
      "Epoch 1614/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8648 - p_acc: 0.6226 - val_loss: 1.1140 - val_p_acc: 0.5897\n",
      "Epoch 1615/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0311 - p_acc: 0.4535 - val_loss: 1.1131 - val_p_acc: 0.5016\n",
      "Epoch 1616/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9200 - p_acc: 0.5825 - val_loss: 1.1133 - val_p_acc: 0.5545\n",
      "Epoch 1617/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9414 - p_acc: 0.5617 - val_loss: 1.1126 - val_p_acc: 0.5545\n",
      "Epoch 1618/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9645 - p_acc: 0.5529 - val_loss: 1.1119 - val_p_acc: 0.5016\n",
      "Epoch 1619/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9396 - p_acc: 0.5913 - val_loss: 1.1112 - val_p_acc: 0.5369\n",
      "Epoch 1620/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8691 - p_acc: 0.6434 - val_loss: 1.1100 - val_p_acc: 0.5192\n",
      "Epoch 1621/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9319 - p_acc: 0.6018 - val_loss: 1.1084 - val_p_acc: 0.5192\n",
      "Epoch 1622/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8590 - p_acc: 0.541 - 0s 681us/sample - loss: 0.8644 - p_acc: 0.6314 - val_loss: 1.1092 - val_p_acc: 0.5016\n",
      "Epoch 1623/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9473 - p_acc: 0.5913 - val_loss: 1.1098 - val_p_acc: 0.5192\n",
      "Epoch 1624/5000\n",
      "85/85 [==============================] - 0s 723us/sample - loss: 0.9652 - p_acc: 0.6330 - val_loss: 1.1095 - val_p_acc: 0.5369\n",
      "Epoch 1625/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9371 - p_acc: 0.6402 - val_loss: 1.1100 - val_p_acc: 0.5192\n",
      "Epoch 1626/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8799 - p_acc: 0.6490 - val_loss: 1.1107 - val_p_acc: 0.5369\n",
      "Epoch 1627/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8510 - p_acc: 0.7308 - val_loss: 1.1112 - val_p_acc: 0.5016\n",
      "Epoch 1628/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9753 - p_acc: 0.5617 - val_loss: 1.1109 - val_p_acc: 0.4840\n",
      "Epoch 1629/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9413 - p_acc: 0.5601 - val_loss: 1.1120 - val_p_acc: 0.5016\n",
      "Epoch 1630/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9568 - p_acc: 0.5705 - val_loss: 1.1120 - val_p_acc: 0.4663\n",
      "Epoch 1631/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8952 - p_acc: 0.6418 - val_loss: 1.1131 - val_p_acc: 0.5192\n",
      "Epoch 1632/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8892 - p_acc: 0.6074 - val_loss: 1.1117 - val_p_acc: 0.4487\n",
      "Epoch 1633/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9465 - p_acc: 0.5232 - val_loss: 1.1111 - val_p_acc: 0.5192\n",
      "Epoch 1634/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9692 - p_acc: 0.5529 - val_loss: 1.1114 - val_p_acc: 0.5721\n",
      "Epoch 1635/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9452 - p_acc: 0.5321 - val_loss: 1.1113 - val_p_acc: 0.4487\n",
      "Epoch 1636/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9427 - p_acc: 0.6418 - val_loss: 1.1104 - val_p_acc: 0.5016\n",
      "Epoch 1637/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8646 - p_acc: 0.7220 - val_loss: 1.1100 - val_p_acc: 0.4840\n",
      "Epoch 1638/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 1.0091 - p_acc: 0.5601 - val_loss: 1.1104 - val_p_acc: 0.5369\n",
      "Epoch 1639/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8966 - p_acc: 0.6298 - val_loss: 1.1101 - val_p_acc: 0.5192\n",
      "Epoch 1640/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9140 - p_acc: 0.5721 - val_loss: 1.1095 - val_p_acc: 0.5369\n",
      "Epoch 1641/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9091 - p_acc: 0.5929 - val_loss: 1.1102 - val_p_acc: 0.5545\n",
      "Epoch 1642/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 1.0260 - p_acc: 0.5825 - val_loss: 1.1109 - val_p_acc: 0.5721\n",
      "Epoch 1643/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8860 - p_acc: 0.6611 - val_loss: 1.1103 - val_p_acc: 0.5369\n",
      "Epoch 1644/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9985 - p_acc: 0.5441 - val_loss: 1.1092 - val_p_acc: 0.5192\n",
      "Epoch 1645/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9151 - p_acc: 0.6434 - val_loss: 1.1087 - val_p_acc: 0.4840\n",
      "Epoch 1646/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9616 - p_acc: 0.5545 - val_loss: 1.1086 - val_p_acc: 0.5192\n",
      "Epoch 1647/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9297 - p_acc: 0.5809 - val_loss: 1.1086 - val_p_acc: 0.5192\n",
      "Epoch 1648/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9504 - p_acc: 0.5793 - val_loss: 1.1092 - val_p_acc: 0.4840\n",
      "Epoch 1649/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8938 - p_acc: 0.5577 - val_loss: 1.1093 - val_p_acc: 0.5369\n",
      "Epoch 1650/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8563 - p_acc: 0.6362 - val_loss: 1.1107 - val_p_acc: 0.4487\n",
      "Epoch 1651/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8587 - p_acc: 0.5721 - val_loss: 1.1118 - val_p_acc: 0.4840\n",
      "Epoch 1652/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9383 - p_acc: 0.5929 - val_loss: 1.1100 - val_p_acc: 0.5016\n",
      "Epoch 1653/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8809 - p_acc: 0.6522 - val_loss: 1.1113 - val_p_acc: 0.5369\n",
      "Epoch 1654/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9562 - p_acc: 0.6242 - val_loss: 1.1111 - val_p_acc: 0.5192\n",
      "Epoch 1655/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8776 - p_acc: 0.6330 - val_loss: 1.1112 - val_p_acc: 0.5016\n",
      "Epoch 1656/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9405 - p_acc: 0.6314 - val_loss: 1.1114 - val_p_acc: 0.5545\n",
      "Epoch 1657/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8973 - p_acc: 0.5441 - val_loss: 1.1128 - val_p_acc: 0.4840\n",
      "Epoch 1658/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9751 - p_acc: 0.5617 - val_loss: 1.1129 - val_p_acc: 0.5369\n",
      "Epoch 1659/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8955 - p_acc: 0.6074 - val_loss: 1.1114 - val_p_acc: 0.5192\n",
      "Epoch 1660/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9354 - p_acc: 0.6923 - val_loss: 1.1114 - val_p_acc: 0.4840\n",
      "Epoch 1661/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9693 - p_acc: 0.6210 - val_loss: 1.1110 - val_p_acc: 0.5016\n",
      "Epoch 1662/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9290 - p_acc: 0.5425 - val_loss: 1.1098 - val_p_acc: 0.5192\n",
      "Epoch 1663/5000\n",
      "85/85 [==============================] - 0s 712us/sample - loss: 0.8760 - p_acc: 0.6466 - val_loss: 1.1099 - val_p_acc: 0.5016\n",
      "Epoch 1664/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8965 - p_acc: 0.6835 - val_loss: 1.1101 - val_p_acc: 0.5369\n",
      "Epoch 1665/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9244 - p_acc: 0.6298 - val_loss: 1.1089 - val_p_acc: 0.5369\n",
      "Epoch 1666/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9144 - p_acc: 0.5633 - val_loss: 1.1087 - val_p_acc: 0.5369\n",
      "Epoch 1667/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9382 - p_acc: 0.6330 - val_loss: 1.1074 - val_p_acc: 0.5192\n",
      "Epoch 1668/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9453 - p_acc: 0.6210 - val_loss: 1.1068 - val_p_acc: 0.4840\n",
      "Epoch 1669/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8988 - p_acc: 0.6106 - val_loss: 1.1054 - val_p_acc: 0.5369\n",
      "Epoch 1670/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9411 - p_acc: 0.5353 - val_loss: 1.1056 - val_p_acc: 0.4487\n",
      "Epoch 1671/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0465 - p_acc: 0.5721 - val_loss: 1.1048 - val_p_acc: 0.4663\n",
      "Epoch 1672/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9666 - p_acc: 0.5633 - val_loss: 1.1038 - val_p_acc: 0.5369\n",
      "Epoch 1673/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9327 - p_acc: 0.6282 - val_loss: 1.1020 - val_p_acc: 0.5192\n",
      "Epoch 1674/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9234 - p_acc: 0.5913 - val_loss: 1.1008 - val_p_acc: 0.4487\n",
      "Epoch 1675/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9205 - p_acc: 0.6018 - val_loss: 1.1009 - val_p_acc: 0.5016\n",
      "Epoch 1676/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8845 - p_acc: 0.6522 - val_loss: 1.1003 - val_p_acc: 0.5192\n",
      "Epoch 1677/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9244 - p_acc: 0.5841 - val_loss: 1.1005 - val_p_acc: 0.5721\n",
      "Epoch 1678/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9005 - p_acc: 0.5825 - val_loss: 1.1019 - val_p_acc: 0.5016\n",
      "Epoch 1679/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8518 - p_acc: 0.5705 - val_loss: 1.1022 - val_p_acc: 0.5192\n",
      "Epoch 1680/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8720 - p_acc: 0.6122 - val_loss: 1.1018 - val_p_acc: 0.5192\n",
      "Epoch 1681/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9653 - p_acc: 0.6194 - val_loss: 1.1011 - val_p_acc: 0.4663\n",
      "Epoch 1682/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9460 - p_acc: 0.6298 - val_loss: 1.0998 - val_p_acc: 0.5545\n",
      "Epoch 1683/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 1.0139 - p_acc: 0.5689 - val_loss: 1.0999 - val_p_acc: 0.5192\n",
      "Epoch 1684/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9290 - p_acc: 0.5721 - val_loss: 1.0996 - val_p_acc: 0.5545\n",
      "Epoch 1685/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9960 - p_acc: 0.6178 - val_loss: 1.0990 - val_p_acc: 0.5192\n",
      "Epoch 1686/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9597 - p_acc: 0.5753 - val_loss: 1.0986 - val_p_acc: 0.5369\n",
      "Epoch 1687/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0308 - p_acc: 0.5913 - val_loss: 1.0981 - val_p_acc: 0.5721\n",
      "Epoch 1688/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9020 - p_acc: 0.6346 - val_loss: 1.0984 - val_p_acc: 0.4840\n",
      "Epoch 1689/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9303 - p_acc: 0.5321 - val_loss: 1.0994 - val_p_acc: 0.4840\n",
      "Epoch 1690/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9129 - p_acc: 0.5841 - val_loss: 1.1006 - val_p_acc: 0.4840\n",
      "Epoch 1691/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9131 - p_acc: 0.5264 - val_loss: 1.1006 - val_p_acc: 0.5016\n",
      "Epoch 1692/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 0.9062 - p_acc: 0.6210 - val_loss: 1.1027 - val_p_acc: 0.4840\n",
      "Epoch 1693/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9680 - p_acc: 0.5008 - val_loss: 1.1044 - val_p_acc: 0.4840\n",
      "Epoch 1694/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9224 - p_acc: 0.6330 - val_loss: 1.1063 - val_p_acc: 0.5192\n",
      "Epoch 1695/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8882 - p_acc: 0.5793 - val_loss: 1.1071 - val_p_acc: 0.4487\n",
      "Epoch 1696/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8828 - p_acc: 0.6106 - val_loss: 1.1073 - val_p_acc: 0.5016\n",
      "Epoch 1697/5000\n",
      "85/85 [==============================] - 0s 738us/sample - loss: 0.8810 - p_acc: 0.6538 - val_loss: 1.1090 - val_p_acc: 0.5369\n",
      "Epoch 1698/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8899 - p_acc: 0.6450 - val_loss: 1.1099 - val_p_acc: 0.4840\n",
      "Epoch 1699/5000\n",
      "85/85 [==============================] - 0s 672us/sample - loss: 0.9187 - p_acc: 0.7011 - val_loss: 1.1114 - val_p_acc: 0.5369\n",
      "Epoch 1700/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9641 - p_acc: 0.5321 - val_loss: 1.1117 - val_p_acc: 0.5016\n",
      "Epoch 1701/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9557 - p_acc: 0.5617 - val_loss: 1.1139 - val_p_acc: 0.4840\n",
      "Epoch 1702/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9836 - p_acc: 0.5441 - val_loss: 1.1141 - val_p_acc: 0.5369\n",
      "Epoch 1703/5000\n",
      "85/85 [==============================] - 0s 684us/sample - loss: 0.9408 - p_acc: 0.6194 - val_loss: 1.1156 - val_p_acc: 0.4840\n",
      "Epoch 1704/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9083 - p_acc: 0.6402 - val_loss: 1.1160 - val_p_acc: 0.5016\n",
      "Epoch 1705/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8943 - p_acc: 0.5321 - val_loss: 1.1156 - val_p_acc: 0.5369\n",
      "Epoch 1706/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8967 - p_acc: 0.6122 - val_loss: 1.1128 - val_p_acc: 0.5192\n",
      "Epoch 1707/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9100 - p_acc: 0.6282 - val_loss: 1.1129 - val_p_acc: 0.5016\n",
      "Epoch 1708/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9087 - p_acc: 0.5529 - val_loss: 1.1128 - val_p_acc: 0.5192\n",
      "Epoch 1709/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9269 - p_acc: 0.5617 - val_loss: 1.1130 - val_p_acc: 0.5369\n",
      "Epoch 1710/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9658 - p_acc: 0.6002 - val_loss: 1.1125 - val_p_acc: 0.5016\n",
      "Epoch 1711/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9032 - p_acc: 0.6226 - val_loss: 1.1128 - val_p_acc: 0.5369\n",
      "Epoch 1712/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8756 - p_acc: 0.5913 - val_loss: 1.1115 - val_p_acc: 0.5016\n",
      "Epoch 1713/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9013 - p_acc: 0.6050 - val_loss: 1.1099 - val_p_acc: 0.5545\n",
      "Epoch 1714/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8618 - p_acc: 0.6763 - val_loss: 1.1087 - val_p_acc: 0.5721\n",
      "Epoch 1715/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9881 - p_acc: 0.5409 - val_loss: 1.1081 - val_p_acc: 0.4840\n",
      "Epoch 1716/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8627 - p_acc: 0.6106 - val_loss: 1.1084 - val_p_acc: 0.5192\n",
      "Epoch 1717/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8770 - p_acc: 0.6434 - val_loss: 1.1098 - val_p_acc: 0.5016\n",
      "Epoch 1718/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9193 - p_acc: 0.6314 - val_loss: 1.1102 - val_p_acc: 0.4840\n",
      "Epoch 1719/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8965 - p_acc: 0.5753 - val_loss: 1.1119 - val_p_acc: 0.5369\n",
      "Epoch 1720/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9794 - p_acc: 0.6138 - val_loss: 1.1125 - val_p_acc: 0.4487\n",
      "Epoch 1721/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9178 - p_acc: 0.5793 - val_loss: 1.1125 - val_p_acc: 0.5016\n",
      "Epoch 1722/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8996 - p_acc: 0.5929 - val_loss: 1.1131 - val_p_acc: 0.4663\n",
      "Epoch 1723/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8795 - p_acc: 0.5946 - val_loss: 1.1134 - val_p_acc: 0.5192\n",
      "Epoch 1724/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8571 - p_acc: 0.6298 - val_loss: 1.1137 - val_p_acc: 0.5721\n",
      "Epoch 1725/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8993 - p_acc: 0.6386 - val_loss: 1.1137 - val_p_acc: 0.5192\n",
      "Epoch 1726/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9222 - p_acc: 0.5841 - val_loss: 1.1132 - val_p_acc: 0.5016\n",
      "Epoch 1727/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8838 - p_acc: 0.6418 - val_loss: 1.1133 - val_p_acc: 0.4840\n",
      "Epoch 1728/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9422 - p_acc: 0.6226 - val_loss: 1.1133 - val_p_acc: 0.5192\n",
      "Epoch 1729/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9339 - p_acc: 0.6210 - val_loss: 1.1155 - val_p_acc: 0.5369\n",
      "Epoch 1730/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 0.9152 - p_acc: 0.5825 - val_loss: 1.1168 - val_p_acc: 0.5192\n",
      "Epoch 1731/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9223 - p_acc: 0.6226 - val_loss: 1.1161 - val_p_acc: 0.5545\n",
      "Epoch 1732/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9041 - p_acc: 0.5825 - val_loss: 1.1158 - val_p_acc: 0.5192\n",
      "Epoch 1733/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8371 - p_acc: 0.5929 - val_loss: 1.1149 - val_p_acc: 0.5192\n",
      "Epoch 1734/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9084 - p_acc: 0.5929 - val_loss: 1.1154 - val_p_acc: 0.5369\n",
      "Epoch 1735/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9567 - p_acc: 0.6907 - val_loss: 1.1141 - val_p_acc: 0.5192\n",
      "Epoch 1736/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8963 - p_acc: 0.5737 - val_loss: 1.1141 - val_p_acc: 0.5369\n",
      "Epoch 1737/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9259 - p_acc: 0.5513 - val_loss: 1.1143 - val_p_acc: 0.5192\n",
      "Epoch 1738/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8950 - p_acc: 0.6122 - val_loss: 1.1131 - val_p_acc: 0.5369\n",
      "Epoch 1739/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8835 - p_acc: 0.5929 - val_loss: 1.1121 - val_p_acc: 0.5192\n",
      "Epoch 1740/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8605 - p_acc: 0.6106 - val_loss: 1.1125 - val_p_acc: 0.5369\n",
      "Epoch 1741/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9057 - p_acc: 0.5529 - val_loss: 1.1136 - val_p_acc: 0.5016\n",
      "Epoch 1742/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8895 - p_acc: 0.6314 - val_loss: 1.1142 - val_p_acc: 0.5369\n",
      "Epoch 1743/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8660 - p_acc: 0.6226 - val_loss: 1.1134 - val_p_acc: 0.4840\n",
      "Epoch 1744/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 1.0269 - p_acc: 0.5425 - val_loss: 1.1117 - val_p_acc: 0.5016\n",
      "Epoch 1745/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8745 - p_acc: 0.6330 - val_loss: 1.1104 - val_p_acc: 0.5016\n",
      "Epoch 1746/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9150 - p_acc: 0.6506 - val_loss: 1.1103 - val_p_acc: 0.5369\n",
      "Epoch 1747/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8905 - p_acc: 0.5721 - val_loss: 1.1086 - val_p_acc: 0.5192\n",
      "Epoch 1748/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9197 - p_acc: 0.6450 - val_loss: 1.1079 - val_p_acc: 0.5369\n",
      "Epoch 1749/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9576 - p_acc: 0.5721 - val_loss: 1.1078 - val_p_acc: 0.4663\n",
      "Epoch 1750/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9629 - p_acc: 0.5497 - val_loss: 1.1064 - val_p_acc: 0.5016\n",
      "Epoch 1751/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9426 - p_acc: 0.5649 - val_loss: 1.1059 - val_p_acc: 0.5369\n",
      "Epoch 1752/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9674 - p_acc: 0.5513 - val_loss: 1.1048 - val_p_acc: 0.4840\n",
      "Epoch 1753/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8751 - p_acc: 0.6194 - val_loss: 1.1051 - val_p_acc: 0.5369\n",
      "Epoch 1754/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8838 - p_acc: 0.5913 - val_loss: 1.1046 - val_p_acc: 0.5545\n",
      "Epoch 1755/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9811 - p_acc: 0.6090 - val_loss: 1.1066 - val_p_acc: 0.4840\n",
      "Epoch 1756/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8791 - p_acc: 0.7115 - val_loss: 1.1058 - val_p_acc: 0.5016\n",
      "Epoch 1757/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9533 - p_acc: 0.6018 - val_loss: 1.1049 - val_p_acc: 0.5192\n",
      "Epoch 1758/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9370 - p_acc: 0.6106 - val_loss: 1.1046 - val_p_acc: 0.5192\n",
      "Epoch 1759/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8520 - p_acc: 0.6210 - val_loss: 1.1061 - val_p_acc: 0.5016\n",
      "Epoch 1760/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8597 - p_acc: 0.6418 - val_loss: 1.1067 - val_p_acc: 0.5192\n",
      "Epoch 1761/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8671 - p_acc: 0.6923 - val_loss: 1.1072 - val_p_acc: 0.5016\n",
      "Epoch 1762/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9042 - p_acc: 0.6154 - val_loss: 1.1082 - val_p_acc: 0.5369\n",
      "Epoch 1763/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9118 - p_acc: 0.5545 - val_loss: 1.1095 - val_p_acc: 0.4663\n",
      "Epoch 1764/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9202 - p_acc: 0.6242 - val_loss: 1.1082 - val_p_acc: 0.5192\n",
      "Epoch 1765/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8234 - p_acc: 0.6178 - val_loss: 1.1090 - val_p_acc: 0.5016\n",
      "Epoch 1766/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8655 - p_acc: 0.6362 - val_loss: 1.1090 - val_p_acc: 0.5369\n",
      "Epoch 1767/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8559 - p_acc: 0.6122 - val_loss: 1.1102 - val_p_acc: 0.4840\n",
      "Epoch 1768/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8636 - p_acc: 0.6194 - val_loss: 1.1114 - val_p_acc: 0.5192\n",
      "Epoch 1769/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9337 - p_acc: 0.5617 - val_loss: 1.1126 - val_p_acc: 0.4663\n",
      "Epoch 1770/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9710 - p_acc: 0.5272 - val_loss: 1.1111 - val_p_acc: 0.4840\n",
      "Epoch 1771/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8768 - p_acc: 0.6346 - val_loss: 1.1113 - val_p_acc: 0.5192\n",
      "Epoch 1772/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8683 - p_acc: 0.6210 - val_loss: 1.1107 - val_p_acc: 0.5369\n",
      "Epoch 1773/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9227 - p_acc: 0.6106 - val_loss: 1.1114 - val_p_acc: 0.5369\n",
      "Epoch 1774/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9717 - p_acc: 0.5721 - val_loss: 1.1107 - val_p_acc: 0.5369\n",
      "Epoch 1775/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9537 - p_acc: 0.5793 - val_loss: 1.1099 - val_p_acc: 0.4663\n",
      "Epoch 1776/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9030 - p_acc: 0.6490 - val_loss: 1.1096 - val_p_acc: 0.5016\n",
      "Epoch 1777/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9487 - p_acc: 0.5946 - val_loss: 1.1098 - val_p_acc: 0.4840\n",
      "Epoch 1778/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9169 - p_acc: 0.5545 - val_loss: 1.1087 - val_p_acc: 0.5545\n",
      "Epoch 1779/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8511 - p_acc: 0.6330 - val_loss: 1.1104 - val_p_acc: 0.5192\n",
      "Epoch 1780/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9838 - p_acc: 0.6210 - val_loss: 1.1093 - val_p_acc: 0.5369\n",
      "Epoch 1781/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8914 - p_acc: 0.6050 - val_loss: 1.1092 - val_p_acc: 0.5016\n",
      "Epoch 1782/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9213 - p_acc: 0.6194 - val_loss: 1.1086 - val_p_acc: 0.5192\n",
      "Epoch 1783/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8960 - p_acc: 0.6018 - val_loss: 1.1083 - val_p_acc: 0.4663\n",
      "Epoch 1784/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9526 - p_acc: 0.6018 - val_loss: 1.1077 - val_p_acc: 0.4840\n",
      "Epoch 1785/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9322 - p_acc: 0.5913 - val_loss: 1.1078 - val_p_acc: 0.5192\n",
      "Epoch 1786/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9609 - p_acc: 0.5929 - val_loss: 1.1083 - val_p_acc: 0.5369\n",
      "Epoch 1787/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8543 - p_acc: 0.5649 - val_loss: 1.1101 - val_p_acc: 0.5016\n",
      "Epoch 1788/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.8790 - p_acc: 0.6538 - val_loss: 1.1107 - val_p_acc: 0.5016\n",
      "Epoch 1789/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9191 - p_acc: 0.5793 - val_loss: 1.1092 - val_p_acc: 0.5192\n",
      "Epoch 1790/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8737 - p_acc: 0.6330 - val_loss: 1.1089 - val_p_acc: 0.4840\n",
      "Epoch 1791/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8904 - p_acc: 0.6194 - val_loss: 1.1099 - val_p_acc: 0.4840\n",
      "Epoch 1792/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8422 - p_acc: 0.5946 - val_loss: 1.1104 - val_p_acc: 0.5369\n",
      "Epoch 1793/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9395 - p_acc: 0.5721 - val_loss: 1.1099 - val_p_acc: 0.5016\n",
      "Epoch 1794/5000\n",
      "85/85 [==============================] - 0s 690us/sample - loss: 0.8792 - p_acc: 0.6242 - val_loss: 1.1103 - val_p_acc: 0.5192\n",
      "Epoch 1795/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9304 - p_acc: 0.6402 - val_loss: 1.1122 - val_p_acc: 0.5016\n",
      "Epoch 1796/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9313 - p_acc: 0.6803 - val_loss: 1.1145 - val_p_acc: 0.5545\n",
      "Epoch 1797/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9123 - p_acc: 0.6418 - val_loss: 1.1186 - val_p_acc: 0.4840\n",
      "Epoch 1798/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9123 - p_acc: 0.6018 - val_loss: 1.1216 - val_p_acc: 0.5545\n",
      "Epoch 1799/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9244 - p_acc: 0.6627 - val_loss: 1.1240 - val_p_acc: 0.5369\n",
      "Epoch 1800/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8888 - p_acc: 0.6122 - val_loss: 1.1230 - val_p_acc: 0.5016\n",
      "Epoch 1801/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 1.0060 - p_acc: 0.6298 - val_loss: 1.1239 - val_p_acc: 0.4840\n",
      "Epoch 1802/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8808 - p_acc: 0.7011 - val_loss: 1.1250 - val_p_acc: 0.4840\n",
      "Epoch 1803/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8921 - p_acc: 0.6699 - val_loss: 1.1260 - val_p_acc: 0.5192\n",
      "Epoch 1804/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9845 - p_acc: 0.5946 - val_loss: 1.1252 - val_p_acc: 0.5016\n",
      "Epoch 1805/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9538 - p_acc: 0.6627 - val_loss: 1.1255 - val_p_acc: 0.4840\n",
      "Epoch 1806/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9293 - p_acc: 0.6034 - val_loss: 1.1253 - val_p_acc: 0.4840\n",
      "Epoch 1807/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9456 - p_acc: 0.6122 - val_loss: 1.1255 - val_p_acc: 0.5016\n",
      "Epoch 1808/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9322 - p_acc: 0.6050 - val_loss: 1.1272 - val_p_acc: 0.5369\n",
      "Epoch 1809/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 1.0196 - p_acc: 0.5064 - val_loss: 1.1265 - val_p_acc: 0.5545\n",
      "Epoch 1810/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9118 - p_acc: 0.6627 - val_loss: 1.1271 - val_p_acc: 0.5369\n",
      "Epoch 1811/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8931 - p_acc: 0.6066 - val_loss: 1.1268 - val_p_acc: 0.5016\n",
      "Epoch 1812/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8596 - p_acc: 0.6034 - val_loss: 1.1251 - val_p_acc: 0.5369\n",
      "Epoch 1813/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8958 - p_acc: 0.6138 - val_loss: 1.1236 - val_p_acc: 0.5192\n",
      "Epoch 1814/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9362 - p_acc: 0.5513 - val_loss: 1.1221 - val_p_acc: 0.4840\n",
      "Epoch 1815/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9400 - p_acc: 0.6194 - val_loss: 1.1200 - val_p_acc: 0.5369\n",
      "Epoch 1816/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9247 - p_acc: 0.5633 - val_loss: 1.1213 - val_p_acc: 0.5369\n",
      "Epoch 1817/5000\n",
      "85/85 [==============================] - 0s 697us/sample - loss: 0.9035 - p_acc: 0.6907 - val_loss: 1.1197 - val_p_acc: 0.4840\n",
      "Epoch 1818/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9355 - p_acc: 0.5737 - val_loss: 1.1182 - val_p_acc: 0.5192\n",
      "Epoch 1819/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8748 - p_acc: 0.6066 - val_loss: 1.1187 - val_p_acc: 0.5192\n",
      "Epoch 1820/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8582 - p_acc: 0.6050 - val_loss: 1.1200 - val_p_acc: 0.5192\n",
      "Epoch 1821/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8040 - p_acc: 0.6907 - val_loss: 1.1199 - val_p_acc: 0.5192\n",
      "Epoch 1822/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8558 - p_acc: 0.6450 - val_loss: 1.1185 - val_p_acc: 0.5545\n",
      "Epoch 1823/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8928 - p_acc: 0.5913 - val_loss: 1.1175 - val_p_acc: 0.5016\n",
      "Epoch 1824/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8600 - p_acc: 0.6595 - val_loss: 1.1183 - val_p_acc: 0.5016\n",
      "Epoch 1825/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9542 - p_acc: 0.6178 - val_loss: 1.1176 - val_p_acc: 0.5016\n",
      "Epoch 1826/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9172 - p_acc: 0.5337 - val_loss: 1.1182 - val_p_acc: 0.5016\n",
      "Epoch 1827/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9192 - p_acc: 0.6907 - val_loss: 1.1166 - val_p_acc: 0.4663\n",
      "Epoch 1828/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9195 - p_acc: 0.6298 - val_loss: 1.1162 - val_p_acc: 0.4663\n",
      "Epoch 1829/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9146 - p_acc: 0.5457 - val_loss: 1.1166 - val_p_acc: 0.5721\n",
      "Epoch 1830/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9020 - p_acc: 0.5721 - val_loss: 1.1172 - val_p_acc: 0.5016\n",
      "Epoch 1831/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8781 - p_acc: 0.6402 - val_loss: 1.1171 - val_p_acc: 0.4840\n",
      "Epoch 1832/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8863 - p_acc: 0.6002 - val_loss: 1.1181 - val_p_acc: 0.5545\n",
      "Epoch 1833/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9425 - p_acc: 0.5929 - val_loss: 1.1183 - val_p_acc: 0.5016\n",
      "Epoch 1834/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8767 - p_acc: 0.6018 - val_loss: 1.1185 - val_p_acc: 0.5369\n",
      "Epoch 1835/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8637 - p_acc: 0.6907 - val_loss: 1.1177 - val_p_acc: 0.5545\n",
      "Epoch 1836/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8771 - p_acc: 0.6050 - val_loss: 1.1163 - val_p_acc: 0.5192\n",
      "Epoch 1837/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8066 - p_acc: 0.6194 - val_loss: 1.1144 - val_p_acc: 0.5192\n",
      "Epoch 1838/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8841 - p_acc: 0.6154 - val_loss: 1.1153 - val_p_acc: 0.4840\n",
      "Epoch 1839/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9136 - p_acc: 0.5825 - val_loss: 1.1162 - val_p_acc: 0.5369\n",
      "Epoch 1840/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8893 - p_acc: 0.5529 - val_loss: 1.1165 - val_p_acc: 0.5016\n",
      "Epoch 1841/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9828 - p_acc: 0.5978 - val_loss: 1.1171 - val_p_acc: 0.5192\n",
      "Epoch 1842/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9659 - p_acc: 0.6002 - val_loss: 1.1184 - val_p_acc: 0.5016\n",
      "Epoch 1843/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9030 - p_acc: 0.6210 - val_loss: 1.1195 - val_p_acc: 0.5545\n",
      "Epoch 1844/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8366 - p_acc: 0.6923 - val_loss: 1.1198 - val_p_acc: 0.5016\n",
      "Epoch 1845/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9495 - p_acc: 0.5929 - val_loss: 1.1185 - val_p_acc: 0.5369\n",
      "Epoch 1846/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9078 - p_acc: 0.6715 - val_loss: 1.1177 - val_p_acc: 0.5369\n",
      "Epoch 1847/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 1.0309 - p_acc: 0.5633 - val_loss: 1.1156 - val_p_acc: 0.5369\n",
      "Epoch 1848/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9488 - p_acc: 0.5425 - val_loss: 1.1150 - val_p_acc: 0.5016\n",
      "Epoch 1849/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8595 - p_acc: 0.6066 - val_loss: 1.1131 - val_p_acc: 0.5369\n",
      "Epoch 1850/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9163 - p_acc: 0.6434 - val_loss: 1.1118 - val_p_acc: 0.5369\n",
      "Epoch 1851/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9286 - p_acc: 0.6210 - val_loss: 1.1117 - val_p_acc: 0.4840\n",
      "Epoch 1852/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9368 - p_acc: 0.6819 - val_loss: 1.1119 - val_p_acc: 0.5545\n",
      "Epoch 1853/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9312 - p_acc: 0.4992 - val_loss: 1.1125 - val_p_acc: 0.5192\n",
      "Epoch 1854/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8891 - p_acc: 0.6034 - val_loss: 1.1119 - val_p_acc: 0.5192\n",
      "Epoch 1855/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9225 - p_acc: 0.5721 - val_loss: 1.1126 - val_p_acc: 0.4663\n",
      "Epoch 1856/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9047 - p_acc: 0.6330 - val_loss: 1.1128 - val_p_acc: 0.5545\n",
      "Epoch 1857/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8294 - p_acc: 0.6506 - val_loss: 1.1120 - val_p_acc: 0.5369\n",
      "Epoch 1858/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8952 - p_acc: 0.6066 - val_loss: 1.1128 - val_p_acc: 0.5192\n",
      "Epoch 1859/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9114 - p_acc: 0.5617 - val_loss: 1.1136 - val_p_acc: 0.5192\n",
      "Epoch 1860/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8532 - p_acc: 0.6210 - val_loss: 1.1134 - val_p_acc: 0.5016\n",
      "Epoch 1861/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8681 - p_acc: 0.5617 - val_loss: 1.1139 - val_p_acc: 0.5369\n",
      "Epoch 1862/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9352 - p_acc: 0.6034 - val_loss: 1.1133 - val_p_acc: 0.5192\n",
      "Epoch 1863/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8809 - p_acc: 0.6731 - val_loss: 1.1134 - val_p_acc: 0.4840\n",
      "Epoch 1864/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8852 - p_acc: 0.5144 - val_loss: 1.1150 - val_p_acc: 0.5369\n",
      "Epoch 1865/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9318 - p_acc: 0.5929 - val_loss: 1.1158 - val_p_acc: 0.5016\n",
      "Epoch 1866/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9789 - p_acc: 0.5721 - val_loss: 1.1153 - val_p_acc: 0.4840\n",
      "Epoch 1867/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9338 - p_acc: 0.5425 - val_loss: 1.1160 - val_p_acc: 0.5016\n",
      "Epoch 1868/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9391 - p_acc: 0.5393 - val_loss: 1.1170 - val_p_acc: 0.5192\n",
      "Epoch 1869/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8924 - p_acc: 0.6034 - val_loss: 1.1178 - val_p_acc: 0.5721\n",
      "Epoch 1870/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8076 - p_acc: 0.6835 - val_loss: 1.1194 - val_p_acc: 0.5192\n",
      "Epoch 1871/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9073 - p_acc: 0.5721 - val_loss: 1.1192 - val_p_acc: 0.5192\n",
      "Epoch 1872/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9116 - p_acc: 0.6066 - val_loss: 1.1194 - val_p_acc: 0.5192\n",
      "Epoch 1873/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9120 - p_acc: 0.5601 - val_loss: 1.1194 - val_p_acc: 0.5192\n",
      "Epoch 1874/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 1.0454 - p_acc: 0.5288 - val_loss: 1.1202 - val_p_acc: 0.5192\n",
      "Epoch 1875/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8891 - p_acc: 0.6402 - val_loss: 1.1213 - val_p_acc: 0.4840\n",
      "Epoch 1876/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8765 - p_acc: 0.5705 - val_loss: 1.1231 - val_p_acc: 0.5192\n",
      "Epoch 1877/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9788 - p_acc: 0.6298 - val_loss: 1.1244 - val_p_acc: 0.4487\n",
      "Epoch 1878/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9304 - p_acc: 0.5128 - val_loss: 1.1242 - val_p_acc: 0.5016\n",
      "Epoch 1879/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8985 - p_acc: 0.5825 - val_loss: 1.1232 - val_p_acc: 0.5016\n",
      "Epoch 1880/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9016 - p_acc: 0.6018 - val_loss: 1.1216 - val_p_acc: 0.5192\n",
      "Epoch 1881/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9460 - p_acc: 0.5793 - val_loss: 1.1202 - val_p_acc: 0.5016\n",
      "Epoch 1882/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8838 - p_acc: 0.6034 - val_loss: 1.1202 - val_p_acc: 0.5016\n",
      "Epoch 1883/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9683 - p_acc: 0.5881 - val_loss: 1.1197 - val_p_acc: 0.5016\n",
      "Epoch 1884/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9108 - p_acc: 0.5946 - val_loss: 1.1187 - val_p_acc: 0.5192\n",
      "Epoch 1885/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9070 - p_acc: 0.5978 - val_loss: 1.1188 - val_p_acc: 0.5369\n",
      "Epoch 1886/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8798 - p_acc: 0.6314 - val_loss: 1.1191 - val_p_acc: 0.5192\n",
      "Epoch 1887/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8890 - p_acc: 0.6386 - val_loss: 1.1178 - val_p_acc: 0.4840\n",
      "Epoch 1888/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8906 - p_acc: 0.6627 - val_loss: 1.1170 - val_p_acc: 0.5016\n",
      "Epoch 1889/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8966 - p_acc: 0.5929 - val_loss: 1.1147 - val_p_acc: 0.5192\n",
      "Epoch 1890/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9080 - p_acc: 0.6018 - val_loss: 1.1128 - val_p_acc: 0.5016\n",
      "Epoch 1891/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8706 - p_acc: 0.6226 - val_loss: 1.1131 - val_p_acc: 0.5016\n",
      "Epoch 1892/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8161 - p_acc: 0.6627 - val_loss: 1.1124 - val_p_acc: 0.4840\n",
      "Epoch 1893/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9276 - p_acc: 0.6226 - val_loss: 1.1125 - val_p_acc: 0.5369\n",
      "Epoch 1894/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8934 - p_acc: 0.7027 - val_loss: 1.1127 - val_p_acc: 0.5016\n",
      "Epoch 1895/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8751 - p_acc: 0.5649 - val_loss: 1.1134 - val_p_acc: 0.4840\n",
      "Epoch 1896/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9030 - p_acc: 0.5825 - val_loss: 1.1149 - val_p_acc: 0.4840\n",
      "Epoch 1897/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8412 - p_acc: 0.6434 - val_loss: 1.1160 - val_p_acc: 0.5016\n",
      "Epoch 1898/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8740 - p_acc: 0.6138 - val_loss: 1.1168 - val_p_acc: 0.4663\n",
      "Epoch 1899/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8184 - p_acc: 0.6939 - val_loss: 1.1179 - val_p_acc: 0.5369\n",
      "Epoch 1900/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9358 - p_acc: 0.5529 - val_loss: 1.1177 - val_p_acc: 0.4840\n",
      "Epoch 1901/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9955 - p_acc: 0.5986 - val_loss: 1.1152 - val_p_acc: 0.5016\n",
      "Epoch 1902/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8337 - p_acc: 0.6450 - val_loss: 1.1147 - val_p_acc: 0.4840\n",
      "Epoch 1903/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9448 - p_acc: 0.5825 - val_loss: 1.1147 - val_p_acc: 0.5545\n",
      "Epoch 1904/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8963 - p_acc: 0.6715 - val_loss: 1.1147 - val_p_acc: 0.5192\n",
      "Epoch 1905/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9750 - p_acc: 0.5841 - val_loss: 1.1136 - val_p_acc: 0.4663\n",
      "Epoch 1906/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9755 - p_acc: 0.6106 - val_loss: 1.1140 - val_p_acc: 0.5369\n",
      "Epoch 1907/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8449 - p_acc: 0.6346 - val_loss: 1.1130 - val_p_acc: 0.4840\n",
      "Epoch 1908/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8691 - p_acc: 0.5721 - val_loss: 1.1127 - val_p_acc: 0.5016\n",
      "Epoch 1909/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8876 - p_acc: 0.6835 - val_loss: 1.1116 - val_p_acc: 0.5016\n",
      "Epoch 1910/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9181 - p_acc: 0.6418 - val_loss: 1.1121 - val_p_acc: 0.5369\n",
      "Epoch 1911/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8393 - p_acc: 0.6066 - val_loss: 1.1121 - val_p_acc: 0.5369\n",
      "Epoch 1912/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8371 - p_acc: 0.6122 - val_loss: 1.1127 - val_p_acc: 0.5369\n",
      "Epoch 1913/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8440 - p_acc: 0.6018 - val_loss: 1.1138 - val_p_acc: 0.5369\n",
      "Epoch 1914/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8273 - p_acc: 0.6538 - val_loss: 1.1148 - val_p_acc: 0.5545\n",
      "Epoch 1915/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8945 - p_acc: 0.6522 - val_loss: 1.1140 - val_p_acc: 0.4840\n",
      "Epoch 1916/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9214 - p_acc: 0.6314 - val_loss: 1.1136 - val_p_acc: 0.5192\n",
      "Epoch 1917/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9295 - p_acc: 0.5825 - val_loss: 1.1138 - val_p_acc: 0.5192\n",
      "Epoch 1918/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9780 - p_acc: 0.5825 - val_loss: 1.1127 - val_p_acc: 0.4840\n",
      "Epoch 1919/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0053 - p_acc: 0.5825 - val_loss: 1.1132 - val_p_acc: 0.5016\n",
      "Epoch 1920/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8546 - p_acc: 0.6402 - val_loss: 1.1143 - val_p_acc: 0.5369\n",
      "Epoch 1921/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9256 - p_acc: 0.6226 - val_loss: 1.1146 - val_p_acc: 0.5192\n",
      "Epoch 1922/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8728 - p_acc: 0.6595 - val_loss: 1.1145 - val_p_acc: 0.5016\n",
      "Epoch 1923/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8869 - p_acc: 0.6034 - val_loss: 1.1133 - val_p_acc: 0.5369\n",
      "Epoch 1924/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9628 - p_acc: 0.5946 - val_loss: 1.1126 - val_p_acc: 0.5192\n",
      "Epoch 1925/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9464 - p_acc: 0.5721 - val_loss: 1.1147 - val_p_acc: 0.5192\n",
      "Epoch 1926/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9128 - p_acc: 0.6066 - val_loss: 1.1165 - val_p_acc: 0.5016\n",
      "Epoch 1927/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8376 - p_acc: 0.6050 - val_loss: 1.1185 - val_p_acc: 0.5369\n",
      "Epoch 1928/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8675 - p_acc: 0.6122 - val_loss: 1.1191 - val_p_acc: 0.5545\n",
      "Epoch 1929/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9728 - p_acc: 0.5825 - val_loss: 1.1202 - val_p_acc: 0.5369\n",
      "Epoch 1930/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9470 - p_acc: 0.5857 - val_loss: 1.1203 - val_p_acc: 0.5016\n",
      "Epoch 1931/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8584 - p_acc: 0.5970 - val_loss: 1.1197 - val_p_acc: 0.5545\n",
      "Epoch 1932/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9690 - p_acc: 0.5793 - val_loss: 1.1194 - val_p_acc: 0.5192\n",
      "Epoch 1933/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9155 - p_acc: 0.5737 - val_loss: 1.1182 - val_p_acc: 0.5192\n",
      "Epoch 1934/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8679 - p_acc: 0.6699 - val_loss: 1.1164 - val_p_acc: 0.5192\n",
      "Epoch 1935/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8625 - p_acc: 0.6226 - val_loss: 1.1154 - val_p_acc: 0.5192\n",
      "Epoch 1936/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8706 - p_acc: 0.6699 - val_loss: 1.1145 - val_p_acc: 0.5192\n",
      "Epoch 1937/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8666 - p_acc: 0.6226 - val_loss: 1.1153 - val_p_acc: 0.5369\n",
      "Epoch 1938/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8713 - p_acc: 0.5529 - val_loss: 1.1160 - val_p_acc: 0.4663\n",
      "Epoch 1939/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8721 - p_acc: 0.6643 - val_loss: 1.1145 - val_p_acc: 0.5192\n",
      "Epoch 1940/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9649 - p_acc: 0.5545 - val_loss: 1.1131 - val_p_acc: 0.5369\n",
      "Epoch 1941/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8865 - p_acc: 0.6002 - val_loss: 1.1131 - val_p_acc: 0.5369\n",
      "Epoch 1942/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8348 - p_acc: 0.5946 - val_loss: 1.1161 - val_p_acc: 0.5369\n",
      "Epoch 1943/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8984 - p_acc: 0.5737 - val_loss: 1.1166 - val_p_acc: 0.5192\n",
      "Epoch 1944/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9294 - p_acc: 0.5529 - val_loss: 1.1169 - val_p_acc: 0.4840\n",
      "Epoch 1945/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9008 - p_acc: 0.6138 - val_loss: 1.1170 - val_p_acc: 0.5192\n",
      "Epoch 1946/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9342 - p_acc: 0.5393 - val_loss: 1.1166 - val_p_acc: 0.5369\n",
      "Epoch 1947/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9634 - p_acc: 0.6106 - val_loss: 1.1152 - val_p_acc: 0.5016\n",
      "Epoch 1948/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8596 - p_acc: 0.6122 - val_loss: 1.1162 - val_p_acc: 0.5192\n",
      "Epoch 1949/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9116 - p_acc: 0.6314 - val_loss: 1.1171 - val_p_acc: 0.5016\n",
      "Epoch 1950/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9520 - p_acc: 0.6330 - val_loss: 1.1187 - val_p_acc: 0.5369\n",
      "Epoch 1951/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8928 - p_acc: 0.6018 - val_loss: 1.1187 - val_p_acc: 0.5545\n",
      "Epoch 1952/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8882 - p_acc: 0.6122 - val_loss: 1.1187 - val_p_acc: 0.5192\n",
      "Epoch 1953/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8031 - p_acc: 0.6835 - val_loss: 1.1175 - val_p_acc: 0.4663\n",
      "Epoch 1954/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8263 - p_acc: 0.6330 - val_loss: 1.1149 - val_p_acc: 0.5897\n",
      "Epoch 1955/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9185 - p_acc: 0.5321 - val_loss: 1.1133 - val_p_acc: 0.5545\n",
      "Epoch 1956/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8741 - p_acc: 0.6386 - val_loss: 1.1119 - val_p_acc: 0.4840\n",
      "Epoch 1957/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9364 - p_acc: 0.5913 - val_loss: 1.1115 - val_p_acc: 0.5016\n",
      "Epoch 1958/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9022 - p_acc: 0.6314 - val_loss: 1.1116 - val_p_acc: 0.5545\n",
      "Epoch 1959/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9685 - p_acc: 0.6314 - val_loss: 1.1120 - val_p_acc: 0.5192\n",
      "Epoch 1960/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8810 - p_acc: 0.6050 - val_loss: 1.1110 - val_p_acc: 0.5192\n",
      "Epoch 1961/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8320 - p_acc: 0.6138 - val_loss: 1.1116 - val_p_acc: 0.5016\n",
      "Epoch 1962/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9205 - p_acc: 0.5705 - val_loss: 1.1133 - val_p_acc: 0.4663\n",
      "Epoch 1963/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8841 - p_acc: 0.6138 - val_loss: 1.1128 - val_p_acc: 0.4663\n",
      "Epoch 1964/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8754 - p_acc: 0.6643 - val_loss: 1.1124 - val_p_acc: 0.5369\n",
      "Epoch 1965/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9814 - p_acc: 0.6090 - val_loss: 1.1114 - val_p_acc: 0.5545\n",
      "Epoch 1966/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8585 - p_acc: 0.6242 - val_loss: 1.1120 - val_p_acc: 0.5369\n",
      "Epoch 1967/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9206 - p_acc: 0.5825 - val_loss: 1.1115 - val_p_acc: 0.5192\n",
      "Epoch 1968/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8515 - p_acc: 0.6643 - val_loss: 1.1111 - val_p_acc: 0.4840\n",
      "Epoch 1969/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8760 - p_acc: 0.6018 - val_loss: 1.1105 - val_p_acc: 0.4663\n",
      "Epoch 1970/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9195 - p_acc: 0.6002 - val_loss: 1.1110 - val_p_acc: 0.5369\n",
      "Epoch 1971/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8814 - p_acc: 0.6418 - val_loss: 1.1115 - val_p_acc: 0.5016\n",
      "Epoch 1972/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8500 - p_acc: 0.6627 - val_loss: 1.1109 - val_p_acc: 0.5192\n",
      "Epoch 1973/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9308 - p_acc: 0.5633 - val_loss: 1.1113 - val_p_acc: 0.5016\n",
      "Epoch 1974/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8442 - p_acc: 0.6418 - val_loss: 1.1113 - val_p_acc: 0.4840\n",
      "Epoch 1975/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8240 - p_acc: 0.6138 - val_loss: 1.1099 - val_p_acc: 0.4840\n",
      "Epoch 1976/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9688 - p_acc: 0.6330 - val_loss: 1.1087 - val_p_acc: 0.4840\n",
      "Epoch 1977/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8880 - p_acc: 0.5633 - val_loss: 1.1088 - val_p_acc: 0.5192\n",
      "Epoch 1978/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8596 - p_acc: 0.6386 - val_loss: 1.1090 - val_p_acc: 0.5369\n",
      "Epoch 1979/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8998 - p_acc: 0.6506 - val_loss: 1.1089 - val_p_acc: 0.5192\n",
      "Epoch 1980/5000\n",
      "85/85 [==============================] - 0s 688us/sample - loss: 0.8469 - p_acc: 0.6258 - val_loss: 1.1080 - val_p_acc: 0.5016\n",
      "Epoch 1981/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8698 - p_acc: 0.6699 - val_loss: 1.1085 - val_p_acc: 0.5016\n",
      "Epoch 1982/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8611 - p_acc: 0.6731 - val_loss: 1.1103 - val_p_acc: 0.5369\n",
      "Epoch 1983/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 0.8776 - p_acc: 0.6346 - val_loss: 1.1120 - val_p_acc: 0.5016\n",
      "Epoch 1984/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8795 - p_acc: 0.7220 - val_loss: 1.1131 - val_p_acc: 0.5192\n",
      "Epoch 1985/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8563 - p_acc: 0.6330 - val_loss: 1.1142 - val_p_acc: 0.4663\n",
      "Epoch 1986/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9078 - p_acc: 0.5825 - val_loss: 1.1126 - val_p_acc: 0.5016\n",
      "Epoch 1987/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8695 - p_acc: 0.6242 - val_loss: 1.1109 - val_p_acc: 0.5192\n",
      "Epoch 1988/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8798 - p_acc: 0.5841 - val_loss: 1.1101 - val_p_acc: 0.5369\n",
      "Epoch 1989/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8428 - p_acc: 0.6138 - val_loss: 1.1088 - val_p_acc: 0.5016\n",
      "Epoch 1990/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9188 - p_acc: 0.6226 - val_loss: 1.1089 - val_p_acc: 0.5192\n",
      "Epoch 1991/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9603 - p_acc: 0.5737 - val_loss: 1.1088 - val_p_acc: 0.4840\n",
      "Epoch 1992/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9329 - p_acc: 0.6106 - val_loss: 1.1112 - val_p_acc: 0.5016\n",
      "Epoch 1993/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9185 - p_acc: 0.5409 - val_loss: 1.1120 - val_p_acc: 0.5192\n",
      "Epoch 1994/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9699 - p_acc: 0.5321 - val_loss: 1.1126 - val_p_acc: 0.5192\n",
      "Epoch 1995/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9078 - p_acc: 0.6018 - val_loss: 1.1126 - val_p_acc: 0.5192\n",
      "Epoch 1996/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8883 - p_acc: 0.6763 - val_loss: 1.1140 - val_p_acc: 0.5016\n",
      "Epoch 1997/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 0.8467 - p_acc: 0.6242 - val_loss: 1.1144 - val_p_acc: 0.5369\n",
      "Epoch 1998/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8803 - p_acc: 0.6819 - val_loss: 1.1155 - val_p_acc: 0.5192\n",
      "Epoch 1999/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8523 - p_acc: 0.7011 - val_loss: 1.1152 - val_p_acc: 0.5545\n",
      "Epoch 2000/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8904 - p_acc: 0.6002 - val_loss: 1.1142 - val_p_acc: 0.5369\n",
      "Epoch 2001/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9260 - p_acc: 0.6418 - val_loss: 1.1135 - val_p_acc: 0.5192\n",
      "Epoch 2002/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8819 - p_acc: 0.6715 - val_loss: 1.1113 - val_p_acc: 0.5192\n",
      "Epoch 2003/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8667 - p_acc: 0.6418 - val_loss: 1.1119 - val_p_acc: 0.5192\n",
      "Epoch 2004/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9028 - p_acc: 0.6242 - val_loss: 1.1108 - val_p_acc: 0.5016\n",
      "Epoch 2005/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8622 - p_acc: 0.5825 - val_loss: 1.1109 - val_p_acc: 0.4663\n",
      "Epoch 2006/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9723 - p_acc: 0.5585 - val_loss: 1.1115 - val_p_acc: 0.5016\n",
      "Epoch 2007/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9062 - p_acc: 0.6506 - val_loss: 1.1118 - val_p_acc: 0.5369\n",
      "Epoch 2008/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9794 - p_acc: 0.5288 - val_loss: 1.1101 - val_p_acc: 0.5192\n",
      "Epoch 2009/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8560 - p_acc: 0.5353 - val_loss: 1.1100 - val_p_acc: 0.4840\n",
      "Epoch 2010/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8685 - p_acc: 0.5737 - val_loss: 1.1094 - val_p_acc: 0.5192\n",
      "Epoch 2011/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9080 - p_acc: 0.6210 - val_loss: 1.1100 - val_p_acc: 0.5369\n",
      "Epoch 2012/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8616 - p_acc: 0.6226 - val_loss: 1.1106 - val_p_acc: 0.5016\n",
      "Epoch 2013/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9157 - p_acc: 0.7011 - val_loss: 1.1115 - val_p_acc: 0.5192\n",
      "Epoch 2014/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8939 - p_acc: 0.6611 - val_loss: 1.1117 - val_p_acc: 0.4840\n",
      "Epoch 2015/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8924 - p_acc: 0.6018 - val_loss: 1.1124 - val_p_acc: 0.5192\n",
      "Epoch 2016/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8547 - p_acc: 0.6330 - val_loss: 1.1118 - val_p_acc: 0.5016\n",
      "Epoch 2017/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8586 - p_acc: 0.6643 - val_loss: 1.1118 - val_p_acc: 0.5369\n",
      "Epoch 2018/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8688 - p_acc: 0.6242 - val_loss: 1.1124 - val_p_acc: 0.5192\n",
      "Epoch 2019/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9425 - p_acc: 0.6122 - val_loss: 1.1130 - val_p_acc: 0.5016\n",
      "Epoch 2020/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9111 - p_acc: 0.6210 - val_loss: 1.1134 - val_p_acc: 0.5016\n",
      "Epoch 2021/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8140 - p_acc: 0.6314 - val_loss: 1.1142 - val_p_acc: 0.4840\n",
      "Epoch 2022/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8901 - p_acc: 0.5929 - val_loss: 1.1149 - val_p_acc: 0.4840\n",
      "Epoch 2023/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8781 - p_acc: 0.5633 - val_loss: 1.1169 - val_p_acc: 0.4663\n",
      "Epoch 2024/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9486 - p_acc: 0.5040 - val_loss: 1.1188 - val_p_acc: 0.5369\n",
      "Epoch 2025/5000\n",
      "85/85 [==============================] - 0s 657us/sample - loss: 0.8918 - p_acc: 0.6627 - val_loss: 1.1187 - val_p_acc: 0.5016\n",
      "Epoch 2026/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8606 - p_acc: 0.7027 - val_loss: 1.1196 - val_p_acc: 0.5545\n",
      "Epoch 2027/5000\n",
      "85/85 [==============================] - 0s 707us/sample - loss: 0.8429 - p_acc: 0.6138 - val_loss: 1.1190 - val_p_acc: 0.5016\n",
      "Epoch 2028/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8120 - p_acc: 0.5721 - val_loss: 1.1190 - val_p_acc: 0.4840\n",
      "Epoch 2029/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8992 - p_acc: 0.5857 - val_loss: 1.1171 - val_p_acc: 0.5369\n",
      "Epoch 2030/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8511 - p_acc: 0.5986 - val_loss: 1.1175 - val_p_acc: 0.5545\n",
      "Epoch 2031/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9044 - p_acc: 0.5529 - val_loss: 1.1181 - val_p_acc: 0.5016\n",
      "Epoch 2032/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9645 - p_acc: 0.6122 - val_loss: 1.1167 - val_p_acc: 0.5369\n",
      "Epoch 2033/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8953 - p_acc: 0.5753 - val_loss: 1.1164 - val_p_acc: 0.5192\n",
      "Epoch 2034/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9407 - p_acc: 0.5248 - val_loss: 1.1147 - val_p_acc: 0.4663\n",
      "Epoch 2035/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8791 - p_acc: 0.6050 - val_loss: 1.1123 - val_p_acc: 0.5192\n",
      "Epoch 2036/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9011 - p_acc: 0.5545 - val_loss: 1.1126 - val_p_acc: 0.5016\n",
      "Epoch 2037/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9502 - p_acc: 0.6330 - val_loss: 1.1128 - val_p_acc: 0.5192\n",
      "Epoch 2038/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8613 - p_acc: 0.5425 - val_loss: 1.1128 - val_p_acc: 0.5369\n",
      "Epoch 2039/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8593 - p_acc: 0.5425 - val_loss: 1.1142 - val_p_acc: 0.5545\n",
      "Epoch 2040/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8834 - p_acc: 0.5753 - val_loss: 1.1135 - val_p_acc: 0.5016\n",
      "Epoch 2041/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9397 - p_acc: 0.6595 - val_loss: 1.1137 - val_p_acc: 0.5016\n",
      "Epoch 2042/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8713 - p_acc: 0.5737 - val_loss: 1.1139 - val_p_acc: 0.5192\n",
      "Epoch 2043/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 1.0030 - p_acc: 0.5913 - val_loss: 1.1142 - val_p_acc: 0.5016\n",
      "Epoch 2044/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8756 - p_acc: 0.6242 - val_loss: 1.1143 - val_p_acc: 0.5016\n",
      "Epoch 2045/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8695 - p_acc: 0.6522 - val_loss: 1.1134 - val_p_acc: 0.5192\n",
      "Epoch 2046/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8899 - p_acc: 0.6434 - val_loss: 1.1132 - val_p_acc: 0.5721\n",
      "Epoch 2047/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9042 - p_acc: 0.6242 - val_loss: 1.1130 - val_p_acc: 0.4840\n",
      "Epoch 2048/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9693 - p_acc: 0.5112 - val_loss: 1.1119 - val_p_acc: 0.4840\n",
      "Epoch 2049/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8704 - p_acc: 0.6258 - val_loss: 1.1111 - val_p_acc: 0.4840\n",
      "Epoch 2050/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8841 - p_acc: 0.5529 - val_loss: 1.1099 - val_p_acc: 0.4840\n",
      "Epoch 2051/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9548 - p_acc: 0.6002 - val_loss: 1.1069 - val_p_acc: 0.5369\n",
      "Epoch 2052/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8907 - p_acc: 0.6402 - val_loss: 1.1048 - val_p_acc: 0.5192\n",
      "Epoch 2053/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8585 - p_acc: 0.5857 - val_loss: 1.1024 - val_p_acc: 0.5016\n",
      "Epoch 2054/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 0.8755 - p_acc: 0.5529 - val_loss: 1.1000 - val_p_acc: 0.5192\n",
      "Epoch 2055/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9422 - p_acc: 0.6050 - val_loss: 1.0997 - val_p_acc: 0.5192\n",
      "Epoch 2056/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8607 - p_acc: 0.6346 - val_loss: 1.0998 - val_p_acc: 0.5721\n",
      "Epoch 2057/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9532 - p_acc: 0.6138 - val_loss: 1.0983 - val_p_acc: 0.5545\n",
      "Epoch 2058/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8622 - p_acc: 0.6995 - val_loss: 1.0976 - val_p_acc: 0.5192\n",
      "Epoch 2059/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9338 - p_acc: 0.5441 - val_loss: 1.0966 - val_p_acc: 0.5369\n",
      "Epoch 2060/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9039 - p_acc: 0.6298 - val_loss: 1.0959 - val_p_acc: 0.5192\n",
      "Epoch 2061/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8923 - p_acc: 0.6450 - val_loss: 1.0947 - val_p_acc: 0.5545\n",
      "Epoch 2062/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8379 - p_acc: 0.6715 - val_loss: 1.0932 - val_p_acc: 0.5192\n",
      "Epoch 2063/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8976 - p_acc: 0.5929 - val_loss: 1.0926 - val_p_acc: 0.5016\n",
      "Epoch 2064/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9135 - p_acc: 0.5913 - val_loss: 1.0925 - val_p_acc: 0.5369\n",
      "Epoch 2065/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8603 - p_acc: 0.5705 - val_loss: 1.0928 - val_p_acc: 0.5369\n",
      "Epoch 2066/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9722 - p_acc: 0.5929 - val_loss: 1.0937 - val_p_acc: 0.5016\n",
      "Epoch 2067/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8008 - p_acc: 0.6731 - val_loss: 1.0918 - val_p_acc: 0.4840\n",
      "Epoch 2068/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8434 - p_acc: 0.6018 - val_loss: 1.0922 - val_p_acc: 0.5192\n",
      "Epoch 2069/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8876 - p_acc: 0.6314 - val_loss: 1.0914 - val_p_acc: 0.5369\n",
      "Epoch 2070/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9008 - p_acc: 0.6002 - val_loss: 1.0926 - val_p_acc: 0.5545\n",
      "Epoch 2071/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8842 - p_acc: 0.6122 - val_loss: 1.0936 - val_p_acc: 0.5016\n",
      "Epoch 2072/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 0.8761 - p_acc: 0.6122 - val_loss: 1.0951 - val_p_acc: 0.5369\n",
      "Epoch 2073/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9072 - p_acc: 0.5705 - val_loss: 1.0971 - val_p_acc: 0.5192\n",
      "Epoch 2074/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9010 - p_acc: 0.6450 - val_loss: 1.0988 - val_p_acc: 0.5369\n",
      "Epoch 2075/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8309 - p_acc: 0.6851 - val_loss: 1.0990 - val_p_acc: 0.5369\n",
      "Epoch 2076/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9089 - p_acc: 0.5425 - val_loss: 1.0994 - val_p_acc: 0.5192\n",
      "Epoch 2077/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9455 - p_acc: 0.6282 - val_loss: 1.0995 - val_p_acc: 0.5192\n",
      "Epoch 2078/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9519 - p_acc: 0.5529 - val_loss: 1.0971 - val_p_acc: 0.5369\n",
      "Epoch 2079/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8802 - p_acc: 0.5946 - val_loss: 1.0959 - val_p_acc: 0.5016\n",
      "Epoch 2080/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8391 - p_acc: 0.5841 - val_loss: 1.0957 - val_p_acc: 0.5192\n",
      "Epoch 2081/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8739 - p_acc: 0.6450 - val_loss: 1.0940 - val_p_acc: 0.4840\n",
      "Epoch 2082/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9416 - p_acc: 0.5617 - val_loss: 1.0927 - val_p_acc: 0.5192\n",
      "Epoch 2083/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8662 - p_acc: 0.6659 - val_loss: 1.0924 - val_p_acc: 0.4840\n",
      "Epoch 2084/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8242 - p_acc: 0.7236 - val_loss: 1.0926 - val_p_acc: 0.5192\n",
      "Epoch 2085/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8513 - p_acc: 0.5561 - val_loss: 1.0918 - val_p_acc: 0.5369\n",
      "Epoch 2086/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8371 - p_acc: 0.6418 - val_loss: 1.0915 - val_p_acc: 0.5369\n",
      "Epoch 2087/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9115 - p_acc: 0.6194 - val_loss: 1.0918 - val_p_acc: 0.5369\n",
      "Epoch 2088/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8533 - p_acc: 0.6715 - val_loss: 1.0919 - val_p_acc: 0.5016\n",
      "Epoch 2089/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9072 - p_acc: 0.5633 - val_loss: 1.0927 - val_p_acc: 0.5016\n",
      "Epoch 2090/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9133 - p_acc: 0.6298 - val_loss: 1.0926 - val_p_acc: 0.4663\n",
      "Epoch 2091/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8595 - p_acc: 0.6715 - val_loss: 1.0939 - val_p_acc: 0.5192\n",
      "Epoch 2092/5000\n",
      "85/85 [==============================] - 0s 700us/sample - loss: 0.9336 - p_acc: 0.6242 - val_loss: 1.0943 - val_p_acc: 0.4663\n",
      "Epoch 2093/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8263 - p_acc: 0.6715 - val_loss: 1.0938 - val_p_acc: 0.5016\n",
      "Epoch 2094/5000\n",
      "85/85 [==============================] - 0s 709us/sample - loss: 0.8752 - p_acc: 0.5633 - val_loss: 1.0946 - val_p_acc: 0.5192\n",
      "Epoch 2095/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8365 - p_acc: 0.6122 - val_loss: 1.0948 - val_p_acc: 0.5016\n",
      "Epoch 2096/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8383 - p_acc: 0.6210 - val_loss: 1.0948 - val_p_acc: 0.5192\n",
      "Epoch 2097/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9216 - p_acc: 0.5809 - val_loss: 1.0952 - val_p_acc: 0.5545\n",
      "Epoch 2098/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9282 - p_acc: 0.6034 - val_loss: 1.0955 - val_p_acc: 0.5192\n",
      "Epoch 2099/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9260 - p_acc: 0.6346 - val_loss: 1.0956 - val_p_acc: 0.5369\n",
      "Epoch 2100/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8923 - p_acc: 0.5513 - val_loss: 1.0961 - val_p_acc: 0.5192\n",
      "Epoch 2101/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8825 - p_acc: 0.6378 - val_loss: 1.0976 - val_p_acc: 0.4487\n",
      "Epoch 2102/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8754 - p_acc: 0.5513 - val_loss: 1.0986 - val_p_acc: 0.4840\n",
      "Epoch 2103/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9082 - p_acc: 0.5721 - val_loss: 1.0996 - val_p_acc: 0.5369\n",
      "Epoch 2104/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8828 - p_acc: 0.6034 - val_loss: 1.0997 - val_p_acc: 0.5192\n",
      "Epoch 2105/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9443 - p_acc: 0.5841 - val_loss: 1.1005 - val_p_acc: 0.5192\n",
      "Epoch 2106/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8113 - p_acc: 0.6066 - val_loss: 1.1015 - val_p_acc: 0.5016\n",
      "Epoch 2107/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9375 - p_acc: 0.5529 - val_loss: 1.1007 - val_p_acc: 0.5545\n",
      "Epoch 2108/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9681 - p_acc: 0.5441 - val_loss: 1.1008 - val_p_acc: 0.5192\n",
      "Epoch 2109/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8132 - p_acc: 0.6330 - val_loss: 1.1015 - val_p_acc: 0.5016\n",
      "Epoch 2110/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8666 - p_acc: 0.6226 - val_loss: 1.1018 - val_p_acc: 0.4840\n",
      "Epoch 2111/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9289 - p_acc: 0.5633 - val_loss: 1.1007 - val_p_acc: 0.5192\n",
      "Epoch 2112/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8906 - p_acc: 0.6434 - val_loss: 1.1012 - val_p_acc: 0.5016\n",
      "Epoch 2113/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8664 - p_acc: 0.5737 - val_loss: 1.1011 - val_p_acc: 0.5192\n",
      "Epoch 2114/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8417 - p_acc: 0.6434 - val_loss: 1.1012 - val_p_acc: 0.4840\n",
      "Epoch 2115/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9127 - p_acc: 0.5585 - val_loss: 1.1024 - val_p_acc: 0.5369\n",
      "Epoch 2116/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9169 - p_acc: 0.5929 - val_loss: 1.1025 - val_p_acc: 0.4840\n",
      "Epoch 2117/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9922 - p_acc: 0.6154 - val_loss: 1.1040 - val_p_acc: 0.5192\n",
      "Epoch 2118/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8205 - p_acc: 0.6627 - val_loss: 1.1068 - val_p_acc: 0.4663\n",
      "Epoch 2119/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8552 - p_acc: 0.6330 - val_loss: 1.1079 - val_p_acc: 0.5192\n",
      "Epoch 2120/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8889 - p_acc: 0.5393 - val_loss: 1.1066 - val_p_acc: 0.5016\n",
      "Epoch 2121/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7654 - p_acc: 0.6907 - val_loss: 1.1067 - val_p_acc: 0.4840\n",
      "Epoch 2122/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8633 - p_acc: 0.6595 - val_loss: 1.1060 - val_p_acc: 0.5369\n",
      "Epoch 2123/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8340 - p_acc: 0.6210 - val_loss: 1.1077 - val_p_acc: 0.5369\n",
      "Epoch 2124/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8647 - p_acc: 0.6242 - val_loss: 1.1080 - val_p_acc: 0.5192\n",
      "Epoch 2125/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8530 - p_acc: 0.6571 - val_loss: 1.1066 - val_p_acc: 0.4663\n",
      "Epoch 2126/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8772 - p_acc: 0.5753 - val_loss: 1.1061 - val_p_acc: 0.5192\n",
      "Epoch 2127/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9003 - p_acc: 0.5825 - val_loss: 1.1044 - val_p_acc: 0.5369\n",
      "Epoch 2128/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8660 - p_acc: 0.5425 - val_loss: 1.1038 - val_p_acc: 0.5369\n",
      "Epoch 2129/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9006 - p_acc: 0.5946 - val_loss: 1.1033 - val_p_acc: 0.5721\n",
      "Epoch 2130/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8190 - p_acc: 0.6226 - val_loss: 1.1007 - val_p_acc: 0.5545\n",
      "Epoch 2131/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9632 - p_acc: 0.5272 - val_loss: 1.1012 - val_p_acc: 0.5369\n",
      "Epoch 2132/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8936 - p_acc: 0.6002 - val_loss: 1.1027 - val_p_acc: 0.5192\n",
      "Epoch 2133/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8918 - p_acc: 0.5513 - val_loss: 1.1033 - val_p_acc: 0.5545\n",
      "Epoch 2134/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8635 - p_acc: 0.6018 - val_loss: 1.1038 - val_p_acc: 0.5369\n",
      "Epoch 2135/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8458 - p_acc: 0.6314 - val_loss: 1.1031 - val_p_acc: 0.5369\n",
      "Epoch 2136/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8455 - p_acc: 0.6330 - val_loss: 1.1019 - val_p_acc: 0.5369\n",
      "Epoch 2137/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8931 - p_acc: 0.6058 - val_loss: 1.1014 - val_p_acc: 0.5369\n",
      "Epoch 2138/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8435 - p_acc: 0.6122 - val_loss: 1.0994 - val_p_acc: 0.5369\n",
      "Epoch 2139/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8879 - p_acc: 0.6522 - val_loss: 1.1001 - val_p_acc: 0.5016\n",
      "Epoch 2140/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9156 - p_acc: 0.5841 - val_loss: 1.0994 - val_p_acc: 0.4840\n",
      "Epoch 2141/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8712 - p_acc: 0.6731 - val_loss: 1.0997 - val_p_acc: 0.5192\n",
      "Epoch 2142/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8543 - p_acc: 0.6819 - val_loss: 1.0996 - val_p_acc: 0.5192\n",
      "Epoch 2143/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9139 - p_acc: 0.6538 - val_loss: 1.1012 - val_p_acc: 0.5369\n",
      "Epoch 2144/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8824 - p_acc: 0.6330 - val_loss: 1.1009 - val_p_acc: 0.5369\n",
      "Epoch 2145/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8678 - p_acc: 0.6346 - val_loss: 1.1011 - val_p_acc: 0.5192\n",
      "Epoch 2146/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8885 - p_acc: 0.5617 - val_loss: 1.1035 - val_p_acc: 0.5016\n",
      "Epoch 2147/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9117 - p_acc: 0.5929 - val_loss: 1.1032 - val_p_acc: 0.4840\n",
      "Epoch 2148/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9385 - p_acc: 0.6034 - val_loss: 1.1031 - val_p_acc: 0.4840\n",
      "Epoch 2149/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8752 - p_acc: 0.6466 - val_loss: 1.1031 - val_p_acc: 0.5192\n",
      "Epoch 2150/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8577 - p_acc: 0.6715 - val_loss: 1.1025 - val_p_acc: 0.4487\n",
      "Epoch 2151/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.8267 - p_acc: 0.6787 - val_loss: 1.1008 - val_p_acc: 0.4840\n",
      "Epoch 2152/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8785 - p_acc: 0.6506 - val_loss: 1.1008 - val_p_acc: 0.4840\n",
      "Epoch 2153/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9312 - p_acc: 0.5705 - val_loss: 1.1019 - val_p_acc: 0.5192\n",
      "Epoch 2154/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8933 - p_acc: 0.5753 - val_loss: 1.1040 - val_p_acc: 0.5192\n",
      "Epoch 2155/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8547 - p_acc: 0.6138 - val_loss: 1.1041 - val_p_acc: 0.4487\n",
      "Epoch 2156/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8815 - p_acc: 0.5913 - val_loss: 1.1035 - val_p_acc: 0.5016\n",
      "Epoch 2157/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8307 - p_acc: 0.5617 - val_loss: 1.1040 - val_p_acc: 0.5192\n",
      "Epoch 2158/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8554 - p_acc: 0.6122 - val_loss: 1.1049 - val_p_acc: 0.5192\n",
      "Epoch 2159/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8693 - p_acc: 0.5809 - val_loss: 1.1044 - val_p_acc: 0.5192\n",
      "Epoch 2160/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8625 - p_acc: 0.6194 - val_loss: 1.1035 - val_p_acc: 0.5369\n",
      "Epoch 2161/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8099 - p_acc: 0.7220 - val_loss: 1.1041 - val_p_acc: 0.5192\n",
      "Epoch 2162/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9405 - p_acc: 0.5986 - val_loss: 1.1041 - val_p_acc: 0.5016\n",
      "Epoch 2163/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7995 - p_acc: 0.6955 - val_loss: 1.1045 - val_p_acc: 0.5192\n",
      "Epoch 2164/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8563 - p_acc: 0.6418 - val_loss: 1.1056 - val_p_acc: 0.5545\n",
      "Epoch 2165/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8681 - p_acc: 0.6955 - val_loss: 1.1059 - val_p_acc: 0.5192\n",
      "Epoch 2166/5000\n",
      "85/85 [==============================] - 0s 698us/sample - loss: 0.9270 - p_acc: 0.6242 - val_loss: 1.1078 - val_p_acc: 0.5545\n",
      "Epoch 2167/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9061 - p_acc: 0.5617 - val_loss: 1.1061 - val_p_acc: 0.5545\n",
      "Epoch 2168/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8459 - p_acc: 0.6346 - val_loss: 1.1059 - val_p_acc: 0.5369\n",
      "Epoch 2169/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8893 - p_acc: 0.5825 - val_loss: 1.1048 - val_p_acc: 0.5016\n",
      "Epoch 2170/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 1.0166 - p_acc: 0.5409 - val_loss: 1.1047 - val_p_acc: 0.5721\n",
      "Epoch 2171/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8910 - p_acc: 0.6402 - val_loss: 1.1034 - val_p_acc: 0.5192\n",
      "Epoch 2172/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8376 - p_acc: 0.5962 - val_loss: 1.1029 - val_p_acc: 0.5192\n",
      "Epoch 2173/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8488 - p_acc: 0.6522 - val_loss: 1.1025 - val_p_acc: 0.5545\n",
      "Epoch 2174/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8196 - p_acc: 0.6923 - val_loss: 1.1032 - val_p_acc: 0.5369\n",
      "Epoch 2175/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8411 - p_acc: 0.6314 - val_loss: 1.1038 - val_p_acc: 0.5545\n",
      "Epoch 2176/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9282 - p_acc: 0.6402 - val_loss: 1.1043 - val_p_acc: 0.5192\n",
      "Epoch 2177/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9068 - p_acc: 0.5841 - val_loss: 1.1058 - val_p_acc: 0.5192\n",
      "Epoch 2178/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9412 - p_acc: 0.5513 - val_loss: 1.1067 - val_p_acc: 0.4840\n",
      "Epoch 2179/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9529 - p_acc: 0.5825 - val_loss: 1.1074 - val_p_acc: 0.5016\n",
      "Epoch 2180/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8666 - p_acc: 0.5617 - val_loss: 1.1076 - val_p_acc: 0.4663\n",
      "Epoch 2181/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8050 - p_acc: 0.6258 - val_loss: 1.1077 - val_p_acc: 0.5192\n",
      "Epoch 2182/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8517 - p_acc: 0.5962 - val_loss: 1.1074 - val_p_acc: 0.5369\n",
      "Epoch 2183/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8729 - p_acc: 0.6226 - val_loss: 1.1077 - val_p_acc: 0.4663\n",
      "Epoch 2184/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8699 - p_acc: 0.5929 - val_loss: 1.1084 - val_p_acc: 0.4840\n",
      "Epoch 2185/5000\n",
      "85/85 [==============================] - 0s 686us/sample - loss: 0.9098 - p_acc: 0.6002 - val_loss: 1.1106 - val_p_acc: 0.5192\n",
      "Epoch 2186/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8941 - p_acc: 0.5353 - val_loss: 1.1113 - val_p_acc: 0.5545\n",
      "Epoch 2187/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9198 - p_acc: 0.5304 - val_loss: 1.1122 - val_p_acc: 0.5192\n",
      "Epoch 2188/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8873 - p_acc: 0.6298 - val_loss: 1.1124 - val_p_acc: 0.5016\n",
      "Epoch 2189/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9057 - p_acc: 0.5753 - val_loss: 1.1134 - val_p_acc: 0.4840\n",
      "Epoch 2190/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8471 - p_acc: 0.6242 - val_loss: 1.1146 - val_p_acc: 0.4663\n",
      "Epoch 2191/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8499 - p_acc: 0.5873 - val_loss: 1.1138 - val_p_acc: 0.5369\n",
      "Epoch 2192/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8458 - p_acc: 0.6242 - val_loss: 1.1150 - val_p_acc: 0.5369\n",
      "Epoch 2193/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 0.9358 - p_acc: 0.6226 - val_loss: 1.1151 - val_p_acc: 0.5016\n",
      "Epoch 2194/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8147 - p_acc: 0.6715 - val_loss: 1.1144 - val_p_acc: 0.4487\n",
      "Epoch 2195/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8804 - p_acc: 0.6450 - val_loss: 1.1148 - val_p_acc: 0.5369\n",
      "Epoch 2196/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7909 - p_acc: 0.7043 - val_loss: 1.1152 - val_p_acc: 0.5369\n",
      "Epoch 2197/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9202 - p_acc: 0.5705 - val_loss: 1.1162 - val_p_acc: 0.5369\n",
      "Epoch 2198/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9296 - p_acc: 0.6106 - val_loss: 1.1178 - val_p_acc: 0.5192\n",
      "Epoch 2199/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9239 - p_acc: 0.5793 - val_loss: 1.1191 - val_p_acc: 0.5016\n",
      "Epoch 2200/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9014 - p_acc: 0.6747 - val_loss: 1.1195 - val_p_acc: 0.5721\n",
      "Epoch 2201/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8463 - p_acc: 0.6506 - val_loss: 1.1190 - val_p_acc: 0.5016\n",
      "Epoch 2202/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8379 - p_acc: 0.6434 - val_loss: 1.1193 - val_p_acc: 0.5192\n",
      "Epoch 2203/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8764 - p_acc: 0.6715 - val_loss: 1.1189 - val_p_acc: 0.5192\n",
      "Epoch 2204/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9131 - p_acc: 0.6506 - val_loss: 1.1199 - val_p_acc: 0.5192\n",
      "Epoch 2205/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8671 - p_acc: 0.6330 - val_loss: 1.1206 - val_p_acc: 0.4663\n",
      "Epoch 2206/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8364 - p_acc: 0.6090 - val_loss: 1.1201 - val_p_acc: 0.5192\n",
      "Epoch 2207/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8739 - p_acc: 0.6418 - val_loss: 1.1195 - val_p_acc: 0.5369\n",
      "Epoch 2208/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9320 - p_acc: 0.5617 - val_loss: 1.1204 - val_p_acc: 0.4663\n",
      "Epoch 2209/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8662 - p_acc: 0.5737 - val_loss: 1.1201 - val_p_acc: 0.5192\n",
      "Epoch 2210/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8617 - p_acc: 0.6418 - val_loss: 1.1201 - val_p_acc: 0.4840\n",
      "Epoch 2211/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9440 - p_acc: 0.6346 - val_loss: 1.1191 - val_p_acc: 0.5016\n",
      "Epoch 2212/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 0.8475 - p_acc: 0.6538 - val_loss: 1.1162 - val_p_acc: 0.4663\n",
      "Epoch 2213/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8218 - p_acc: 0.6627 - val_loss: 1.1156 - val_p_acc: 0.5192\n",
      "Epoch 2214/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8368 - p_acc: 0.6482 - val_loss: 1.1128 - val_p_acc: 0.5016\n",
      "Epoch 2215/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9421 - p_acc: 0.5513 - val_loss: 1.1123 - val_p_acc: 0.4663\n",
      "Epoch 2216/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8610 - p_acc: 0.5529 - val_loss: 1.1124 - val_p_acc: 0.4840\n",
      "Epoch 2217/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8080 - p_acc: 0.6851 - val_loss: 1.1129 - val_p_acc: 0.5369\n",
      "Epoch 2218/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8458 - p_acc: 0.6450 - val_loss: 1.1136 - val_p_acc: 0.5192\n",
      "Epoch 2219/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7468 - p_acc: 0.6554 - val_loss: 1.1137 - val_p_acc: 0.5016\n",
      "Epoch 2220/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8672 - p_acc: 0.6050 - val_loss: 1.1159 - val_p_acc: 0.4840\n",
      "Epoch 2221/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9176 - p_acc: 0.5337 - val_loss: 1.1161 - val_p_acc: 0.5016\n",
      "Epoch 2222/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8471 - p_acc: 0.5841 - val_loss: 1.1177 - val_p_acc: 0.5192\n",
      "Epoch 2223/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8740 - p_acc: 0.6538 - val_loss: 1.1180 - val_p_acc: 0.5016\n",
      "Epoch 2224/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8259 - p_acc: 0.6522 - val_loss: 1.1186 - val_p_acc: 0.4840\n",
      "Epoch 2225/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8786 - p_acc: 0.6699 - val_loss: 1.1183 - val_p_acc: 0.5192\n",
      "Epoch 2226/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9233 - p_acc: 0.6242 - val_loss: 1.1180 - val_p_acc: 0.5016\n",
      "Epoch 2227/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9215 - p_acc: 0.5913 - val_loss: 1.1184 - val_p_acc: 0.5016\n",
      "Epoch 2228/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8493 - p_acc: 0.6122 - val_loss: 1.1192 - val_p_acc: 0.4840\n",
      "Epoch 2229/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8544 - p_acc: 0.6242 - val_loss: 1.1183 - val_p_acc: 0.5016\n",
      "Epoch 2230/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8767 - p_acc: 0.6907 - val_loss: 1.1175 - val_p_acc: 0.5192\n",
      "Epoch 2231/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9444 - p_acc: 0.5561 - val_loss: 1.1159 - val_p_acc: 0.4840\n",
      "Epoch 2232/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8995 - p_acc: 0.6210 - val_loss: 1.1157 - val_p_acc: 0.5369\n",
      "Epoch 2233/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8430 - p_acc: 0.6803 - val_loss: 1.1167 - val_p_acc: 0.5016\n",
      "Epoch 2234/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7915 - p_acc: 0.7460 - val_loss: 1.1189 - val_p_acc: 0.5369\n",
      "Epoch 2235/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8943 - p_acc: 0.6002 - val_loss: 1.1201 - val_p_acc: 0.5192\n",
      "Epoch 2236/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8756 - p_acc: 0.6346 - val_loss: 1.1203 - val_p_acc: 0.5016\n",
      "Epoch 2237/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7985 - p_acc: 0.7220 - val_loss: 1.1219 - val_p_acc: 0.4840\n",
      "Epoch 2238/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8367 - p_acc: 0.6434 - val_loss: 1.1220 - val_p_acc: 0.5369\n",
      "Epoch 2239/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9055 - p_acc: 0.6450 - val_loss: 1.1221 - val_p_acc: 0.5369\n",
      "Epoch 2240/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8743 - p_acc: 0.6402 - val_loss: 1.1213 - val_p_acc: 0.5016\n",
      "Epoch 2241/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8701 - p_acc: 0.6002 - val_loss: 1.1211 - val_p_acc: 0.5016\n",
      "Epoch 2242/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8823 - p_acc: 0.6154 - val_loss: 1.1198 - val_p_acc: 0.4840\n",
      "Epoch 2243/5000\n",
      "85/85 [==============================] - 0s 707us/sample - loss: 0.9427 - p_acc: 0.5721 - val_loss: 1.1195 - val_p_acc: 0.5369\n",
      "Epoch 2244/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8337 - p_acc: 0.6242 - val_loss: 1.1203 - val_p_acc: 0.5016\n",
      "Epoch 2245/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8201 - p_acc: 0.6210 - val_loss: 1.1210 - val_p_acc: 0.5545\n",
      "Epoch 2246/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9367 - p_acc: 0.5825 - val_loss: 1.1222 - val_p_acc: 0.5016\n",
      "Epoch 2247/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8749 - p_acc: 0.6138 - val_loss: 1.1230 - val_p_acc: 0.4840\n",
      "Epoch 2248/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8371 - p_acc: 0.6907 - val_loss: 1.1225 - val_p_acc: 0.5016\n",
      "Epoch 2249/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8928 - p_acc: 0.6226 - val_loss: 1.1220 - val_p_acc: 0.5192\n",
      "Epoch 2250/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.9321 - p_acc: 0.5809 - val_loss: 1.1215 - val_p_acc: 0.5016\n",
      "Epoch 2251/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8622 - p_acc: 0.5753 - val_loss: 1.1213 - val_p_acc: 0.4840\n",
      "Epoch 2252/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8488 - p_acc: 0.6402 - val_loss: 1.1236 - val_p_acc: 0.5369\n",
      "Epoch 2253/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6760 - p_acc: 0.708 - 0s 716us/sample - loss: 0.9007 - p_acc: 0.5946 - val_loss: 1.1247 - val_p_acc: 0.5016\n",
      "Epoch 2254/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8952 - p_acc: 0.5529 - val_loss: 1.1273 - val_p_acc: 0.5016\n",
      "Epoch 2255/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8860 - p_acc: 0.6226 - val_loss: 1.1286 - val_p_acc: 0.5369\n",
      "Epoch 2256/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8681 - p_acc: 0.6090 - val_loss: 1.1306 - val_p_acc: 0.5192\n",
      "Epoch 2257/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7962 - p_acc: 0.6434 - val_loss: 1.1313 - val_p_acc: 0.5545\n",
      "Epoch 2258/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8756 - p_acc: 0.7043 - val_loss: 1.1314 - val_p_acc: 0.5545\n",
      "Epoch 2259/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9070 - p_acc: 0.6314 - val_loss: 1.1330 - val_p_acc: 0.5016\n",
      "Epoch 2260/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9067 - p_acc: 0.5753 - val_loss: 1.1339 - val_p_acc: 0.5016\n",
      "Epoch 2261/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9262 - p_acc: 0.6002 - val_loss: 1.1350 - val_p_acc: 0.5016\n",
      "Epoch 2262/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8429 - p_acc: 0.6482 - val_loss: 1.1362 - val_p_acc: 0.5016\n",
      "Epoch 2263/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8185 - p_acc: 0.6747 - val_loss: 1.1374 - val_p_acc: 0.4840\n",
      "Epoch 2264/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8679 - p_acc: 0.6699 - val_loss: 1.1378 - val_p_acc: 0.5369\n",
      "Epoch 2265/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8997 - p_acc: 0.5457 - val_loss: 1.1381 - val_p_acc: 0.5016\n",
      "Epoch 2266/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8258 - p_acc: 0.6731 - val_loss: 1.1379 - val_p_acc: 0.4840\n",
      "Epoch 2267/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8475 - p_acc: 0.6538 - val_loss: 1.1373 - val_p_acc: 0.5016\n",
      "Epoch 2268/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9179 - p_acc: 0.5897 - val_loss: 1.1368 - val_p_acc: 0.5016\n",
      "Epoch 2269/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8423 - p_acc: 0.6506 - val_loss: 1.1374 - val_p_acc: 0.5016\n",
      "Epoch 2270/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8267 - p_acc: 0.6450 - val_loss: 1.1380 - val_p_acc: 0.5016\n",
      "Epoch 2271/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8735 - p_acc: 0.6330 - val_loss: 1.1382 - val_p_acc: 0.4663\n",
      "Epoch 2272/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8537 - p_acc: 0.6731 - val_loss: 1.1358 - val_p_acc: 0.5369\n",
      "Epoch 2273/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8869 - p_acc: 0.6314 - val_loss: 1.1349 - val_p_acc: 0.5369\n",
      "Epoch 2274/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8504 - p_acc: 0.6050 - val_loss: 1.1342 - val_p_acc: 0.5369\n",
      "Epoch 2275/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9410 - p_acc: 0.6386 - val_loss: 1.1325 - val_p_acc: 0.5369\n",
      "Epoch 2276/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8688 - p_acc: 0.6154 - val_loss: 1.1325 - val_p_acc: 0.4663\n",
      "Epoch 2277/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8777 - p_acc: 0.6643 - val_loss: 1.1319 - val_p_acc: 0.5192\n",
      "Epoch 2278/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8918 - p_acc: 0.6210 - val_loss: 1.1313 - val_p_acc: 0.4840\n",
      "Epoch 2279/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9275 - p_acc: 0.5721 - val_loss: 1.1310 - val_p_acc: 0.4840\n",
      "Epoch 2280/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8165 - p_acc: 0.6050 - val_loss: 1.1299 - val_p_acc: 0.4840\n",
      "Epoch 2281/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8058 - p_acc: 0.6018 - val_loss: 1.1293 - val_p_acc: 0.5016\n",
      "Epoch 2282/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9698 - p_acc: 0.5409 - val_loss: 1.1299 - val_p_acc: 0.5192\n",
      "Epoch 2283/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.7848 - p_acc: 0.5913 - val_loss: 1.1301 - val_p_acc: 0.5192\n",
      "Epoch 2284/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9200 - p_acc: 0.6210 - val_loss: 1.1312 - val_p_acc: 0.5016\n",
      "Epoch 2285/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8716 - p_acc: 0.5769 - val_loss: 1.1315 - val_p_acc: 0.4840\n",
      "Epoch 2286/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8681 - p_acc: 0.6346 - val_loss: 1.1310 - val_p_acc: 0.4663\n",
      "Epoch 2287/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8364 - p_acc: 0.6554 - val_loss: 1.1318 - val_p_acc: 0.5192\n",
      "Epoch 2288/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8111 - p_acc: 0.6715 - val_loss: 1.1312 - val_p_acc: 0.5369\n",
      "Epoch 2289/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9051 - p_acc: 0.5176 - val_loss: 1.1311 - val_p_acc: 0.4663\n",
      "Epoch 2290/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8640 - p_acc: 0.6002 - val_loss: 1.1319 - val_p_acc: 0.4487\n",
      "Epoch 2291/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8317 - p_acc: 0.5753 - val_loss: 1.1327 - val_p_acc: 0.5016\n",
      "Epoch 2292/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8309 - p_acc: 0.6210 - val_loss: 1.1321 - val_p_acc: 0.5545\n",
      "Epoch 2293/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8977 - p_acc: 0.5841 - val_loss: 1.1321 - val_p_acc: 0.5016\n",
      "Epoch 2294/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8128 - p_acc: 0.6955 - val_loss: 1.1308 - val_p_acc: 0.5192\n",
      "Epoch 2295/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9409 - p_acc: 0.5825 - val_loss: 1.1296 - val_p_acc: 0.5016\n",
      "Epoch 2296/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8781 - p_acc: 0.5841 - val_loss: 1.1275 - val_p_acc: 0.5192\n",
      "Epoch 2297/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8664 - p_acc: 0.6226 - val_loss: 1.1260 - val_p_acc: 0.4840\n",
      "Epoch 2298/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8582 - p_acc: 0.5513 - val_loss: 1.1239 - val_p_acc: 0.5016\n",
      "Epoch 2299/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8390 - p_acc: 0.5929 - val_loss: 1.1215 - val_p_acc: 0.5545\n",
      "Epoch 2300/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8179 - p_acc: 0.6378 - val_loss: 1.1203 - val_p_acc: 0.4840\n",
      "Epoch 2301/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8766 - p_acc: 0.6138 - val_loss: 1.1196 - val_p_acc: 0.5369\n",
      "Epoch 2302/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8696 - p_acc: 0.6282 - val_loss: 1.1181 - val_p_acc: 0.5545\n",
      "Epoch 2303/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8529 - p_acc: 0.6595 - val_loss: 1.1169 - val_p_acc: 0.5016\n",
      "Epoch 2304/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7955 - p_acc: 0.7163 - val_loss: 1.1164 - val_p_acc: 0.5192\n",
      "Epoch 2305/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.2403 - p_acc: 0.500 - 0s 692us/sample - loss: 0.9654 - p_acc: 0.6154 - val_loss: 1.1160 - val_p_acc: 0.5192\n",
      "Epoch 2306/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8369 - p_acc: 0.6627 - val_loss: 1.1170 - val_p_acc: 0.5545\n",
      "Epoch 2307/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8758 - p_acc: 0.5929 - val_loss: 1.1172 - val_p_acc: 0.4663\n",
      "Epoch 2308/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8776 - p_acc: 0.6819 - val_loss: 1.1153 - val_p_acc: 0.5545\n",
      "Epoch 2309/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8214 - p_acc: 0.6034 - val_loss: 1.1152 - val_p_acc: 0.4840\n",
      "Epoch 2310/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9266 - p_acc: 0.6002 - val_loss: 1.1143 - val_p_acc: 0.4663\n",
      "Epoch 2311/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9219 - p_acc: 0.5497 - val_loss: 1.1140 - val_p_acc: 0.5721\n",
      "Epoch 2312/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8696 - p_acc: 0.5112 - val_loss: 1.1137 - val_p_acc: 0.5016\n",
      "Epoch 2313/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8469 - p_acc: 0.6418 - val_loss: 1.1143 - val_p_acc: 0.5192\n",
      "Epoch 2314/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9022 - p_acc: 0.6106 - val_loss: 1.1139 - val_p_acc: 0.5192\n",
      "Epoch 2315/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7743 - p_acc: 0.6418 - val_loss: 1.1134 - val_p_acc: 0.4663\n",
      "Epoch 2316/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8522 - p_acc: 0.5897 - val_loss: 1.1133 - val_p_acc: 0.5192\n",
      "Epoch 2317/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9030 - p_acc: 0.6138 - val_loss: 1.1143 - val_p_acc: 0.5545\n",
      "Epoch 2318/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8724 - p_acc: 0.5825 - val_loss: 1.1150 - val_p_acc: 0.4840\n",
      "Epoch 2319/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8595 - p_acc: 0.5793 - val_loss: 1.1149 - val_p_acc: 0.5192\n",
      "Epoch 2320/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8273 - p_acc: 0.5970 - val_loss: 1.1134 - val_p_acc: 0.5016\n",
      "Epoch 2321/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9125 - p_acc: 0.6018 - val_loss: 1.1128 - val_p_acc: 0.5016\n",
      "Epoch 2322/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8644 - p_acc: 0.6018 - val_loss: 1.1136 - val_p_acc: 0.5016\n",
      "Epoch 2323/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9355 - p_acc: 0.5441 - val_loss: 1.1140 - val_p_acc: 0.5369\n",
      "Epoch 2324/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9333 - p_acc: 0.5929 - val_loss: 1.1144 - val_p_acc: 0.4840\n",
      "Epoch 2325/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8744 - p_acc: 0.6090 - val_loss: 1.1145 - val_p_acc: 0.5016\n",
      "Epoch 2326/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8633 - p_acc: 0.6346 - val_loss: 1.1140 - val_p_acc: 0.5369\n",
      "Epoch 2327/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8592 - p_acc: 0.5705 - val_loss: 1.1141 - val_p_acc: 0.5192\n",
      "Epoch 2328/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9009 - p_acc: 0.6226 - val_loss: 1.1138 - val_p_acc: 0.4663\n",
      "Epoch 2329/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8322 - p_acc: 0.6330 - val_loss: 1.1136 - val_p_acc: 0.4840\n",
      "Epoch 2330/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9477 - p_acc: 0.5513 - val_loss: 1.1130 - val_p_acc: 0.5369\n",
      "Epoch 2331/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8439 - p_acc: 0.6522 - val_loss: 1.1135 - val_p_acc: 0.5016\n",
      "Epoch 2332/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8231 - p_acc: 0.6034 - val_loss: 1.1112 - val_p_acc: 0.5192\n",
      "Epoch 2333/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8961 - p_acc: 0.6851 - val_loss: 1.1113 - val_p_acc: 0.5016\n",
      "Epoch 2334/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8419 - p_acc: 0.7027 - val_loss: 1.1118 - val_p_acc: 0.5369\n",
      "Epoch 2335/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8720 - p_acc: 0.6298 - val_loss: 1.1122 - val_p_acc: 0.5545\n",
      "Epoch 2336/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9043 - p_acc: 0.6330 - val_loss: 1.1123 - val_p_acc: 0.5016\n",
      "Epoch 2337/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8127 - p_acc: 0.5793 - val_loss: 1.1116 - val_p_acc: 0.5192\n",
      "Epoch 2338/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9050 - p_acc: 0.6226 - val_loss: 1.1117 - val_p_acc: 0.5192\n",
      "Epoch 2339/5000\n",
      "85/85 [==============================] - 0s 734us/sample - loss: 0.8973 - p_acc: 0.6314 - val_loss: 1.1119 - val_p_acc: 0.5192\n",
      "Epoch 2340/5000\n",
      "85/85 [==============================] - 0s 834us/sample - loss: 0.8284 - p_acc: 0.6138 - val_loss: 1.1132 - val_p_acc: 0.4840\n",
      "Epoch 2341/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8542 - p_acc: 0.6106 - val_loss: 1.1142 - val_p_acc: 0.5192\n",
      "Epoch 2342/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8967 - p_acc: 0.5825 - val_loss: 1.1171 - val_p_acc: 0.5016\n",
      "Epoch 2343/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.8715 - p_acc: 0.5737 - val_loss: 1.1182 - val_p_acc: 0.5192\n",
      "Epoch 2344/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8743 - p_acc: 0.6346 - val_loss: 1.1175 - val_p_acc: 0.5545\n",
      "Epoch 2345/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8594 - p_acc: 0.6683 - val_loss: 1.1176 - val_p_acc: 0.4663\n",
      "Epoch 2346/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8171 - p_acc: 0.6418 - val_loss: 1.1177 - val_p_acc: 0.5192\n",
      "Epoch 2347/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8736 - p_acc: 0.6611 - val_loss: 1.1161 - val_p_acc: 0.5016\n",
      "Epoch 2348/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8323 - p_acc: 0.6643 - val_loss: 1.1153 - val_p_acc: 0.4663\n",
      "Epoch 2349/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8902 - p_acc: 0.6434 - val_loss: 1.1144 - val_p_acc: 0.5192\n",
      "Epoch 2350/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9134 - p_acc: 0.6434 - val_loss: 1.1130 - val_p_acc: 0.5369\n",
      "Epoch 2351/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8167 - p_acc: 0.6522 - val_loss: 1.1134 - val_p_acc: 0.5721\n",
      "Epoch 2352/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8979 - p_acc: 0.5617 - val_loss: 1.1157 - val_p_acc: 0.5016\n",
      "Epoch 2353/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8795 - p_acc: 0.6402 - val_loss: 1.1163 - val_p_acc: 0.5016\n",
      "Epoch 2354/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8700 - p_acc: 0.6538 - val_loss: 1.1175 - val_p_acc: 0.5192\n",
      "Epoch 2355/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7869 - p_acc: 0.7236 - val_loss: 1.1160 - val_p_acc: 0.5369\n",
      "Epoch 2356/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8689 - p_acc: 0.5946 - val_loss: 1.1164 - val_p_acc: 0.5016\n",
      "Epoch 2357/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8452 - p_acc: 0.6242 - val_loss: 1.1154 - val_p_acc: 0.5016\n",
      "Epoch 2358/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8285 - p_acc: 0.6346 - val_loss: 1.1160 - val_p_acc: 0.4840\n",
      "Epoch 2359/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9008 - p_acc: 0.5144 - val_loss: 1.1161 - val_p_acc: 0.4840\n",
      "Epoch 2360/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8375 - p_acc: 0.7099 - val_loss: 1.1152 - val_p_acc: 0.5192\n",
      "Epoch 2361/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8019 - p_acc: 0.7043 - val_loss: 1.1151 - val_p_acc: 0.5016\n",
      "Epoch 2362/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8270 - p_acc: 0.6362 - val_loss: 1.1124 - val_p_acc: 0.5545\n",
      "Epoch 2363/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9760 - p_acc: 0.6002 - val_loss: 1.1119 - val_p_acc: 0.5192\n",
      "Epoch 2364/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9214 - p_acc: 0.6362 - val_loss: 1.1105 - val_p_acc: 0.5192\n",
      "Epoch 2365/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8337 - p_acc: 0.6258 - val_loss: 1.1094 - val_p_acc: 0.4840\n",
      "Epoch 2366/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.8591 - p_acc: 0.6643 - val_loss: 1.1094 - val_p_acc: 0.5369\n",
      "Epoch 2367/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8040 - p_acc: 0.6627 - val_loss: 1.1100 - val_p_acc: 0.5016\n",
      "Epoch 2368/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9032 - p_acc: 0.5248 - val_loss: 1.1100 - val_p_acc: 0.5192\n",
      "Epoch 2369/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9038 - p_acc: 0.6314 - val_loss: 1.1103 - val_p_acc: 0.5192\n",
      "Epoch 2370/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8554 - p_acc: 0.6506 - val_loss: 1.1108 - val_p_acc: 0.5369\n",
      "Epoch 2371/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7972 - p_acc: 0.6490 - val_loss: 1.1107 - val_p_acc: 0.5016\n",
      "Epoch 2372/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8768 - p_acc: 0.6314 - val_loss: 1.1120 - val_p_acc: 0.4840\n",
      "Epoch 2373/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9030 - p_acc: 0.6050 - val_loss: 1.1128 - val_p_acc: 0.5545\n",
      "Epoch 2374/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8781 - p_acc: 0.5353 - val_loss: 1.1124 - val_p_acc: 0.4840\n",
      "Epoch 2375/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8954 - p_acc: 0.6330 - val_loss: 1.1137 - val_p_acc: 0.5192\n",
      "Epoch 2376/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8696 - p_acc: 0.6082 - val_loss: 1.1142 - val_p_acc: 0.5016\n",
      "Epoch 2377/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8093 - p_acc: 0.7027 - val_loss: 1.1135 - val_p_acc: 0.5192\n",
      "Epoch 2378/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7840 - p_acc: 0.6522 - val_loss: 1.1122 - val_p_acc: 0.5545\n",
      "Epoch 2379/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8601 - p_acc: 0.6242 - val_loss: 1.1127 - val_p_acc: 0.5016\n",
      "Epoch 2380/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9762 - p_acc: 0.5721 - val_loss: 1.1141 - val_p_acc: 0.5545\n",
      "Epoch 2381/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8293 - p_acc: 0.7147 - val_loss: 1.1135 - val_p_acc: 0.5545\n",
      "Epoch 2382/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8971 - p_acc: 0.5393 - val_loss: 1.1141 - val_p_acc: 0.5545\n",
      "Epoch 2383/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7980 - p_acc: 0.6226 - val_loss: 1.1150 - val_p_acc: 0.5016\n",
      "Epoch 2384/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8229 - p_acc: 0.6418 - val_loss: 1.1150 - val_p_acc: 0.5016\n",
      "Epoch 2385/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 1.0475 - p_acc: 0.5601 - val_loss: 1.1159 - val_p_acc: 0.5369\n",
      "Epoch 2386/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8271 - p_acc: 0.6835 - val_loss: 1.1153 - val_p_acc: 0.5192\n",
      "Epoch 2387/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7670 - p_acc: 0.7460 - val_loss: 1.1153 - val_p_acc: 0.5016\n",
      "Epoch 2388/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8761 - p_acc: 0.6210 - val_loss: 1.1154 - val_p_acc: 0.4663\n",
      "Epoch 2389/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8122 - p_acc: 0.6538 - val_loss: 1.1153 - val_p_acc: 0.5192\n",
      "Epoch 2390/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8105 - p_acc: 0.6034 - val_loss: 1.1149 - val_p_acc: 0.5192\n",
      "Epoch 2391/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8585 - p_acc: 0.5737 - val_loss: 1.1161 - val_p_acc: 0.5016\n",
      "Epoch 2392/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8554 - p_acc: 0.5705 - val_loss: 1.1160 - val_p_acc: 0.5192\n",
      "Epoch 2393/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9323 - p_acc: 0.5633 - val_loss: 1.1178 - val_p_acc: 0.5545\n",
      "Epoch 2394/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8282 - p_acc: 0.6939 - val_loss: 1.1189 - val_p_acc: 0.5192\n",
      "Epoch 2395/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9100 - p_acc: 0.6346 - val_loss: 1.1200 - val_p_acc: 0.5016\n",
      "Epoch 2396/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7633 - p_acc: 0.6434 - val_loss: 1.1210 - val_p_acc: 0.4840\n",
      "Epoch 2397/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8481 - p_acc: 0.6538 - val_loss: 1.1223 - val_p_acc: 0.4663\n",
      "Epoch 2398/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7660 - p_acc: 0.7532 - val_loss: 1.1248 - val_p_acc: 0.5016\n",
      "Epoch 2399/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8849 - p_acc: 0.5825 - val_loss: 1.1260 - val_p_acc: 0.5545\n",
      "Epoch 2400/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8900 - p_acc: 0.6402 - val_loss: 1.1263 - val_p_acc: 0.5192\n",
      "Epoch 2401/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7828 - p_acc: 0.7115 - val_loss: 1.1269 - val_p_acc: 0.5192\n",
      "Epoch 2402/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8137 - p_acc: 0.6226 - val_loss: 1.1264 - val_p_acc: 0.5016\n",
      "Epoch 2403/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8700 - p_acc: 0.6747 - val_loss: 1.1281 - val_p_acc: 0.4840\n",
      "Epoch 2404/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9124 - p_acc: 0.6034 - val_loss: 1.1278 - val_p_acc: 0.4840\n",
      "Epoch 2405/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8652 - p_acc: 0.6450 - val_loss: 1.1275 - val_p_acc: 0.4840\n",
      "Epoch 2406/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8717 - p_acc: 0.5128 - val_loss: 1.1288 - val_p_acc: 0.5192\n",
      "Epoch 2407/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9362 - p_acc: 0.5946 - val_loss: 1.1290 - val_p_acc: 0.5369\n",
      "Epoch 2408/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8151 - p_acc: 0.6242 - val_loss: 1.1297 - val_p_acc: 0.4840\n",
      "Epoch 2409/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8274 - p_acc: 0.5705 - val_loss: 1.1278 - val_p_acc: 0.5369\n",
      "Epoch 2410/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7899 - p_acc: 0.6763 - val_loss: 1.1270 - val_p_acc: 0.5192\n",
      "Epoch 2411/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8774 - p_acc: 0.5841 - val_loss: 1.1260 - val_p_acc: 0.5369\n",
      "Epoch 2412/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8234 - p_acc: 0.6611 - val_loss: 1.1252 - val_p_acc: 0.5192\n",
      "Epoch 2413/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9009 - p_acc: 0.6018 - val_loss: 1.1250 - val_p_acc: 0.4663\n",
      "Epoch 2414/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8572 - p_acc: 0.5737 - val_loss: 1.1249 - val_p_acc: 0.5192\n",
      "Epoch 2415/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8312 - p_acc: 0.6314 - val_loss: 1.1245 - val_p_acc: 0.5369\n",
      "Epoch 2416/5000\n",
      "85/85 [==============================] - 0s 711us/sample - loss: 0.8256 - p_acc: 0.6298 - val_loss: 1.1225 - val_p_acc: 0.5545\n",
      "Epoch 2417/5000\n",
      "85/85 [==============================] - 0s 722us/sample - loss: 0.9596 - p_acc: 0.6330 - val_loss: 1.1216 - val_p_acc: 0.5016\n",
      "Epoch 2418/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9562 - p_acc: 0.6194 - val_loss: 1.1201 - val_p_acc: 0.4663\n",
      "Epoch 2419/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9733 - p_acc: 0.6226 - val_loss: 1.1203 - val_p_acc: 0.5192\n",
      "Epoch 2420/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8415 - p_acc: 0.6627 - val_loss: 1.1192 - val_p_acc: 0.5192\n",
      "Epoch 2421/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9226 - p_acc: 0.5617 - val_loss: 1.1195 - val_p_acc: 0.4663\n",
      "Epoch 2422/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8224 - p_acc: 0.6298 - val_loss: 1.1194 - val_p_acc: 0.5016\n",
      "Epoch 2423/5000\n",
      "85/85 [==============================] - 0s 702us/sample - loss: 0.8321 - p_acc: 0.6226 - val_loss: 1.1209 - val_p_acc: 0.5192\n",
      "Epoch 2424/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8299 - p_acc: 0.6450 - val_loss: 1.1187 - val_p_acc: 0.5016\n",
      "Epoch 2425/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8431 - p_acc: 0.6122 - val_loss: 1.1105 - val_p_acc: 0.4663\n",
      "Epoch 2426/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9013 - p_acc: 0.5825 - val_loss: 1.1057 - val_p_acc: 0.5545\n",
      "Epoch 2427/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8084 - p_acc: 0.6835 - val_loss: 1.1024 - val_p_acc: 0.5369\n",
      "Epoch 2428/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8414 - p_acc: 0.6298 - val_loss: 1.1002 - val_p_acc: 0.5016\n",
      "Epoch 2429/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8952 - p_acc: 0.5232 - val_loss: 1.0987 - val_p_acc: 0.5369\n",
      "Epoch 2430/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8468 - p_acc: 0.6346 - val_loss: 1.0985 - val_p_acc: 0.5369\n",
      "Epoch 2431/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8456 - p_acc: 0.6643 - val_loss: 1.0992 - val_p_acc: 0.5369\n",
      "Epoch 2432/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8981 - p_acc: 0.6242 - val_loss: 1.1002 - val_p_acc: 0.5545\n",
      "Epoch 2433/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9387 - p_acc: 0.6090 - val_loss: 1.1036 - val_p_acc: 0.5545\n",
      "Epoch 2434/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8938 - p_acc: 0.5689 - val_loss: 1.1054 - val_p_acc: 0.5369\n",
      "Epoch 2435/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9199 - p_acc: 0.6579 - val_loss: 1.1064 - val_p_acc: 0.5192\n",
      "Epoch 2436/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9705 - p_acc: 0.5793 - val_loss: 1.1081 - val_p_acc: 0.5545\n",
      "Epoch 2437/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8290 - p_acc: 0.6330 - val_loss: 1.1084 - val_p_acc: 0.5016\n",
      "Epoch 2438/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8710 - p_acc: 0.6106 - val_loss: 1.1077 - val_p_acc: 0.5545\n",
      "Epoch 2439/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9076 - p_acc: 0.6715 - val_loss: 1.1077 - val_p_acc: 0.5192\n",
      "Epoch 2440/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9449 - p_acc: 0.5080 - val_loss: 1.1076 - val_p_acc: 0.5192\n",
      "Epoch 2441/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7742 - p_acc: 0.6538 - val_loss: 1.1078 - val_p_acc: 0.5016\n",
      "Epoch 2442/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8902 - p_acc: 0.5617 - val_loss: 1.1079 - val_p_acc: 0.5369\n",
      "Epoch 2443/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9079 - p_acc: 0.6034 - val_loss: 1.1093 - val_p_acc: 0.4840\n",
      "Epoch 2444/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8421 - p_acc: 0.6627 - val_loss: 1.1106 - val_p_acc: 0.5192\n",
      "Epoch 2445/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7948 - p_acc: 0.7043 - val_loss: 1.1108 - val_p_acc: 0.4663\n",
      "Epoch 2446/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9032 - p_acc: 0.6210 - val_loss: 1.1119 - val_p_acc: 0.4840\n",
      "Epoch 2447/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8498 - p_acc: 0.5353 - val_loss: 1.1137 - val_p_acc: 0.5192\n",
      "Epoch 2448/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7674 - p_acc: 0.6242 - val_loss: 1.1147 - val_p_acc: 0.5192\n",
      "Epoch 2449/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8026 - p_acc: 0.6258 - val_loss: 1.1143 - val_p_acc: 0.5016\n",
      "Epoch 2450/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8102 - p_acc: 0.6034 - val_loss: 1.1135 - val_p_acc: 0.5192\n",
      "Epoch 2451/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8339 - p_acc: 0.5825 - val_loss: 1.1148 - val_p_acc: 0.4663\n",
      "Epoch 2452/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8838 - p_acc: 0.6418 - val_loss: 1.1154 - val_p_acc: 0.5192\n",
      "Epoch 2453/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8983 - p_acc: 0.6346 - val_loss: 1.1167 - val_p_acc: 0.5192\n",
      "Epoch 2454/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8791 - p_acc: 0.6210 - val_loss: 1.1169 - val_p_acc: 0.5369\n",
      "Epoch 2455/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9176 - p_acc: 0.5809 - val_loss: 1.1163 - val_p_acc: 0.5721\n",
      "Epoch 2456/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8538 - p_acc: 0.5497 - val_loss: 1.1169 - val_p_acc: 0.4663\n",
      "Epoch 2457/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8598 - p_acc: 0.6506 - val_loss: 1.1160 - val_p_acc: 0.5369\n",
      "Epoch 2458/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8174 - p_acc: 0.6835 - val_loss: 1.1157 - val_p_acc: 0.5192\n",
      "Epoch 2459/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8612 - p_acc: 0.5897 - val_loss: 1.1155 - val_p_acc: 0.4840\n",
      "Epoch 2460/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7915 - p_acc: 0.6346 - val_loss: 1.1146 - val_p_acc: 0.5369\n",
      "Epoch 2461/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8888 - p_acc: 0.5529 - val_loss: 1.1139 - val_p_acc: 0.4840\n",
      "Epoch 2462/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8797 - p_acc: 0.5841 - val_loss: 1.1125 - val_p_acc: 0.5192\n",
      "Epoch 2463/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8396 - p_acc: 0.6819 - val_loss: 1.1121 - val_p_acc: 0.5545\n",
      "Epoch 2464/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8685 - p_acc: 0.6106 - val_loss: 1.1108 - val_p_acc: 0.5192\n",
      "Epoch 2465/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7913 - p_acc: 0.6418 - val_loss: 1.1094 - val_p_acc: 0.5016\n",
      "Epoch 2466/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8825 - p_acc: 0.6242 - val_loss: 1.1093 - val_p_acc: 0.5016\n",
      "Epoch 2467/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8894 - p_acc: 0.6034 - val_loss: 1.1101 - val_p_acc: 0.5016\n",
      "Epoch 2468/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9348 - p_acc: 0.5946 - val_loss: 1.1110 - val_p_acc: 0.4840\n",
      "Epoch 2469/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7116 - p_acc: 0.6747 - val_loss: 1.1081 - val_p_acc: 0.5016\n",
      "Epoch 2470/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8819 - p_acc: 0.6522 - val_loss: 1.1076 - val_p_acc: 0.5369\n",
      "Epoch 2471/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8143 - p_acc: 0.6106 - val_loss: 1.1073 - val_p_acc: 0.5192\n",
      "Epoch 2472/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9144 - p_acc: 0.5529 - val_loss: 1.1070 - val_p_acc: 0.4840\n",
      "Epoch 2473/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8918 - p_acc: 0.5529 - val_loss: 1.1084 - val_p_acc: 0.5192\n",
      "Epoch 2474/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9038 - p_acc: 0.5633 - val_loss: 1.1087 - val_p_acc: 0.5016\n",
      "Epoch 2475/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7742 - p_acc: 0.6851 - val_loss: 1.1085 - val_p_acc: 0.4840\n",
      "Epoch 2476/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9078 - p_acc: 0.6210 - val_loss: 1.1091 - val_p_acc: 0.5016\n",
      "Epoch 2477/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8141 - p_acc: 0.6715 - val_loss: 1.1097 - val_p_acc: 0.4840\n",
      "Epoch 2478/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8126 - p_acc: 0.6034 - val_loss: 1.1082 - val_p_acc: 0.5192\n",
      "Epoch 2479/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8434 - p_acc: 0.6138 - val_loss: 1.1085 - val_p_acc: 0.5721\n",
      "Epoch 2480/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8007 - p_acc: 0.6731 - val_loss: 1.1079 - val_p_acc: 0.5016\n",
      "Epoch 2481/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8439 - p_acc: 0.7220 - val_loss: 1.1074 - val_p_acc: 0.5016\n",
      "Epoch 2482/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9124 - p_acc: 0.6298 - val_loss: 1.1083 - val_p_acc: 0.5016\n",
      "Epoch 2483/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9053 - p_acc: 0.5705 - val_loss: 1.1087 - val_p_acc: 0.5369\n",
      "Epoch 2484/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8503 - p_acc: 0.6923 - val_loss: 1.1095 - val_p_acc: 0.5016\n",
      "Epoch 2485/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8162 - p_acc: 0.6763 - val_loss: 1.1103 - val_p_acc: 0.4663\n",
      "Epoch 2486/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8299 - p_acc: 0.5304 - val_loss: 1.1098 - val_p_acc: 0.5016\n",
      "Epoch 2487/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8830 - p_acc: 0.6506 - val_loss: 1.1109 - val_p_acc: 0.5016\n",
      "Epoch 2488/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8567 - p_acc: 0.6554 - val_loss: 1.1103 - val_p_acc: 0.5369\n",
      "Epoch 2489/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8154 - p_acc: 0.6715 - val_loss: 1.1107 - val_p_acc: 0.5192\n",
      "Epoch 2490/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8430 - p_acc: 0.6538 - val_loss: 1.1107 - val_p_acc: 0.4840\n",
      "Epoch 2491/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8635 - p_acc: 0.6386 - val_loss: 1.1111 - val_p_acc: 0.5192\n",
      "Epoch 2492/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8472 - p_acc: 0.6522 - val_loss: 1.1098 - val_p_acc: 0.5192\n",
      "Epoch 2493/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7769 - p_acc: 0.6330 - val_loss: 1.1098 - val_p_acc: 0.5192\n",
      "Epoch 2494/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8760 - p_acc: 0.6122 - val_loss: 1.1110 - val_p_acc: 0.5192\n",
      "Epoch 2495/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7811 - p_acc: 0.6731 - val_loss: 1.1108 - val_p_acc: 0.4840\n",
      "Epoch 2496/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9108 - p_acc: 0.6242 - val_loss: 1.1134 - val_p_acc: 0.4840\n",
      "Epoch 2497/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8686 - p_acc: 0.5633 - val_loss: 1.1150 - val_p_acc: 0.5192\n",
      "Epoch 2498/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9115 - p_acc: 0.5513 - val_loss: 1.1136 - val_p_acc: 0.5192\n",
      "Epoch 2499/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8256 - p_acc: 0.6538 - val_loss: 1.1140 - val_p_acc: 0.5016\n",
      "Epoch 2500/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9018 - p_acc: 0.6194 - val_loss: 1.1152 - val_p_acc: 0.5369\n",
      "Epoch 2501/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8534 - p_acc: 0.5457 - val_loss: 1.1157 - val_p_acc: 0.5192\n",
      "Epoch 2502/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8298 - p_acc: 0.6715 - val_loss: 1.1161 - val_p_acc: 0.5016\n",
      "Epoch 2503/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8168 - p_acc: 0.6611 - val_loss: 1.1158 - val_p_acc: 0.4663\n",
      "Epoch 2504/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8663 - p_acc: 0.5737 - val_loss: 1.1149 - val_p_acc: 0.4840\n",
      "Epoch 2505/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8866 - p_acc: 0.6050 - val_loss: 1.1156 - val_p_acc: 0.5192\n",
      "Epoch 2506/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8434 - p_acc: 0.6018 - val_loss: 1.1163 - val_p_acc: 0.4840\n",
      "Epoch 2507/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 0.8952 - p_acc: 0.5721 - val_loss: 1.1172 - val_p_acc: 0.5192\n",
      "Epoch 2508/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7787 - p_acc: 0.6138 - val_loss: 1.1182 - val_p_acc: 0.4840\n",
      "Epoch 2509/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8408 - p_acc: 0.6378 - val_loss: 1.1186 - val_p_acc: 0.5192\n",
      "Epoch 2510/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8098 - p_acc: 0.6298 - val_loss: 1.1189 - val_p_acc: 0.5192\n",
      "Epoch 2511/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8472 - p_acc: 0.6402 - val_loss: 1.1204 - val_p_acc: 0.5369\n",
      "Epoch 2512/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7939 - p_acc: 0.6939 - val_loss: 1.1201 - val_p_acc: 0.5016\n",
      "Epoch 2513/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8770 - p_acc: 0.6402 - val_loss: 1.1204 - val_p_acc: 0.5545\n",
      "Epoch 2514/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8160 - p_acc: 0.6362 - val_loss: 1.1191 - val_p_acc: 0.4840\n",
      "Epoch 2515/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8347 - p_acc: 0.6226 - val_loss: 1.1201 - val_p_acc: 0.5192\n",
      "Epoch 2516/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8521 - p_acc: 0.6330 - val_loss: 1.1197 - val_p_acc: 0.5545\n",
      "Epoch 2517/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8792 - p_acc: 0.6611 - val_loss: 1.1190 - val_p_acc: 0.5721\n",
      "Epoch 2518/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8272 - p_acc: 0.6731 - val_loss: 1.1188 - val_p_acc: 0.5192\n",
      "Epoch 2519/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8905 - p_acc: 0.5929 - val_loss: 1.1206 - val_p_acc: 0.5369\n",
      "Epoch 2520/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.9441 - p_acc: 0.5913 - val_loss: 1.1226 - val_p_acc: 0.5192\n",
      "Epoch 2521/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8913 - p_acc: 0.6346 - val_loss: 1.1244 - val_p_acc: 0.5369\n",
      "Epoch 2522/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8450 - p_acc: 0.5809 - val_loss: 1.1255 - val_p_acc: 0.5016\n",
      "Epoch 2523/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7890 - p_acc: 0.7147 - val_loss: 1.1264 - val_p_acc: 0.5016\n",
      "Epoch 2524/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9595 - p_acc: 0.5825 - val_loss: 1.1265 - val_p_acc: 0.5016\n",
      "Epoch 2525/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8356 - p_acc: 0.6835 - val_loss: 1.1259 - val_p_acc: 0.5369\n",
      "Epoch 2526/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9614 - p_acc: 0.5441 - val_loss: 1.1252 - val_p_acc: 0.5545\n",
      "Epoch 2527/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8344 - p_acc: 0.6034 - val_loss: 1.1250 - val_p_acc: 0.5016\n",
      "Epoch 2528/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7868 - p_acc: 0.7043 - val_loss: 1.1242 - val_p_acc: 0.4840\n",
      "Epoch 2529/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8897 - p_acc: 0.6731 - val_loss: 1.1248 - val_p_acc: 0.5016\n",
      "Epoch 2530/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9327 - p_acc: 0.4920 - val_loss: 1.1250 - val_p_acc: 0.4840\n",
      "Epoch 2531/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7695 - p_acc: 0.6466 - val_loss: 1.1250 - val_p_acc: 0.5016\n",
      "Epoch 2532/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7892 - p_acc: 0.7268 - val_loss: 1.1239 - val_p_acc: 0.4663\n",
      "Epoch 2533/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8624 - p_acc: 0.6106 - val_loss: 1.1238 - val_p_acc: 0.5192\n",
      "Epoch 2534/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8160 - p_acc: 0.6210 - val_loss: 1.1238 - val_p_acc: 0.5369\n",
      "Epoch 2535/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7646 - p_acc: 0.7147 - val_loss: 1.1241 - val_p_acc: 0.5016\n",
      "Epoch 2536/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9511 - p_acc: 0.6402 - val_loss: 1.1234 - val_p_acc: 0.4840\n",
      "Epoch 2537/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8236 - p_acc: 0.5962 - val_loss: 1.1238 - val_p_acc: 0.5545\n",
      "Epoch 2538/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9587 - p_acc: 0.6122 - val_loss: 1.1233 - val_p_acc: 0.5545\n",
      "Epoch 2539/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8486 - p_acc: 0.6274 - val_loss: 1.1241 - val_p_acc: 0.5192\n",
      "Epoch 2540/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8648 - p_acc: 0.5753 - val_loss: 1.1237 - val_p_acc: 0.5369\n",
      "Epoch 2541/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9304 - p_acc: 0.6034 - val_loss: 1.1237 - val_p_acc: 0.5369\n",
      "Epoch 2542/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8035 - p_acc: 0.6683 - val_loss: 1.1222 - val_p_acc: 0.5192\n",
      "Epoch 2543/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8116 - p_acc: 0.6819 - val_loss: 1.1224 - val_p_acc: 0.5545\n",
      "Epoch 2544/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8206 - p_acc: 0.6506 - val_loss: 1.1227 - val_p_acc: 0.5016\n",
      "Epoch 2545/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9449 - p_acc: 0.5841 - val_loss: 1.1242 - val_p_acc: 0.5192\n",
      "Epoch 2546/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8024 - p_acc: 0.7724 - val_loss: 1.1249 - val_p_acc: 0.5192\n",
      "Epoch 2547/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8036 - p_acc: 0.6538 - val_loss: 1.1253 - val_p_acc: 0.5192\n",
      "Epoch 2548/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8725 - p_acc: 0.6803 - val_loss: 1.1258 - val_p_acc: 0.5369\n",
      "Epoch 2549/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8672 - p_acc: 0.6851 - val_loss: 1.1269 - val_p_acc: 0.5016\n",
      "Epoch 2550/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7925 - p_acc: 0.6490 - val_loss: 1.1265 - val_p_acc: 0.4840\n",
      "Epoch 2551/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8654 - p_acc: 0.6418 - val_loss: 1.1269 - val_p_acc: 0.5192\n",
      "Epoch 2552/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8086 - p_acc: 0.6106 - val_loss: 1.1270 - val_p_acc: 0.5016\n",
      "Epoch 2553/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8947 - p_acc: 0.6226 - val_loss: 1.1277 - val_p_acc: 0.5369\n",
      "Epoch 2554/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8676 - p_acc: 0.6018 - val_loss: 1.1279 - val_p_acc: 0.4311\n",
      "Epoch 2555/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8564 - p_acc: 0.6731 - val_loss: 1.1284 - val_p_acc: 0.4840\n",
      "Epoch 2556/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8554 - p_acc: 0.6851 - val_loss: 1.1281 - val_p_acc: 0.4663\n",
      "Epoch 2557/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8180 - p_acc: 0.6138 - val_loss: 1.1277 - val_p_acc: 0.4840\n",
      "Epoch 2558/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9187 - p_acc: 0.6154 - val_loss: 1.1278 - val_p_acc: 0.5369\n",
      "Epoch 2559/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8359 - p_acc: 0.6346 - val_loss: 1.1264 - val_p_acc: 0.5192\n",
      "Epoch 2560/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8646 - p_acc: 0.6434 - val_loss: 1.1270 - val_p_acc: 0.5016\n",
      "Epoch 2561/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9029 - p_acc: 0.6643 - val_loss: 1.1291 - val_p_acc: 0.5369\n",
      "Epoch 2562/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8188 - p_acc: 0.6731 - val_loss: 1.1295 - val_p_acc: 0.4840\n",
      "Epoch 2563/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9272 - p_acc: 0.6122 - val_loss: 1.1282 - val_p_acc: 0.5192\n",
      "Epoch 2564/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9025 - p_acc: 0.7204 - val_loss: 1.1281 - val_p_acc: 0.5192\n",
      "Epoch 2565/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8771 - p_acc: 0.6018 - val_loss: 1.1285 - val_p_acc: 0.5016\n",
      "Epoch 2566/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8960 - p_acc: 0.5929 - val_loss: 1.1282 - val_p_acc: 0.5016\n",
      "Epoch 2567/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8719 - p_acc: 0.5721 - val_loss: 1.1292 - val_p_acc: 0.5016\n",
      "Epoch 2568/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8241 - p_acc: 0.7147 - val_loss: 1.1308 - val_p_acc: 0.5016\n",
      "Epoch 2569/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8062 - p_acc: 0.6835 - val_loss: 1.1314 - val_p_acc: 0.4840\n",
      "Epoch 2570/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8818 - p_acc: 0.6002 - val_loss: 1.1330 - val_p_acc: 0.5016\n",
      "Epoch 2571/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8199 - p_acc: 0.6731 - val_loss: 1.1339 - val_p_acc: 0.5192\n",
      "Epoch 2572/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8399 - p_acc: 0.6122 - val_loss: 1.1347 - val_p_acc: 0.4840\n",
      "Epoch 2573/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8519 - p_acc: 0.6627 - val_loss: 1.1359 - val_p_acc: 0.5016\n",
      "Epoch 2574/5000\n",
      "85/85 [==============================] - 0s 734us/sample - loss: 0.8497 - p_acc: 0.6434 - val_loss: 1.1362 - val_p_acc: 0.5016\n",
      "Epoch 2575/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7766 - p_acc: 0.6538 - val_loss: 1.1358 - val_p_acc: 0.5016\n",
      "Epoch 2576/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7730 - p_acc: 0.7340 - val_loss: 1.1356 - val_p_acc: 0.5016\n",
      "Epoch 2577/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8458 - p_acc: 0.541 - 0s 692us/sample - loss: 0.8482 - p_acc: 0.6018 - val_loss: 1.1363 - val_p_acc: 0.5192\n",
      "Epoch 2578/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8585 - p_acc: 0.6715 - val_loss: 1.1359 - val_p_acc: 0.5016\n",
      "Epoch 2579/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8933 - p_acc: 0.5962 - val_loss: 1.1356 - val_p_acc: 0.5192\n",
      "Epoch 2580/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7950 - p_acc: 0.7412 - val_loss: 1.1358 - val_p_acc: 0.5016\n",
      "Epoch 2581/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8157 - p_acc: 0.6346 - val_loss: 1.1352 - val_p_acc: 0.5016\n",
      "Epoch 2582/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8170 - p_acc: 0.7043 - val_loss: 1.1354 - val_p_acc: 0.5192\n",
      "Epoch 2583/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8994 - p_acc: 0.6210 - val_loss: 1.1341 - val_p_acc: 0.5369\n",
      "Epoch 2584/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8658 - p_acc: 0.6018 - val_loss: 1.1302 - val_p_acc: 0.5545\n",
      "Epoch 2585/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7776 - p_acc: 0.6939 - val_loss: 1.1294 - val_p_acc: 0.5369\n",
      "Epoch 2586/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8485 - p_acc: 0.6034 - val_loss: 1.1283 - val_p_acc: 0.4840\n",
      "Epoch 2587/5000\n",
      "85/85 [==============================] - 0s 680us/sample - loss: 0.8977 - p_acc: 0.6490 - val_loss: 1.1289 - val_p_acc: 0.5369\n",
      "Epoch 2588/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7795 - p_acc: 0.6747 - val_loss: 1.1287 - val_p_acc: 0.4487\n",
      "Epoch 2589/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8984 - p_acc: 0.6386 - val_loss: 1.1290 - val_p_acc: 0.5016\n",
      "Epoch 2590/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8412 - p_acc: 0.6402 - val_loss: 1.1300 - val_p_acc: 0.5192\n",
      "Epoch 2591/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9066 - p_acc: 0.7027 - val_loss: 1.1308 - val_p_acc: 0.5545\n",
      "Epoch 2592/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9188 - p_acc: 0.5617 - val_loss: 1.1311 - val_p_acc: 0.5016\n",
      "Epoch 2593/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8103 - p_acc: 0.6506 - val_loss: 1.1305 - val_p_acc: 0.5016\n",
      "Epoch 2594/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7913 - p_acc: 0.5825 - val_loss: 1.1301 - val_p_acc: 0.4840\n",
      "Epoch 2595/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8281 - p_acc: 0.6611 - val_loss: 1.1302 - val_p_acc: 0.5192\n",
      "Epoch 2596/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8940 - p_acc: 0.6194 - val_loss: 1.1288 - val_p_acc: 0.5016\n",
      "Epoch 2597/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9653 - p_acc: 0.6538 - val_loss: 1.1284 - val_p_acc: 0.4663\n",
      "Epoch 2598/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8183 - p_acc: 0.7220 - val_loss: 1.1289 - val_p_acc: 0.5545\n",
      "Epoch 2599/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8419 - p_acc: 0.6314 - val_loss: 1.1290 - val_p_acc: 0.4840\n",
      "Epoch 2600/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9086 - p_acc: 0.4920 - val_loss: 1.1298 - val_p_acc: 0.5369\n",
      "Epoch 2601/5000\n",
      "85/85 [==============================] - 0s 687us/sample - loss: 0.8496 - p_acc: 0.6314 - val_loss: 1.1299 - val_p_acc: 0.5369\n",
      "Epoch 2602/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8808 - p_acc: 0.6643 - val_loss: 1.1308 - val_p_acc: 0.5369\n",
      "Epoch 2603/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8307 - p_acc: 0.6450 - val_loss: 1.1324 - val_p_acc: 0.5369\n",
      "Epoch 2604/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8605 - p_acc: 0.6627 - val_loss: 1.1333 - val_p_acc: 0.5545\n",
      "Epoch 2605/5000\n",
      "85/85 [==============================] - 0s 694us/sample - loss: 0.8712 - p_acc: 0.6066 - val_loss: 1.1327 - val_p_acc: 0.5016\n",
      "Epoch 2606/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8037 - p_acc: 0.6522 - val_loss: 1.1322 - val_p_acc: 0.4663\n",
      "Epoch 2607/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8651 - p_acc: 0.5633 - val_loss: 1.1313 - val_p_acc: 0.5192\n",
      "Epoch 2608/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8486 - p_acc: 0.6138 - val_loss: 1.1321 - val_p_acc: 0.5016\n",
      "Epoch 2609/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8387 - p_acc: 0.6554 - val_loss: 1.1326 - val_p_acc: 0.5192\n",
      "Epoch 2610/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8208 - p_acc: 0.6346 - val_loss: 1.1332 - val_p_acc: 0.5545\n",
      "Epoch 2611/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8386 - p_acc: 0.6643 - val_loss: 1.1334 - val_p_acc: 0.4840\n",
      "Epoch 2612/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8235 - p_acc: 0.6418 - val_loss: 1.1333 - val_p_acc: 0.5192\n",
      "Epoch 2613/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8882 - p_acc: 0.6627 - val_loss: 1.1341 - val_p_acc: 0.4840\n",
      "Epoch 2614/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8864 - p_acc: 0.6611 - val_loss: 1.1312 - val_p_acc: 0.5369\n",
      "Epoch 2615/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8760 - p_acc: 0.5705 - val_loss: 1.1292 - val_p_acc: 0.5192\n",
      "Epoch 2616/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8529 - p_acc: 0.6258 - val_loss: 1.1283 - val_p_acc: 0.5721\n",
      "Epoch 2617/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8247 - p_acc: 0.6418 - val_loss: 1.1288 - val_p_acc: 0.5369\n",
      "Epoch 2618/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8518 - p_acc: 0.6018 - val_loss: 1.1283 - val_p_acc: 0.5016\n",
      "Epoch 2619/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7837 - p_acc: 0.6835 - val_loss: 1.1288 - val_p_acc: 0.5016\n",
      "Epoch 2620/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8020 - p_acc: 0.6538 - val_loss: 1.1300 - val_p_acc: 0.5192\n",
      "Epoch 2621/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8081 - p_acc: 0.5946 - val_loss: 1.1294 - val_p_acc: 0.5369\n",
      "Epoch 2622/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7864 - p_acc: 0.7027 - val_loss: 1.1289 - val_p_acc: 0.4840\n",
      "Epoch 2623/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9306 - p_acc: 0.5721 - val_loss: 1.1288 - val_p_acc: 0.5192\n",
      "Epoch 2624/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8643 - p_acc: 0.6522 - val_loss: 1.1274 - val_p_acc: 0.5545\n",
      "Epoch 2625/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8823 - p_acc: 0.6699 - val_loss: 1.1257 - val_p_acc: 0.5369\n",
      "Epoch 2626/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7924 - p_acc: 0.7011 - val_loss: 1.1243 - val_p_acc: 0.5016\n",
      "Epoch 2627/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8827 - p_acc: 0.5721 - val_loss: 1.1230 - val_p_acc: 0.5192\n",
      "Epoch 2628/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7876 - p_acc: 0.6522 - val_loss: 1.1217 - val_p_acc: 0.5192\n",
      "Epoch 2629/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8203 - p_acc: 0.7043 - val_loss: 1.1198 - val_p_acc: 0.5016\n",
      "Epoch 2630/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8399 - p_acc: 0.5160 - val_loss: 1.1198 - val_p_acc: 0.5545\n",
      "Epoch 2631/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8667 - p_acc: 0.7147 - val_loss: 1.1202 - val_p_acc: 0.5192\n",
      "Epoch 2632/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9340 - p_acc: 0.5601 - val_loss: 1.1192 - val_p_acc: 0.5369\n",
      "Epoch 2633/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8654 - p_acc: 0.6643 - val_loss: 1.1193 - val_p_acc: 0.5545\n",
      "Epoch 2634/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9138 - p_acc: 0.5577 - val_loss: 1.1196 - val_p_acc: 0.5192\n",
      "Epoch 2635/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8328 - p_acc: 0.6699 - val_loss: 1.1184 - val_p_acc: 0.5016\n",
      "Epoch 2636/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8146 - p_acc: 0.6611 - val_loss: 1.1183 - val_p_acc: 0.5192\n",
      "Epoch 2637/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7821 - p_acc: 0.6747 - val_loss: 1.1180 - val_p_acc: 0.5016\n",
      "Epoch 2638/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8166 - p_acc: 0.6314 - val_loss: 1.1176 - val_p_acc: 0.5545\n",
      "Epoch 2639/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8579 - p_acc: 0.6506 - val_loss: 1.1165 - val_p_acc: 0.5369\n",
      "Epoch 2640/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8151 - p_acc: 0.6138 - val_loss: 1.1174 - val_p_acc: 0.5192\n",
      "Epoch 2641/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9149 - p_acc: 0.6418 - val_loss: 1.1178 - val_p_acc: 0.5192\n",
      "Epoch 2642/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8784 - p_acc: 0.5481 - val_loss: 1.1188 - val_p_acc: 0.5016\n",
      "Epoch 2643/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8226 - p_acc: 0.6434 - val_loss: 1.1181 - val_p_acc: 0.5369\n",
      "Epoch 2644/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9183 - p_acc: 0.6346 - val_loss: 1.1185 - val_p_acc: 0.5192\n",
      "Epoch 2645/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8240 - p_acc: 0.6835 - val_loss: 1.1189 - val_p_acc: 0.4840\n",
      "Epoch 2646/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8622 - p_acc: 0.5913 - val_loss: 1.1173 - val_p_acc: 0.5369\n",
      "Epoch 2647/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8546 - p_acc: 0.5986 - val_loss: 1.1171 - val_p_acc: 0.4840\n",
      "Epoch 2648/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8490 - p_acc: 0.6282 - val_loss: 1.1161 - val_p_acc: 0.5016\n",
      "Epoch 2649/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8357 - p_acc: 0.6907 - val_loss: 1.1161 - val_p_acc: 0.5016\n",
      "Epoch 2650/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8140 - p_acc: 0.6506 - val_loss: 1.1164 - val_p_acc: 0.5192\n",
      "Epoch 2651/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8544 - p_acc: 0.6034 - val_loss: 1.1158 - val_p_acc: 0.5016\n",
      "Epoch 2652/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8729 - p_acc: 0.6210 - val_loss: 1.1162 - val_p_acc: 0.5369\n",
      "Epoch 2653/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8688 - p_acc: 0.6330 - val_loss: 1.1155 - val_p_acc: 0.5192\n",
      "Epoch 2654/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8637 - p_acc: 0.6490 - val_loss: 1.1155 - val_p_acc: 0.5192\n",
      "Epoch 2655/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8119 - p_acc: 0.6699 - val_loss: 1.1167 - val_p_acc: 0.4840\n",
      "Epoch 2656/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8345 - p_acc: 0.6611 - val_loss: 1.1161 - val_p_acc: 0.5192\n",
      "Epoch 2657/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7634 - p_acc: 0.7204 - val_loss: 1.1164 - val_p_acc: 0.5192\n",
      "Epoch 2658/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8590 - p_acc: 0.6434 - val_loss: 1.1153 - val_p_acc: 0.5016\n",
      "Epoch 2659/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9015 - p_acc: 0.5232 - val_loss: 1.1137 - val_p_acc: 0.4663\n",
      "Epoch 2660/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9008 - p_acc: 0.5897 - val_loss: 1.1138 - val_p_acc: 0.4487\n",
      "Epoch 2661/5000\n",
      "85/85 [==============================] - 0s 707us/sample - loss: 0.8230 - p_acc: 0.6819 - val_loss: 1.1127 - val_p_acc: 0.4840\n",
      "Epoch 2662/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9232 - p_acc: 0.6002 - val_loss: 1.1130 - val_p_acc: 0.5016\n",
      "Epoch 2663/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7926 - p_acc: 0.6314 - val_loss: 1.1200 - val_p_acc: 0.5192\n",
      "Epoch 2664/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.7894 - p_acc: 0.6643 - val_loss: 1.1232 - val_p_acc: 0.5545\n",
      "Epoch 2665/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8333 - p_acc: 0.6330 - val_loss: 1.1256 - val_p_acc: 0.4840\n",
      "Epoch 2666/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8676 - p_acc: 0.6226 - val_loss: 1.1277 - val_p_acc: 0.5016\n",
      "Epoch 2667/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9038 - p_acc: 0.6346 - val_loss: 1.1294 - val_p_acc: 0.5016\n",
      "Epoch 2668/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9171 - p_acc: 0.6258 - val_loss: 1.1307 - val_p_acc: 0.5016\n",
      "Epoch 2669/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8143 - p_acc: 0.7043 - val_loss: 1.1312 - val_p_acc: 0.5016\n",
      "Epoch 2670/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8232 - p_acc: 0.6330 - val_loss: 1.1300 - val_p_acc: 0.5016\n",
      "Epoch 2671/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8488 - p_acc: 0.6194 - val_loss: 1.1284 - val_p_acc: 0.5016\n",
      "Epoch 2672/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.7952 - p_acc: 0.6018 - val_loss: 1.1292 - val_p_acc: 0.5192\n",
      "Epoch 2673/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9177 - p_acc: 0.6066 - val_loss: 1.1293 - val_p_acc: 0.5016\n",
      "Epoch 2674/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9229 - p_acc: 0.6018 - val_loss: 1.1289 - val_p_acc: 0.4840\n",
      "Epoch 2675/5000\n",
      "85/85 [==============================] - 0s 707us/sample - loss: 0.7957 - p_acc: 0.7179 - val_loss: 1.1267 - val_p_acc: 0.4840\n",
      "Epoch 2676/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7415 - p_acc: 0.6787 - val_loss: 1.1271 - val_p_acc: 0.5016\n",
      "Epoch 2677/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8027 - p_acc: 0.5809 - val_loss: 1.1272 - val_p_acc: 0.4663\n",
      "Epoch 2678/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7163 - p_acc: 0.6835 - val_loss: 1.1261 - val_p_acc: 0.5369\n",
      "Epoch 2679/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8888 - p_acc: 0.5705 - val_loss: 1.1265 - val_p_acc: 0.5016\n",
      "Epoch 2680/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8057 - p_acc: 0.6627 - val_loss: 1.1250 - val_p_acc: 0.5192\n",
      "Epoch 2681/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8276 - p_acc: 0.6643 - val_loss: 1.1254 - val_p_acc: 0.5369\n",
      "Epoch 2682/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7612 - p_acc: 0.6522 - val_loss: 1.1244 - val_p_acc: 0.5192\n",
      "Epoch 2683/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7616 - p_acc: 0.6506 - val_loss: 1.1231 - val_p_acc: 0.4840\n",
      "Epoch 2684/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8354 - p_acc: 0.6538 - val_loss: 1.1232 - val_p_acc: 0.4840\n",
      "Epoch 2685/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8664 - p_acc: 0.5857 - val_loss: 1.1229 - val_p_acc: 0.5016\n",
      "Epoch 2686/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8415 - p_acc: 0.6242 - val_loss: 1.1238 - val_p_acc: 0.4840\n",
      "Epoch 2687/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7498 - p_acc: 0.7131 - val_loss: 1.1220 - val_p_acc: 0.4663\n",
      "Epoch 2688/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8086 - p_acc: 0.6611 - val_loss: 1.1213 - val_p_acc: 0.4487\n",
      "Epoch 2689/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8615 - p_acc: 0.6122 - val_loss: 1.1223 - val_p_acc: 0.5192\n",
      "Epoch 2690/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8353 - p_acc: 0.5929 - val_loss: 1.1213 - val_p_acc: 0.5016\n",
      "Epoch 2691/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8466 - p_acc: 0.6699 - val_loss: 1.1186 - val_p_acc: 0.5192\n",
      "Epoch 2692/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8227 - p_acc: 0.6034 - val_loss: 1.1182 - val_p_acc: 0.5016\n",
      "Epoch 2693/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7921 - p_acc: 0.6506 - val_loss: 1.1162 - val_p_acc: 0.4840\n",
      "Epoch 2694/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8058 - p_acc: 0.6522 - val_loss: 1.1163 - val_p_acc: 0.5192\n",
      "Epoch 2695/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8658 - p_acc: 0.6506 - val_loss: 1.1176 - val_p_acc: 0.5016\n",
      "Epoch 2696/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8406 - p_acc: 0.6699 - val_loss: 1.1181 - val_p_acc: 0.5929\n",
      "Epoch 2697/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 681us/sample - loss: 0.9420 - p_acc: 0.5393 - val_loss: 1.1188 - val_p_acc: 0.5048\n",
      "Epoch 2698/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8433 - p_acc: 0.6715 - val_loss: 1.1199 - val_p_acc: 0.5192\n",
      "Epoch 2699/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8544 - p_acc: 0.6554 - val_loss: 1.1202 - val_p_acc: 0.5401\n",
      "Epoch 2700/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9009 - p_acc: 0.5529 - val_loss: 1.1196 - val_p_acc: 0.5401\n",
      "Epoch 2701/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7978 - p_acc: 0.6258 - val_loss: 1.1192 - val_p_acc: 0.5224\n",
      "Epoch 2702/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8645 - p_acc: 0.6242 - val_loss: 1.1191 - val_p_acc: 0.5753\n",
      "Epoch 2703/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8669 - p_acc: 0.6522 - val_loss: 1.1189 - val_p_acc: 0.5577\n",
      "Epoch 2704/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8522 - p_acc: 0.5737 - val_loss: 1.1193 - val_p_acc: 0.5401\n",
      "Epoch 2705/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8537 - p_acc: 0.6907 - val_loss: 1.1196 - val_p_acc: 0.5224\n",
      "Epoch 2706/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8536 - p_acc: 0.6050 - val_loss: 1.1206 - val_p_acc: 0.5401\n",
      "Epoch 2707/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7818 - p_acc: 0.7131 - val_loss: 1.1213 - val_p_acc: 0.5401\n",
      "Epoch 2708/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8221 - p_acc: 0.6835 - val_loss: 1.1215 - val_p_acc: 0.5224\n",
      "Epoch 2709/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8342 - p_acc: 0.6242 - val_loss: 1.1217 - val_p_acc: 0.5753\n",
      "Epoch 2710/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8831 - p_acc: 0.6330 - val_loss: 1.1227 - val_p_acc: 0.5401\n",
      "Epoch 2711/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9234 - p_acc: 0.5737 - val_loss: 1.1275 - val_p_acc: 0.5401\n",
      "Epoch 2712/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8926 - p_acc: 0.5617 - val_loss: 1.1318 - val_p_acc: 0.5929\n",
      "Epoch 2713/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8044 - p_acc: 0.6346 - val_loss: 1.1349 - val_p_acc: 0.5401\n",
      "Epoch 2714/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8616 - p_acc: 0.5705 - val_loss: 1.1379 - val_p_acc: 0.5753\n",
      "Epoch 2715/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8573 - p_acc: 0.6330 - val_loss: 1.1399 - val_p_acc: 0.5577\n",
      "Epoch 2716/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7989 - p_acc: 0.6538 - val_loss: 1.1401 - val_p_acc: 0.5401\n",
      "Epoch 2717/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7777 - p_acc: 0.6138 - val_loss: 1.1410 - val_p_acc: 0.5224\n",
      "Epoch 2718/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8138 - p_acc: 0.6266 - val_loss: 1.1411 - val_p_acc: 0.5401\n",
      "Epoch 2719/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7852 - p_acc: 0.7444 - val_loss: 1.1401 - val_p_acc: 0.5401\n",
      "Epoch 2720/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.9393 - p_acc: 0.6490 - val_loss: 1.1388 - val_p_acc: 0.5401\n",
      "Epoch 2721/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9190 - p_acc: 0.6122 - val_loss: 1.1377 - val_p_acc: 0.5224\n",
      "Epoch 2722/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8614 - p_acc: 0.6330 - val_loss: 1.1372 - val_p_acc: 0.5577\n",
      "Epoch 2723/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8184 - p_acc: 0.6346 - val_loss: 1.1369 - val_p_acc: 0.5224\n",
      "Epoch 2724/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7344 - p_acc: 0.7324 - val_loss: 1.1353 - val_p_acc: 0.5753\n",
      "Epoch 2725/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8689 - p_acc: 0.6090 - val_loss: 1.1332 - val_p_acc: 0.5577\n",
      "Epoch 2726/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7903 - p_acc: 0.6787 - val_loss: 1.1339 - val_p_acc: 0.5224\n",
      "Epoch 2727/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8243 - p_acc: 0.6330 - val_loss: 1.1337 - val_p_acc: 0.5048\n",
      "Epoch 2728/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8098 - p_acc: 0.6627 - val_loss: 1.1320 - val_p_acc: 0.5401\n",
      "Epoch 2729/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8258 - p_acc: 0.6034 - val_loss: 1.1329 - val_p_acc: 0.5577\n",
      "Epoch 2730/5000\n",
      "85/85 [==============================] - 0s 687us/sample - loss: 0.8499 - p_acc: 0.5793 - val_loss: 1.1314 - val_p_acc: 0.5224\n",
      "Epoch 2731/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8484 - p_acc: 0.6210 - val_loss: 1.1307 - val_p_acc: 0.5753\n",
      "Epoch 2732/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8309 - p_acc: 0.6907 - val_loss: 1.1312 - val_p_acc: 0.5577\n",
      "Epoch 2733/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8288 - p_acc: 0.7516 - val_loss: 1.1325 - val_p_acc: 0.5224\n",
      "Epoch 2734/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7836 - p_acc: 0.6835 - val_loss: 1.1334 - val_p_acc: 0.5401\n",
      "Epoch 2735/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8820 - p_acc: 0.6418 - val_loss: 1.1332 - val_p_acc: 0.5401\n",
      "Epoch 2736/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8507 - p_acc: 0.5857 - val_loss: 1.1338 - val_p_acc: 0.5577\n",
      "Epoch 2737/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8479 - p_acc: 0.6034 - val_loss: 1.1341 - val_p_acc: 0.5577\n",
      "Epoch 2738/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8641 - p_acc: 0.6955 - val_loss: 1.1351 - val_p_acc: 0.5577\n",
      "Epoch 2739/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8574 - p_acc: 0.6170 - val_loss: 1.1343 - val_p_acc: 0.5048\n",
      "Epoch 2740/5000\n",
      "85/85 [==============================] - 0s 707us/sample - loss: 0.7685 - p_acc: 0.6538 - val_loss: 1.1349 - val_p_acc: 0.5401\n",
      "Epoch 2741/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9479 - p_acc: 0.5689 - val_loss: 1.1339 - val_p_acc: 0.5224\n",
      "Epoch 2742/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7801 - p_acc: 0.6314 - val_loss: 1.1330 - val_p_acc: 0.5577\n",
      "Epoch 2743/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8210 - p_acc: 0.6923 - val_loss: 1.1322 - val_p_acc: 0.5577\n",
      "Epoch 2744/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8065 - p_acc: 0.7115 - val_loss: 1.1304 - val_p_acc: 0.5401\n",
      "Epoch 2745/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8895 - p_acc: 0.5649 - val_loss: 1.1304 - val_p_acc: 0.5401\n",
      "Epoch 2746/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8256 - p_acc: 0.6346 - val_loss: 1.1331 - val_p_acc: 0.5401\n",
      "Epoch 2747/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7586 - p_acc: 0.6955 - val_loss: 1.1355 - val_p_acc: 0.5224\n",
      "Epoch 2748/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8090 - p_acc: 0.5809 - val_loss: 1.1362 - val_p_acc: 0.4872\n",
      "Epoch 2749/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8913 - p_acc: 0.5946 - val_loss: 1.1380 - val_p_acc: 0.5753\n",
      "Epoch 2750/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8393 - p_acc: 0.6715 - val_loss: 1.1394 - val_p_acc: 0.5048\n",
      "Epoch 2751/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8373 - p_acc: 0.6346 - val_loss: 1.1396 - val_p_acc: 0.5401\n",
      "Epoch 2752/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7586 - p_acc: 0.6506 - val_loss: 1.1400 - val_p_acc: 0.5048\n",
      "Epoch 2753/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9025 - p_acc: 0.6002 - val_loss: 1.1405 - val_p_acc: 0.5577\n",
      "Epoch 2754/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9115 - p_acc: 0.6154 - val_loss: 1.1407 - val_p_acc: 0.5401\n",
      "Epoch 2755/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8722 - p_acc: 0.6418 - val_loss: 1.1411 - val_p_acc: 0.5224\n",
      "Epoch 2756/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8651 - p_acc: 0.5809 - val_loss: 1.1411 - val_p_acc: 0.5401\n",
      "Epoch 2757/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8548 - p_acc: 0.6122 - val_loss: 1.1390 - val_p_acc: 0.5401\n",
      "Epoch 2758/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7981 - p_acc: 0.6643 - val_loss: 1.1391 - val_p_acc: 0.5224\n",
      "Epoch 2759/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8502 - p_acc: 0.6314 - val_loss: 1.1391 - val_p_acc: 0.5048\n",
      "Epoch 2760/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8065 - p_acc: 0.6819 - val_loss: 1.1385 - val_p_acc: 0.5753\n",
      "Epoch 2761/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8542 - p_acc: 0.6122 - val_loss: 1.1379 - val_p_acc: 0.5929\n",
      "Epoch 2762/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8403 - p_acc: 0.6418 - val_loss: 1.1366 - val_p_acc: 0.5224\n",
      "Epoch 2763/5000\n",
      "85/85 [==============================] - 0s 676us/sample - loss: 0.9022 - p_acc: 0.6106 - val_loss: 1.1349 - val_p_acc: 0.5753\n",
      "Epoch 2764/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8679 - p_acc: 0.7324 - val_loss: 1.1350 - val_p_acc: 0.5401\n",
      "Epoch 2765/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9146 - p_acc: 0.6314 - val_loss: 1.1352 - val_p_acc: 0.5224\n",
      "Epoch 2766/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9136 - p_acc: 0.5929 - val_loss: 1.1337 - val_p_acc: 0.5577\n",
      "Epoch 2767/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8916 - p_acc: 0.5633 - val_loss: 1.1332 - val_p_acc: 0.5401\n",
      "Epoch 2768/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8911 - p_acc: 0.5649 - val_loss: 1.1316 - val_p_acc: 0.5224\n",
      "Epoch 2769/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8440 - p_acc: 0.6506 - val_loss: 1.1307 - val_p_acc: 0.5224\n",
      "Epoch 2770/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7917 - p_acc: 0.5809 - val_loss: 1.1296 - val_p_acc: 0.5401\n",
      "Epoch 2771/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7904 - p_acc: 0.6803 - val_loss: 1.1289 - val_p_acc: 0.5224\n",
      "Epoch 2772/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8617 - p_acc: 0.6154 - val_loss: 1.1285 - val_p_acc: 0.5577\n",
      "Epoch 2773/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8603 - p_acc: 0.6242 - val_loss: 1.1288 - val_p_acc: 0.5401\n",
      "Epoch 2774/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7735 - p_acc: 0.6939 - val_loss: 1.1282 - val_p_acc: 0.5401\n",
      "Epoch 2775/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8215 - p_acc: 0.6330 - val_loss: 1.1274 - val_p_acc: 0.5577\n",
      "Epoch 2776/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8042 - p_acc: 0.6402 - val_loss: 1.1279 - val_p_acc: 0.5224\n",
      "Epoch 2777/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8906 - p_acc: 0.5793 - val_loss: 1.1276 - val_p_acc: 0.5401\n",
      "Epoch 2778/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8336 - p_acc: 0.6538 - val_loss: 1.1266 - val_p_acc: 0.5401\n",
      "Epoch 2779/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9176 - p_acc: 0.5929 - val_loss: 1.1252 - val_p_acc: 0.5401\n",
      "Epoch 2780/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8691 - p_acc: 0.6611 - val_loss: 1.1248 - val_p_acc: 0.5401\n",
      "Epoch 2781/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8496 - p_acc: 0.6923 - val_loss: 1.1240 - val_p_acc: 0.5048\n",
      "Epoch 2782/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8413 - p_acc: 0.6747 - val_loss: 1.1231 - val_p_acc: 0.5224\n",
      "Epoch 2783/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9008 - p_acc: 0.6122 - val_loss: 1.1226 - val_p_acc: 0.5753\n",
      "Epoch 2784/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8299 - p_acc: 0.6939 - val_loss: 1.1222 - val_p_acc: 0.5577\n",
      "Epoch 2785/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7921 - p_acc: 0.7043 - val_loss: 1.1211 - val_p_acc: 0.5048\n",
      "Epoch 2786/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8547 - p_acc: 0.6402 - val_loss: 1.1212 - val_p_acc: 0.5401\n",
      "Epoch 2787/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9024 - p_acc: 0.5737 - val_loss: 1.1217 - val_p_acc: 0.5401\n",
      "Epoch 2788/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8248 - p_acc: 0.6242 - val_loss: 1.1228 - val_p_acc: 0.5401\n",
      "Epoch 2789/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8298 - p_acc: 0.6330 - val_loss: 1.1236 - val_p_acc: 0.5224\n",
      "Epoch 2790/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9029 - p_acc: 0.6170 - val_loss: 1.1237 - val_p_acc: 0.5401\n",
      "Epoch 2791/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7318 - p_acc: 0.6554 - val_loss: 1.1229 - val_p_acc: 0.5401\n",
      "Epoch 2792/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8133 - p_acc: 0.6226 - val_loss: 1.1216 - val_p_acc: 0.5577\n",
      "Epoch 2793/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9132 - p_acc: 0.6154 - val_loss: 1.1216 - val_p_acc: 0.5401\n",
      "Epoch 2794/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8128 - p_acc: 0.6731 - val_loss: 1.1217 - val_p_acc: 0.5224\n",
      "Epoch 2795/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8924 - p_acc: 0.6611 - val_loss: 1.1211 - val_p_acc: 0.5577\n",
      "Epoch 2796/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9666 - p_acc: 0.5946 - val_loss: 1.1216 - val_p_acc: 0.5577\n",
      "Epoch 2797/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8615 - p_acc: 0.5425 - val_loss: 1.1228 - val_p_acc: 0.5401\n",
      "Epoch 2798/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7993 - p_acc: 0.5737 - val_loss: 1.1231 - val_p_acc: 0.5753\n",
      "Epoch 2799/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8483 - p_acc: 0.6018 - val_loss: 1.1223 - val_p_acc: 0.5048\n",
      "Epoch 2800/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8800 - p_acc: 0.5617 - val_loss: 1.1232 - val_p_acc: 0.5401\n",
      "Epoch 2801/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8178 - p_acc: 0.6835 - val_loss: 1.1237 - val_p_acc: 0.5401\n",
      "Epoch 2802/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8675 - p_acc: 0.6923 - val_loss: 1.1231 - val_p_acc: 0.5753\n",
      "Epoch 2803/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8213 - p_acc: 0.6018 - val_loss: 1.1238 - val_p_acc: 0.4696\n",
      "Epoch 2804/5000\n",
      "85/85 [==============================] - 0s 721us/sample - loss: 0.7815 - p_acc: 0.6522 - val_loss: 1.1243 - val_p_acc: 0.5224\n",
      "Epoch 2805/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7964 - p_acc: 0.6226 - val_loss: 1.1254 - val_p_acc: 0.5401\n",
      "Epoch 2806/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7911 - p_acc: 0.6346 - val_loss: 1.1260 - val_p_acc: 0.5401\n",
      "Epoch 2807/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7675 - p_acc: 0.7027 - val_loss: 1.1259 - val_p_acc: 0.5401\n",
      "Epoch 2808/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9155 - p_acc: 0.5777 - val_loss: 1.1257 - val_p_acc: 0.5224\n",
      "Epoch 2809/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8348 - p_acc: 0.6330 - val_loss: 1.1255 - val_p_acc: 0.4872\n",
      "Epoch 2810/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7716 - p_acc: 0.6418 - val_loss: 1.1250 - val_p_acc: 0.5048\n",
      "Epoch 2811/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8390 - p_acc: 0.6627 - val_loss: 1.1243 - val_p_acc: 0.5224\n",
      "Epoch 2812/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8740 - p_acc: 0.6138 - val_loss: 1.1233 - val_p_acc: 0.5753\n",
      "Epoch 2813/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7483 - p_acc: 0.7115 - val_loss: 1.1230 - val_p_acc: 0.5401\n",
      "Epoch 2814/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7811 - p_acc: 0.6675 - val_loss: 1.1227 - val_p_acc: 0.5753\n",
      "Epoch 2815/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8081 - p_acc: 0.6522 - val_loss: 1.1224 - val_p_acc: 0.5401\n",
      "Epoch 2816/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8774 - p_acc: 0.6050 - val_loss: 1.1256 - val_p_acc: 0.5224\n",
      "Epoch 2817/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8237 - p_acc: 0.6226 - val_loss: 1.1298 - val_p_acc: 0.5224\n",
      "Epoch 2818/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8808 - p_acc: 0.6106 - val_loss: 1.1314 - val_p_acc: 0.5753\n",
      "Epoch 2819/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8341 - p_acc: 0.6210 - val_loss: 1.1327 - val_p_acc: 0.5577\n",
      "Epoch 2820/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8939 - p_acc: 0.6554 - val_loss: 1.1328 - val_p_acc: 0.5224\n",
      "Epoch 2821/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8064 - p_acc: 0.6867 - val_loss: 1.1319 - val_p_acc: 0.5401\n",
      "Epoch 2822/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7984 - p_acc: 0.7428 - val_loss: 1.1301 - val_p_acc: 0.5401\n",
      "Epoch 2823/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8552 - p_acc: 0.5793 - val_loss: 1.1296 - val_p_acc: 0.5401\n",
      "Epoch 2824/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8077 - p_acc: 0.6538 - val_loss: 1.1293 - val_p_acc: 0.5577\n",
      "Epoch 2825/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8241 - p_acc: 0.5809 - val_loss: 1.1305 - val_p_acc: 0.5753\n",
      "Epoch 2826/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8212 - p_acc: 0.6314 - val_loss: 1.1305 - val_p_acc: 0.5224\n",
      "Epoch 2827/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8638 - p_acc: 0.6627 - val_loss: 1.1308 - val_p_acc: 0.5048\n",
      "Epoch 2828/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8825 - p_acc: 0.6314 - val_loss: 1.1332 - val_p_acc: 0.5401\n",
      "Epoch 2829/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7940 - p_acc: 0.6282 - val_loss: 1.1330 - val_p_acc: 0.5224\n",
      "Epoch 2830/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7501 - p_acc: 0.6939 - val_loss: 1.1321 - val_p_acc: 0.5401\n",
      "Epoch 2831/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8825 - p_acc: 0.5793 - val_loss: 1.1330 - val_p_acc: 0.5224\n",
      "Epoch 2832/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8521 - p_acc: 0.5649 - val_loss: 1.1324 - val_p_acc: 0.5048\n",
      "Epoch 2833/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8214 - p_acc: 0.6731 - val_loss: 1.1329 - val_p_acc: 0.5224\n",
      "Epoch 2834/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7465 - p_acc: 0.7356 - val_loss: 1.1318 - val_p_acc: 0.5577\n",
      "Epoch 2835/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8043 - p_acc: 0.6955 - val_loss: 1.1325 - val_p_acc: 0.5753\n",
      "Epoch 2836/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8219 - p_acc: 0.6138 - val_loss: 1.1330 - val_p_acc: 0.5753\n",
      "Epoch 2837/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8597 - p_acc: 0.6362 - val_loss: 1.1344 - val_p_acc: 0.5401\n",
      "Epoch 2838/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7987 - p_acc: 0.7027 - val_loss: 1.1359 - val_p_acc: 0.4872\n",
      "Epoch 2839/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.8295 - p_acc: 0.5825 - val_loss: 1.1357 - val_p_acc: 0.5401\n",
      "Epoch 2840/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9230 - p_acc: 0.5369 - val_loss: 1.1365 - val_p_acc: 0.5577\n",
      "Epoch 2841/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8121 - p_acc: 0.6346 - val_loss: 1.1356 - val_p_acc: 0.5401\n",
      "Epoch 2842/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9338 - p_acc: 0.5353 - val_loss: 1.1345 - val_p_acc: 0.5401\n",
      "Epoch 2843/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8650 - p_acc: 0.6835 - val_loss: 1.1342 - val_p_acc: 0.5401\n",
      "Epoch 2844/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7287 - p_acc: 0.7340 - val_loss: 1.1336 - val_p_acc: 0.5048\n",
      "Epoch 2845/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7789 - p_acc: 0.6923 - val_loss: 1.1338 - val_p_acc: 0.5577\n",
      "Epoch 2846/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8867 - p_acc: 0.6506 - val_loss: 1.1338 - val_p_acc: 0.5577\n",
      "Epoch 2847/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8046 - p_acc: 0.6643 - val_loss: 1.1332 - val_p_acc: 0.5401\n",
      "Epoch 2848/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7719 - p_acc: 0.6731 - val_loss: 1.1328 - val_p_acc: 0.5577\n",
      "Epoch 2849/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8808 - p_acc: 0.7043 - val_loss: 1.1354 - val_p_acc: 0.5401\n",
      "Epoch 2850/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7865 - p_acc: 0.7131 - val_loss: 1.1367 - val_p_acc: 0.5224\n",
      "Epoch 2851/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8565 - p_acc: 0.6018 - val_loss: 1.1356 - val_p_acc: 0.5401\n",
      "Epoch 2852/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9074 - p_acc: 0.6522 - val_loss: 1.1363 - val_p_acc: 0.5401\n",
      "Epoch 2853/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7800 - p_acc: 0.7147 - val_loss: 1.1369 - val_p_acc: 0.5577\n",
      "Epoch 2854/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8933 - p_acc: 0.6122 - val_loss: 1.1360 - val_p_acc: 0.5577\n",
      "Epoch 2855/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8911 - p_acc: 0.6122 - val_loss: 1.1346 - val_p_acc: 0.5224\n",
      "Epoch 2856/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8633 - p_acc: 0.5841 - val_loss: 1.1338 - val_p_acc: 0.5224\n",
      "Epoch 2857/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8625 - p_acc: 0.6122 - val_loss: 1.1327 - val_p_acc: 0.5577\n",
      "Epoch 2858/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.8089 - p_acc: 0.6763 - val_loss: 1.1327 - val_p_acc: 0.5401\n",
      "Epoch 2859/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.8493 - p_acc: 0.6226 - val_loss: 1.1306 - val_p_acc: 0.5401\n",
      "Epoch 2860/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.8048 - p_acc: 0.6242 - val_loss: 1.1313 - val_p_acc: 0.5401\n",
      "Epoch 2861/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.7603 - p_acc: 0.6643 - val_loss: 1.1314 - val_p_acc: 0.5401\n",
      "Epoch 2862/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.9383 - p_acc: 0.5721 - val_loss: 1.1304 - val_p_acc: 0.4872\n",
      "Epoch 2863/5000\n",
      "85/85 [==============================] - 0s 856us/sample - loss: 0.7806 - p_acc: 0.6747 - val_loss: 1.1299 - val_p_acc: 0.5224\n",
      "Epoch 2864/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.7939 - p_acc: 0.6643 - val_loss: 1.1294 - val_p_acc: 0.5577\n",
      "Epoch 2865/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.7989 - p_acc: 0.6346 - val_loss: 1.1295 - val_p_acc: 0.5401\n",
      "Epoch 2866/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.7872 - p_acc: 0.6242 - val_loss: 1.1299 - val_p_acc: 0.5753\n",
      "Epoch 2867/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.8526 - p_acc: 0.6611 - val_loss: 1.1313 - val_p_acc: 0.5577\n",
      "Epoch 2868/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.8578 - p_acc: 0.6050 - val_loss: 1.1320 - val_p_acc: 0.5401\n",
      "Epoch 2869/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.8539 - p_acc: 0.6506 - val_loss: 1.1324 - val_p_acc: 0.6106\n",
      "Epoch 2870/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.7855 - p_acc: 0.6819 - val_loss: 1.1340 - val_p_acc: 0.5753\n",
      "Epoch 2871/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.8423 - p_acc: 0.6819 - val_loss: 1.1351 - val_p_acc: 0.5753\n",
      "Epoch 2872/5000\n",
      "85/85 [==============================] - 0s 809us/sample - loss: 0.8091 - p_acc: 0.6835 - val_loss: 1.1356 - val_p_acc: 0.5577\n",
      "Epoch 2873/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.8697 - p_acc: 0.6194 - val_loss: 1.1374 - val_p_acc: 0.5401\n",
      "Epoch 2874/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.8556 - p_acc: 0.5897 - val_loss: 1.1385 - val_p_acc: 0.4872\n",
      "Epoch 2875/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.7620 - p_acc: 0.6779 - val_loss: 1.1389 - val_p_acc: 0.5224\n",
      "Epoch 2876/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.8219 - p_acc: 0.6034 - val_loss: 1.1383 - val_p_acc: 0.5929\n",
      "Epoch 2877/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8245 - p_acc: 0.6434 - val_loss: 1.1377 - val_p_acc: 0.5753\n",
      "Epoch 2878/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8501 - p_acc: 0.6522 - val_loss: 1.1380 - val_p_acc: 0.5401\n",
      "Epoch 2879/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.8446 - p_acc: 0.6402 - val_loss: 1.1371 - val_p_acc: 0.5224\n",
      "Epoch 2880/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7495 - p_acc: 0.6819 - val_loss: 1.1383 - val_p_acc: 0.5224\n",
      "Epoch 2881/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8758 - p_acc: 0.6122 - val_loss: 1.1382 - val_p_acc: 0.5048\n",
      "Epoch 2882/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7866 - p_acc: 0.6611 - val_loss: 1.1407 - val_p_acc: 0.5048\n",
      "Epoch 2883/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8322 - p_acc: 0.6851 - val_loss: 1.1414 - val_p_acc: 0.5224\n",
      "Epoch 2884/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9596 - p_acc: 0.5881 - val_loss: 1.1410 - val_p_acc: 0.5577\n",
      "Epoch 2885/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8876 - p_acc: 0.6194 - val_loss: 1.1395 - val_p_acc: 0.5577\n",
      "Epoch 2886/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8260 - p_acc: 0.5601 - val_loss: 1.1391 - val_p_acc: 0.5224\n",
      "Epoch 2887/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8433 - p_acc: 0.6314 - val_loss: 1.1404 - val_p_acc: 0.5224\n",
      "Epoch 2888/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8051 - p_acc: 0.6242 - val_loss: 1.1394 - val_p_acc: 0.5929\n",
      "Epoch 2889/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9190 - p_acc: 0.6346 - val_loss: 1.1392 - val_p_acc: 0.5577\n",
      "Epoch 2890/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8091 - p_acc: 0.6538 - val_loss: 1.1386 - val_p_acc: 0.5401\n",
      "Epoch 2891/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7632 - p_acc: 0.6595 - val_loss: 1.1364 - val_p_acc: 0.5401\n",
      "Epoch 2892/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8007 - p_acc: 0.7027 - val_loss: 1.1341 - val_p_acc: 0.5401\n",
      "Epoch 2893/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7917 - p_acc: 0.6747 - val_loss: 1.1338 - val_p_acc: 0.5929\n",
      "Epoch 2894/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 0.8646 - p_acc: 0.6819 - val_loss: 1.1324 - val_p_acc: 0.5577\n",
      "Epoch 2895/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.8718 - p_acc: 0.5737 - val_loss: 1.1321 - val_p_acc: 0.5401\n",
      "Epoch 2896/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.8654 - p_acc: 0.5633 - val_loss: 1.1324 - val_p_acc: 0.5577\n",
      "Epoch 2897/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.9057 - p_acc: 0.6034 - val_loss: 1.1339 - val_p_acc: 0.5048\n",
      "Epoch 2898/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 0.7553 - p_acc: 0.6907 - val_loss: 1.1349 - val_p_acc: 0.5577\n",
      "Epoch 2899/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9433 - p_acc: 0.6090 - val_loss: 1.1331 - val_p_acc: 0.5224\n",
      "Epoch 2900/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.8459 - p_acc: 0.6402 - val_loss: 1.1335 - val_p_acc: 0.5401\n",
      "Epoch 2901/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7818 - p_acc: 0.6659 - val_loss: 1.1315 - val_p_acc: 0.5401\n",
      "Epoch 2902/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8384 - p_acc: 0.6643 - val_loss: 1.1316 - val_p_acc: 0.5401\n",
      "Epoch 2903/5000\n",
      "85/85 [==============================] - 0s 822us/sample - loss: 0.8721 - p_acc: 0.6138 - val_loss: 1.1316 - val_p_acc: 0.5577\n",
      "Epoch 2904/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.9160 - p_acc: 0.5601 - val_loss: 1.1309 - val_p_acc: 0.5401\n",
      "Epoch 2905/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.8885 - p_acc: 0.6627 - val_loss: 1.1311 - val_p_acc: 0.5224\n",
      "Epoch 2906/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7724 - p_acc: 0.6851 - val_loss: 1.1325 - val_p_acc: 0.5224\n",
      "Epoch 2907/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8881 - p_acc: 0.6554 - val_loss: 1.1341 - val_p_acc: 0.5577\n",
      "Epoch 2908/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8006 - p_acc: 0.7131 - val_loss: 1.1346 - val_p_acc: 0.5224\n",
      "Epoch 2909/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8436 - p_acc: 0.6050 - val_loss: 1.1357 - val_p_acc: 0.5929\n",
      "Epoch 2910/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8014 - p_acc: 0.5929 - val_loss: 1.1349 - val_p_acc: 0.5753\n",
      "Epoch 2911/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8513 - p_acc: 0.5617 - val_loss: 1.1346 - val_p_acc: 0.5224\n",
      "Epoch 2912/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.7236 - p_acc: 0.7059 - val_loss: 1.1339 - val_p_acc: 0.5401\n",
      "Epoch 2913/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.7918 - p_acc: 0.6699 - val_loss: 1.1328 - val_p_acc: 0.5048\n",
      "Epoch 2914/5000\n",
      "85/85 [==============================] - 0s 822us/sample - loss: 0.8142 - p_acc: 0.6747 - val_loss: 1.1306 - val_p_acc: 0.5401\n",
      "Epoch 2915/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7941 - p_acc: 0.5304 - val_loss: 1.1318 - val_p_acc: 0.5577\n",
      "Epoch 2916/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.7591 - p_acc: 0.6522 - val_loss: 1.1333 - val_p_acc: 0.5929\n",
      "Epoch 2917/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 0.8722 - p_acc: 0.5913 - val_loss: 1.1329 - val_p_acc: 0.5224\n",
      "Epoch 2918/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8521 - p_acc: 0.6186 - val_loss: 1.1333 - val_p_acc: 0.5577\n",
      "Epoch 2919/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7884 - p_acc: 0.6226 - val_loss: 1.1328 - val_p_acc: 0.5224\n",
      "Epoch 2920/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.9252 - p_acc: 0.5040 - val_loss: 1.1351 - val_p_acc: 0.5401\n",
      "Epoch 2921/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8445 - p_acc: 0.6210 - val_loss: 1.1351 - val_p_acc: 0.5224\n",
      "Epoch 2922/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8328 - p_acc: 0.6242 - val_loss: 1.1348 - val_p_acc: 0.5224\n",
      "Epoch 2923/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8089 - p_acc: 0.6995 - val_loss: 1.1353 - val_p_acc: 0.5224\n",
      "Epoch 2924/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8475 - p_acc: 0.5545 - val_loss: 1.1355 - val_p_acc: 0.5048\n",
      "Epoch 2925/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 762us/sample - loss: 0.8049 - p_acc: 0.6522 - val_loss: 1.1352 - val_p_acc: 0.5577\n",
      "Epoch 2926/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7482 - p_acc: 0.6851 - val_loss: 1.1347 - val_p_acc: 0.5048\n",
      "Epoch 2927/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8144 - p_acc: 0.6643 - val_loss: 1.1336 - val_p_acc: 0.5577\n",
      "Epoch 2928/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8072 - p_acc: 0.6378 - val_loss: 1.1328 - val_p_acc: 0.5401\n",
      "Epoch 2929/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7688 - p_acc: 0.6955 - val_loss: 1.1315 - val_p_acc: 0.5577\n",
      "Epoch 2930/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8142 - p_acc: 0.6210 - val_loss: 1.1312 - val_p_acc: 0.5048\n",
      "Epoch 2931/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8408 - p_acc: 0.6314 - val_loss: 1.1291 - val_p_acc: 0.5224\n",
      "Epoch 2932/5000\n",
      "85/85 [==============================] - 0s 762us/sample - loss: 0.8228 - p_acc: 0.6226 - val_loss: 1.1283 - val_p_acc: 0.5577\n",
      "Epoch 2933/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8742 - p_acc: 0.5913 - val_loss: 1.1297 - val_p_acc: 0.5224\n",
      "Epoch 2934/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8472 - p_acc: 0.5793 - val_loss: 1.1285 - val_p_acc: 0.4696\n",
      "Epoch 2935/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9214 - p_acc: 0.5857 - val_loss: 1.1283 - val_p_acc: 0.5753\n",
      "Epoch 2936/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7511 - p_acc: 0.6066 - val_loss: 1.1276 - val_p_acc: 0.5224\n",
      "Epoch 2937/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8796 - p_acc: 0.6314 - val_loss: 1.1287 - val_p_acc: 0.4696\n",
      "Epoch 2938/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8698 - p_acc: 0.6226 - val_loss: 1.1283 - val_p_acc: 0.5401\n",
      "Epoch 2939/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8546 - p_acc: 0.6571 - val_loss: 1.1281 - val_p_acc: 0.5929\n",
      "Epoch 2940/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7952 - p_acc: 0.6747 - val_loss: 1.1273 - val_p_acc: 0.5192\n",
      "Epoch 2941/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8767 - p_acc: 0.6122 - val_loss: 1.1271 - val_p_acc: 0.5369\n",
      "Epoch 2942/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7963 - p_acc: 0.5946 - val_loss: 1.1251 - val_p_acc: 0.5545\n",
      "Epoch 2943/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8507 - p_acc: 0.7147 - val_loss: 1.1240 - val_p_acc: 0.4663\n",
      "Epoch 2944/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.9550 - p_acc: 0.6731 - val_loss: 1.1242 - val_p_acc: 0.5369\n",
      "Epoch 2945/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8001 - p_acc: 0.7131 - val_loss: 1.1244 - val_p_acc: 0.4808\n",
      "Epoch 2946/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9548 - p_acc: 0.5913 - val_loss: 1.1249 - val_p_acc: 0.5160\n",
      "Epoch 2947/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8294 - p_acc: 0.5457 - val_loss: 1.1244 - val_p_acc: 0.4455\n",
      "Epoch 2948/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8760 - p_acc: 0.6346 - val_loss: 1.1267 - val_p_acc: 0.5721\n",
      "Epoch 2949/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7820 - p_acc: 0.6659 - val_loss: 1.1289 - val_p_acc: 0.4840\n",
      "Epoch 2950/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8364 - p_acc: 0.5929 - val_loss: 1.1288 - val_p_acc: 0.4840\n",
      "Epoch 2951/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7623 - p_acc: 0.6122 - val_loss: 1.1294 - val_p_acc: 0.5192\n",
      "Epoch 2952/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8339 - p_acc: 0.6699 - val_loss: 1.1298 - val_p_acc: 0.5545\n",
      "Epoch 2953/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8239 - p_acc: 0.6522 - val_loss: 1.1297 - val_p_acc: 0.5048\n",
      "Epoch 2954/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8160 - p_acc: 0.6763 - val_loss: 1.1303 - val_p_acc: 0.5577\n",
      "Epoch 2955/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7384 - p_acc: 0.6554 - val_loss: 1.1315 - val_p_acc: 0.5224\n",
      "Epoch 2956/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7984 - p_acc: 0.5929 - val_loss: 1.1314 - val_p_acc: 0.5224\n",
      "Epoch 2957/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7829 - p_acc: 0.6226 - val_loss: 1.1294 - val_p_acc: 0.4840\n",
      "Epoch 2958/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8089 - p_acc: 0.6923 - val_loss: 1.1290 - val_p_acc: 0.5192\n",
      "Epoch 2959/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7399 - p_acc: 0.7059 - val_loss: 1.1268 - val_p_acc: 0.5369\n",
      "Epoch 2960/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8055 - p_acc: 0.6242 - val_loss: 1.1261 - val_p_acc: 0.5192\n",
      "Epoch 2961/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8836 - p_acc: 0.6018 - val_loss: 1.1249 - val_p_acc: 0.5192\n",
      "Epoch 2962/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7668 - p_acc: 0.6907 - val_loss: 1.1254 - val_p_acc: 0.5192\n",
      "Epoch 2963/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8432 - p_acc: 0.6226 - val_loss: 1.1251 - val_p_acc: 0.4840\n",
      "Epoch 2964/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7570 - p_acc: 0.6314 - val_loss: 1.1241 - val_p_acc: 0.5016\n",
      "Epoch 2965/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8305 - p_acc: 0.6643 - val_loss: 1.1247 - val_p_acc: 0.5369\n",
      "Epoch 2966/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7874 - p_acc: 0.6506 - val_loss: 1.1232 - val_p_acc: 0.5016\n",
      "Epoch 2967/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8355 - p_acc: 0.5946 - val_loss: 1.1215 - val_p_acc: 0.5192\n",
      "Epoch 2968/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8439 - p_acc: 0.6627 - val_loss: 1.1213 - val_p_acc: 0.4663\n",
      "Epoch 2969/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8477 - p_acc: 0.6643 - val_loss: 1.1217 - val_p_acc: 0.5369\n",
      "Epoch 2970/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7418 - p_acc: 0.7236 - val_loss: 1.1217 - val_p_acc: 0.5016\n",
      "Epoch 2971/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8907 - p_acc: 0.5425 - val_loss: 1.1220 - val_p_acc: 0.4663\n",
      "Epoch 2972/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8245 - p_acc: 0.6522 - val_loss: 1.1215 - val_p_acc: 0.5545\n",
      "Epoch 2973/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8093 - p_acc: 0.5633 - val_loss: 1.1208 - val_p_acc: 0.5545\n",
      "Epoch 2974/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9017 - p_acc: 0.5913 - val_loss: 1.1200 - val_p_acc: 0.4840\n",
      "Epoch 2975/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8194 - p_acc: 0.5737 - val_loss: 1.1212 - val_p_acc: 0.5016\n",
      "Epoch 2976/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8319 - p_acc: 0.6138 - val_loss: 1.1216 - val_p_acc: 0.5224\n",
      "Epoch 2977/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9121 - p_acc: 0.6106 - val_loss: 1.1225 - val_p_acc: 0.5753\n",
      "Epoch 2978/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8163 - p_acc: 0.6715 - val_loss: 1.1245 - val_p_acc: 0.5224\n",
      "Epoch 2979/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7686 - p_acc: 0.6819 - val_loss: 1.1242 - val_p_acc: 0.4872\n",
      "Epoch 2980/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8724 - p_acc: 0.5601 - val_loss: 1.1237 - val_p_acc: 0.5401\n",
      "Epoch 2981/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8607 - p_acc: 0.6034 - val_loss: 1.1245 - val_p_acc: 0.5929\n",
      "Epoch 2982/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7822 - p_acc: 0.6434 - val_loss: 1.1244 - val_p_acc: 0.5577\n",
      "Epoch 2983/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8688 - p_acc: 0.6627 - val_loss: 1.1226 - val_p_acc: 0.5577\n",
      "Epoch 2984/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8771 - p_acc: 0.6194 - val_loss: 1.1211 - val_p_acc: 0.5192\n",
      "Epoch 2985/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7315 - p_acc: 0.6747 - val_loss: 1.1193 - val_p_acc: 0.4808\n",
      "Epoch 2986/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8305 - p_acc: 0.6611 - val_loss: 1.1177 - val_p_acc: 0.4984\n",
      "Epoch 2987/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8239 - p_acc: 0.6731 - val_loss: 1.1167 - val_p_acc: 0.4808\n",
      "Epoch 2988/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7935 - p_acc: 0.6290 - val_loss: 1.1170 - val_p_acc: 0.4455\n",
      "Epoch 2989/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7199 - p_acc: 0.6819 - val_loss: 1.1165 - val_p_acc: 0.4808\n",
      "Epoch 2990/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8205 - p_acc: 0.6538 - val_loss: 1.1170 - val_p_acc: 0.4631\n",
      "Epoch 2991/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.7944 - p_acc: 0.7444 - val_loss: 1.1165 - val_p_acc: 0.4808\n",
      "Epoch 2992/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.8950 - p_acc: 0.6450 - val_loss: 1.1164 - val_p_acc: 0.4808\n",
      "Epoch 2993/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.7932 - p_acc: 0.7308 - val_loss: 1.1186 - val_p_acc: 0.4984\n",
      "Epoch 2994/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.8155 - p_acc: 0.6434 - val_loss: 1.1199 - val_p_acc: 0.5337\n",
      "Epoch 2995/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8507 - p_acc: 0.6450 - val_loss: 1.1215 - val_p_acc: 0.4808\n",
      "Epoch 2996/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8309 - p_acc: 0.6418 - val_loss: 1.1215 - val_p_acc: 0.5160\n",
      "Epoch 2997/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8368 - p_acc: 0.6731 - val_loss: 1.1209 - val_p_acc: 0.4631\n",
      "Epoch 2998/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8363 - p_acc: 0.6538 - val_loss: 1.1210 - val_p_acc: 0.5192\n",
      "Epoch 2999/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.8673 - p_acc: 0.6242 - val_loss: 1.1226 - val_p_acc: 0.4279\n",
      "Epoch 3000/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.7658 - p_acc: 0.7131 - val_loss: 1.1238 - val_p_acc: 0.5369\n",
      "Epoch 3001/5000\n",
      "85/85 [==============================] - 0s 834us/sample - loss: 0.8767 - p_acc: 0.6138 - val_loss: 1.1256 - val_p_acc: 0.5401\n",
      "Epoch 3002/5000\n",
      "85/85 [==============================] - 0s 822us/sample - loss: 0.9004 - p_acc: 0.6346 - val_loss: 1.1264 - val_p_acc: 0.5577\n",
      "Epoch 3003/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.8136 - p_acc: 0.6362 - val_loss: 1.1282 - val_p_acc: 0.5224\n",
      "Epoch 3004/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.7644 - p_acc: 0.7147 - val_loss: 1.1296 - val_p_acc: 0.5224\n",
      "Epoch 3005/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8446 - p_acc: 0.6210 - val_loss: 1.1308 - val_p_acc: 0.5401\n",
      "Epoch 3006/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.7952 - p_acc: 0.6122 - val_loss: 1.1310 - val_p_acc: 0.5753\n",
      "Epoch 3007/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.9252 - p_acc: 0.5946 - val_loss: 1.1311 - val_p_acc: 0.5401\n",
      "Epoch 3008/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8181 - p_acc: 0.6330 - val_loss: 1.1304 - val_p_acc: 0.5577\n",
      "Epoch 3009/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8269 - p_acc: 0.7043 - val_loss: 1.1266 - val_p_acc: 0.5224\n",
      "Epoch 3010/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8804 - p_acc: 0.5841 - val_loss: 1.1235 - val_p_acc: 0.5192\n",
      "Epoch 3011/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8433 - p_acc: 0.6715 - val_loss: 1.1194 - val_p_acc: 0.4631\n",
      "Epoch 3012/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8736 - p_acc: 0.6346 - val_loss: 1.1184 - val_p_acc: 0.5160\n",
      "Epoch 3013/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7840 - p_acc: 0.6571 - val_loss: 1.1183 - val_p_acc: 0.4808\n",
      "Epoch 3014/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8317 - p_acc: 0.5809 - val_loss: 1.1186 - val_p_acc: 0.4984\n",
      "Epoch 3015/5000\n",
      "85/85 [==============================] - 0s 741us/sample - loss: 0.8568 - p_acc: 0.6226 - val_loss: 1.1179 - val_p_acc: 0.4984\n",
      "Epoch 3016/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.8071 - p_acc: 0.6434 - val_loss: 1.1183 - val_p_acc: 0.4455\n",
      "Epoch 3017/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7567 - p_acc: 0.7027 - val_loss: 1.1184 - val_p_acc: 0.4631\n",
      "Epoch 3018/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8665 - p_acc: 0.5929 - val_loss: 1.1178 - val_p_acc: 0.4808\n",
      "Epoch 3019/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7701 - p_acc: 0.7027 - val_loss: 1.1178 - val_p_acc: 0.4808\n",
      "Epoch 3020/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7943 - p_acc: 0.6835 - val_loss: 1.1171 - val_p_acc: 0.5160\n",
      "Epoch 3021/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8107 - p_acc: 0.6643 - val_loss: 1.1172 - val_p_acc: 0.4631\n",
      "Epoch 3022/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8120 - p_acc: 0.6538 - val_loss: 1.1169 - val_p_acc: 0.4631\n",
      "Epoch 3023/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8303 - p_acc: 0.6362 - val_loss: 1.1170 - val_p_acc: 0.4631\n",
      "Epoch 3024/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.8803 - p_acc: 0.6803 - val_loss: 1.1186 - val_p_acc: 0.4984\n",
      "Epoch 3025/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8910 - p_acc: 0.6330 - val_loss: 1.1202 - val_p_acc: 0.5160\n",
      "Epoch 3026/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.8279 - p_acc: 0.6554 - val_loss: 1.1186 - val_p_acc: 0.4631\n",
      "Epoch 3027/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8057 - p_acc: 0.6819 - val_loss: 1.1178 - val_p_acc: 0.4984\n",
      "Epoch 3028/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8144 - p_acc: 0.5841 - val_loss: 1.1185 - val_p_acc: 0.4984\n",
      "Epoch 3029/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8129 - p_acc: 0.5841 - val_loss: 1.1191 - val_p_acc: 0.4984\n",
      "Epoch 3030/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7440 - p_acc: 0.6851 - val_loss: 1.1203 - val_p_acc: 0.4808\n",
      "Epoch 3031/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8244 - p_acc: 0.6138 - val_loss: 1.1212 - val_p_acc: 0.4631\n",
      "Epoch 3032/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.8044 - p_acc: 0.6242 - val_loss: 1.1211 - val_p_acc: 0.4808\n",
      "Epoch 3033/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8136 - p_acc: 0.6955 - val_loss: 1.1217 - val_p_acc: 0.5369\n",
      "Epoch 3034/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7790 - p_acc: 0.6002 - val_loss: 1.1210 - val_p_acc: 0.5577\n",
      "Epoch 3035/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7714 - p_acc: 0.6434 - val_loss: 1.1220 - val_p_acc: 0.5753\n",
      "Epoch 3036/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8729 - p_acc: 0.6490 - val_loss: 1.1223 - val_p_acc: 0.5401\n",
      "Epoch 3037/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8074 - p_acc: 0.6370 - val_loss: 1.1226 - val_p_acc: 0.5048\n",
      "Epoch 3038/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7578 - p_acc: 0.6835 - val_loss: 1.1213 - val_p_acc: 0.5224\n",
      "Epoch 3039/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8541 - p_acc: 0.6154 - val_loss: 1.1214 - val_p_acc: 0.5577\n",
      "Epoch 3040/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.8582 - p_acc: 0.6034 - val_loss: 1.1222 - val_p_acc: 0.5753\n",
      "Epoch 3041/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8889 - p_acc: 0.5705 - val_loss: 1.1233 - val_p_acc: 0.5224\n",
      "Epoch 3042/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7793 - p_acc: 0.7059 - val_loss: 1.1221 - val_p_acc: 0.5401\n",
      "Epoch 3043/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7686 - p_acc: 0.6923 - val_loss: 1.1230 - val_p_acc: 0.5224\n",
      "Epoch 3044/5000\n",
      "85/85 [==============================] - 0s 916us/sample - loss: 0.8730 - p_acc: 0.5441 - val_loss: 1.1231 - val_p_acc: 0.5577\n",
      "Epoch 3045/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 0.7637 - p_acc: 0.7356 - val_loss: 1.1218 - val_p_acc: 0.4455\n",
      "Epoch 3046/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.7380 - p_acc: 0.6538 - val_loss: 1.1208 - val_p_acc: 0.4808\n",
      "Epoch 3047/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.7561 - p_acc: 0.6819 - val_loss: 1.1203 - val_p_acc: 0.5224\n",
      "Epoch 3048/5000\n",
      "85/85 [==============================] - 0s 892us/sample - loss: 0.7877 - p_acc: 0.6627 - val_loss: 1.1209 - val_p_acc: 0.5192\n",
      "Epoch 3049/5000\n",
      "85/85 [==============================] - 0s 892us/sample - loss: 0.8113 - p_acc: 0.6138 - val_loss: 1.1202 - val_p_acc: 0.5192\n",
      "Epoch 3050/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.7524 - p_acc: 0.7043 - val_loss: 1.1205 - val_p_acc: 0.5016\n",
      "Epoch 3051/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 0.8196 - p_acc: 0.6034 - val_loss: 1.1209 - val_p_acc: 0.4840\n",
      "Epoch 3052/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 0.9446 - p_acc: 0.6194 - val_loss: 1.1210 - val_p_acc: 0.4663\n",
      "Epoch 3053/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.7914 - p_acc: 0.6418 - val_loss: 1.1210 - val_p_acc: 0.4840\n",
      "Epoch 3054/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.7819 - p_acc: 0.6867 - val_loss: 1.1213 - val_p_acc: 0.5545\n",
      "Epoch 3055/5000\n",
      "85/85 [==============================] - 0s 892us/sample - loss: 0.7735 - p_acc: 0.6346 - val_loss: 1.1219 - val_p_acc: 0.5192\n",
      "Epoch 3056/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.7774 - p_acc: 0.6466 - val_loss: 1.1228 - val_p_acc: 0.5192\n",
      "Epoch 3057/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.7493 - p_acc: 0.6242 - val_loss: 1.1208 - val_p_acc: 0.5192\n",
      "Epoch 3058/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.9119 - p_acc: 0.6611 - val_loss: 1.1204 - val_p_acc: 0.5192\n",
      "Epoch 3059/5000\n",
      "85/85 [==============================] - 0s 892us/sample - loss: 0.8163 - p_acc: 0.6402 - val_loss: 1.1203 - val_p_acc: 0.5369\n",
      "Epoch 3060/5000\n",
      "85/85 [==============================] - 0s 869us/sample - loss: 0.7892 - p_acc: 0.6971 - val_loss: 1.1207 - val_p_acc: 0.5016\n",
      "Epoch 3061/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.7677 - p_acc: 0.6595 - val_loss: 1.1194 - val_p_acc: 0.4984\n",
      "Epoch 3062/5000\n",
      "85/85 [==============================] - 0s 903us/sample - loss: 0.7585 - p_acc: 0.6362 - val_loss: 1.1173 - val_p_acc: 0.4631\n",
      "Epoch 3063/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 0.7649 - p_acc: 0.6418 - val_loss: 1.1149 - val_p_acc: 0.4631\n",
      "Epoch 3064/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.8537 - p_acc: 0.5633 - val_loss: 1.1133 - val_p_acc: 0.4984\n",
      "Epoch 3065/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.8220 - p_acc: 0.6538 - val_loss: 1.1126 - val_p_acc: 0.4984\n",
      "Epoch 3066/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.8221 - p_acc: 0.6122 - val_loss: 1.1127 - val_p_acc: 0.5337\n",
      "Epoch 3067/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.8175 - p_acc: 0.6170 - val_loss: 1.1115 - val_p_acc: 0.4455\n",
      "Epoch 3068/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.8686 - p_acc: 0.6867 - val_loss: 1.1125 - val_p_acc: 0.5160\n",
      "Epoch 3069/5000\n",
      "85/85 [==============================] - 0s 822us/sample - loss: 0.8408 - p_acc: 0.6611 - val_loss: 1.1134 - val_p_acc: 0.4631\n",
      "Epoch 3070/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.8715 - p_acc: 0.6506 - val_loss: 1.1138 - val_p_acc: 0.4984\n",
      "Epoch 3071/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.7270 - p_acc: 0.7147 - val_loss: 1.1151 - val_p_acc: 0.4984\n",
      "Epoch 3072/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.7811 - p_acc: 0.6643 - val_loss: 1.1153 - val_p_acc: 0.4984\n",
      "Epoch 3073/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.8252 - p_acc: 0.6402 - val_loss: 1.1160 - val_p_acc: 0.4984\n",
      "Epoch 3074/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.8336 - p_acc: 0.6002 - val_loss: 1.1187 - val_p_acc: 0.4984\n",
      "Epoch 3075/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.8477 - p_acc: 0.6835 - val_loss: 1.1213 - val_p_acc: 0.4984\n",
      "Epoch 3076/5000\n",
      "85/85 [==============================] - 0s 822us/sample - loss: 0.8947 - p_acc: 0.6346 - val_loss: 1.1225 - val_p_acc: 0.5192\n",
      "Epoch 3077/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.8223 - p_acc: 0.6506 - val_loss: 1.1238 - val_p_acc: 0.5016\n",
      "Epoch 3078/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 0.7571 - p_acc: 0.6819 - val_loss: 1.1249 - val_p_acc: 0.5192\n",
      "Epoch 3079/5000\n",
      "85/85 [==============================] - 0s 915us/sample - loss: 0.7503 - p_acc: 0.7532 - val_loss: 1.1255 - val_p_acc: 0.5192\n",
      "Epoch 3080/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 0.7794 - p_acc: 0.6538 - val_loss: 1.1252 - val_p_acc: 0.5192\n",
      "Epoch 3081/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.8183 - p_acc: 0.6522 - val_loss: 1.1274 - val_p_acc: 0.5369\n",
      "Epoch 3082/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 0.7133 - p_acc: 0.6643 - val_loss: 1.1290 - val_p_acc: 0.5224\n",
      "Epoch 3083/5000\n",
      "85/85 [==============================] - 0s 797us/sample - loss: 0.8274 - p_acc: 0.7220 - val_loss: 1.1292 - val_p_acc: 0.5545\n",
      "Epoch 3084/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8147 - p_acc: 0.6643 - val_loss: 1.1294 - val_p_acc: 0.4840\n",
      "Epoch 3085/5000\n",
      "85/85 [==============================] - 0s 762us/sample - loss: 0.7765 - p_acc: 0.6731 - val_loss: 1.1289 - val_p_acc: 0.5016\n",
      "Epoch 3086/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7997 - p_acc: 0.6835 - val_loss: 1.1289 - val_p_acc: 0.5929\n",
      "Epoch 3087/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.7681 - p_acc: 0.5913 - val_loss: 1.1299 - val_p_acc: 0.5401\n",
      "Epoch 3088/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8000 - p_acc: 0.6715 - val_loss: 1.1314 - val_p_acc: 0.5224\n",
      "Epoch 3089/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7414 - p_acc: 0.7740 - val_loss: 1.1303 - val_p_acc: 0.5369\n",
      "Epoch 3090/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8592 - p_acc: 0.6787 - val_loss: 1.1291 - val_p_acc: 0.5369\n",
      "Epoch 3091/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8836 - p_acc: 0.6226 - val_loss: 1.1271 - val_p_acc: 0.5016\n",
      "Epoch 3092/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.8486 - p_acc: 0.6418 - val_loss: 1.1260 - val_p_acc: 0.4840\n",
      "Epoch 3093/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7294 - p_acc: 0.6450 - val_loss: 1.1250 - val_p_acc: 0.5369\n",
      "Epoch 3094/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7768 - p_acc: 0.7075 - val_loss: 1.1232 - val_p_acc: 0.5016\n",
      "Epoch 3095/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 0.8508 - p_acc: 0.6643 - val_loss: 1.1222 - val_p_acc: 0.5337\n",
      "Epoch 3096/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8013 - p_acc: 0.6715 - val_loss: 1.1221 - val_p_acc: 0.4808\n",
      "Epoch 3097/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7814 - p_acc: 0.6747 - val_loss: 1.1209 - val_p_acc: 0.4984\n",
      "Epoch 3098/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.9040 - p_acc: 0.6050 - val_loss: 1.1205 - val_p_acc: 0.4984\n",
      "Epoch 3099/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.9161 - p_acc: 0.5841 - val_loss: 1.1206 - val_p_acc: 0.4631\n",
      "Epoch 3100/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7671 - p_acc: 0.6835 - val_loss: 1.1180 - val_p_acc: 0.4808\n",
      "Epoch 3101/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7862 - p_acc: 0.6923 - val_loss: 1.1159 - val_p_acc: 0.4984\n",
      "Epoch 3102/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8417 - p_acc: 0.5962 - val_loss: 1.1145 - val_p_acc: 0.4808\n",
      "Epoch 3103/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9519 - p_acc: 0.6282 - val_loss: 1.1128 - val_p_acc: 0.5337\n",
      "Epoch 3104/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.8520 - p_acc: 0.6418 - val_loss: 1.1122 - val_p_acc: 0.4808\n",
      "Epoch 3105/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9328 - p_acc: 0.5721 - val_loss: 1.1120 - val_p_acc: 0.5337\n",
      "Epoch 3106/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7514 - p_acc: 0.7340 - val_loss: 1.1107 - val_p_acc: 0.4631\n",
      "Epoch 3107/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8002 - p_acc: 0.6819 - val_loss: 1.1110 - val_p_acc: 0.4455\n",
      "Epoch 3108/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7817 - p_acc: 0.6258 - val_loss: 1.1115 - val_p_acc: 0.4631\n",
      "Epoch 3109/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7586 - p_acc: 0.6050 - val_loss: 1.1116 - val_p_acc: 0.4808\n",
      "Epoch 3110/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8049 - p_acc: 0.6659 - val_loss: 1.1117 - val_p_acc: 0.5160\n",
      "Epoch 3111/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8414 - p_acc: 0.6611 - val_loss: 1.1116 - val_p_acc: 0.4984\n",
      "Epoch 3112/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8187 - p_acc: 0.6258 - val_loss: 1.1123 - val_p_acc: 0.4808\n",
      "Epoch 3113/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7665 - p_acc: 0.6362 - val_loss: 1.1141 - val_p_acc: 0.4808\n",
      "Epoch 3114/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8176 - p_acc: 0.6466 - val_loss: 1.1160 - val_p_acc: 0.4631\n",
      "Epoch 3115/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7753 - p_acc: 0.6835 - val_loss: 1.1171 - val_p_acc: 0.4808\n",
      "Epoch 3116/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8047 - p_acc: 0.6258 - val_loss: 1.1180 - val_p_acc: 0.4808\n",
      "Epoch 3117/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8993 - p_acc: 0.6138 - val_loss: 1.1193 - val_p_acc: 0.5160\n",
      "Epoch 3118/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8154 - p_acc: 0.6066 - val_loss: 1.1205 - val_p_acc: 0.4984\n",
      "Epoch 3119/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8762 - p_acc: 0.5529 - val_loss: 1.1211 - val_p_acc: 0.4984\n",
      "Epoch 3120/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8250 - p_acc: 0.6450 - val_loss: 1.1212 - val_p_acc: 0.4808\n",
      "Epoch 3121/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7839 - p_acc: 0.6418 - val_loss: 1.1216 - val_p_acc: 0.4984\n",
      "Epoch 3122/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7981 - p_acc: 0.7220 - val_loss: 1.1211 - val_p_acc: 0.4984\n",
      "Epoch 3123/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8160 - p_acc: 0.7043 - val_loss: 1.1208 - val_p_acc: 0.4808\n",
      "Epoch 3124/5000\n",
      "85/85 [==============================] - 0s 746us/sample - loss: 0.7990 - p_acc: 0.6002 - val_loss: 1.1214 - val_p_acc: 0.4808\n",
      "Epoch 3125/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8246 - p_acc: 0.6138 - val_loss: 1.1201 - val_p_acc: 0.5337\n",
      "Epoch 3126/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7647 - p_acc: 0.6538 - val_loss: 1.1181 - val_p_acc: 0.4984\n",
      "Epoch 3127/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7851 - p_acc: 0.6554 - val_loss: 1.1170 - val_p_acc: 0.5160\n",
      "Epoch 3128/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.8206 - p_acc: 0.5841 - val_loss: 1.1166 - val_p_acc: 0.5160\n",
      "Epoch 3129/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8200 - p_acc: 0.7220 - val_loss: 1.1158 - val_p_acc: 0.4808\n",
      "Epoch 3130/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8028 - p_acc: 0.6643 - val_loss: 1.1160 - val_p_acc: 0.4808\n",
      "Epoch 3131/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.7250 - p_acc: 0.7163 - val_loss: 1.1180 - val_p_acc: 0.4631\n",
      "Epoch 3132/5000\n",
      "85/85 [==============================] - 0s 834us/sample - loss: 0.7156 - p_acc: 0.7163 - val_loss: 1.1194 - val_p_acc: 0.4808\n",
      "Epoch 3133/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8426 - p_acc: 0.6154 - val_loss: 1.1204 - val_p_acc: 0.4631\n",
      "Epoch 3134/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7162 - p_acc: 0.7428 - val_loss: 1.1206 - val_p_acc: 0.4631\n",
      "Epoch 3135/5000\n",
      "85/85 [==============================] - 0s 797us/sample - loss: 0.8021 - p_acc: 0.6851 - val_loss: 1.1194 - val_p_acc: 0.4455\n",
      "Epoch 3136/5000\n",
      "85/85 [==============================] - 0s 752us/sample - loss: 0.8157 - p_acc: 0.6258 - val_loss: 1.1218 - val_p_acc: 0.4631\n",
      "Epoch 3137/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9418 - p_acc: 0.5545 - val_loss: 1.1245 - val_p_acc: 0.4631\n",
      "Epoch 3138/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7404 - p_acc: 0.6955 - val_loss: 1.1249 - val_p_acc: 0.4631\n",
      "Epoch 3139/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.7617 - p_acc: 0.6346 - val_loss: 1.1257 - val_p_acc: 0.4808\n",
      "Epoch 3140/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7547 - p_acc: 0.6659 - val_loss: 1.1271 - val_p_acc: 0.5337\n",
      "Epoch 3141/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8157 - p_acc: 0.6611 - val_loss: 1.1262 - val_p_acc: 0.5160\n",
      "Epoch 3142/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.8211 - p_acc: 0.6747 - val_loss: 1.1266 - val_p_acc: 0.5160\n",
      "Epoch 3143/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7174 - p_acc: 0.6346 - val_loss: 1.1268 - val_p_acc: 0.4631\n",
      "Epoch 3144/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7528 - p_acc: 0.6611 - val_loss: 1.1272 - val_p_acc: 0.4455\n",
      "Epoch 3145/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8969 - p_acc: 0.6138 - val_loss: 1.1278 - val_p_acc: 0.5192\n",
      "Epoch 3146/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8903 - p_acc: 0.6050 - val_loss: 1.1261 - val_p_acc: 0.5545\n",
      "Epoch 3147/5000\n",
      "85/85 [==============================] - 0s 726us/sample - loss: 0.7971 - p_acc: 0.5737 - val_loss: 1.1252 - val_p_acc: 0.5016\n",
      "Epoch 3148/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7375 - p_acc: 0.7011 - val_loss: 1.1247 - val_p_acc: 0.4808\n",
      "Epoch 3149/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8237 - p_acc: 0.6923 - val_loss: 1.1230 - val_p_acc: 0.4631\n",
      "Epoch 3150/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8188 - p_acc: 0.6330 - val_loss: 1.1226 - val_p_acc: 0.4631\n",
      "Epoch 3151/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8273 - p_acc: 0.6226 - val_loss: 1.1245 - val_p_acc: 0.4984\n",
      "Epoch 3152/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7450 - p_acc: 0.6450 - val_loss: 1.1241 - val_p_acc: 0.4631\n",
      "Epoch 3153/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8004 - p_acc: 0.6522 - val_loss: 1.1238 - val_p_acc: 0.4455\n",
      "Epoch 3154/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.9465 - p_acc: 0.5425 - val_loss: 1.1239 - val_p_acc: 0.4631\n",
      "Epoch 3155/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8874 - p_acc: 0.5737 - val_loss: 1.1259 - val_p_acc: 0.4984\n",
      "Epoch 3156/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8413 - p_acc: 0.5857 - val_loss: 1.1257 - val_p_acc: 0.4631\n",
      "Epoch 3157/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7430 - p_acc: 0.7027 - val_loss: 1.1267 - val_p_acc: 0.4455\n",
      "Epoch 3158/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7500 - p_acc: 0.6362 - val_loss: 1.1269 - val_p_acc: 0.4808\n",
      "Epoch 3159/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7312 - p_acc: 0.6851 - val_loss: 1.1265 - val_p_acc: 0.4984\n",
      "Epoch 3160/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7967 - p_acc: 0.5946 - val_loss: 1.1267 - val_p_acc: 0.4984\n",
      "Epoch 3161/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8186 - p_acc: 0.6659 - val_loss: 1.1272 - val_p_acc: 0.4808\n",
      "Epoch 3162/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7366 - p_acc: 0.6554 - val_loss: 1.1267 - val_p_acc: 0.4984\n",
      "Epoch 3163/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8117 - p_acc: 0.6835 - val_loss: 1.1276 - val_p_acc: 0.4984\n",
      "Epoch 3164/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7778 - p_acc: 0.6282 - val_loss: 1.1263 - val_p_acc: 0.4984\n",
      "Epoch 3165/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8125 - p_acc: 0.5913 - val_loss: 1.1260 - val_p_acc: 0.4984\n",
      "Epoch 3166/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8950 - p_acc: 0.6106 - val_loss: 1.1251 - val_p_acc: 0.4455\n",
      "Epoch 3167/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7676 - p_acc: 0.6907 - val_loss: 1.1240 - val_p_acc: 0.4808\n",
      "Epoch 3168/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8601 - p_acc: 0.6450 - val_loss: 1.1224 - val_p_acc: 0.4808\n",
      "Epoch 3169/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7756 - p_acc: 0.6923 - val_loss: 1.1228 - val_p_acc: 0.4455\n",
      "Epoch 3170/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9500 - p_acc: 0.5617 - val_loss: 1.1229 - val_p_acc: 0.4984\n",
      "Epoch 3171/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7335 - p_acc: 0.7043 - val_loss: 1.1256 - val_p_acc: 0.4984\n",
      "Epoch 3172/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8245 - p_acc: 0.6939 - val_loss: 1.1261 - val_p_acc: 0.5160\n",
      "Epoch 3173/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9031 - p_acc: 0.6450 - val_loss: 1.1274 - val_p_acc: 0.4984\n",
      "Epoch 3174/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8060 - p_acc: 0.7027 - val_loss: 1.1299 - val_p_acc: 0.4631\n",
      "Epoch 3175/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8336 - p_acc: 0.5825 - val_loss: 1.1316 - val_p_acc: 0.4808\n",
      "Epoch 3176/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8392 - p_acc: 0.7500 - val_loss: 1.1343 - val_p_acc: 0.4808\n",
      "Epoch 3177/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8272 - p_acc: 0.6538 - val_loss: 1.1347 - val_p_acc: 0.5337\n",
      "Epoch 3178/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7688 - p_acc: 0.7027 - val_loss: 1.1348 - val_p_acc: 0.4808\n",
      "Epoch 3179/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8653 - p_acc: 0.5304 - val_loss: 1.1335 - val_p_acc: 0.5160\n",
      "Epoch 3180/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8315 - p_acc: 0.5777 - val_loss: 1.1341 - val_p_acc: 0.5337\n",
      "Epoch 3181/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7489 - p_acc: 0.6378 - val_loss: 1.1357 - val_p_acc: 0.5016\n",
      "Epoch 3182/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8523 - p_acc: 0.6138 - val_loss: 1.1371 - val_p_acc: 0.5369\n",
      "Epoch 3183/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8135 - p_acc: 0.6106 - val_loss: 1.1375 - val_p_acc: 0.5192\n",
      "Epoch 3184/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8071 - p_acc: 0.6106 - val_loss: 1.1370 - val_p_acc: 0.4663\n",
      "Epoch 3185/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7585 - p_acc: 0.7268 - val_loss: 1.1360 - val_p_acc: 0.5369\n",
      "Epoch 3186/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7811 - p_acc: 0.6819 - val_loss: 1.1367 - val_p_acc: 0.5016\n",
      "Epoch 3187/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8187 - p_acc: 0.6643 - val_loss: 1.1373 - val_p_acc: 0.5016\n",
      "Epoch 3188/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8386 - p_acc: 0.6715 - val_loss: 1.1383 - val_p_acc: 0.5401\n",
      "Epoch 3189/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7436 - p_acc: 0.7115 - val_loss: 1.1387 - val_p_acc: 0.5753\n",
      "Epoch 3190/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8679 - p_acc: 0.6835 - val_loss: 1.1380 - val_p_acc: 0.5401\n",
      "Epoch 3191/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7706 - p_acc: 0.6522 - val_loss: 1.1386 - val_p_acc: 0.5401\n",
      "Epoch 3192/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8065 - p_acc: 0.5737 - val_loss: 1.1390 - val_p_acc: 0.5577\n",
      "Epoch 3193/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8125 - p_acc: 0.6835 - val_loss: 1.1414 - val_p_acc: 0.5401\n",
      "Epoch 3194/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8049 - p_acc: 0.6819 - val_loss: 1.1414 - val_p_acc: 0.5224\n",
      "Epoch 3195/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8834 - p_acc: 0.5825 - val_loss: 1.1424 - val_p_acc: 0.5224\n",
      "Epoch 3196/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7774 - p_acc: 0.7724 - val_loss: 1.1431 - val_p_acc: 0.5753\n",
      "Epoch 3197/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8049 - p_acc: 0.6450 - val_loss: 1.1427 - val_p_acc: 0.5753\n",
      "Epoch 3198/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7522 - p_acc: 0.6819 - val_loss: 1.1417 - val_p_acc: 0.5401\n",
      "Epoch 3199/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8131 - p_acc: 0.6522 - val_loss: 1.1419 - val_p_acc: 0.5401\n",
      "Epoch 3200/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7152 - p_acc: 0.6034 - val_loss: 1.1421 - val_p_acc: 0.5048\n",
      "Epoch 3201/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7534 - p_acc: 0.6971 - val_loss: 1.1420 - val_p_acc: 0.4872\n",
      "Epoch 3202/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8402 - p_acc: 0.6835 - val_loss: 1.1408 - val_p_acc: 0.5577\n",
      "Epoch 3203/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7912 - p_acc: 0.6466 - val_loss: 1.1392 - val_p_acc: 0.5048\n",
      "Epoch 3204/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7507 - p_acc: 0.6699 - val_loss: 1.1375 - val_p_acc: 0.5224\n",
      "Epoch 3205/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.9076 - p_acc: 0.6643 - val_loss: 1.1370 - val_p_acc: 0.6106\n",
      "Epoch 3206/5000\n",
      "85/85 [==============================] - 0s 717us/sample - loss: 0.8090 - p_acc: 0.6522 - val_loss: 1.1357 - val_p_acc: 0.5224\n",
      "Epoch 3207/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.6936 - p_acc: 0.7147 - val_loss: 1.1341 - val_p_acc: 0.5577\n",
      "Epoch 3208/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8327 - p_acc: 0.6194 - val_loss: 1.1337 - val_p_acc: 0.5401\n",
      "Epoch 3209/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8694 - p_acc: 0.6314 - val_loss: 1.1337 - val_p_acc: 0.5224\n",
      "Epoch 3210/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.8316 - p_acc: 0.6643 - val_loss: 1.1338 - val_p_acc: 0.4696\n",
      "Epoch 3211/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.9300 - p_acc: 0.6194 - val_loss: 1.1342 - val_p_acc: 0.5401\n",
      "Epoch 3212/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.8228 - p_acc: 0.6210 - val_loss: 1.1341 - val_p_acc: 0.4872\n",
      "Epoch 3213/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.8104 - p_acc: 0.6939 - val_loss: 1.1338 - val_p_acc: 0.5401\n",
      "Epoch 3214/5000\n",
      "85/85 [==============================] - 0s 834us/sample - loss: 0.8002 - p_acc: 0.6450 - val_loss: 1.1327 - val_p_acc: 0.5401\n",
      "Epoch 3215/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.8137 - p_acc: 0.5913 - val_loss: 1.1349 - val_p_acc: 0.5401\n",
      "Epoch 3216/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.7771 - p_acc: 0.6346 - val_loss: 1.1370 - val_p_acc: 0.5753\n",
      "Epoch 3217/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7815 - p_acc: 0.6819 - val_loss: 1.1431 - val_p_acc: 0.5577\n",
      "Epoch 3218/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7534 - p_acc: 0.7131 - val_loss: 1.1457 - val_p_acc: 0.5577\n",
      "Epoch 3219/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.8099 - p_acc: 0.6522 - val_loss: 1.1483 - val_p_acc: 0.5577\n",
      "Epoch 3220/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.8623 - p_acc: 0.6418 - val_loss: 1.1490 - val_p_acc: 0.5048\n",
      "Epoch 3221/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.7804 - p_acc: 0.6330 - val_loss: 1.1500 - val_p_acc: 0.5048\n",
      "Epoch 3222/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.7660 - p_acc: 0.7548 - val_loss: 1.1514 - val_p_acc: 0.5401\n",
      "Epoch 3223/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.7901 - p_acc: 0.6034 - val_loss: 1.1514 - val_p_acc: 0.5048\n",
      "Epoch 3224/5000\n",
      "85/85 [==============================] - 0s 757us/sample - loss: 0.8227 - p_acc: 0.6715 - val_loss: 1.1499 - val_p_acc: 0.5401\n",
      "Epoch 3225/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8479 - p_acc: 0.7099 - val_loss: 1.1480 - val_p_acc: 0.5048\n",
      "Epoch 3226/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8164 - p_acc: 0.6611 - val_loss: 1.1458 - val_p_acc: 0.5401\n",
      "Epoch 3227/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8156 - p_acc: 0.6346 - val_loss: 1.1437 - val_p_acc: 0.5577\n",
      "Epoch 3228/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7532 - p_acc: 0.6731 - val_loss: 1.1417 - val_p_acc: 0.5048\n",
      "Epoch 3229/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7956 - p_acc: 0.6835 - val_loss: 1.1382 - val_p_acc: 0.5577\n",
      "Epoch 3230/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.7715 - p_acc: 0.6450 - val_loss: 1.1374 - val_p_acc: 0.5401\n",
      "Epoch 3231/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8427 - p_acc: 0.6402 - val_loss: 1.1362 - val_p_acc: 0.5048\n",
      "Epoch 3232/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 0.8550 - p_acc: 0.6819 - val_loss: 1.1344 - val_p_acc: 0.5753\n",
      "Epoch 3233/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8017 - p_acc: 0.7131 - val_loss: 1.1345 - val_p_acc: 0.5401\n",
      "Epoch 3234/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7604 - p_acc: 0.6643 - val_loss: 1.1349 - val_p_acc: 0.5224\n",
      "Epoch 3235/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8110 - p_acc: 0.6835 - val_loss: 1.1363 - val_p_acc: 0.5401\n",
      "Epoch 3236/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7943 - p_acc: 0.6418 - val_loss: 1.1362 - val_p_acc: 0.5048\n",
      "Epoch 3237/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8687 - p_acc: 0.6490 - val_loss: 1.1339 - val_p_acc: 0.5224\n",
      "Epoch 3238/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8567 - p_acc: 0.6034 - val_loss: 1.1347 - val_p_acc: 0.5577\n",
      "Epoch 3239/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7787 - p_acc: 0.6106 - val_loss: 1.1340 - val_p_acc: 0.5753\n",
      "Epoch 3240/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7800 - p_acc: 0.7027 - val_loss: 1.1329 - val_p_acc: 0.5048\n",
      "Epoch 3241/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8167 - p_acc: 0.5809 - val_loss: 1.1322 - val_p_acc: 0.5401\n",
      "Epoch 3242/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8674 - p_acc: 0.6066 - val_loss: 1.1313 - val_p_acc: 0.5753\n",
      "Epoch 3243/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8344 - p_acc: 0.5913 - val_loss: 1.1324 - val_p_acc: 0.5753\n",
      "Epoch 3244/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7769 - p_acc: 0.6939 - val_loss: 1.1330 - val_p_acc: 0.5401\n",
      "Epoch 3245/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8916 - p_acc: 0.7027 - val_loss: 1.1333 - val_p_acc: 0.5401\n",
      "Epoch 3246/5000\n",
      "85/85 [==============================] - 0s 822us/sample - loss: 0.7613 - p_acc: 0.7043 - val_loss: 1.1326 - val_p_acc: 0.5224\n",
      "Epoch 3247/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8107 - p_acc: 0.6819 - val_loss: 1.1335 - val_p_acc: 0.5048\n",
      "Epoch 3248/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7771 - p_acc: 0.6731 - val_loss: 1.1340 - val_p_acc: 0.5577\n",
      "Epoch 3249/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7893 - p_acc: 0.6747 - val_loss: 1.1355 - val_p_acc: 0.5401\n",
      "Epoch 3250/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8525 - p_acc: 0.6731 - val_loss: 1.1365 - val_p_acc: 0.5224\n",
      "Epoch 3251/5000\n",
      "85/85 [==============================] - 0s 736us/sample - loss: 0.8384 - p_acc: 0.6314 - val_loss: 1.1374 - val_p_acc: 0.5401\n",
      "Epoch 3252/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8341 - p_acc: 0.6747 - val_loss: 1.1383 - val_p_acc: 0.5577\n",
      "Epoch 3253/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7053 - p_acc: 0.7284 - val_loss: 1.1395 - val_p_acc: 0.5577\n",
      "Epoch 3254/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7900 - p_acc: 0.6627 - val_loss: 1.1383 - val_p_acc: 0.5577\n",
      "Epoch 3255/5000\n",
      "85/85 [==============================] - 0s 762us/sample - loss: 0.7874 - p_acc: 0.6522 - val_loss: 1.1388 - val_p_acc: 0.5224\n",
      "Epoch 3256/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8542 - p_acc: 0.5929 - val_loss: 1.1393 - val_p_acc: 0.5929\n",
      "Epoch 3257/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7764 - p_acc: 0.7308 - val_loss: 1.1384 - val_p_acc: 0.5753\n",
      "Epoch 3258/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8019 - p_acc: 0.6522 - val_loss: 1.1369 - val_p_acc: 0.5401\n",
      "Epoch 3259/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.7314 - p_acc: 0.7179 - val_loss: 1.1354 - val_p_acc: 0.4872\n",
      "Epoch 3260/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8804 - p_acc: 0.5946 - val_loss: 1.1342 - val_p_acc: 0.5048\n",
      "Epoch 3261/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.8556 - p_acc: 0.6482 - val_loss: 1.1331 - val_p_acc: 0.5048\n",
      "Epoch 3262/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8234 - p_acc: 0.6522 - val_loss: 1.1306 - val_p_acc: 0.5929\n",
      "Epoch 3263/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.8658 - p_acc: 0.6747 - val_loss: 1.1297 - val_p_acc: 0.5401\n",
      "Epoch 3264/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8608 - p_acc: 0.5825 - val_loss: 1.1306 - val_p_acc: 0.5721\n",
      "Epoch 3265/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8372 - p_acc: 0.6659 - val_loss: 1.1314 - val_p_acc: 0.5401\n",
      "Epoch 3266/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7222 - p_acc: 0.7043 - val_loss: 1.1307 - val_p_acc: 0.5577\n",
      "Epoch 3267/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8520 - p_acc: 0.6018 - val_loss: 1.1320 - val_p_acc: 0.5401\n",
      "Epoch 3268/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8009 - p_acc: 0.6819 - val_loss: 1.1340 - val_p_acc: 0.5753\n",
      "Epoch 3269/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7847 - p_acc: 0.6538 - val_loss: 1.1345 - val_p_acc: 0.5753\n",
      "Epoch 3270/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8814 - p_acc: 0.6018 - val_loss: 1.1360 - val_p_acc: 0.5401\n",
      "Epoch 3271/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8038 - p_acc: 0.6715 - val_loss: 1.1361 - val_p_acc: 0.5224\n",
      "Epoch 3272/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8106 - p_acc: 0.6138 - val_loss: 1.1368 - val_p_acc: 0.5753\n",
      "Epoch 3273/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7537 - p_acc: 0.6554 - val_loss: 1.1367 - val_p_acc: 0.5048\n",
      "Epoch 3274/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8325 - p_acc: 0.6330 - val_loss: 1.1339 - val_p_acc: 0.5577\n",
      "Epoch 3275/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8080 - p_acc: 0.6907 - val_loss: 1.1318 - val_p_acc: 0.5369\n",
      "Epoch 3276/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7979 - p_acc: 0.7220 - val_loss: 1.1309 - val_p_acc: 0.5369\n",
      "Epoch 3277/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7057 - p_acc: 0.6939 - val_loss: 1.1303 - val_p_acc: 0.5369\n",
      "Epoch 3278/5000\n",
      "85/85 [==============================] - 0s 738us/sample - loss: 0.8068 - p_acc: 0.6955 - val_loss: 1.1314 - val_p_acc: 0.4840\n",
      "Epoch 3279/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8974 - p_acc: 0.5881 - val_loss: 1.1320 - val_p_acc: 0.5224\n",
      "Epoch 3280/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8314 - p_acc: 0.5897 - val_loss: 1.1321 - val_p_acc: 0.5577\n",
      "Epoch 3281/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8746 - p_acc: 0.4968 - val_loss: 1.1313 - val_p_acc: 0.5224\n",
      "Epoch 3282/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8199 - p_acc: 0.6923 - val_loss: 1.1306 - val_p_acc: 0.5577\n",
      "Epoch 3283/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9146 - p_acc: 0.5425 - val_loss: 1.1300 - val_p_acc: 0.5577\n",
      "Epoch 3284/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8107 - p_acc: 0.6627 - val_loss: 1.1306 - val_p_acc: 0.5224\n",
      "Epoch 3285/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8248 - p_acc: 0.6418 - val_loss: 1.1313 - val_p_acc: 0.5401\n",
      "Epoch 3286/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8759 - p_acc: 0.6018 - val_loss: 1.1326 - val_p_acc: 0.5929\n",
      "Epoch 3287/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.7404 - p_acc: 0.7115 - val_loss: 1.1324 - val_p_acc: 0.5048\n",
      "Epoch 3288/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.8887 - p_acc: 0.6242 - val_loss: 1.1319 - val_p_acc: 0.5048\n",
      "Epoch 3289/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7513 - p_acc: 0.6210 - val_loss: 1.1320 - val_p_acc: 0.5577\n",
      "Epoch 3290/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8011 - p_acc: 0.6939 - val_loss: 1.1317 - val_p_acc: 0.5929\n",
      "Epoch 3291/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7098 - p_acc: 0.7444 - val_loss: 1.1273 - val_p_acc: 0.5753\n",
      "Epoch 3292/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8194 - p_acc: 0.6402 - val_loss: 1.1244 - val_p_acc: 0.4840\n",
      "Epoch 3293/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7791 - p_acc: 0.6675 - val_loss: 1.1219 - val_p_acc: 0.4840\n",
      "Epoch 3294/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8778 - p_acc: 0.5473 - val_loss: 1.1212 - val_p_acc: 0.4840\n",
      "Epoch 3295/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7874 - p_acc: 0.5753 - val_loss: 1.1215 - val_p_acc: 0.5545\n",
      "Epoch 3296/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7887 - p_acc: 0.7220 - val_loss: 1.1218 - val_p_acc: 0.5016\n",
      "Epoch 3297/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7849 - p_acc: 0.6226 - val_loss: 1.1223 - val_p_acc: 0.5192\n",
      "Epoch 3298/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7280 - p_acc: 0.7428 - val_loss: 1.1206 - val_p_acc: 0.5016\n",
      "Epoch 3299/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8319 - p_acc: 0.6450 - val_loss: 1.1206 - val_p_acc: 0.5192\n",
      "Epoch 3300/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.8288 - p_acc: 0.6747 - val_loss: 1.1212 - val_p_acc: 0.5369\n",
      "Epoch 3301/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.7428 - p_acc: 0.7428 - val_loss: 1.1200 - val_p_acc: 0.4840\n",
      "Epoch 3302/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.7380 - p_acc: 0.7949 - val_loss: 1.1194 - val_p_acc: 0.5016\n",
      "Epoch 3303/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.8657 - p_acc: 0.6034 - val_loss: 1.1203 - val_p_acc: 0.5369\n",
      "Epoch 3304/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7797 - p_acc: 0.7011 - val_loss: 1.1201 - val_p_acc: 0.5369\n",
      "Epoch 3305/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7015 - p_acc: 0.7460 - val_loss: 1.1191 - val_p_acc: 0.4872\n",
      "Epoch 3306/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7975 - p_acc: 0.5897 - val_loss: 1.1192 - val_p_acc: 0.5401\n",
      "Epoch 3307/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8078 - p_acc: 0.6402 - val_loss: 1.1199 - val_p_acc: 0.5016\n",
      "Epoch 3308/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7509 - p_acc: 0.6731 - val_loss: 1.1201 - val_p_acc: 0.5192\n",
      "Epoch 3309/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7959 - p_acc: 0.6106 - val_loss: 1.1199 - val_p_acc: 0.5192\n",
      "Epoch 3310/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8604 - p_acc: 0.6170 - val_loss: 1.1178 - val_p_acc: 0.5224\n",
      "Epoch 3311/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8198 - p_acc: 0.6538 - val_loss: 1.1168 - val_p_acc: 0.5401\n",
      "Epoch 3312/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8058 - p_acc: 0.6506 - val_loss: 1.1182 - val_p_acc: 0.5401\n",
      "Epoch 3313/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7883 - p_acc: 0.6971 - val_loss: 1.1189 - val_p_acc: 0.5048\n",
      "Epoch 3314/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7979 - p_acc: 0.6611 - val_loss: 1.1196 - val_p_acc: 0.5753\n",
      "Epoch 3315/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8184 - p_acc: 0.6314 - val_loss: 1.1210 - val_p_acc: 0.4840\n",
      "Epoch 3316/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7789 - p_acc: 0.6226 - val_loss: 1.1216 - val_p_acc: 0.4663\n",
      "Epoch 3317/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7622 - p_acc: 0.6402 - val_loss: 1.1233 - val_p_acc: 0.5016\n",
      "Epoch 3318/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7884 - p_acc: 0.6522 - val_loss: 1.1235 - val_p_acc: 0.5545\n",
      "Epoch 3319/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8236 - p_acc: 0.5929 - val_loss: 1.1238 - val_p_acc: 0.5369\n",
      "Epoch 3320/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8298 - p_acc: 0.6763 - val_loss: 1.1237 - val_p_acc: 0.5401\n",
      "Epoch 3321/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7618 - p_acc: 0.6747 - val_loss: 1.1231 - val_p_acc: 0.5048\n",
      "Epoch 3322/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7491 - p_acc: 0.6763 - val_loss: 1.1221 - val_p_acc: 0.5577\n",
      "Epoch 3323/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7868 - p_acc: 0.7220 - val_loss: 1.1227 - val_p_acc: 0.5224\n",
      "Epoch 3324/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7655 - p_acc: 0.6330 - val_loss: 1.1229 - val_p_acc: 0.5224\n",
      "Epoch 3325/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8549 - p_acc: 0.5962 - val_loss: 1.1238 - val_p_acc: 0.5753\n",
      "Epoch 3326/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7451 - p_acc: 0.6939 - val_loss: 1.1250 - val_p_acc: 0.5401\n",
      "Epoch 3327/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7978 - p_acc: 0.7460 - val_loss: 1.1255 - val_p_acc: 0.5401\n",
      "Epoch 3328/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8664 - p_acc: 0.6226 - val_loss: 1.1252 - val_p_acc: 0.5753\n",
      "Epoch 3329/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7779 - p_acc: 0.6867 - val_loss: 1.1262 - val_p_acc: 0.5753\n",
      "Epoch 3330/5000\n",
      "85/85 [==============================] - 0s 701us/sample - loss: 0.7689 - p_acc: 0.6835 - val_loss: 1.1274 - val_p_acc: 0.5401\n",
      "Epoch 3331/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8066 - p_acc: 0.6731 - val_loss: 1.1288 - val_p_acc: 0.5753\n",
      "Epoch 3332/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7936 - p_acc: 0.7043 - val_loss: 1.1293 - val_p_acc: 0.5401\n",
      "Epoch 3333/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8208 - p_acc: 0.7011 - val_loss: 1.1300 - val_p_acc: 0.5577\n",
      "Epoch 3334/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7967 - p_acc: 0.7059 - val_loss: 1.1317 - val_p_acc: 0.5577\n",
      "Epoch 3335/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7599 - p_acc: 0.6955 - val_loss: 1.1307 - val_p_acc: 0.5401\n",
      "Epoch 3336/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8240 - p_acc: 0.7043 - val_loss: 1.1284 - val_p_acc: 0.5224\n",
      "Epoch 3337/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7202 - p_acc: 0.6835 - val_loss: 1.1252 - val_p_acc: 0.5048\n",
      "Epoch 3338/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7744 - p_acc: 0.6450 - val_loss: 1.1237 - val_p_acc: 0.5369\n",
      "Epoch 3339/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8258 - p_acc: 0.6034 - val_loss: 1.1226 - val_p_acc: 0.5016\n",
      "Epoch 3340/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7431 - p_acc: 0.6923 - val_loss: 1.1227 - val_p_acc: 0.4840\n",
      "Epoch 3341/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8034 - p_acc: 0.6939 - val_loss: 1.1223 - val_p_acc: 0.4840\n",
      "Epoch 3342/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7551 - p_acc: 0.6587 - val_loss: 1.1236 - val_p_acc: 0.4663\n",
      "Epoch 3343/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8138 - p_acc: 0.6138 - val_loss: 1.1231 - val_p_acc: 0.5369\n",
      "Epoch 3344/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8013 - p_acc: 0.6418 - val_loss: 1.1248 - val_p_acc: 0.5192\n",
      "Epoch 3345/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7184 - p_acc: 0.7043 - val_loss: 1.1249 - val_p_acc: 0.5369\n",
      "Epoch 3346/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7629 - p_acc: 0.5946 - val_loss: 1.1239 - val_p_acc: 0.5192\n",
      "Epoch 3347/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8021 - p_acc: 0.6466 - val_loss: 1.1250 - val_p_acc: 0.5577\n",
      "Epoch 3348/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7603 - p_acc: 0.6554 - val_loss: 1.1226 - val_p_acc: 0.5224\n",
      "Epoch 3349/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7224 - p_acc: 0.7252 - val_loss: 1.1224 - val_p_acc: 0.5224\n",
      "Epoch 3350/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7964 - p_acc: 0.6538 - val_loss: 1.1247 - val_p_acc: 0.5577\n",
      "Epoch 3351/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8021 - p_acc: 0.6450 - val_loss: 1.1249 - val_p_acc: 0.5753\n",
      "Epoch 3352/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7287 - p_acc: 0.6258 - val_loss: 1.1255 - val_p_acc: 0.5753\n",
      "Epoch 3353/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8187 - p_acc: 0.6122 - val_loss: 1.1259 - val_p_acc: 0.4872\n",
      "Epoch 3354/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8376 - p_acc: 0.6538 - val_loss: 1.1260 - val_p_acc: 0.5577\n",
      "Epoch 3355/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8238 - p_acc: 0.6314 - val_loss: 1.1273 - val_p_acc: 0.5577\n",
      "Epoch 3356/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7966 - p_acc: 0.6538 - val_loss: 1.1272 - val_p_acc: 0.5048\n",
      "Epoch 3357/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7590 - p_acc: 0.5929 - val_loss: 1.1268 - val_p_acc: 0.6106\n",
      "Epoch 3358/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8343 - p_acc: 0.7011 - val_loss: 1.1267 - val_p_acc: 0.5577\n",
      "Epoch 3359/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8070 - p_acc: 0.7027 - val_loss: 1.1277 - val_p_acc: 0.5577\n",
      "Epoch 3360/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7519 - p_acc: 0.6506 - val_loss: 1.1266 - val_p_acc: 0.5401\n",
      "Epoch 3361/5000\n",
      "85/85 [==============================] - 0s 702us/sample - loss: 0.7681 - p_acc: 0.6851 - val_loss: 1.1267 - val_p_acc: 0.5401\n",
      "Epoch 3362/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8439 - p_acc: 0.6346 - val_loss: 1.1263 - val_p_acc: 0.5753\n",
      "Epoch 3363/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8595 - p_acc: 0.6210 - val_loss: 1.1269 - val_p_acc: 0.5224\n",
      "Epoch 3364/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7488 - p_acc: 0.6538 - val_loss: 1.1279 - val_p_acc: 0.5048\n",
      "Epoch 3365/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8171 - p_acc: 0.6154 - val_loss: 1.1288 - val_p_acc: 0.5401\n",
      "Epoch 3366/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8063 - p_acc: 0.6418 - val_loss: 1.1291 - val_p_acc: 0.5224\n",
      "Epoch 3367/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7329 - p_acc: 0.7548 - val_loss: 1.1286 - val_p_acc: 0.5577\n",
      "Epoch 3368/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7508 - p_acc: 0.6450 - val_loss: 1.1284 - val_p_acc: 0.5401\n",
      "Epoch 3369/5000\n",
      "85/85 [==============================] - 0s 722us/sample - loss: 0.7211 - p_acc: 0.7412 - val_loss: 1.1292 - val_p_acc: 0.5224\n",
      "Epoch 3370/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8224 - p_acc: 0.6627 - val_loss: 1.1302 - val_p_acc: 0.5224\n",
      "Epoch 3371/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8110 - p_acc: 0.6290 - val_loss: 1.1299 - val_p_acc: 0.5401\n",
      "Epoch 3372/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8063 - p_acc: 0.6034 - val_loss: 1.1312 - val_p_acc: 0.5401\n",
      "Epoch 3373/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7822 - p_acc: 0.6643 - val_loss: 1.1324 - val_p_acc: 0.5401\n",
      "Epoch 3374/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6581 - p_acc: 0.7236 - val_loss: 1.1337 - val_p_acc: 0.5224\n",
      "Epoch 3375/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8995 - p_acc: 0.6138 - val_loss: 1.1339 - val_p_acc: 0.5224\n",
      "Epoch 3376/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7969 - p_acc: 0.6330 - val_loss: 1.1336 - val_p_acc: 0.5224\n",
      "Epoch 3377/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7583 - p_acc: 0.7043 - val_loss: 1.1352 - val_p_acc: 0.5401\n",
      "Epoch 3378/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9130 - p_acc: 0.6226 - val_loss: 1.1376 - val_p_acc: 0.5016\n",
      "Epoch 3379/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8648 - p_acc: 0.6298 - val_loss: 1.1379 - val_p_acc: 0.5192\n",
      "Epoch 3380/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8283 - p_acc: 0.6715 - val_loss: 1.1393 - val_p_acc: 0.4840\n",
      "Epoch 3381/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8018 - p_acc: 0.6242 - val_loss: 1.1383 - val_p_acc: 0.5577\n",
      "Epoch 3382/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8254 - p_acc: 0.6226 - val_loss: 1.1373 - val_p_acc: 0.5401\n",
      "Epoch 3383/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7636 - p_acc: 0.6450 - val_loss: 1.1361 - val_p_acc: 0.5577\n",
      "Epoch 3384/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8172 - p_acc: 0.6210 - val_loss: 1.1365 - val_p_acc: 0.5401\n",
      "Epoch 3385/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7806 - p_acc: 0.6330 - val_loss: 1.1361 - val_p_acc: 0.5577\n",
      "Epoch 3386/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8422 - p_acc: 0.6346 - val_loss: 1.1359 - val_p_acc: 0.5401\n",
      "Epoch 3387/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7077 - p_acc: 0.7043 - val_loss: 1.1361 - val_p_acc: 0.5753\n",
      "Epoch 3388/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8561 - p_acc: 0.6522 - val_loss: 1.1370 - val_p_acc: 0.5401\n",
      "Epoch 3389/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8790 - p_acc: 0.6330 - val_loss: 1.1379 - val_p_acc: 0.5753\n",
      "Epoch 3390/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8064 - p_acc: 0.6803 - val_loss: 1.1377 - val_p_acc: 0.5401\n",
      "Epoch 3391/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7563 - p_acc: 0.6242 - val_loss: 1.1379 - val_p_acc: 0.5577\n",
      "Epoch 3392/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9297 - p_acc: 0.6819 - val_loss: 1.1387 - val_p_acc: 0.5401\n",
      "Epoch 3393/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8061 - p_acc: 0.6538 - val_loss: 1.1385 - val_p_acc: 0.5753\n",
      "Epoch 3394/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8806 - p_acc: 0.6538 - val_loss: 1.1380 - val_p_acc: 0.5401\n",
      "Epoch 3395/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7206 - p_acc: 0.6819 - val_loss: 1.1363 - val_p_acc: 0.5401\n",
      "Epoch 3396/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8450 - p_acc: 0.6659 - val_loss: 1.1370 - val_p_acc: 0.5401\n",
      "Epoch 3397/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7226 - p_acc: 0.7532 - val_loss: 1.1376 - val_p_acc: 0.5577\n",
      "Epoch 3398/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8269 - p_acc: 0.6258 - val_loss: 1.1377 - val_p_acc: 0.5401\n",
      "Epoch 3399/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7578 - p_acc: 0.6851 - val_loss: 1.1372 - val_p_acc: 0.5753\n",
      "Epoch 3400/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7459 - p_acc: 0.6955 - val_loss: 1.1360 - val_p_acc: 0.5401\n",
      "Epoch 3401/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8250 - p_acc: 0.6627 - val_loss: 1.1359 - val_p_acc: 0.5401\n",
      "Epoch 3402/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7442 - p_acc: 0.6923 - val_loss: 1.1351 - val_p_acc: 0.5401\n",
      "Epoch 3403/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7586 - p_acc: 0.7147 - val_loss: 1.1338 - val_p_acc: 0.5048\n",
      "Epoch 3404/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7339 - p_acc: 0.6170 - val_loss: 1.1341 - val_p_acc: 0.5577\n",
      "Epoch 3405/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8725 - p_acc: 0.6522 - val_loss: 1.1342 - val_p_acc: 0.5192\n",
      "Epoch 3406/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7963 - p_acc: 0.6554 - val_loss: 1.1346 - val_p_acc: 0.5721\n",
      "Epoch 3407/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8121 - p_acc: 0.6506 - val_loss: 1.1365 - val_p_acc: 0.5192\n",
      "Epoch 3408/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8494 - p_acc: 0.6763 - val_loss: 1.1373 - val_p_acc: 0.4840\n",
      "Epoch 3409/5000\n",
      "85/85 [==============================] - 0s 717us/sample - loss: 0.7349 - p_acc: 0.7011 - val_loss: 1.1384 - val_p_acc: 0.5016\n",
      "Epoch 3410/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8317 - p_acc: 0.6122 - val_loss: 1.1406 - val_p_acc: 0.4840\n",
      "Epoch 3411/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8205 - p_acc: 0.6611 - val_loss: 1.1436 - val_p_acc: 0.4840\n",
      "Epoch 3412/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7686 - p_acc: 0.6851 - val_loss: 1.1441 - val_p_acc: 0.4840\n",
      "Epoch 3413/5000\n",
      "85/85 [==============================] - 0s 699us/sample - loss: 0.8229 - p_acc: 0.6434 - val_loss: 1.1436 - val_p_acc: 0.5192\n",
      "Epoch 3414/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7774 - p_acc: 0.6627 - val_loss: 1.1413 - val_p_acc: 0.5192\n",
      "Epoch 3415/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7751 - p_acc: 0.7131 - val_loss: 1.1403 - val_p_acc: 0.4840\n",
      "Epoch 3416/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8051 - p_acc: 0.6434 - val_loss: 1.1399 - val_p_acc: 0.4311\n",
      "Epoch 3417/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8077 - p_acc: 0.6242 - val_loss: 1.1407 - val_p_acc: 0.5545\n",
      "Epoch 3418/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8292 - p_acc: 0.6731 - val_loss: 1.1413 - val_p_acc: 0.5192\n",
      "Epoch 3419/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7420 - p_acc: 0.6627 - val_loss: 1.1431 - val_p_acc: 0.5192\n",
      "Epoch 3420/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7758 - p_acc: 0.7308 - val_loss: 1.1455 - val_p_acc: 0.5545\n",
      "Epoch 3421/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7798 - p_acc: 0.6346 - val_loss: 1.1474 - val_p_acc: 0.4840\n",
      "Epoch 3422/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8263 - p_acc: 0.6995 - val_loss: 1.1494 - val_p_acc: 0.4840\n",
      "Epoch 3423/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8804 - p_acc: 0.6050 - val_loss: 1.1507 - val_p_acc: 0.5192\n",
      "Epoch 3424/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8397 - p_acc: 0.6346 - val_loss: 1.1511 - val_p_acc: 0.5016\n",
      "Epoch 3425/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7637 - p_acc: 0.6691 - val_loss: 1.1490 - val_p_acc: 0.5369\n",
      "Epoch 3426/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8263 - p_acc: 0.6018 - val_loss: 1.1473 - val_p_acc: 0.4663\n",
      "Epoch 3427/5000\n",
      "85/85 [==============================] - 0s 714us/sample - loss: 0.6796 - p_acc: 0.7220 - val_loss: 1.1453 - val_p_acc: 0.5016\n",
      "Epoch 3428/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8005 - p_acc: 0.6867 - val_loss: 1.1436 - val_p_acc: 0.5192\n",
      "Epoch 3429/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7882 - p_acc: 0.7043 - val_loss: 1.1444 - val_p_acc: 0.5192\n",
      "Epoch 3430/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7188 - p_acc: 0.6330 - val_loss: 1.1442 - val_p_acc: 0.4840\n",
      "Epoch 3431/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8568 - p_acc: 0.6346 - val_loss: 1.1438 - val_p_acc: 0.5192\n",
      "Epoch 3432/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9002 - p_acc: 0.6226 - val_loss: 1.1438 - val_p_acc: 0.4840\n",
      "Epoch 3433/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8064 - p_acc: 0.7027 - val_loss: 1.1420 - val_p_acc: 0.5369\n",
      "Epoch 3434/5000\n",
      "85/85 [==============================] - 0s 733us/sample - loss: 0.7948 - p_acc: 0.6611 - val_loss: 1.1403 - val_p_acc: 0.5192\n",
      "Epoch 3435/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8583 - p_acc: 0.6346 - val_loss: 1.1391 - val_p_acc: 0.5048\n",
      "Epoch 3436/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7310 - p_acc: 0.7059 - val_loss: 1.1387 - val_p_acc: 0.5224\n",
      "Epoch 3437/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8084 - p_acc: 0.6402 - val_loss: 1.1369 - val_p_acc: 0.5401\n",
      "Epoch 3438/5000\n",
      "85/85 [==============================] - 0s 721us/sample - loss: 0.8218 - p_acc: 0.6611 - val_loss: 1.1372 - val_p_acc: 0.4840\n",
      "Epoch 3439/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7921 - p_acc: 0.6122 - val_loss: 1.1370 - val_p_acc: 0.5545\n",
      "Epoch 3440/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7762 - p_acc: 0.6971 - val_loss: 1.1369 - val_p_acc: 0.5753\n",
      "Epoch 3441/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7995 - p_acc: 0.6571 - val_loss: 1.1384 - val_p_acc: 0.5224\n",
      "Epoch 3442/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8506 - p_acc: 0.6522 - val_loss: 1.1383 - val_p_acc: 0.5753\n",
      "Epoch 3443/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7934 - p_acc: 0.6434 - val_loss: 1.1404 - val_p_acc: 0.5401\n",
      "Epoch 3444/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8183 - p_acc: 0.6466 - val_loss: 1.1442 - val_p_acc: 0.5224\n",
      "Epoch 3445/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8043 - p_acc: 0.6627 - val_loss: 1.1446 - val_p_acc: 0.5577\n",
      "Epoch 3446/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.8434 - p_acc: 0.6106 - val_loss: 1.1433 - val_p_acc: 0.5401\n",
      "Epoch 3447/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8765 - p_acc: 0.5737 - val_loss: 1.1439 - val_p_acc: 0.5224\n",
      "Epoch 3448/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8101 - p_acc: 0.6907 - val_loss: 1.1455 - val_p_acc: 0.5048\n",
      "Epoch 3449/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7927 - p_acc: 0.6675 - val_loss: 1.1473 - val_p_acc: 0.5577\n",
      "Epoch 3450/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7189 - p_acc: 0.6971 - val_loss: 1.1486 - val_p_acc: 0.5577\n",
      "Epoch 3451/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7092 - p_acc: 0.6939 - val_loss: 1.1493 - val_p_acc: 0.5401\n",
      "Epoch 3452/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7430 - p_acc: 0.7236 - val_loss: 1.1495 - val_p_acc: 0.5577\n",
      "Epoch 3453/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7770 - p_acc: 0.6418 - val_loss: 1.1486 - val_p_acc: 0.5753\n",
      "Epoch 3454/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8407 - p_acc: 0.6522 - val_loss: 1.1470 - val_p_acc: 0.5577\n",
      "Epoch 3455/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.9364 - p_acc: 0.6434 - val_loss: 1.1466 - val_p_acc: 0.5224\n",
      "Epoch 3456/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8183 - p_acc: 0.5769 - val_loss: 1.1458 - val_p_acc: 0.5929\n",
      "Epoch 3457/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7166 - p_acc: 0.6955 - val_loss: 1.1424 - val_p_acc: 0.5401\n",
      "Epoch 3458/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8364 - p_acc: 0.6819 - val_loss: 1.1392 - val_p_acc: 0.5577\n",
      "Epoch 3459/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8189 - p_acc: 0.6747 - val_loss: 1.1388 - val_p_acc: 0.5224\n",
      "Epoch 3460/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7141 - p_acc: 0.6939 - val_loss: 1.1385 - val_p_acc: 0.5753\n",
      "Epoch 3461/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7223 - p_acc: 0.7236 - val_loss: 1.1380 - val_p_acc: 0.5224\n",
      "Epoch 3462/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7377 - p_acc: 0.6627 - val_loss: 1.1397 - val_p_acc: 0.5577\n",
      "Epoch 3463/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8574 - p_acc: 0.6330 - val_loss: 1.1391 - val_p_acc: 0.5401\n",
      "Epoch 3464/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6824 - p_acc: 0.6538 - val_loss: 1.1380 - val_p_acc: 0.5048\n",
      "Epoch 3465/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6693 - p_acc: 0.7772 - val_loss: 1.1377 - val_p_acc: 0.5224\n",
      "Epoch 3466/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8690 - p_acc: 0.6074 - val_loss: 1.1366 - val_p_acc: 0.5224\n",
      "Epoch 3467/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8729 - p_acc: 0.6122 - val_loss: 1.1378 - val_p_acc: 0.5224\n",
      "Epoch 3468/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7450 - p_acc: 0.6018 - val_loss: 1.1403 - val_p_acc: 0.5577\n",
      "Epoch 3469/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8018 - p_acc: 0.6835 - val_loss: 1.1410 - val_p_acc: 0.5224\n",
      "Epoch 3470/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8425 - p_acc: 0.6538 - val_loss: 1.1428 - val_p_acc: 0.5224\n",
      "Epoch 3471/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6873 - p_acc: 0.7444 - val_loss: 1.1431 - val_p_acc: 0.5401\n",
      "Epoch 3472/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7109 - p_acc: 0.6450 - val_loss: 1.1438 - val_p_acc: 0.5577\n",
      "Epoch 3473/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8715 - p_acc: 0.7131 - val_loss: 1.1418 - val_p_acc: 0.4872\n",
      "Epoch 3474/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7329 - p_acc: 0.6643 - val_loss: 1.1414 - val_p_acc: 0.5048\n",
      "Epoch 3475/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8732 - p_acc: 0.5929 - val_loss: 1.1439 - val_p_acc: 0.5577\n",
      "Epoch 3476/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7942 - p_acc: 0.6346 - val_loss: 1.1468 - val_p_acc: 0.5577\n",
      "Epoch 3477/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8736 - p_acc: 0.5825 - val_loss: 1.1454 - val_p_acc: 0.5753\n",
      "Epoch 3478/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8181 - p_acc: 0.6226 - val_loss: 1.1439 - val_p_acc: 0.5016\n",
      "Epoch 3479/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8096 - p_acc: 0.6883 - val_loss: 1.1415 - val_p_acc: 0.5192\n",
      "Epoch 3480/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8164 - p_acc: 0.6955 - val_loss: 1.1403 - val_p_acc: 0.5577\n",
      "Epoch 3481/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7282 - p_acc: 0.6907 - val_loss: 1.1392 - val_p_acc: 0.5753\n",
      "Epoch 3482/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7523 - p_acc: 0.6747 - val_loss: 1.1380 - val_p_acc: 0.5401\n",
      "Epoch 3483/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8275 - p_acc: 0.5617 - val_loss: 1.1393 - val_p_acc: 0.5401\n",
      "Epoch 3484/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8187 - p_acc: 0.6066 - val_loss: 1.1395 - val_p_acc: 0.5048\n",
      "Epoch 3485/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7936 - p_acc: 0.6923 - val_loss: 1.1393 - val_p_acc: 0.5401\n",
      "Epoch 3486/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7536 - p_acc: 0.6611 - val_loss: 1.1401 - val_p_acc: 0.5224\n",
      "Epoch 3487/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8484 - p_acc: 0.6362 - val_loss: 1.1401 - val_p_acc: 0.5224\n",
      "Epoch 3488/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8916 - p_acc: 0.6314 - val_loss: 1.1414 - val_p_acc: 0.5016\n",
      "Epoch 3489/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8341 - p_acc: 0.6226 - val_loss: 1.1400 - val_p_acc: 0.5192\n",
      "Epoch 3490/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7909 - p_acc: 0.6747 - val_loss: 1.1383 - val_p_acc: 0.5577\n",
      "Epoch 3491/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7989 - p_acc: 0.6835 - val_loss: 1.1367 - val_p_acc: 0.5224\n",
      "Epoch 3492/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8357 - p_acc: 0.6538 - val_loss: 1.1383 - val_p_acc: 0.5224\n",
      "Epoch 3493/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7703 - p_acc: 0.7444 - val_loss: 1.1389 - val_p_acc: 0.5048\n",
      "Epoch 3494/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8506 - p_acc: 0.7011 - val_loss: 1.1405 - val_p_acc: 0.5224\n",
      "Epoch 3495/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7540 - p_acc: 0.7220 - val_loss: 1.1414 - val_p_acc: 0.4696\n",
      "Epoch 3496/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8901 - p_acc: 0.6138 - val_loss: 1.1424 - val_p_acc: 0.5224\n",
      "Epoch 3497/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7216 - p_acc: 0.6835 - val_loss: 1.1426 - val_p_acc: 0.5753\n",
      "Epoch 3498/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8417 - p_acc: 0.6450 - val_loss: 1.1437 - val_p_acc: 0.5401\n",
      "Epoch 3499/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7893 - p_acc: 0.6506 - val_loss: 1.1436 - val_p_acc: 0.5048\n",
      "Epoch 3500/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8932 - p_acc: 0.6715 - val_loss: 1.1451 - val_p_acc: 0.5577\n",
      "Epoch 3501/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8469 - p_acc: 0.6627 - val_loss: 1.1467 - val_p_acc: 0.5753\n",
      "Epoch 3502/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7504 - p_acc: 0.6242 - val_loss: 1.1468 - val_p_acc: 0.5401\n",
      "Epoch 3503/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8612 - p_acc: 0.6066 - val_loss: 1.1474 - val_p_acc: 0.5224\n",
      "Epoch 3504/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7018 - p_acc: 0.7412 - val_loss: 1.1470 - val_p_acc: 0.5048\n",
      "Epoch 3505/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7432 - p_acc: 0.7412 - val_loss: 1.1476 - val_p_acc: 0.5401\n",
      "Epoch 3506/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6945 - p_acc: 0.7300 - val_loss: 1.1491 - val_p_acc: 0.5401\n",
      "Epoch 3507/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7347 - p_acc: 0.5841 - val_loss: 1.1488 - val_p_acc: 0.5224\n",
      "Epoch 3508/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7398 - p_acc: 0.6851 - val_loss: 1.1479 - val_p_acc: 0.5401\n",
      "Epoch 3509/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8177 - p_acc: 0.6731 - val_loss: 1.1485 - val_p_acc: 0.5545\n",
      "Epoch 3510/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8446 - p_acc: 0.6226 - val_loss: 1.1483 - val_p_acc: 0.5192\n",
      "Epoch 3511/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8045 - p_acc: 0.5962 - val_loss: 1.1485 - val_p_acc: 0.5545\n",
      "Epoch 3512/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7686 - p_acc: 0.5841 - val_loss: 1.1476 - val_p_acc: 0.5192\n",
      "Epoch 3513/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7219 - p_acc: 0.7011 - val_loss: 1.1450 - val_p_acc: 0.4840\n",
      "Epoch 3514/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8502 - p_acc: 0.5929 - val_loss: 1.1428 - val_p_acc: 0.4840\n",
      "Epoch 3515/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7754 - p_acc: 0.6611 - val_loss: 1.1421 - val_p_acc: 0.4840\n",
      "Epoch 3516/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7768 - p_acc: 0.6923 - val_loss: 1.1410 - val_p_acc: 0.4808\n",
      "Epoch 3517/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7407 - p_acc: 0.7204 - val_loss: 1.1394 - val_p_acc: 0.4279\n",
      "Epoch 3518/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8850 - p_acc: 0.5513 - val_loss: 1.1405 - val_p_acc: 0.4984\n",
      "Epoch 3519/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7952 - p_acc: 0.6522 - val_loss: 1.1419 - val_p_acc: 0.4631\n",
      "Epoch 3520/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8591 - p_acc: 0.6611 - val_loss: 1.1425 - val_p_acc: 0.5160\n",
      "Epoch 3521/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8222 - p_acc: 0.6643 - val_loss: 1.1422 - val_p_acc: 0.5545\n",
      "Epoch 3522/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7729 - p_acc: 0.6434 - val_loss: 1.1430 - val_p_acc: 0.5192\n",
      "Epoch 3523/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8809 - p_acc: 0.6018 - val_loss: 1.1434 - val_p_acc: 0.4840\n",
      "Epoch 3524/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8135 - p_acc: 0.6226 - val_loss: 1.1434 - val_p_acc: 0.5192\n",
      "Epoch 3525/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8369 - p_acc: 0.7204 - val_loss: 1.1420 - val_p_acc: 0.4984\n",
      "Epoch 3526/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7534 - p_acc: 0.6378 - val_loss: 1.1429 - val_p_acc: 0.4984\n",
      "Epoch 3527/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8185 - p_acc: 0.6627 - val_loss: 1.1433 - val_p_acc: 0.4808\n",
      "Epoch 3528/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9134 - p_acc: 0.6907 - val_loss: 1.1438 - val_p_acc: 0.4808\n",
      "Epoch 3529/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8251 - p_acc: 0.6731 - val_loss: 1.1423 - val_p_acc: 0.5016\n",
      "Epoch 3530/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8036 - p_acc: 0.6386 - val_loss: 1.1417 - val_p_acc: 0.5192\n",
      "Epoch 3531/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8393 - p_acc: 0.6803 - val_loss: 1.1438 - val_p_acc: 0.4840\n",
      "Epoch 3532/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7655 - p_acc: 0.6362 - val_loss: 1.1444 - val_p_acc: 0.5369\n",
      "Epoch 3533/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8019 - p_acc: 0.6450 - val_loss: 1.1433 - val_p_acc: 0.5192\n",
      "Epoch 3534/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7625 - p_acc: 0.6522 - val_loss: 1.1424 - val_p_acc: 0.5369\n",
      "Epoch 3535/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7359 - p_acc: 0.7059 - val_loss: 1.1425 - val_p_acc: 0.5192\n",
      "Epoch 3536/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7980 - p_acc: 0.6418 - val_loss: 1.1416 - val_p_acc: 0.5016\n",
      "Epoch 3537/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.9266 - p_acc: 0.6314 - val_loss: 1.1431 - val_p_acc: 0.5192\n",
      "Epoch 3538/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8185 - p_acc: 0.6138 - val_loss: 1.1440 - val_p_acc: 0.4840\n",
      "Epoch 3539/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7815 - p_acc: 0.6699 - val_loss: 1.1444 - val_p_acc: 0.5192\n",
      "Epoch 3540/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7517 - p_acc: 0.6050 - val_loss: 1.1438 - val_p_acc: 0.5192\n",
      "Epoch 3541/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7836 - p_acc: 0.6154 - val_loss: 1.1431 - val_p_acc: 0.5192\n",
      "Epoch 3542/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7767 - p_acc: 0.6819 - val_loss: 1.1429 - val_p_acc: 0.5369\n",
      "Epoch 3543/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8239 - p_acc: 0.6643 - val_loss: 1.1419 - val_p_acc: 0.5016\n",
      "Epoch 3544/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8662 - p_acc: 0.6122 - val_loss: 1.1400 - val_p_acc: 0.5369\n",
      "Epoch 3545/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7751 - p_acc: 0.7476 - val_loss: 1.1390 - val_p_acc: 0.4840\n",
      "Epoch 3546/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7579 - p_acc: 0.6747 - val_loss: 1.1374 - val_p_acc: 0.5192\n",
      "Epoch 3547/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7574 - p_acc: 0.7444 - val_loss: 1.1366 - val_p_acc: 0.4663\n",
      "Epoch 3548/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7486 - p_acc: 0.7220 - val_loss: 1.1357 - val_p_acc: 0.5192\n",
      "Epoch 3549/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8102 - p_acc: 0.6362 - val_loss: 1.1351 - val_p_acc: 0.4663\n",
      "Epoch 3550/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7932 - p_acc: 0.6050 - val_loss: 1.1352 - val_p_acc: 0.5192\n",
      "Epoch 3551/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7847 - p_acc: 0.6955 - val_loss: 1.1346 - val_p_acc: 0.5016\n",
      "Epoch 3552/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7706 - p_acc: 0.7131 - val_loss: 1.1336 - val_p_acc: 0.4455\n",
      "Epoch 3553/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7339 - p_acc: 0.7428 - val_loss: 1.1310 - val_p_acc: 0.4984\n",
      "Epoch 3554/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8836 - p_acc: 0.6378 - val_loss: 1.1290 - val_p_acc: 0.4808\n",
      "Epoch 3555/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9055 - p_acc: 0.5825 - val_loss: 1.1240 - val_p_acc: 0.5192\n",
      "Epoch 3556/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8608 - p_acc: 0.6122 - val_loss: 1.1214 - val_p_acc: 0.5369\n",
      "Epoch 3557/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7959 - p_acc: 0.7308 - val_loss: 1.1193 - val_p_acc: 0.5192\n",
      "Epoch 3558/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7873 - p_acc: 0.7324 - val_loss: 1.1178 - val_p_acc: 0.5016\n",
      "Epoch 3559/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8207 - p_acc: 0.7115 - val_loss: 1.1167 - val_p_acc: 0.5369\n",
      "Epoch 3560/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7005 - p_acc: 0.6867 - val_loss: 1.1170 - val_p_acc: 0.5369\n",
      "Epoch 3561/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8075 - p_acc: 0.6715 - val_loss: 1.1173 - val_p_acc: 0.5016\n",
      "Epoch 3562/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7936 - p_acc: 0.7027 - val_loss: 1.1180 - val_p_acc: 0.5192\n",
      "Epoch 3563/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7875 - p_acc: 0.6867 - val_loss: 1.1173 - val_p_acc: 0.5192\n",
      "Epoch 3564/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7938 - p_acc: 0.6402 - val_loss: 1.1164 - val_p_acc: 0.5016\n",
      "Epoch 3565/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8320 - p_acc: 0.6226 - val_loss: 1.1174 - val_p_acc: 0.5545\n",
      "Epoch 3566/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8124 - p_acc: 0.5946 - val_loss: 1.1206 - val_p_acc: 0.5369\n",
      "Epoch 3567/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7820 - p_acc: 0.6923 - val_loss: 1.1222 - val_p_acc: 0.5369\n",
      "Epoch 3568/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7572 - p_acc: 0.6450 - val_loss: 1.1227 - val_p_acc: 0.4840\n",
      "Epoch 3569/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8927 - p_acc: 0.6490 - val_loss: 1.1210 - val_p_acc: 0.5016\n",
      "Epoch 3570/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8109 - p_acc: 0.7043 - val_loss: 1.1209 - val_p_acc: 0.5369\n",
      "Epoch 3571/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8619 - p_acc: 0.6122 - val_loss: 1.1192 - val_p_acc: 0.5192\n",
      "Epoch 3572/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7123 - p_acc: 0.6226 - val_loss: 1.1180 - val_p_acc: 0.5016\n",
      "Epoch 3573/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7807 - p_acc: 0.6522 - val_loss: 1.1184 - val_p_acc: 0.5016\n",
      "Epoch 3574/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8681 - p_acc: 0.6346 - val_loss: 1.1187 - val_p_acc: 0.4487\n",
      "Epoch 3575/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7704 - p_acc: 0.6506 - val_loss: 1.1176 - val_p_acc: 0.5192\n",
      "Epoch 3576/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8390 - p_acc: 0.6138 - val_loss: 1.1187 - val_p_acc: 0.5545\n",
      "Epoch 3577/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8751 - p_acc: 0.5962 - val_loss: 1.1190 - val_p_acc: 0.5192\n",
      "Epoch 3578/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8289 - p_acc: 0.6891 - val_loss: 1.1199 - val_p_acc: 0.5369\n",
      "Epoch 3579/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8244 - p_acc: 0.7059 - val_loss: 1.1210 - val_p_acc: 0.5016\n",
      "Epoch 3580/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8662 - p_acc: 0.6242 - val_loss: 1.1198 - val_p_acc: 0.5192\n",
      "Epoch 3581/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7445 - p_acc: 0.7340 - val_loss: 1.1195 - val_p_acc: 0.5369\n",
      "Epoch 3582/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7752 - p_acc: 0.6434 - val_loss: 1.1214 - val_p_acc: 0.5016\n",
      "Epoch 3583/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7973 - p_acc: 0.5721 - val_loss: 1.1220 - val_p_acc: 0.5016\n",
      "Epoch 3584/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8059 - p_acc: 0.7131 - val_loss: 1.1246 - val_p_acc: 0.4840\n",
      "Epoch 3585/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7600 - p_acc: 0.6106 - val_loss: 1.1267 - val_p_acc: 0.5369\n",
      "Epoch 3586/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8314 - p_acc: 0.6122 - val_loss: 1.1265 - val_p_acc: 0.5192\n",
      "Epoch 3587/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8133 - p_acc: 0.6034 - val_loss: 1.1256 - val_p_acc: 0.5192\n",
      "Epoch 3588/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7414 - p_acc: 0.7532 - val_loss: 1.1246 - val_p_acc: 0.5016\n",
      "Epoch 3589/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7754 - p_acc: 0.6242 - val_loss: 1.1264 - val_p_acc: 0.4840\n",
      "Epoch 3590/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7451 - p_acc: 0.6939 - val_loss: 1.1261 - val_p_acc: 0.4487\n",
      "Epoch 3591/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7206 - p_acc: 0.7236 - val_loss: 1.1261 - val_p_acc: 0.5016\n",
      "Epoch 3592/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7698 - p_acc: 0.6627 - val_loss: 1.1267 - val_p_acc: 0.5016\n",
      "Epoch 3593/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.7587 - p_acc: 0.6434 - val_loss: 1.1273 - val_p_acc: 0.5192\n",
      "Epoch 3594/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7281 - p_acc: 0.6659 - val_loss: 1.1305 - val_p_acc: 0.5016\n",
      "Epoch 3595/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7929 - p_acc: 0.6258 - val_loss: 1.1302 - val_p_acc: 0.4663\n",
      "Epoch 3596/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8558 - p_acc: 0.6346 - val_loss: 1.1296 - val_p_acc: 0.4663\n",
      "Epoch 3597/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8007 - p_acc: 0.6819 - val_loss: 1.1276 - val_p_acc: 0.5016\n",
      "Epoch 3598/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8526 - p_acc: 0.6715 - val_loss: 1.1266 - val_p_acc: 0.5016\n",
      "Epoch 3599/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7648 - p_acc: 0.6747 - val_loss: 1.1264 - val_p_acc: 0.4840\n",
      "Epoch 3600/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8377 - p_acc: 0.6867 - val_loss: 1.1285 - val_p_acc: 0.5016\n",
      "Epoch 3601/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8802 - p_acc: 0.5753 - val_loss: 1.1303 - val_p_acc: 0.5545\n",
      "Epoch 3602/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7877 - p_acc: 0.6851 - val_loss: 1.1331 - val_p_acc: 0.5545\n",
      "Epoch 3603/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7596 - p_acc: 0.6731 - val_loss: 1.1335 - val_p_acc: 0.5192\n",
      "Epoch 3604/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7748 - p_acc: 0.6226 - val_loss: 1.1318 - val_p_acc: 0.5369\n",
      "Epoch 3605/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7739 - p_acc: 0.6434 - val_loss: 1.1322 - val_p_acc: 0.5369\n",
      "Epoch 3606/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8299 - p_acc: 0.5425 - val_loss: 1.1322 - val_p_acc: 0.5016\n",
      "Epoch 3607/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7747 - p_acc: 0.6466 - val_loss: 1.1339 - val_p_acc: 0.5545\n",
      "Epoch 3608/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7940 - p_acc: 0.6571 - val_loss: 1.1323 - val_p_acc: 0.5369\n",
      "Epoch 3609/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 750us/sample - loss: 0.8138 - p_acc: 0.6394 - val_loss: 1.1313 - val_p_acc: 0.5545\n",
      "Epoch 3610/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9325 - p_acc: 0.5529 - val_loss: 1.1305 - val_p_acc: 0.5545\n",
      "Epoch 3611/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8217 - p_acc: 0.5721 - val_loss: 1.1282 - val_p_acc: 0.5160\n",
      "Epoch 3612/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9078 - p_acc: 0.5897 - val_loss: 1.1276 - val_p_acc: 0.4808\n",
      "Epoch 3613/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7918 - p_acc: 0.7027 - val_loss: 1.1286 - val_p_acc: 0.4984\n",
      "Epoch 3614/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8383 - p_acc: 0.6314 - val_loss: 1.1283 - val_p_acc: 0.4984\n",
      "Epoch 3615/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6720 - p_acc: 0.7428 - val_loss: 1.1291 - val_p_acc: 0.4631\n",
      "Epoch 3616/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8141 - p_acc: 0.6643 - val_loss: 1.1278 - val_p_acc: 0.4279\n",
      "Epoch 3617/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8413 - p_acc: 0.6226 - val_loss: 1.1261 - val_p_acc: 0.4984\n",
      "Epoch 3618/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7804 - p_acc: 0.6170 - val_loss: 1.1235 - val_p_acc: 0.4984\n",
      "Epoch 3619/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8439 - p_acc: 0.6434 - val_loss: 1.1244 - val_p_acc: 0.4808\n",
      "Epoch 3620/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6852 - p_acc: 0.7268 - val_loss: 1.1240 - val_p_acc: 0.4808\n",
      "Epoch 3621/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8344 - p_acc: 0.6330 - val_loss: 1.1263 - val_p_acc: 0.5897\n",
      "Epoch 3622/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7517 - p_acc: 0.6402 - val_loss: 1.1276 - val_p_acc: 0.5545\n",
      "Epoch 3623/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8902 - p_acc: 0.6506 - val_loss: 1.1285 - val_p_acc: 0.5192\n",
      "Epoch 3624/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7983 - p_acc: 0.5873 - val_loss: 1.1286 - val_p_acc: 0.5192\n",
      "Epoch 3625/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8568 - p_acc: 0.5873 - val_loss: 1.1285 - val_p_acc: 0.5369\n",
      "Epoch 3626/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7777 - p_acc: 0.7115 - val_loss: 1.1281 - val_p_acc: 0.5545\n",
      "Epoch 3627/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7780 - p_acc: 0.7179 - val_loss: 1.1273 - val_p_acc: 0.5016\n",
      "Epoch 3628/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8668 - p_acc: 0.5721 - val_loss: 1.1292 - val_p_acc: 0.4631\n",
      "Epoch 3629/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7728 - p_acc: 0.7059 - val_loss: 1.1312 - val_p_acc: 0.5160\n",
      "Epoch 3630/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8042 - p_acc: 0.7115 - val_loss: 1.1300 - val_p_acc: 0.4631\n",
      "Epoch 3631/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7853 - p_acc: 0.6747 - val_loss: 1.1306 - val_p_acc: 0.4808\n",
      "Epoch 3632/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7365 - p_acc: 0.6282 - val_loss: 1.1299 - val_p_acc: 0.4631\n",
      "Epoch 3633/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7547 - p_acc: 0.6298 - val_loss: 1.1295 - val_p_acc: 0.5016\n",
      "Epoch 3634/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7481 - p_acc: 0.6819 - val_loss: 1.1295 - val_p_acc: 0.5369\n",
      "Epoch 3635/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7834 - p_acc: 0.6330 - val_loss: 1.1306 - val_p_acc: 0.5369\n",
      "Epoch 3636/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8226 - p_acc: 0.5809 - val_loss: 1.1313 - val_p_acc: 0.4840\n",
      "Epoch 3637/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7606 - p_acc: 0.7027 - val_loss: 1.1306 - val_p_acc: 0.5192\n",
      "Epoch 3638/5000\n",
      "85/85 [==============================] - 0s 713us/sample - loss: 0.7748 - p_acc: 0.6835 - val_loss: 1.1319 - val_p_acc: 0.4487\n",
      "Epoch 3639/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8054 - p_acc: 0.6210 - val_loss: 1.1311 - val_p_acc: 0.5369\n",
      "Epoch 3640/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8790 - p_acc: 0.6819 - val_loss: 1.1301 - val_p_acc: 0.5545\n",
      "Epoch 3641/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7465 - p_acc: 0.5962 - val_loss: 1.1289 - val_p_acc: 0.5192\n",
      "Epoch 3642/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8613 - p_acc: 0.6907 - val_loss: 1.1284 - val_p_acc: 0.5016\n",
      "Epoch 3643/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7326 - p_acc: 0.6554 - val_loss: 1.1290 - val_p_acc: 0.5545\n",
      "Epoch 3644/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7727 - p_acc: 0.6466 - val_loss: 1.1282 - val_p_acc: 0.4663\n",
      "Epoch 3645/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8159 - p_acc: 0.7147 - val_loss: 1.1277 - val_p_acc: 0.5016\n",
      "Epoch 3646/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7463 - p_acc: 0.7236 - val_loss: 1.1295 - val_p_acc: 0.5721\n",
      "Epoch 3647/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7418 - p_acc: 0.6691 - val_loss: 1.1312 - val_p_acc: 0.5369\n",
      "Epoch 3648/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7345 - p_acc: 0.7027 - val_loss: 1.1305 - val_p_acc: 0.5369\n",
      "Epoch 3649/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7562 - p_acc: 0.7043 - val_loss: 1.1293 - val_p_acc: 0.5192\n",
      "Epoch 3650/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7543 - p_acc: 0.6450 - val_loss: 1.1287 - val_p_acc: 0.5192\n",
      "Epoch 3651/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8470 - p_acc: 0.6747 - val_loss: 1.1263 - val_p_acc: 0.5369\n",
      "Epoch 3652/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7508 - p_acc: 0.6747 - val_loss: 1.1251 - val_p_acc: 0.5016\n",
      "Epoch 3653/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6187 - p_acc: 0.7564 - val_loss: 1.1250 - val_p_acc: 0.5192\n",
      "Epoch 3654/5000\n",
      "85/85 [==============================] - 0s 752us/sample - loss: 0.9199 - p_acc: 0.6314 - val_loss: 1.1258 - val_p_acc: 0.5192\n",
      "Epoch 3655/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8871 - p_acc: 0.6418 - val_loss: 1.1267 - val_p_acc: 0.4455\n",
      "Epoch 3656/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7543 - p_acc: 0.7147 - val_loss: 1.1297 - val_p_acc: 0.4455\n",
      "Epoch 3657/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8017 - p_acc: 0.6434 - val_loss: 1.1323 - val_p_acc: 0.4808\n",
      "Epoch 3658/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7510 - p_acc: 0.7043 - val_loss: 1.1353 - val_p_acc: 0.5192\n",
      "Epoch 3659/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7248 - p_acc: 0.7131 - val_loss: 1.1373 - val_p_acc: 0.5192\n",
      "Epoch 3660/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7127 - p_acc: 0.7252 - val_loss: 1.1391 - val_p_acc: 0.5016\n",
      "Epoch 3661/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7966 - p_acc: 0.6330 - val_loss: 1.1388 - val_p_acc: 0.5016\n",
      "Epoch 3662/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8591 - p_acc: 0.7011 - val_loss: 1.1395 - val_p_acc: 0.5192\n",
      "Epoch 3663/5000\n",
      "85/85 [==============================] - 0s 738us/sample - loss: 0.7436 - p_acc: 0.6330 - val_loss: 1.1391 - val_p_acc: 0.4840\n",
      "Epoch 3664/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7560 - p_acc: 0.6034 - val_loss: 1.1392 - val_p_acc: 0.5016\n",
      "Epoch 3665/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7211 - p_acc: 0.6611 - val_loss: 1.1380 - val_p_acc: 0.5016\n",
      "Epoch 3666/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.6976 - p_acc: 0.7163 - val_loss: 1.1364 - val_p_acc: 0.5545\n",
      "Epoch 3667/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8821 - p_acc: 0.6731 - val_loss: 1.1355 - val_p_acc: 0.5192\n",
      "Epoch 3668/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7198 - p_acc: 0.6835 - val_loss: 1.1364 - val_p_acc: 0.5192\n",
      "Epoch 3669/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.9008 - p_acc: 0.6747 - val_loss: 1.1375 - val_p_acc: 0.5369\n",
      "Epoch 3670/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8418 - p_acc: 0.6210 - val_loss: 1.1385 - val_p_acc: 0.4840\n",
      "Epoch 3671/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7887 - p_acc: 0.6643 - val_loss: 1.1391 - val_p_acc: 0.5545\n",
      "Epoch 3672/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7929 - p_acc: 0.6699 - val_loss: 1.1383 - val_p_acc: 0.5192\n",
      "Epoch 3673/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8264 - p_acc: 0.6258 - val_loss: 1.1388 - val_p_acc: 0.5369\n",
      "Epoch 3674/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7817 - p_acc: 0.6835 - val_loss: 1.1376 - val_p_acc: 0.5192\n",
      "Epoch 3675/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8082 - p_acc: 0.6018 - val_loss: 1.1355 - val_p_acc: 0.4840\n",
      "Epoch 3676/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8214 - p_acc: 0.7412 - val_loss: 1.1328 - val_p_acc: 0.4631\n",
      "Epoch 3677/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7965 - p_acc: 0.6627 - val_loss: 1.1313 - val_p_acc: 0.5337\n",
      "Epoch 3678/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7853 - p_acc: 0.6346 - val_loss: 1.1302 - val_p_acc: 0.4808\n",
      "Epoch 3679/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8287 - p_acc: 0.5841 - val_loss: 1.1299 - val_p_acc: 0.5160\n",
      "Epoch 3680/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7115 - p_acc: 0.7131 - val_loss: 1.1308 - val_p_acc: 0.4984\n",
      "Epoch 3681/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7032 - p_acc: 0.7516 - val_loss: 1.1314 - val_p_acc: 0.4984\n",
      "Epoch 3682/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6778 - p_acc: 0.7340 - val_loss: 1.1318 - val_p_acc: 0.4984\n",
      "Epoch 3683/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8646 - p_acc: 0.6803 - val_loss: 1.1330 - val_p_acc: 0.5160\n",
      "Epoch 3684/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8662 - p_acc: 0.6450 - val_loss: 1.1335 - val_p_acc: 0.4631\n",
      "Epoch 3685/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8064 - p_acc: 0.6939 - val_loss: 1.1343 - val_p_acc: 0.4808\n",
      "Epoch 3686/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7565 - p_acc: 0.6675 - val_loss: 1.1377 - val_p_acc: 0.5160\n",
      "Epoch 3687/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7994 - p_acc: 0.6242 - val_loss: 1.1397 - val_p_acc: 0.5369\n",
      "Epoch 3688/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7477 - p_acc: 0.7340 - val_loss: 1.1400 - val_p_acc: 0.5369\n",
      "Epoch 3689/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7005 - p_acc: 0.7548 - val_loss: 1.1428 - val_p_acc: 0.5545\n",
      "Epoch 3690/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.6955 - p_acc: 0.7027 - val_loss: 1.1429 - val_p_acc: 0.5369\n",
      "Epoch 3691/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7810 - p_acc: 0.6154 - val_loss: 1.1440 - val_p_acc: 0.5369\n",
      "Epoch 3692/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7736 - p_acc: 0.5873 - val_loss: 1.1451 - val_p_acc: 0.5192\n",
      "Epoch 3693/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8066 - p_acc: 0.6611 - val_loss: 1.1444 - val_p_acc: 0.5016\n",
      "Epoch 3694/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7556 - p_acc: 0.6939 - val_loss: 1.1431 - val_p_acc: 0.5192\n",
      "Epoch 3695/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8924 - p_acc: 0.6346 - val_loss: 1.1410 - val_p_acc: 0.5016\n",
      "Epoch 3696/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8393 - p_acc: 0.6715 - val_loss: 1.1384 - val_p_acc: 0.4808\n",
      "Epoch 3697/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8945 - p_acc: 0.6482 - val_loss: 1.1352 - val_p_acc: 0.5337\n",
      "Epoch 3698/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7849 - p_acc: 0.6346 - val_loss: 1.1353 - val_p_acc: 0.4808\n",
      "Epoch 3699/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7145 - p_acc: 0.6851 - val_loss: 1.1371 - val_p_acc: 0.4808\n",
      "Epoch 3700/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8202 - p_acc: 0.6554 - val_loss: 1.1389 - val_p_acc: 0.5160\n",
      "Epoch 3701/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7596 - p_acc: 0.6939 - val_loss: 1.1398 - val_p_acc: 0.4840\n",
      "Epoch 3702/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7700 - p_acc: 0.5737 - val_loss: 1.1425 - val_p_acc: 0.5369\n",
      "Epoch 3703/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7029 - p_acc: 0.5913 - val_loss: 1.1445 - val_p_acc: 0.5016\n",
      "Epoch 3704/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7927 - p_acc: 0.6851 - val_loss: 1.1462 - val_p_acc: 0.5192\n",
      "Epoch 3705/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7621 - p_acc: 0.6627 - val_loss: 1.1484 - val_p_acc: 0.5016\n",
      "Epoch 3706/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7580 - p_acc: 0.6330 - val_loss: 1.1490 - val_p_acc: 0.4840\n",
      "Epoch 3707/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8554 - p_acc: 0.7196 - val_loss: 1.1483 - val_p_acc: 0.5192\n",
      "Epoch 3708/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8408 - p_acc: 0.6386 - val_loss: 1.1450 - val_p_acc: 0.5192\n",
      "Epoch 3709/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7893 - p_acc: 0.6955 - val_loss: 1.1443 - val_p_acc: 0.5016\n",
      "Epoch 3710/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7563 - p_acc: 0.6939 - val_loss: 1.1436 - val_p_acc: 0.5016\n",
      "Epoch 3711/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7692 - p_acc: 0.5753 - val_loss: 1.1432 - val_p_acc: 0.4840\n",
      "Epoch 3712/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7948 - p_acc: 0.6522 - val_loss: 1.1415 - val_p_acc: 0.4663\n",
      "Epoch 3713/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8067 - p_acc: 0.5889 - val_loss: 1.1435 - val_p_acc: 0.5016\n",
      "Epoch 3714/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7324 - p_acc: 0.7147 - val_loss: 1.1442 - val_p_acc: 0.5192\n",
      "Epoch 3715/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7692 - p_acc: 0.6362 - val_loss: 1.1460 - val_p_acc: 0.5192\n",
      "Epoch 3716/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8243 - p_acc: 0.6522 - val_loss: 1.1506 - val_p_acc: 0.5192\n",
      "Epoch 3717/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7744 - p_acc: 0.6659 - val_loss: 1.1535 - val_p_acc: 0.4663\n",
      "Epoch 3718/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7957 - p_acc: 0.6835 - val_loss: 1.1544 - val_p_acc: 0.5369\n",
      "Epoch 3719/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7437 - p_acc: 0.6851 - val_loss: 1.1571 - val_p_acc: 0.5016\n",
      "Epoch 3720/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7789 - p_acc: 0.6867 - val_loss: 1.1605 - val_p_acc: 0.5016\n",
      "Epoch 3721/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.9584 - p_acc: 0.5897 - val_loss: 1.1613 - val_p_acc: 0.5369\n",
      "Epoch 3722/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8729 - p_acc: 0.6522 - val_loss: 1.1638 - val_p_acc: 0.5192\n",
      "Epoch 3723/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7261 - p_acc: 0.6907 - val_loss: 1.1634 - val_p_acc: 0.4840\n",
      "Epoch 3724/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8616 - p_acc: 0.5601 - val_loss: 1.1643 - val_p_acc: 0.5192\n",
      "Epoch 3725/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7139 - p_acc: 0.7444 - val_loss: 1.1626 - val_p_acc: 0.5016\n",
      "Epoch 3726/5000\n",
      "85/85 [==============================] - 0s 711us/sample - loss: 0.7633 - p_acc: 0.6747 - val_loss: 1.1612 - val_p_acc: 0.4663\n",
      "Epoch 3727/5000\n",
      "85/85 [==============================] - 0s 710us/sample - loss: 0.7568 - p_acc: 0.7131 - val_loss: 1.1590 - val_p_acc: 0.5016\n",
      "Epoch 3728/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6813 - p_acc: 0.7772 - val_loss: 1.1605 - val_p_acc: 0.5369\n",
      "Epoch 3729/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7960 - p_acc: 0.6242 - val_loss: 1.1606 - val_p_acc: 0.5369\n",
      "Epoch 3730/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8104 - p_acc: 0.6554 - val_loss: 1.1612 - val_p_acc: 0.5016\n",
      "Epoch 3731/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7780 - p_acc: 0.6210 - val_loss: 1.1609 - val_p_acc: 0.4840\n",
      "Epoch 3732/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7508 - p_acc: 0.5929 - val_loss: 1.1627 - val_p_acc: 0.5016\n",
      "Epoch 3733/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9136 - p_acc: 0.5929 - val_loss: 1.1634 - val_p_acc: 0.5192\n",
      "Epoch 3734/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7334 - p_acc: 0.7147 - val_loss: 1.1635 - val_p_acc: 0.5016\n",
      "Epoch 3735/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8234 - p_acc: 0.6835 - val_loss: 1.1633 - val_p_acc: 0.5369\n",
      "Epoch 3736/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7331 - p_acc: 0.6330 - val_loss: 1.1644 - val_p_acc: 0.5545\n",
      "Epoch 3737/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8275 - p_acc: 0.7027 - val_loss: 1.1636 - val_p_acc: 0.4840\n",
      "Epoch 3738/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7816 - p_acc: 0.6330 - val_loss: 1.1641 - val_p_acc: 0.4840\n",
      "Epoch 3739/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8710 - p_acc: 0.6851 - val_loss: 1.1654 - val_p_acc: 0.5192\n",
      "Epoch 3740/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8980 - p_acc: 0.6418 - val_loss: 1.1647 - val_p_acc: 0.4663\n",
      "Epoch 3741/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8034 - p_acc: 0.6522 - val_loss: 1.1667 - val_p_acc: 0.4663\n",
      "Epoch 3742/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8052 - p_acc: 0.6050 - val_loss: 1.1688 - val_p_acc: 0.4840\n",
      "Epoch 3743/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8040 - p_acc: 0.6138 - val_loss: 1.1704 - val_p_acc: 0.4663\n",
      "Epoch 3744/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8141 - p_acc: 0.6242 - val_loss: 1.1715 - val_p_acc: 0.4840\n",
      "Epoch 3745/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7051 - p_acc: 0.6747 - val_loss: 1.1718 - val_p_acc: 0.5369\n",
      "Epoch 3746/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7869 - p_acc: 0.6466 - val_loss: 1.1714 - val_p_acc: 0.5016\n",
      "Epoch 3747/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8355 - p_acc: 0.5809 - val_loss: 1.1728 - val_p_acc: 0.5192\n",
      "Epoch 3748/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8200 - p_acc: 0.6298 - val_loss: 1.1735 - val_p_acc: 0.4840\n",
      "Epoch 3749/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8478 - p_acc: 0.6154 - val_loss: 1.1737 - val_p_acc: 0.5016\n",
      "Epoch 3750/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7686 - p_acc: 0.6747 - val_loss: 1.1712 - val_p_acc: 0.5192\n",
      "Epoch 3751/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8208 - p_acc: 0.5962 - val_loss: 1.1699 - val_p_acc: 0.5192\n",
      "Epoch 3752/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7589 - p_acc: 0.6939 - val_loss: 1.1648 - val_p_acc: 0.4840\n",
      "Epoch 3753/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8451 - p_acc: 0.6851 - val_loss: 1.1621 - val_p_acc: 0.4840\n",
      "Epoch 3754/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7695 - p_acc: 0.6274 - val_loss: 1.1620 - val_p_acc: 0.5545\n",
      "Epoch 3755/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7784 - p_acc: 0.7027 - val_loss: 1.1620 - val_p_acc: 0.4840\n",
      "Epoch 3756/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7749 - p_acc: 0.6731 - val_loss: 1.1611 - val_p_acc: 0.5369\n",
      "Epoch 3757/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8710 - p_acc: 0.6314 - val_loss: 1.1624 - val_p_acc: 0.4840\n",
      "Epoch 3758/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8463 - p_acc: 0.7340 - val_loss: 1.1610 - val_p_acc: 0.5016\n",
      "Epoch 3759/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7950 - p_acc: 0.6907 - val_loss: 1.1628 - val_p_acc: 0.5192\n",
      "Epoch 3760/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7910 - p_acc: 0.6314 - val_loss: 1.1626 - val_p_acc: 0.5192\n",
      "Epoch 3761/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7666 - p_acc: 0.7324 - val_loss: 1.1599 - val_p_acc: 0.5369\n",
      "Epoch 3762/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7747 - p_acc: 0.7027 - val_loss: 1.1586 - val_p_acc: 0.5721\n",
      "Epoch 3763/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8148 - p_acc: 0.5825 - val_loss: 1.1571 - val_p_acc: 0.5192\n",
      "Epoch 3764/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8242 - p_acc: 0.5825 - val_loss: 1.1554 - val_p_acc: 0.5016\n",
      "Epoch 3765/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7838 - p_acc: 0.6522 - val_loss: 1.1552 - val_p_acc: 0.4487\n",
      "Epoch 3766/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8265 - p_acc: 0.6154 - val_loss: 1.1540 - val_p_acc: 0.5016\n",
      "Epoch 3767/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7539 - p_acc: 0.7011 - val_loss: 1.1536 - val_p_acc: 0.5369\n",
      "Epoch 3768/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7227 - p_acc: 0.7532 - val_loss: 1.1532 - val_p_acc: 0.5192\n",
      "Epoch 3769/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8030 - p_acc: 0.6538 - val_loss: 1.1515 - val_p_acc: 0.5016\n",
      "Epoch 3770/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6896 - p_acc: 0.7444 - val_loss: 1.1519 - val_p_acc: 0.4840\n",
      "Epoch 3771/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7766 - p_acc: 0.7236 - val_loss: 1.1534 - val_p_acc: 0.5369\n",
      "Epoch 3772/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7597 - p_acc: 0.7532 - val_loss: 1.1525 - val_p_acc: 0.5192\n",
      "Epoch 3773/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7733 - p_acc: 0.791 - 0s 727us/sample - loss: 0.8640 - p_acc: 0.6659 - val_loss: 1.1532 - val_p_acc: 0.5192\n",
      "Epoch 3774/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7362 - p_acc: 0.6779 - val_loss: 1.1508 - val_p_acc: 0.5016\n",
      "Epoch 3775/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6959 - p_acc: 0.7444 - val_loss: 1.1493 - val_p_acc: 0.5192\n",
      "Epoch 3776/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7611 - p_acc: 0.6835 - val_loss: 1.1489 - val_p_acc: 0.5192\n",
      "Epoch 3777/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7858 - p_acc: 0.6154 - val_loss: 1.1490 - val_p_acc: 0.4487\n",
      "Epoch 3778/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7675 - p_acc: 0.6370 - val_loss: 1.1478 - val_p_acc: 0.5016\n",
      "Epoch 3779/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.7653 - p_acc: 0.7147 - val_loss: 1.1478 - val_p_acc: 0.5016\n",
      "Epoch 3780/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7345 - p_acc: 0.7179 - val_loss: 1.1466 - val_p_acc: 0.5369\n",
      "Epoch 3781/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7597 - p_acc: 0.6402 - val_loss: 1.1446 - val_p_acc: 0.4840\n",
      "Epoch 3782/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7547 - p_acc: 0.6851 - val_loss: 1.1441 - val_p_acc: 0.5192\n",
      "Epoch 3783/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7925 - p_acc: 0.6715 - val_loss: 1.1423 - val_p_acc: 0.5192\n",
      "Epoch 3784/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8547 - p_acc: 0.6418 - val_loss: 1.1438 - val_p_acc: 0.5192\n",
      "Epoch 3785/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7513 - p_acc: 0.6819 - val_loss: 1.1450 - val_p_acc: 0.5192\n",
      "Epoch 3786/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8053 - p_acc: 0.5825 - val_loss: 1.1452 - val_p_acc: 0.5369\n",
      "Epoch 3787/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7333 - p_acc: 0.6939 - val_loss: 1.1445 - val_p_acc: 0.5192\n",
      "Epoch 3788/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7540 - p_acc: 0.6538 - val_loss: 1.1445 - val_p_acc: 0.5192\n",
      "Epoch 3789/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7635 - p_acc: 0.6538 - val_loss: 1.1439 - val_p_acc: 0.5016\n",
      "Epoch 3790/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7887 - p_acc: 0.5497 - val_loss: 1.1428 - val_p_acc: 0.5369\n",
      "Epoch 3791/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7541 - p_acc: 0.6466 - val_loss: 1.1433 - val_p_acc: 0.5192\n",
      "Epoch 3792/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7388 - p_acc: 0.6675 - val_loss: 1.1445 - val_p_acc: 0.5369\n",
      "Epoch 3793/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8346 - p_acc: 0.6298 - val_loss: 1.1466 - val_p_acc: 0.5016\n",
      "Epoch 3794/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8231 - p_acc: 0.6330 - val_loss: 1.1476 - val_p_acc: 0.5016\n",
      "Epoch 3795/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7209 - p_acc: 0.6571 - val_loss: 1.1482 - val_p_acc: 0.5192\n",
      "Epoch 3796/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.9107 - p_acc: 0.6346 - val_loss: 1.1473 - val_p_acc: 0.5016\n",
      "Epoch 3797/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7746 - p_acc: 0.6867 - val_loss: 1.1472 - val_p_acc: 0.4840\n",
      "Epoch 3798/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8295 - p_acc: 0.6715 - val_loss: 1.1466 - val_p_acc: 0.5369\n",
      "Epoch 3799/5000\n",
      "85/85 [==============================] - 0s 711us/sample - loss: 0.8203 - p_acc: 0.6907 - val_loss: 1.1477 - val_p_acc: 0.5192\n",
      "Epoch 3800/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8231 - p_acc: 0.7027 - val_loss: 1.1496 - val_p_acc: 0.5369\n",
      "Epoch 3801/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7820 - p_acc: 0.6571 - val_loss: 1.1508 - val_p_acc: 0.5721\n",
      "Epoch 3802/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7087 - p_acc: 0.7099 - val_loss: 1.1512 - val_p_acc: 0.5192\n",
      "Epoch 3803/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6915 - p_acc: 0.7236 - val_loss: 1.1530 - val_p_acc: 0.4840\n",
      "Epoch 3804/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6695 - p_acc: 0.6923 - val_loss: 1.1536 - val_p_acc: 0.5369\n",
      "Epoch 3805/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7283 - p_acc: 0.7252 - val_loss: 1.1534 - val_p_acc: 0.4487\n",
      "Epoch 3806/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8170 - p_acc: 0.6643 - val_loss: 1.1508 - val_p_acc: 0.5369\n",
      "Epoch 3807/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7418 - p_acc: 0.6747 - val_loss: 1.1489 - val_p_acc: 0.4487\n",
      "Epoch 3808/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7698 - p_acc: 0.6571 - val_loss: 1.1473 - val_p_acc: 0.5192\n",
      "Epoch 3809/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7898 - p_acc: 0.7115 - val_loss: 1.1459 - val_p_acc: 0.5016\n",
      "Epoch 3810/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8267 - p_acc: 0.6138 - val_loss: 1.1460 - val_p_acc: 0.5369\n",
      "Epoch 3811/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7443 - p_acc: 0.6154 - val_loss: 1.1447 - val_p_acc: 0.5016\n",
      "Epoch 3812/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8310 - p_acc: 0.6298 - val_loss: 1.1449 - val_p_acc: 0.4663\n",
      "Epoch 3813/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7370 - p_acc: 0.7131 - val_loss: 1.1452 - val_p_acc: 0.5016\n",
      "Epoch 3814/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7682 - p_acc: 0.6659 - val_loss: 1.1453 - val_p_acc: 0.5016\n",
      "Epoch 3815/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7925 - p_acc: 0.6314 - val_loss: 1.1470 - val_p_acc: 0.5192\n",
      "Epoch 3816/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7251 - p_acc: 0.7845 - val_loss: 1.1471 - val_p_acc: 0.5016\n",
      "Epoch 3817/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7986 - p_acc: 0.6747 - val_loss: 1.1476 - val_p_acc: 0.4840\n",
      "Epoch 3818/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8455 - p_acc: 0.6450 - val_loss: 1.1471 - val_p_acc: 0.5016\n",
      "Epoch 3819/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7149 - p_acc: 0.6819 - val_loss: 1.1469 - val_p_acc: 0.5545\n",
      "Epoch 3820/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8983 - p_acc: 0.6242 - val_loss: 1.1475 - val_p_acc: 0.5545\n",
      "Epoch 3821/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7834 - p_acc: 0.6226 - val_loss: 1.1470 - val_p_acc: 0.5016\n",
      "Epoch 3822/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7224 - p_acc: 0.7163 - val_loss: 1.1482 - val_p_acc: 0.5192\n",
      "Epoch 3823/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7408 - p_acc: 0.6835 - val_loss: 1.1478 - val_p_acc: 0.5369\n",
      "Epoch 3824/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7589 - p_acc: 0.6226 - val_loss: 1.1465 - val_p_acc: 0.4840\n",
      "Epoch 3825/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8503 - p_acc: 0.5721 - val_loss: 1.1453 - val_p_acc: 0.5545\n",
      "Epoch 3826/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8149 - p_acc: 0.6835 - val_loss: 1.1433 - val_p_acc: 0.5545\n",
      "Epoch 3827/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7066 - p_acc: 0.6955 - val_loss: 1.1427 - val_p_acc: 0.5545\n",
      "Epoch 3828/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7600 - p_acc: 0.6627 - val_loss: 1.1402 - val_p_acc: 0.5753\n",
      "Epoch 3829/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7013 - p_acc: 0.6867 - val_loss: 1.1390 - val_p_acc: 0.5401\n",
      "Epoch 3830/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6827 - p_acc: 0.7532 - val_loss: 1.1377 - val_p_acc: 0.5192\n",
      "Epoch 3831/5000\n",
      "85/85 [==============================] - 0s 735us/sample - loss: 0.8286 - p_acc: 0.6330 - val_loss: 1.1354 - val_p_acc: 0.5369\n",
      "Epoch 3832/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7742 - p_acc: 0.6819 - val_loss: 1.1358 - val_p_acc: 0.5016\n",
      "Epoch 3833/5000\n",
      "85/85 [==============================] - 0s 754us/sample - loss: 0.7337 - p_acc: 0.6418 - val_loss: 1.1351 - val_p_acc: 0.5016\n",
      "Epoch 3834/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7552 - p_acc: 0.6747 - val_loss: 1.1334 - val_p_acc: 0.4663\n",
      "Epoch 3835/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7969 - p_acc: 0.6258 - val_loss: 1.1339 - val_p_acc: 0.5369\n",
      "Epoch 3836/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8639 - p_acc: 0.5946 - val_loss: 1.1332 - val_p_acc: 0.4840\n",
      "Epoch 3837/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8251 - p_acc: 0.6314 - val_loss: 1.1339 - val_p_acc: 0.5016\n",
      "Epoch 3838/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7176 - p_acc: 0.6819 - val_loss: 1.1326 - val_p_acc: 0.5016\n",
      "Epoch 3839/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7723 - p_acc: 0.5513 - val_loss: 1.1343 - val_p_acc: 0.5192\n",
      "Epoch 3840/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8214 - p_acc: 0.6242 - val_loss: 1.1359 - val_p_acc: 0.4840\n",
      "Epoch 3841/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8269 - p_acc: 0.7099 - val_loss: 1.1389 - val_p_acc: 0.5016\n",
      "Epoch 3842/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7874 - p_acc: 0.6659 - val_loss: 1.1418 - val_p_acc: 0.4984\n",
      "Epoch 3843/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8491 - p_acc: 0.6595 - val_loss: 1.1420 - val_p_acc: 0.4631\n",
      "Epoch 3844/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6562 - p_acc: 0.7476 - val_loss: 1.1401 - val_p_acc: 0.5160\n",
      "Epoch 3845/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8331 - p_acc: 0.6571 - val_loss: 1.1409 - val_p_acc: 0.4840\n",
      "Epoch 3846/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8477 - p_acc: 0.6715 - val_loss: 1.1404 - val_p_acc: 0.4631\n",
      "Epoch 3847/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8093 - p_acc: 0.6522 - val_loss: 1.1421 - val_p_acc: 0.5016\n",
      "Epoch 3848/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6427 - p_acc: 0.7043 - val_loss: 1.1444 - val_p_acc: 0.5369\n",
      "Epoch 3849/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8174 - p_acc: 0.6907 - val_loss: 1.1461 - val_p_acc: 0.4840\n",
      "Epoch 3850/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7863 - p_acc: 0.6226 - val_loss: 1.1469 - val_p_acc: 0.5192\n",
      "Epoch 3851/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8095 - p_acc: 0.6330 - val_loss: 1.1477 - val_p_acc: 0.4663\n",
      "Epoch 3852/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8283 - p_acc: 0.5929 - val_loss: 1.1486 - val_p_acc: 0.5016\n",
      "Epoch 3853/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7522 - p_acc: 0.6763 - val_loss: 1.1507 - val_p_acc: 0.5016\n",
      "Epoch 3854/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7316 - p_acc: 0.6747 - val_loss: 1.1498 - val_p_acc: 0.5369\n",
      "Epoch 3855/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6868 - p_acc: 0.7043 - val_loss: 1.1487 - val_p_acc: 0.5369\n",
      "Epoch 3856/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7038 - p_acc: 0.7516 - val_loss: 1.1481 - val_p_acc: 0.5016\n",
      "Epoch 3857/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7512 - p_acc: 0.6835 - val_loss: 1.1473 - val_p_acc: 0.4840\n",
      "Epoch 3858/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7646 - p_acc: 0.7740 - val_loss: 1.1448 - val_p_acc: 0.4808\n",
      "Epoch 3859/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7629 - p_acc: 0.6506 - val_loss: 1.1442 - val_p_acc: 0.4631\n",
      "Epoch 3860/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7868 - p_acc: 0.6731 - val_loss: 1.1442 - val_p_acc: 0.5160\n",
      "Epoch 3861/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7131 - p_acc: 0.7147 - val_loss: 1.1436 - val_p_acc: 0.4984\n",
      "Epoch 3862/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7731 - p_acc: 0.6747 - val_loss: 1.1426 - val_p_acc: 0.4984\n",
      "Epoch 3863/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8223 - p_acc: 0.7131 - val_loss: 1.1429 - val_p_acc: 0.4984\n",
      "Epoch 3864/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7520 - p_acc: 0.6274 - val_loss: 1.1421 - val_p_acc: 0.4808\n",
      "Epoch 3865/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8146 - p_acc: 0.6867 - val_loss: 1.1437 - val_p_acc: 0.5160\n",
      "Epoch 3866/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8613 - p_acc: 0.6122 - val_loss: 1.1462 - val_p_acc: 0.4808\n",
      "Epoch 3867/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8918 - p_acc: 0.6074 - val_loss: 1.1509 - val_p_acc: 0.5369\n",
      "Epoch 3868/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8811 - p_acc: 0.6346 - val_loss: 1.1536 - val_p_acc: 0.5192\n",
      "Epoch 3869/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7413 - p_acc: 0.6466 - val_loss: 1.1555 - val_p_acc: 0.4840\n",
      "Epoch 3870/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8603 - p_acc: 0.6330 - val_loss: 1.1584 - val_p_acc: 0.4840\n",
      "Epoch 3871/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7547 - p_acc: 0.6122 - val_loss: 1.1580 - val_p_acc: 0.5192\n",
      "Epoch 3872/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8620 - p_acc: 0.5497 - val_loss: 1.1598 - val_p_acc: 0.5369\n",
      "Epoch 3873/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6872 - p_acc: 0.6731 - val_loss: 1.1617 - val_p_acc: 0.4840\n",
      "Epoch 3874/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7714 - p_acc: 0.7220 - val_loss: 1.1612 - val_p_acc: 0.5369\n",
      "Epoch 3875/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8318 - p_acc: 0.6643 - val_loss: 1.1609 - val_p_acc: 0.5721\n",
      "Epoch 3876/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7994 - p_acc: 0.6226 - val_loss: 1.1606 - val_p_acc: 0.5192\n",
      "Epoch 3877/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7848 - p_acc: 0.6122 - val_loss: 1.1599 - val_p_acc: 0.4840\n",
      "Epoch 3878/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7042 - p_acc: 0.7652 - val_loss: 1.1573 - val_p_acc: 0.5192\n",
      "Epoch 3879/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7693 - p_acc: 0.6122 - val_loss: 1.1550 - val_p_acc: 0.5369\n",
      "Epoch 3880/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7889 - p_acc: 0.6554 - val_loss: 1.1531 - val_p_acc: 0.4840\n",
      "Epoch 3881/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7186 - p_acc: 0.7027 - val_loss: 1.1537 - val_p_acc: 0.5016\n",
      "Epoch 3882/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7456 - p_acc: 0.6835 - val_loss: 1.1567 - val_p_acc: 0.5016\n",
      "Epoch 3883/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7647 - p_acc: 0.7059 - val_loss: 1.1566 - val_p_acc: 0.5192\n",
      "Epoch 3884/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7261 - p_acc: 0.6867 - val_loss: 1.1548 - val_p_acc: 0.5192\n",
      "Epoch 3885/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7242 - p_acc: 0.6923 - val_loss: 1.1532 - val_p_acc: 0.4840\n",
      "Epoch 3886/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8712 - p_acc: 0.5681 - val_loss: 1.1521 - val_p_acc: 0.5369\n",
      "Epoch 3887/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7969 - p_acc: 0.6923 - val_loss: 1.1515 - val_p_acc: 0.5016\n",
      "Epoch 3888/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7845 - p_acc: 0.6851 - val_loss: 1.1513 - val_p_acc: 0.5192\n",
      "Epoch 3889/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8501 - p_acc: 0.6346 - val_loss: 1.1522 - val_p_acc: 0.5192\n",
      "Epoch 3890/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7967 - p_acc: 0.6731 - val_loss: 1.1525 - val_p_acc: 0.5369\n",
      "Epoch 3891/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7953 - p_acc: 0.6434 - val_loss: 1.1528 - val_p_acc: 0.5016\n",
      "Epoch 3892/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7341 - p_acc: 0.7163 - val_loss: 1.1516 - val_p_acc: 0.5016\n",
      "Epoch 3893/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8229 - p_acc: 0.5825 - val_loss: 1.1519 - val_p_acc: 0.5016\n",
      "Epoch 3894/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7804 - p_acc: 0.6538 - val_loss: 1.1531 - val_p_acc: 0.5016\n",
      "Epoch 3895/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8019 - p_acc: 0.6939 - val_loss: 1.1529 - val_p_acc: 0.5016\n",
      "Epoch 3896/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8281 - p_acc: 0.6939 - val_loss: 1.1519 - val_p_acc: 0.4840\n",
      "Epoch 3897/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7613 - p_acc: 0.6258 - val_loss: 1.1500 - val_p_acc: 0.5016\n",
      "Epoch 3898/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6829 - p_acc: 0.7372 - val_loss: 1.1491 - val_p_acc: 0.5016\n",
      "Epoch 3899/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8866 - p_acc: 0.6715 - val_loss: 1.1479 - val_p_acc: 0.4808\n",
      "Epoch 3900/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8421 - p_acc: 0.6138 - val_loss: 1.1488 - val_p_acc: 0.4808\n",
      "Epoch 3901/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7299 - p_acc: 0.6819 - val_loss: 1.1487 - val_p_acc: 0.4455\n",
      "Epoch 3902/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8044 - p_acc: 0.6819 - val_loss: 1.1492 - val_p_acc: 0.4984\n",
      "Epoch 3903/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7362 - p_acc: 0.7324 - val_loss: 1.1480 - val_p_acc: 0.4631\n",
      "Epoch 3904/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7888 - p_acc: 0.6627 - val_loss: 1.1470 - val_p_acc: 0.5160\n",
      "Epoch 3905/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7212 - p_acc: 0.6346 - val_loss: 1.1495 - val_p_acc: 0.4984\n",
      "Epoch 3906/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7438 - p_acc: 0.6851 - val_loss: 1.1527 - val_p_acc: 0.5192\n",
      "Epoch 3907/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7214 - p_acc: 0.6138 - val_loss: 1.1540 - val_p_acc: 0.5192\n",
      "Epoch 3908/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8207 - p_acc: 0.6386 - val_loss: 1.1558 - val_p_acc: 0.5016\n",
      "Epoch 3909/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8209 - p_acc: 0.5913 - val_loss: 1.1573 - val_p_acc: 0.5016\n",
      "Epoch 3910/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8334 - p_acc: 0.6450 - val_loss: 1.1561 - val_p_acc: 0.5192\n",
      "Epoch 3911/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7180 - p_acc: 0.7043 - val_loss: 1.1539 - val_p_acc: 0.4840\n",
      "Epoch 3912/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8065 - p_acc: 0.7324 - val_loss: 1.1518 - val_p_acc: 0.5401\n",
      "Epoch 3913/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8132 - p_acc: 0.6923 - val_loss: 1.1510 - val_p_acc: 0.5192\n",
      "Epoch 3914/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.6874 - p_acc: 0.7548 - val_loss: 1.1517 - val_p_acc: 0.5016\n",
      "Epoch 3915/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7207 - p_acc: 0.7236 - val_loss: 1.1521 - val_p_acc: 0.4840\n",
      "Epoch 3916/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7100 - p_acc: 0.6747 - val_loss: 1.1522 - val_p_acc: 0.5369\n",
      "Epoch 3917/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7648 - p_acc: 0.6835 - val_loss: 1.1502 - val_p_acc: 0.5016\n",
      "Epoch 3918/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7400 - p_acc: 0.7252 - val_loss: 1.1486 - val_p_acc: 0.5016\n",
      "Epoch 3919/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7510 - p_acc: 0.6955 - val_loss: 1.1472 - val_p_acc: 0.5016\n",
      "Epoch 3920/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7234 - p_acc: 0.7340 - val_loss: 1.1466 - val_p_acc: 0.5192\n",
      "Epoch 3921/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8098 - p_acc: 0.6538 - val_loss: 1.1450 - val_p_acc: 0.5016\n",
      "Epoch 3922/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8348 - p_acc: 0.6050 - val_loss: 1.1440 - val_p_acc: 0.5545\n",
      "Epoch 3923/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7621 - p_acc: 0.7652 - val_loss: 1.1437 - val_p_acc: 0.5192\n",
      "Epoch 3924/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7724 - p_acc: 0.6611 - val_loss: 1.1447 - val_p_acc: 0.5016\n",
      "Epoch 3925/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8371 - p_acc: 0.6659 - val_loss: 1.1469 - val_p_acc: 0.5369\n",
      "Epoch 3926/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8097 - p_acc: 0.6867 - val_loss: 1.1518 - val_p_acc: 0.5192\n",
      "Epoch 3927/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8237 - p_acc: 0.6627 - val_loss: 1.1558 - val_p_acc: 0.4663\n",
      "Epoch 3928/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7637 - p_acc: 0.6434 - val_loss: 1.1535 - val_p_acc: 0.5545\n",
      "Epoch 3929/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6756 - p_acc: 0.6659 - val_loss: 1.1529 - val_p_acc: 0.5192\n",
      "Epoch 3930/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8014 - p_acc: 0.6522 - val_loss: 1.1513 - val_p_acc: 0.5369\n",
      "Epoch 3931/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8127 - p_acc: 0.6362 - val_loss: 1.1498 - val_p_acc: 0.5369\n",
      "Epoch 3932/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7510 - p_acc: 0.6314 - val_loss: 1.1493 - val_p_acc: 0.4631\n",
      "Epoch 3933/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7719 - p_acc: 0.6899 - val_loss: 1.1468 - val_p_acc: 0.4455\n",
      "Epoch 3934/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8519 - p_acc: 0.5264 - val_loss: 1.1464 - val_p_acc: 0.4984\n",
      "Epoch 3935/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7765 - p_acc: 0.6675 - val_loss: 1.1478 - val_p_acc: 0.5192\n",
      "Epoch 3936/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6974 - p_acc: 0.7428 - val_loss: 1.1476 - val_p_acc: 0.4840\n",
      "Epoch 3937/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7179 - p_acc: 0.7532 - val_loss: 1.1457 - val_p_acc: 0.4663\n",
      "Epoch 3938/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7796 - p_acc: 0.6659 - val_loss: 1.1446 - val_p_acc: 0.5513\n",
      "Epoch 3939/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8210 - p_acc: 0.7011 - val_loss: 1.1458 - val_p_acc: 0.4455\n",
      "Epoch 3940/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7511 - p_acc: 0.7516 - val_loss: 1.1443 - val_p_acc: 0.5192\n",
      "Epoch 3941/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7981 - p_acc: 0.6226 - val_loss: 1.1419 - val_p_acc: 0.5016\n",
      "Epoch 3942/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7042 - p_acc: 0.7027 - val_loss: 1.1396 - val_p_acc: 0.5192\n",
      "Epoch 3943/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7066 - p_acc: 0.7564 - val_loss: 1.1366 - val_p_acc: 0.5016\n",
      "Epoch 3944/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8174 - p_acc: 0.6138 - val_loss: 1.1376 - val_p_acc: 0.5369\n",
      "Epoch 3945/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8507 - p_acc: 0.6138 - val_loss: 1.1383 - val_p_acc: 0.5369\n",
      "Epoch 3946/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7146 - p_acc: 0.6867 - val_loss: 1.1387 - val_p_acc: 0.5016\n",
      "Epoch 3947/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7341 - p_acc: 0.7308 - val_loss: 1.1410 - val_p_acc: 0.5192\n",
      "Epoch 3948/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7709 - p_acc: 0.6571 - val_loss: 1.1419 - val_p_acc: 0.5192\n",
      "Epoch 3949/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7266 - p_acc: 0.6747 - val_loss: 1.1439 - val_p_acc: 0.5016\n",
      "Epoch 3950/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8136 - p_acc: 0.6154 - val_loss: 1.1452 - val_p_acc: 0.5016\n",
      "Epoch 3951/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8293 - p_acc: 0.6186 - val_loss: 1.1469 - val_p_acc: 0.5192\n",
      "Epoch 3952/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7843 - p_acc: 0.6923 - val_loss: 1.1479 - val_p_acc: 0.5016\n",
      "Epoch 3953/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7262 - p_acc: 0.6170 - val_loss: 1.1463 - val_p_acc: 0.5369\n",
      "Epoch 3954/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8077 - p_acc: 0.6434 - val_loss: 1.1467 - val_p_acc: 0.5192\n",
      "Epoch 3955/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7676 - p_acc: 0.7147 - val_loss: 1.1497 - val_p_acc: 0.4840\n",
      "Epoch 3956/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7292 - p_acc: 0.7340 - val_loss: 1.1519 - val_p_acc: 0.5016\n",
      "Epoch 3957/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8588 - p_acc: 0.6595 - val_loss: 1.1484 - val_p_acc: 0.5369\n",
      "Epoch 3958/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7035 - p_acc: 0.6939 - val_loss: 1.1477 - val_p_acc: 0.4663\n",
      "Epoch 3959/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.6817 - p_acc: 0.6939 - val_loss: 1.1484 - val_p_acc: 0.5192\n",
      "Epoch 3960/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7300 - p_acc: 0.7115 - val_loss: 1.1493 - val_p_acc: 0.5192\n",
      "Epoch 3961/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7288 - p_acc: 0.6851 - val_loss: 1.1486 - val_p_acc: 0.5192\n",
      "Epoch 3962/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7034 - p_acc: 0.6779 - val_loss: 1.1477 - val_p_acc: 0.4840\n",
      "Epoch 3963/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7423 - p_acc: 0.7091 - val_loss: 1.1471 - val_p_acc: 0.5016\n",
      "Epoch 3964/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7934 - p_acc: 0.6330 - val_loss: 1.1476 - val_p_acc: 0.5016\n",
      "Epoch 3965/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7744 - p_acc: 0.7131 - val_loss: 1.1502 - val_p_acc: 0.5192\n",
      "Epoch 3966/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7742 - p_acc: 0.6571 - val_loss: 1.1508 - val_p_acc: 0.5192\n",
      "Epoch 3967/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7617 - p_acc: 0.6538 - val_loss: 1.1518 - val_p_acc: 0.4840\n",
      "Epoch 3968/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7663 - p_acc: 0.6891 - val_loss: 1.1520 - val_p_acc: 0.5545\n",
      "Epoch 3969/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8372 - p_acc: 0.6538 - val_loss: 1.1526 - val_p_acc: 0.5192\n",
      "Epoch 3970/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7150 - p_acc: 0.7236 - val_loss: 1.1535 - val_p_acc: 0.5369\n",
      "Epoch 3971/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7723 - p_acc: 0.5825 - val_loss: 1.1533 - val_p_acc: 0.5192\n",
      "Epoch 3972/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8200 - p_acc: 0.5529 - val_loss: 1.1515 - val_p_acc: 0.4840\n",
      "Epoch 3973/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8311 - p_acc: 0.5232 - val_loss: 1.1523 - val_p_acc: 0.5192\n",
      "Epoch 3974/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.6991 - p_acc: 0.7652 - val_loss: 1.1517 - val_p_acc: 0.5369\n",
      "Epoch 3975/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8985 - p_acc: 0.6002 - val_loss: 1.1533 - val_p_acc: 0.5192\n",
      "Epoch 3976/5000\n",
      "85/85 [==============================] - 0s 736us/sample - loss: 0.7215 - p_acc: 0.6627 - val_loss: 1.1573 - val_p_acc: 0.5016\n",
      "Epoch 3977/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7783 - p_acc: 0.6450 - val_loss: 1.1575 - val_p_acc: 0.5545\n",
      "Epoch 3978/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7083 - p_acc: 0.6835 - val_loss: 1.1606 - val_p_acc: 0.5369\n",
      "Epoch 3979/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8152 - p_acc: 0.6018 - val_loss: 1.1608 - val_p_acc: 0.5192\n",
      "Epoch 3980/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8452 - p_acc: 0.5721 - val_loss: 1.1632 - val_p_acc: 0.5192\n",
      "Epoch 3981/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7562 - p_acc: 0.6995 - val_loss: 1.1638 - val_p_acc: 0.5016\n",
      "Epoch 3982/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6965 - p_acc: 0.7220 - val_loss: 1.1629 - val_p_acc: 0.5192\n",
      "Epoch 3983/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8320 - p_acc: 0.6819 - val_loss: 1.1643 - val_p_acc: 0.5369\n",
      "Epoch 3984/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8627 - p_acc: 0.6434 - val_loss: 1.1618 - val_p_acc: 0.5016\n",
      "Epoch 3985/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8163 - p_acc: 0.6891 - val_loss: 1.1621 - val_p_acc: 0.5016\n",
      "Epoch 3986/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8314 - p_acc: 0.6691 - val_loss: 1.1626 - val_p_acc: 0.5192\n",
      "Epoch 3987/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7600 - p_acc: 0.6186 - val_loss: 1.1648 - val_p_acc: 0.4840\n",
      "Epoch 3988/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7994 - p_acc: 0.6835 - val_loss: 1.1653 - val_p_acc: 0.5369\n",
      "Epoch 3989/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7794 - p_acc: 0.6923 - val_loss: 1.1656 - val_p_acc: 0.5192\n",
      "Epoch 3990/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7430 - p_acc: 0.7059 - val_loss: 1.1660 - val_p_acc: 0.4663\n",
      "Epoch 3991/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7673 - p_acc: 0.6923 - val_loss: 1.1643 - val_p_acc: 0.5016\n",
      "Epoch 3992/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7393 - p_acc: 0.7500 - val_loss: 1.1654 - val_p_acc: 0.5369\n",
      "Epoch 3993/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7614 - p_acc: 0.6434 - val_loss: 1.1642 - val_p_acc: 0.4663\n",
      "Epoch 3994/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8049 - p_acc: 0.6138 - val_loss: 1.1662 - val_p_acc: 0.5545\n",
      "Epoch 3995/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7575 - p_acc: 0.6450 - val_loss: 1.1661 - val_p_acc: 0.5545\n",
      "Epoch 3996/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8168 - p_acc: 0.6418 - val_loss: 1.1632 - val_p_acc: 0.5369\n",
      "Epoch 3997/5000\n",
      "85/85 [==============================] - 0s 713us/sample - loss: 0.7350 - p_acc: 0.6923 - val_loss: 1.1605 - val_p_acc: 0.5545\n",
      "Epoch 3998/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7459 - p_acc: 0.6627 - val_loss: 1.1581 - val_p_acc: 0.4840\n",
      "Epoch 3999/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7944 - p_acc: 0.6298 - val_loss: 1.1583 - val_p_acc: 0.5016\n",
      "Epoch 4000/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7430 - p_acc: 0.6819 - val_loss: 1.1573 - val_p_acc: 0.5192\n",
      "Epoch 4001/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6689 - p_acc: 0.7236 - val_loss: 1.1559 - val_p_acc: 0.5369\n",
      "Epoch 4002/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7237 - p_acc: 0.7708 - val_loss: 1.1558 - val_p_acc: 0.5016\n",
      "Epoch 4003/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7177 - p_acc: 0.7268 - val_loss: 1.1558 - val_p_acc: 0.5192\n",
      "Epoch 4004/5000\n",
      "85/85 [==============================] - 0s 738us/sample - loss: 0.8303 - p_acc: 0.6450 - val_loss: 1.1571 - val_p_acc: 0.4663\n",
      "Epoch 4005/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7046 - p_acc: 0.7099 - val_loss: 1.1616 - val_p_acc: 0.5192\n",
      "Epoch 4006/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8003 - p_acc: 0.7027 - val_loss: 1.1631 - val_p_acc: 0.5369\n",
      "Epoch 4007/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8022 - p_acc: 0.6715 - val_loss: 1.1645 - val_p_acc: 0.5192\n",
      "Epoch 4008/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7636 - p_acc: 0.7236 - val_loss: 1.1627 - val_p_acc: 0.5192\n",
      "Epoch 4009/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7259 - p_acc: 0.7356 - val_loss: 1.1611 - val_p_acc: 0.5192\n",
      "Epoch 4010/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7026 - p_acc: 0.7059 - val_loss: 1.1605 - val_p_acc: 0.5369\n",
      "Epoch 4011/5000\n",
      "85/85 [==============================] - 0s 731us/sample - loss: 0.7486 - p_acc: 0.7220 - val_loss: 1.1599 - val_p_acc: 0.5016\n",
      "Epoch 4012/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8235 - p_acc: 0.6194 - val_loss: 1.1603 - val_p_acc: 0.5192\n",
      "Epoch 4013/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7456 - p_acc: 0.7059 - val_loss: 1.1594 - val_p_acc: 0.4840\n",
      "Epoch 4014/5000\n",
      "85/85 [==============================] - 0s 717us/sample - loss: 0.7375 - p_acc: 0.6747 - val_loss: 1.1582 - val_p_acc: 0.5192\n",
      "Epoch 4015/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7683 - p_acc: 0.6923 - val_loss: 1.1568 - val_p_acc: 0.5016\n",
      "Epoch 4016/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7479 - p_acc: 0.6939 - val_loss: 1.1586 - val_p_acc: 0.5192\n",
      "Epoch 4017/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6812 - p_acc: 0.7043 - val_loss: 1.1581 - val_p_acc: 0.5192\n",
      "Epoch 4018/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7051 - p_acc: 0.6939 - val_loss: 1.1561 - val_p_acc: 0.4840\n",
      "Epoch 4019/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.6990 - p_acc: 0.7668 - val_loss: 1.1553 - val_p_acc: 0.5192\n",
      "Epoch 4020/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8816 - p_acc: 0.5513 - val_loss: 1.1567 - val_p_acc: 0.4840\n",
      "Epoch 4021/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7450 - p_acc: 0.6907 - val_loss: 1.1566 - val_p_acc: 0.5369\n",
      "Epoch 4022/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7323 - p_acc: 0.7131 - val_loss: 1.1585 - val_p_acc: 0.4840\n",
      "Epoch 4023/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7401 - p_acc: 0.7027 - val_loss: 1.1585 - val_p_acc: 0.5192\n",
      "Epoch 4024/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6941 - p_acc: 0.7845 - val_loss: 1.1572 - val_p_acc: 0.5721\n",
      "Epoch 4025/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7465 - p_acc: 0.7027 - val_loss: 1.1589 - val_p_acc: 0.5192\n",
      "Epoch 4026/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8482 - p_acc: 0.5825 - val_loss: 1.1627 - val_p_acc: 0.5192\n",
      "Epoch 4027/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7744 - p_acc: 0.6643 - val_loss: 1.1656 - val_p_acc: 0.5369\n",
      "Epoch 4028/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7091 - p_acc: 0.7220 - val_loss: 1.1674 - val_p_acc: 0.4663\n",
      "Epoch 4029/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7830 - p_acc: 0.6747 - val_loss: 1.1690 - val_p_acc: 0.5369\n",
      "Epoch 4030/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7334 - p_acc: 0.6138 - val_loss: 1.1717 - val_p_acc: 0.4840\n",
      "Epoch 4031/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8166 - p_acc: 0.6715 - val_loss: 1.1727 - val_p_acc: 0.5192\n",
      "Epoch 4032/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7093 - p_acc: 0.7027 - val_loss: 1.1709 - val_p_acc: 0.5016\n",
      "Epoch 4033/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7648 - p_acc: 0.6274 - val_loss: 1.1681 - val_p_acc: 0.4840\n",
      "Epoch 4034/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7270 - p_acc: 0.7131 - val_loss: 1.1650 - val_p_acc: 0.5016\n",
      "Epoch 4035/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8110 - p_acc: 0.6434 - val_loss: 1.1633 - val_p_acc: 0.5016\n",
      "Epoch 4036/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.7612 - p_acc: 0.6627 - val_loss: 1.1623 - val_p_acc: 0.5016\n",
      "Epoch 4037/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7504 - p_acc: 0.7324 - val_loss: 1.1618 - val_p_acc: 0.5369\n",
      "Epoch 4038/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7249 - p_acc: 0.6538 - val_loss: 1.1606 - val_p_acc: 0.4840\n",
      "Epoch 4039/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7634 - p_acc: 0.7324 - val_loss: 1.1599 - val_p_acc: 0.4663\n",
      "Epoch 4040/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7899 - p_acc: 0.6659 - val_loss: 1.1582 - val_p_acc: 0.5369\n",
      "Epoch 4041/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6983 - p_acc: 0.7131 - val_loss: 1.1589 - val_p_acc: 0.5016\n",
      "Epoch 4042/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7978 - p_acc: 0.6138 - val_loss: 1.1597 - val_p_acc: 0.5192\n",
      "Epoch 4043/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8289 - p_acc: 0.6434 - val_loss: 1.1631 - val_p_acc: 0.5192\n",
      "Epoch 4044/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7634 - p_acc: 0.7115 - val_loss: 1.1645 - val_p_acc: 0.5545\n",
      "Epoch 4045/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7979 - p_acc: 0.6450 - val_loss: 1.1671 - val_p_acc: 0.5369\n",
      "Epoch 4046/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7967 - p_acc: 0.6731 - val_loss: 1.1681 - val_p_acc: 0.4840\n",
      "Epoch 4047/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7977 - p_acc: 0.6434 - val_loss: 1.1697 - val_p_acc: 0.5369\n",
      "Epoch 4048/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7683 - p_acc: 0.6939 - val_loss: 1.1715 - val_p_acc: 0.5192\n",
      "Epoch 4049/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7697 - p_acc: 0.7532 - val_loss: 1.1734 - val_p_acc: 0.5192\n",
      "Epoch 4050/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6581 - p_acc: 0.7163 - val_loss: 1.1761 - val_p_acc: 0.5192\n",
      "Epoch 4051/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8340 - p_acc: 0.6194 - val_loss: 1.1742 - val_p_acc: 0.5016\n",
      "Epoch 4052/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7021 - p_acc: 0.7027 - val_loss: 1.1729 - val_p_acc: 0.5369\n",
      "Epoch 4053/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8347 - p_acc: 0.583 - 0s 704us/sample - loss: 0.7333 - p_acc: 0.6659 - val_loss: 1.1730 - val_p_acc: 0.5016\n",
      "Epoch 4054/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7832 - p_acc: 0.6747 - val_loss: 1.1719 - val_p_acc: 0.5192\n",
      "Epoch 4055/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7767 - p_acc: 0.6939 - val_loss: 1.1701 - val_p_acc: 0.5369\n",
      "Epoch 4056/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6726 - p_acc: 0.6763 - val_loss: 1.1694 - val_p_acc: 0.4663\n",
      "Epoch 4057/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7388 - p_acc: 0.6763 - val_loss: 1.1701 - val_p_acc: 0.5721\n",
      "Epoch 4058/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7804 - p_acc: 0.6418 - val_loss: 1.1735 - val_p_acc: 0.4840\n",
      "Epoch 4059/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6613 - p_acc: 0.7532 - val_loss: 1.1760 - val_p_acc: 0.5192\n",
      "Epoch 4060/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8204 - p_acc: 0.6554 - val_loss: 1.1762 - val_p_acc: 0.5192\n",
      "Epoch 4061/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8432 - p_acc: 0.6971 - val_loss: 1.1732 - val_p_acc: 0.5369\n",
      "Epoch 4062/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7816 - p_acc: 0.6346 - val_loss: 1.1715 - val_p_acc: 0.5545\n",
      "Epoch 4063/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7772 - p_acc: 0.6538 - val_loss: 1.1712 - val_p_acc: 0.4840\n",
      "Epoch 4064/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7030 - p_acc: 0.7131 - val_loss: 1.1688 - val_p_acc: 0.5369\n",
      "Epoch 4065/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7336 - p_acc: 0.6418 - val_loss: 1.1669 - val_p_acc: 0.5192\n",
      "Epoch 4066/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7318 - p_acc: 0.7059 - val_loss: 1.1656 - val_p_acc: 0.5016\n",
      "Epoch 4067/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.9058 - p_acc: 0.6106 - val_loss: 1.1631 - val_p_acc: 0.4840\n",
      "Epoch 4068/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7556 - p_acc: 0.6402 - val_loss: 1.1599 - val_p_acc: 0.4840\n",
      "Epoch 4069/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7147 - p_acc: 0.7740 - val_loss: 1.1586 - val_p_acc: 0.5016\n",
      "Epoch 4070/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7208 - p_acc: 0.7356 - val_loss: 1.1593 - val_p_acc: 0.5369\n",
      "Epoch 4071/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7555 - p_acc: 0.6034 - val_loss: 1.1581 - val_p_acc: 0.5545\n",
      "Epoch 4072/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7966 - p_acc: 0.7027 - val_loss: 1.1581 - val_p_acc: 0.5369\n",
      "Epoch 4073/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7846 - p_acc: 0.6330 - val_loss: 1.1570 - val_p_acc: 0.4840\n",
      "Epoch 4074/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7711 - p_acc: 0.6627 - val_loss: 1.1574 - val_p_acc: 0.4663\n",
      "Epoch 4075/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6993 - p_acc: 0.7636 - val_loss: 1.1585 - val_p_acc: 0.5369\n",
      "Epoch 4076/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8840 - p_acc: 0.5441 - val_loss: 1.1613 - val_p_acc: 0.5016\n",
      "Epoch 4077/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8046 - p_acc: 0.6554 - val_loss: 1.1616 - val_p_acc: 0.5192\n",
      "Epoch 4078/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7164 - p_acc: 0.7324 - val_loss: 1.1618 - val_p_acc: 0.4840\n",
      "Epoch 4079/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7728 - p_acc: 0.6643 - val_loss: 1.1613 - val_p_acc: 0.5016\n",
      "Epoch 4080/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6699 - p_acc: 0.6851 - val_loss: 1.1601 - val_p_acc: 0.5192\n",
      "Epoch 4081/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7835 - p_acc: 0.6763 - val_loss: 1.1587 - val_p_acc: 0.5369\n",
      "Epoch 4082/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7835 - p_acc: 0.6522 - val_loss: 1.1574 - val_p_acc: 0.5721\n",
      "Epoch 4083/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6768 - p_acc: 0.6851 - val_loss: 1.1572 - val_p_acc: 0.5369\n",
      "Epoch 4084/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8279 - p_acc: 0.6154 - val_loss: 1.1551 - val_p_acc: 0.5016\n",
      "Epoch 4085/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8556 - p_acc: 0.5986 - val_loss: 1.1540 - val_p_acc: 0.5016\n",
      "Epoch 4086/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8384 - p_acc: 0.6434 - val_loss: 1.1509 - val_p_acc: 0.5016\n",
      "Epoch 4087/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8392 - p_acc: 0.6122 - val_loss: 1.1503 - val_p_acc: 0.5369\n",
      "Epoch 4088/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6987 - p_acc: 0.7027 - val_loss: 1.1497 - val_p_acc: 0.5016\n",
      "Epoch 4089/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7899 - p_acc: 0.6627 - val_loss: 1.1512 - val_p_acc: 0.4840\n",
      "Epoch 4090/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7550 - p_acc: 0.6907 - val_loss: 1.1534 - val_p_acc: 0.5192\n",
      "Epoch 4091/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6950 - p_acc: 0.6538 - val_loss: 1.1567 - val_p_acc: 0.5016\n",
      "Epoch 4092/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7339 - p_acc: 0.6731 - val_loss: 1.1603 - val_p_acc: 0.4840\n",
      "Epoch 4093/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7826 - p_acc: 0.7220 - val_loss: 1.1608 - val_p_acc: 0.5545\n",
      "Epoch 4094/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7364 - p_acc: 0.6971 - val_loss: 1.1599 - val_p_acc: 0.5545\n",
      "Epoch 4095/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7340 - p_acc: 0.6506 - val_loss: 1.1582 - val_p_acc: 0.5192\n",
      "Epoch 4096/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8579 - p_acc: 0.5962 - val_loss: 1.1576 - val_p_acc: 0.4840\n",
      "Epoch 4097/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7531 - p_acc: 0.5809 - val_loss: 1.1578 - val_p_acc: 0.4840\n",
      "Epoch 4098/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.6804 - p_acc: 0.7236 - val_loss: 1.1577 - val_p_acc: 0.5192\n",
      "Epoch 4099/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7384 - p_acc: 0.6747 - val_loss: 1.1588 - val_p_acc: 0.5016\n",
      "Epoch 4100/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7762 - p_acc: 0.6418 - val_loss: 1.1611 - val_p_acc: 0.5192\n",
      "Epoch 4101/5000\n",
      "85/85 [==============================] - 0s 721us/sample - loss: 0.7808 - p_acc: 0.6538 - val_loss: 1.1635 - val_p_acc: 0.5369\n",
      "Epoch 4102/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8381 - p_acc: 0.6434 - val_loss: 1.1642 - val_p_acc: 0.5016\n",
      "Epoch 4103/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7039 - p_acc: 0.6659 - val_loss: 1.1645 - val_p_acc: 0.5369\n",
      "Epoch 4104/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8135 - p_acc: 0.6675 - val_loss: 1.1689 - val_p_acc: 0.4840\n",
      "Epoch 4105/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7513 - p_acc: 0.7444 - val_loss: 1.1709 - val_p_acc: 0.5369\n",
      "Epoch 4106/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7925 - p_acc: 0.7027 - val_loss: 1.1724 - val_p_acc: 0.5016\n",
      "Epoch 4107/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8429 - p_acc: 0.6731 - val_loss: 1.1724 - val_p_acc: 0.5016\n",
      "Epoch 4108/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.6609 - p_acc: 0.6362 - val_loss: 1.1714 - val_p_acc: 0.5369\n",
      "Epoch 4109/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8163 - p_acc: 0.6747 - val_loss: 1.1717 - val_p_acc: 0.5369\n",
      "Epoch 4110/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7800 - p_acc: 0.6643 - val_loss: 1.1710 - val_p_acc: 0.5192\n",
      "Epoch 4111/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7662 - p_acc: 0.6971 - val_loss: 1.1710 - val_p_acc: 0.5016\n",
      "Epoch 4112/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7390 - p_acc: 0.6923 - val_loss: 1.1711 - val_p_acc: 0.5369\n",
      "Epoch 4113/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 0.8141 - p_acc: 0.5841 - val_loss: 1.1737 - val_p_acc: 0.5016\n",
      "Epoch 4114/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7308 - p_acc: 0.7252 - val_loss: 1.1732 - val_p_acc: 0.5369\n",
      "Epoch 4115/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7505 - p_acc: 0.7043 - val_loss: 1.1716 - val_p_acc: 0.5369\n",
      "Epoch 4116/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7508 - p_acc: 0.6538 - val_loss: 1.1704 - val_p_acc: 0.4840\n",
      "Epoch 4117/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6493 - p_acc: 0.7147 - val_loss: 1.1699 - val_p_acc: 0.4840\n",
      "Epoch 4118/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8090 - p_acc: 0.6226 - val_loss: 1.1715 - val_p_acc: 0.4663\n",
      "Epoch 4119/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7242 - p_acc: 0.7340 - val_loss: 1.1719 - val_p_acc: 0.4840\n",
      "Epoch 4120/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7549 - p_acc: 0.7308 - val_loss: 1.1724 - val_p_acc: 0.5369\n",
      "Epoch 4121/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7481 - p_acc: 0.6955 - val_loss: 1.1729 - val_p_acc: 0.5016\n",
      "Epoch 4122/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7388 - p_acc: 0.7147 - val_loss: 1.1733 - val_p_acc: 0.5369\n",
      "Epoch 4123/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.7758 - p_acc: 0.6138 - val_loss: 1.1705 - val_p_acc: 0.5016\n",
      "Epoch 4124/5000\n",
      "85/85 [==============================] - 0s 881us/sample - loss: 0.7610 - p_acc: 0.6538 - val_loss: 1.1691 - val_p_acc: 0.5545\n",
      "Epoch 4125/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7384 - p_acc: 0.6450 - val_loss: 1.1680 - val_p_acc: 0.4840\n",
      "Epoch 4126/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.7189 - p_acc: 0.6747 - val_loss: 1.1672 - val_p_acc: 0.4840\n",
      "Epoch 4127/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7087 - p_acc: 0.6851 - val_loss: 1.1659 - val_p_acc: 0.4663\n",
      "Epoch 4128/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8119 - p_acc: 0.6138 - val_loss: 1.1635 - val_p_acc: 0.5545\n",
      "Epoch 4129/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8586 - p_acc: 0.6050 - val_loss: 1.1594 - val_p_acc: 0.5545\n",
      "Epoch 4130/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7265 - p_acc: 0.6835 - val_loss: 1.1582 - val_p_acc: 0.5545\n",
      "Epoch 4131/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7012 - p_acc: 0.7444 - val_loss: 1.1568 - val_p_acc: 0.5192\n",
      "Epoch 4132/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8321 - p_acc: 0.5649 - val_loss: 1.1577 - val_p_acc: 0.4840\n",
      "Epoch 4133/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.9134 - p_acc: 0.5633 - val_loss: 1.1581 - val_p_acc: 0.4840\n",
      "Epoch 4134/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.6661 - p_acc: 0.7933 - val_loss: 1.1595 - val_p_acc: 0.5369\n",
      "Epoch 4135/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7033 - p_acc: 0.6795 - val_loss: 1.1598 - val_p_acc: 0.4840\n",
      "Epoch 4136/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6810 - p_acc: 0.7147 - val_loss: 1.1587 - val_p_acc: 0.5192\n",
      "Epoch 4137/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.6794 - p_acc: 0.7324 - val_loss: 1.1623 - val_p_acc: 0.4487\n",
      "Epoch 4138/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8376 - p_acc: 0.6506 - val_loss: 1.1624 - val_p_acc: 0.5545\n",
      "Epoch 4139/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7575 - p_acc: 0.6346 - val_loss: 1.1616 - val_p_acc: 0.5721\n",
      "Epoch 4140/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7421 - p_acc: 0.7236 - val_loss: 1.1597 - val_p_acc: 0.5016\n",
      "Epoch 4141/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7663 - p_acc: 0.6034 - val_loss: 1.1599 - val_p_acc: 0.4840\n",
      "Epoch 4142/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7142 - p_acc: 0.7412 - val_loss: 1.1592 - val_p_acc: 0.5192\n",
      "Epoch 4143/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.6930 - p_acc: 0.7075 - val_loss: 1.1583 - val_p_acc: 0.5016\n",
      "Epoch 4144/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6915 - p_acc: 0.7548 - val_loss: 1.1569 - val_p_acc: 0.4663\n",
      "Epoch 4145/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7244 - p_acc: 0.6923 - val_loss: 1.1577 - val_p_acc: 0.5192\n",
      "Epoch 4146/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7845 - p_acc: 0.6731 - val_loss: 1.1582 - val_p_acc: 0.5545\n",
      "Epoch 4147/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8157 - p_acc: 0.6154 - val_loss: 1.1583 - val_p_acc: 0.5192\n",
      "Epoch 4148/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7757 - p_acc: 0.7340 - val_loss: 1.1564 - val_p_acc: 0.4663\n",
      "Epoch 4149/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7222 - p_acc: 0.7059 - val_loss: 1.1523 - val_p_acc: 0.5192\n",
      "Epoch 4150/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7942 - p_acc: 0.6210 - val_loss: 1.1482 - val_p_acc: 0.5369\n",
      "Epoch 4151/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7294 - p_acc: 0.7131 - val_loss: 1.1424 - val_p_acc: 0.5048\n",
      "Epoch 4152/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7205 - p_acc: 0.6939 - val_loss: 1.1409 - val_p_acc: 0.5192\n",
      "Epoch 4153/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8429 - p_acc: 0.6418 - val_loss: 1.1394 - val_p_acc: 0.5192\n",
      "Epoch 4154/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7456 - p_acc: 0.6819 - val_loss: 1.1396 - val_p_acc: 0.4984\n",
      "Epoch 4155/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.7798 - p_acc: 0.7147 - val_loss: 1.1399 - val_p_acc: 0.4808\n",
      "Epoch 4156/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7523 - p_acc: 0.6522 - val_loss: 1.1398 - val_p_acc: 0.5192\n",
      "Epoch 4157/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7830 - p_acc: 0.6154 - val_loss: 1.1404 - val_p_acc: 0.4663\n",
      "Epoch 4158/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8319 - p_acc: 0.6835 - val_loss: 1.1399 - val_p_acc: 0.5369\n",
      "Epoch 4159/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7531 - p_acc: 0.7115 - val_loss: 1.1385 - val_p_acc: 0.4808\n",
      "Epoch 4160/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7899 - p_acc: 0.6835 - val_loss: 1.1397 - val_p_acc: 0.5337\n",
      "Epoch 4161/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8930 - p_acc: 0.6971 - val_loss: 1.1400 - val_p_acc: 0.5048\n",
      "Epoch 4162/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7882 - p_acc: 0.6434 - val_loss: 1.1408 - val_p_acc: 0.5577\n",
      "Epoch 4163/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8100 - p_acc: 0.6138 - val_loss: 1.1422 - val_p_acc: 0.5224\n",
      "Epoch 4164/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7022 - p_acc: 0.7075 - val_loss: 1.1418 - val_p_acc: 0.5753\n",
      "Epoch 4165/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7963 - p_acc: 0.6138 - val_loss: 1.1435 - val_p_acc: 0.5577\n",
      "Epoch 4166/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7392 - p_acc: 0.7236 - val_loss: 1.1440 - val_p_acc: 0.5224\n",
      "Epoch 4167/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7506 - p_acc: 0.6731 - val_loss: 1.1448 - val_p_acc: 0.5753\n",
      "Epoch 4168/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8226 - p_acc: 0.6258 - val_loss: 1.1465 - val_p_acc: 0.5048\n",
      "Epoch 4169/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7354 - p_acc: 0.6434 - val_loss: 1.1479 - val_p_acc: 0.5401\n",
      "Epoch 4170/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8112 - p_acc: 0.6538 - val_loss: 1.1483 - val_p_acc: 0.5401\n",
      "Epoch 4171/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7810 - p_acc: 0.7011 - val_loss: 1.1493 - val_p_acc: 0.5577\n",
      "Epoch 4172/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7660 - p_acc: 0.6522 - val_loss: 1.1503 - val_p_acc: 0.5577\n",
      "Epoch 4173/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7109 - p_acc: 0.6971 - val_loss: 1.1533 - val_p_acc: 0.5577\n",
      "Epoch 4174/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7020 - p_acc: 0.7652 - val_loss: 1.1542 - val_p_acc: 0.5577\n",
      "Epoch 4175/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8078 - p_acc: 0.6106 - val_loss: 1.1539 - val_p_acc: 0.5224\n",
      "Epoch 4176/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7450 - p_acc: 0.6418 - val_loss: 1.1547 - val_p_acc: 0.5401\n",
      "Epoch 4177/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7402 - p_acc: 0.7131 - val_loss: 1.1547 - val_p_acc: 0.5048\n",
      "Epoch 4178/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.6939 - p_acc: 0.6955 - val_loss: 1.1548 - val_p_acc: 0.5577\n",
      "Epoch 4179/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7422 - p_acc: 0.7027 - val_loss: 1.1554 - val_p_acc: 0.5016\n",
      "Epoch 4180/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7173 - p_acc: 0.7636 - val_loss: 1.1553 - val_p_acc: 0.5369\n",
      "Epoch 4181/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7574 - p_acc: 0.6627 - val_loss: 1.1582 - val_p_acc: 0.5369\n",
      "Epoch 4182/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7213 - p_acc: 0.6867 - val_loss: 1.1602 - val_p_acc: 0.5192\n",
      "Epoch 4183/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.6810 - p_acc: 0.7324 - val_loss: 1.1612 - val_p_acc: 0.4663\n",
      "Epoch 4184/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8088 - p_acc: 0.6378 - val_loss: 1.1625 - val_p_acc: 0.5192\n",
      "Epoch 4185/5000\n",
      "85/85 [==============================] - 0s 762us/sample - loss: 0.8311 - p_acc: 0.6154 - val_loss: 1.1641 - val_p_acc: 0.5192\n",
      "Epoch 4186/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7564 - p_acc: 0.6747 - val_loss: 1.1656 - val_p_acc: 0.4840\n",
      "Epoch 4187/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8289 - p_acc: 0.6835 - val_loss: 1.1661 - val_p_acc: 0.4840\n",
      "Epoch 4188/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7832 - p_acc: 0.6803 - val_loss: 1.1663 - val_p_acc: 0.5192\n",
      "Epoch 4189/5000\n",
      "85/85 [==============================] - 0s 714us/sample - loss: 0.7830 - p_acc: 0.6923 - val_loss: 1.1665 - val_p_acc: 0.5192\n",
      "Epoch 4190/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7710 - p_acc: 0.7252 - val_loss: 1.1692 - val_p_acc: 0.5016\n",
      "Epoch 4191/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7211 - p_acc: 0.6362 - val_loss: 1.1687 - val_p_acc: 0.5192\n",
      "Epoch 4192/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7785 - p_acc: 0.6122 - val_loss: 1.1687 - val_p_acc: 0.5192\n",
      "Epoch 4193/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7503 - p_acc: 0.6290 - val_loss: 1.1697 - val_p_acc: 0.5016\n",
      "Epoch 4194/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7367 - p_acc: 0.6643 - val_loss: 1.1699 - val_p_acc: 0.4840\n",
      "Epoch 4195/5000\n",
      "85/85 [==============================] - 0s 737us/sample - loss: 0.7587 - p_acc: 0.7059 - val_loss: 1.1708 - val_p_acc: 0.4840\n",
      "Epoch 4196/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7115 - p_acc: 0.7460 - val_loss: 1.1717 - val_p_acc: 0.5545\n",
      "Epoch 4197/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7711 - p_acc: 0.6330 - val_loss: 1.1717 - val_p_acc: 0.5016\n",
      "Epoch 4198/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7834 - p_acc: 0.6330 - val_loss: 1.1707 - val_p_acc: 0.5721\n",
      "Epoch 4199/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8689 - p_acc: 0.6226 - val_loss: 1.1685 - val_p_acc: 0.5545\n",
      "Epoch 4200/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7267 - p_acc: 0.6538 - val_loss: 1.1663 - val_p_acc: 0.5545\n",
      "Epoch 4201/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7197 - p_acc: 0.6763 - val_loss: 1.1665 - val_p_acc: 0.5016\n",
      "Epoch 4202/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7322 - p_acc: 0.6867 - val_loss: 1.1672 - val_p_acc: 0.5016\n",
      "Epoch 4203/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7362 - p_acc: 0.7075 - val_loss: 1.1698 - val_p_acc: 0.4663\n",
      "Epoch 4204/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7556 - p_acc: 0.7428 - val_loss: 1.1723 - val_p_acc: 0.5192\n",
      "Epoch 4205/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8382 - p_acc: 0.6346 - val_loss: 1.1737 - val_p_acc: 0.5192\n",
      "Epoch 4206/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7648 - p_acc: 0.6715 - val_loss: 1.1721 - val_p_acc: 0.5192\n",
      "Epoch 4207/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8031 - p_acc: 0.6819 - val_loss: 1.1705 - val_p_acc: 0.4840\n",
      "Epoch 4208/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6834 - p_acc: 0.6731 - val_loss: 1.1682 - val_p_acc: 0.4663\n",
      "Epoch 4209/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7644 - p_acc: 0.6939 - val_loss: 1.1681 - val_p_acc: 0.5369\n",
      "Epoch 4210/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8067 - p_acc: 0.7204 - val_loss: 1.1645 - val_p_acc: 0.4840\n",
      "Epoch 4211/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7564 - p_acc: 0.7236 - val_loss: 1.1629 - val_p_acc: 0.5192\n",
      "Epoch 4212/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5094 - p_acc: 0.916 - 0s 751us/sample - loss: 0.6209 - p_acc: 0.7372 - val_loss: 1.1633 - val_p_acc: 0.4840\n",
      "Epoch 4213/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7801 - p_acc: 0.6731 - val_loss: 1.1599 - val_p_acc: 0.5192\n",
      "Epoch 4214/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7078 - p_acc: 0.6346 - val_loss: 1.1586 - val_p_acc: 0.4840\n",
      "Epoch 4215/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8757 - p_acc: 0.6939 - val_loss: 1.1550 - val_p_acc: 0.5369\n",
      "Epoch 4216/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7132 - p_acc: 0.7131 - val_loss: 1.1507 - val_p_acc: 0.4984\n",
      "Epoch 4217/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.6857 - p_acc: 0.7252 - val_loss: 1.1481 - val_p_acc: 0.5160\n",
      "Epoch 4218/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7723 - p_acc: 0.6330 - val_loss: 1.1439 - val_p_acc: 0.4631\n",
      "Epoch 4219/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7111 - p_acc: 0.6538 - val_loss: 1.1420 - val_p_acc: 0.5337\n",
      "Epoch 4220/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6412 - p_acc: 0.7564 - val_loss: 1.1391 - val_p_acc: 0.4808\n",
      "Epoch 4221/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7415 - p_acc: 0.6050 - val_loss: 1.1380 - val_p_acc: 0.4808\n",
      "Epoch 4222/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7316 - p_acc: 0.6611 - val_loss: 1.1369 - val_p_acc: 0.4631\n",
      "Epoch 4223/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7325 - p_acc: 0.6731 - val_loss: 1.1371 - val_p_acc: 0.4984\n",
      "Epoch 4224/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.6955 - p_acc: 0.7444 - val_loss: 1.1374 - val_p_acc: 0.4631\n",
      "Epoch 4225/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8687 - p_acc: 0.6154 - val_loss: 1.1382 - val_p_acc: 0.4808\n",
      "Epoch 4226/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7811 - p_acc: 0.6274 - val_loss: 1.1363 - val_p_acc: 0.4984\n",
      "Epoch 4227/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7279 - p_acc: 0.7236 - val_loss: 1.1341 - val_p_acc: 0.4984\n",
      "Epoch 4228/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6966 - p_acc: 0.7011 - val_loss: 1.1321 - val_p_acc: 0.4984\n",
      "Epoch 4229/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7981 - p_acc: 0.6611 - val_loss: 1.1322 - val_p_acc: 0.4984\n",
      "Epoch 4230/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8012 - p_acc: 0.6330 - val_loss: 1.1344 - val_p_acc: 0.4984\n",
      "Epoch 4231/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7870 - p_acc: 0.7340 - val_loss: 1.1322 - val_p_acc: 0.4984\n",
      "Epoch 4232/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8239 - p_acc: 0.5929 - val_loss: 1.1325 - val_p_acc: 0.4279\n",
      "Epoch 4233/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7220 - p_acc: 0.7252 - val_loss: 1.1318 - val_p_acc: 0.4984\n",
      "Epoch 4234/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.6783 - p_acc: 0.7147 - val_loss: 1.1312 - val_p_acc: 0.5160\n",
      "Epoch 4235/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7711 - p_acc: 0.6923 - val_loss: 1.1314 - val_p_acc: 0.4984\n",
      "Epoch 4236/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6784 - p_acc: 0.7147 - val_loss: 1.1316 - val_p_acc: 0.4984\n",
      "Epoch 4237/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7701 - p_acc: 0.6699 - val_loss: 1.1318 - val_p_acc: 0.4984\n",
      "Epoch 4238/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6772 - p_acc: 0.7236 - val_loss: 1.1320 - val_p_acc: 0.4808\n",
      "Epoch 4239/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6957 - p_acc: 0.7861 - val_loss: 1.1322 - val_p_acc: 0.4631\n",
      "Epoch 4240/5000\n",
      "85/85 [==============================] - 0s 809us/sample - loss: 0.7878 - p_acc: 0.6226 - val_loss: 1.1316 - val_p_acc: 0.4631\n",
      "Epoch 4241/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.8189 - p_acc: 0.6314 - val_loss: 1.1317 - val_p_acc: 0.5160\n",
      "Epoch 4242/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.7299 - p_acc: 0.6707 - val_loss: 1.1324 - val_p_acc: 0.4808\n",
      "Epoch 4243/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7804 - p_acc: 0.6715 - val_loss: 1.1330 - val_p_acc: 0.5337\n",
      "Epoch 4244/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7017 - p_acc: 0.6659 - val_loss: 1.1322 - val_p_acc: 0.4984\n",
      "Epoch 4245/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8658 - p_acc: 0.6346 - val_loss: 1.1328 - val_p_acc: 0.5160\n",
      "Epoch 4246/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7366 - p_acc: 0.7268 - val_loss: 1.1320 - val_p_acc: 0.4984\n",
      "Epoch 4247/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7193 - p_acc: 0.7147 - val_loss: 1.1315 - val_p_acc: 0.4984\n",
      "Epoch 4248/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7492 - p_acc: 0.6466 - val_loss: 1.1309 - val_p_acc: 0.4984\n",
      "Epoch 4249/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7589 - p_acc: 0.7147 - val_loss: 1.1286 - val_p_acc: 0.4631\n",
      "Epoch 4250/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7738 - p_acc: 0.7075 - val_loss: 1.1284 - val_p_acc: 0.4984\n",
      "Epoch 4251/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7157 - p_acc: 0.7252 - val_loss: 1.1286 - val_p_acc: 0.4631\n",
      "Epoch 4252/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.7656 - p_acc: 0.7324 - val_loss: 1.1284 - val_p_acc: 0.5337\n",
      "Epoch 4253/5000\n",
      "85/85 [==============================] - 0s 738us/sample - loss: 0.6954 - p_acc: 0.7236 - val_loss: 1.1293 - val_p_acc: 0.4808\n",
      "Epoch 4254/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6668 - p_acc: 0.7460 - val_loss: 1.1311 - val_p_acc: 0.4984\n",
      "Epoch 4255/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.6807 - p_acc: 0.7356 - val_loss: 1.1336 - val_p_acc: 0.4984\n",
      "Epoch 4256/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7003 - p_acc: 0.6643 - val_loss: 1.1349 - val_p_acc: 0.4455\n",
      "Epoch 4257/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7500 - p_acc: 0.6554 - val_loss: 1.1321 - val_p_acc: 0.4984\n",
      "Epoch 4258/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7868 - p_acc: 0.6554 - val_loss: 1.1312 - val_p_acc: 0.4984\n",
      "Epoch 4259/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7542 - p_acc: 0.6122 - val_loss: 1.1297 - val_p_acc: 0.4455\n",
      "Epoch 4260/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8161 - p_acc: 0.7236 - val_loss: 1.1290 - val_p_acc: 0.4984\n",
      "Epoch 4261/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.7083 - p_acc: 0.7949 - val_loss: 1.1303 - val_p_acc: 0.4808\n",
      "Epoch 4262/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.6955 - p_acc: 0.7043 - val_loss: 1.1319 - val_p_acc: 0.5160\n",
      "Epoch 4263/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.7862 - p_acc: 0.6298 - val_loss: 1.1336 - val_p_acc: 0.4984\n",
      "Epoch 4264/5000\n",
      "85/85 [==============================] - 0s 752us/sample - loss: 0.8132 - p_acc: 0.6659 - val_loss: 1.1364 - val_p_acc: 0.4808\n",
      "Epoch 4265/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6415 - p_acc: 0.7652 - val_loss: 1.1370 - val_p_acc: 0.4984\n",
      "Epoch 4266/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7313 - p_acc: 0.7444 - val_loss: 1.1391 - val_p_acc: 0.4808\n",
      "Epoch 4267/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7082 - p_acc: 0.7059 - val_loss: 1.1411 - val_p_acc: 0.4984\n",
      "Epoch 4268/5000\n",
      "85/85 [==============================] - 0s 725us/sample - loss: 0.8012 - p_acc: 0.6659 - val_loss: 1.1440 - val_p_acc: 0.5016\n",
      "Epoch 4269/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6943 - p_acc: 0.6731 - val_loss: 1.1449 - val_p_acc: 0.5369\n",
      "Epoch 4270/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7661 - p_acc: 0.6138 - val_loss: 1.1452 - val_p_acc: 0.4840\n",
      "Epoch 4271/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7041 - p_acc: 0.6835 - val_loss: 1.1460 - val_p_acc: 0.5224\n",
      "Epoch 4272/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6742 - p_acc: 0.7428 - val_loss: 1.1484 - val_p_acc: 0.5224\n",
      "Epoch 4273/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6745 - p_acc: 0.7636 - val_loss: 1.1489 - val_p_acc: 0.5048\n",
      "Epoch 4274/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8780 - p_acc: 0.5946 - val_loss: 1.1480 - val_p_acc: 0.5753\n",
      "Epoch 4275/5000\n",
      "85/85 [==============================] - 0s 762us/sample - loss: 0.7942 - p_acc: 0.7115 - val_loss: 1.1460 - val_p_acc: 0.5016\n",
      "Epoch 4276/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7130 - p_acc: 0.7444 - val_loss: 1.1487 - val_p_acc: 0.5577\n",
      "Epoch 4277/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7406 - p_acc: 0.6835 - val_loss: 1.1491 - val_p_acc: 0.5048\n",
      "Epoch 4278/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6919 - p_acc: 0.7476 - val_loss: 1.1501 - val_p_acc: 0.5401\n",
      "Epoch 4279/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7272 - p_acc: 0.7163 - val_loss: 1.1503 - val_p_acc: 0.4984\n",
      "Epoch 4280/5000\n",
      "85/85 [==============================] - 0s 724us/sample - loss: 0.8826 - p_acc: 0.6675 - val_loss: 1.1505 - val_p_acc: 0.4663\n",
      "Epoch 4281/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.6909 - p_acc: 0.6971 - val_loss: 1.1491 - val_p_acc: 0.4487\n",
      "Epoch 4282/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7646 - p_acc: 0.6939 - val_loss: 1.1451 - val_p_acc: 0.4840\n",
      "Epoch 4283/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7536 - p_acc: 0.6819 - val_loss: 1.1417 - val_p_acc: 0.4631\n",
      "Epoch 4284/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7928 - p_acc: 0.7043 - val_loss: 1.1414 - val_p_acc: 0.4808\n",
      "Epoch 4285/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7550 - p_acc: 0.7284 - val_loss: 1.1410 - val_p_acc: 0.4984\n",
      "Epoch 4286/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8714 - p_acc: 0.6122 - val_loss: 1.1409 - val_p_acc: 0.4808\n",
      "Epoch 4287/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8041 - p_acc: 0.6034 - val_loss: 1.1390 - val_p_acc: 0.4984\n",
      "Epoch 4288/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7911 - p_acc: 0.6971 - val_loss: 1.1365 - val_p_acc: 0.5160\n",
      "Epoch 4289/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7577 - p_acc: 0.7324 - val_loss: 1.1377 - val_p_acc: 0.4631\n",
      "Epoch 4290/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7608 - p_acc: 0.6434 - val_loss: 1.1389 - val_p_acc: 0.5160\n",
      "Epoch 4291/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8406 - p_acc: 0.6226 - val_loss: 1.1398 - val_p_acc: 0.4631\n",
      "Epoch 4292/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8139 - p_acc: 0.5929 - val_loss: 1.1437 - val_p_acc: 0.4455\n",
      "Epoch 4293/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7699 - p_acc: 0.7236 - val_loss: 1.1435 - val_p_acc: 0.5160\n",
      "Epoch 4294/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.8149 - p_acc: 0.6434 - val_loss: 1.1428 - val_p_acc: 0.4808\n",
      "Epoch 4295/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7726 - p_acc: 0.6643 - val_loss: 1.1414 - val_p_acc: 0.4631\n",
      "Epoch 4296/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8302 - p_acc: 0.6939 - val_loss: 1.1421 - val_p_acc: 0.5160\n",
      "Epoch 4297/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7837 - p_acc: 0.7043 - val_loss: 1.1424 - val_p_acc: 0.5160\n",
      "Epoch 4298/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7533 - p_acc: 0.6538 - val_loss: 1.1420 - val_p_acc: 0.4808\n",
      "Epoch 4299/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6678 - p_acc: 0.7340 - val_loss: 1.1451 - val_p_acc: 0.4984\n",
      "Epoch 4300/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6941 - p_acc: 0.7131 - val_loss: 1.1448 - val_p_acc: 0.4984\n",
      "Epoch 4301/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.6654 - p_acc: 0.7236 - val_loss: 1.1427 - val_p_acc: 0.4808\n",
      "Epoch 4302/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7720 - p_acc: 0.6226 - val_loss: 1.1399 - val_p_acc: 0.5160\n",
      "Epoch 4303/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7873 - p_acc: 0.6106 - val_loss: 1.1400 - val_p_acc: 0.4279\n",
      "Epoch 4304/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7951 - p_acc: 0.7131 - val_loss: 1.1392 - val_p_acc: 0.4808\n",
      "Epoch 4305/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8454 - p_acc: 0.6450 - val_loss: 1.1411 - val_p_acc: 0.4455\n",
      "Epoch 4306/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7225 - p_acc: 0.7372 - val_loss: 1.1422 - val_p_acc: 0.4984\n",
      "Epoch 4307/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7631 - p_acc: 0.6659 - val_loss: 1.1446 - val_p_acc: 0.5337\n",
      "Epoch 4308/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8189 - p_acc: 0.6050 - val_loss: 1.1471 - val_p_acc: 0.4984\n",
      "Epoch 4309/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7002 - p_acc: 0.6955 - val_loss: 1.1473 - val_p_acc: 0.4984\n",
      "Epoch 4310/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7849 - p_acc: 0.7115 - val_loss: 1.1481 - val_p_acc: 0.5192\n",
      "Epoch 4311/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7757 - p_acc: 0.6691 - val_loss: 1.1472 - val_p_acc: 0.5192\n",
      "Epoch 4312/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7980 - p_acc: 0.6522 - val_loss: 1.1490 - val_p_acc: 0.4984\n",
      "Epoch 4313/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6732 - p_acc: 0.7252 - val_loss: 1.1487 - val_p_acc: 0.4808\n",
      "Epoch 4314/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7705 - p_acc: 0.6835 - val_loss: 1.1469 - val_p_acc: 0.5192\n",
      "Epoch 4315/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.6628 - p_acc: 0.7772 - val_loss: 1.1451 - val_p_acc: 0.4279\n",
      "Epoch 4316/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7534 - p_acc: 0.6659 - val_loss: 1.1445 - val_p_acc: 0.4808\n",
      "Epoch 4317/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6711 - p_acc: 0.7340 - val_loss: 1.1451 - val_p_acc: 0.4455\n",
      "Epoch 4318/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6939 - p_acc: 0.7236 - val_loss: 1.1438 - val_p_acc: 0.4984\n",
      "Epoch 4319/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7258 - p_acc: 0.6274 - val_loss: 1.1407 - val_p_acc: 0.4455\n",
      "Epoch 4320/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7609 - p_acc: 0.6939 - val_loss: 1.1390 - val_p_acc: 0.4808\n",
      "Epoch 4321/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7269 - p_acc: 0.6923 - val_loss: 1.1371 - val_p_acc: 0.5160\n",
      "Epoch 4322/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9078 - p_acc: 0.5897 - val_loss: 1.1361 - val_p_acc: 0.4984\n",
      "Epoch 4323/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7495 - p_acc: 0.7532 - val_loss: 1.1360 - val_p_acc: 0.4984\n",
      "Epoch 4324/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.6965 - p_acc: 0.7356 - val_loss: 1.1363 - val_p_acc: 0.4631\n",
      "Epoch 4325/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8038 - p_acc: 0.7131 - val_loss: 1.1380 - val_p_acc: 0.4631\n",
      "Epoch 4326/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7689 - p_acc: 0.6378 - val_loss: 1.1417 - val_p_acc: 0.5545\n",
      "Epoch 4327/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7845 - p_acc: 0.6835 - val_loss: 1.1431 - val_p_acc: 0.5192\n",
      "Epoch 4328/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7235 - p_acc: 0.7444 - val_loss: 1.1430 - val_p_acc: 0.5192\n",
      "Epoch 4329/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.8261 - p_acc: 0.6402 - val_loss: 1.1451 - val_p_acc: 0.5016\n",
      "Epoch 4330/5000\n",
      "85/85 [==============================] - 0s 869us/sample - loss: 0.7275 - p_acc: 0.6851 - val_loss: 1.1442 - val_p_acc: 0.4840\n",
      "Epoch 4331/5000\n",
      "85/85 [==============================] - 0s 939us/sample - loss: 0.7527 - p_acc: 0.6434 - val_loss: 1.1456 - val_p_acc: 0.5192\n",
      "Epoch 4332/5000\n",
      "85/85 [==============================] - 0s 892us/sample - loss: 0.8041 - p_acc: 0.6522 - val_loss: 1.1491 - val_p_acc: 0.4631\n",
      "Epoch 4333/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.6582 - p_acc: 0.6971 - val_loss: 1.1529 - val_p_acc: 0.5545\n",
      "Epoch 4334/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.8236 - p_acc: 0.6258 - val_loss: 1.1549 - val_p_acc: 0.5016\n",
      "Epoch 4335/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7023 - p_acc: 0.7091 - val_loss: 1.1575 - val_p_acc: 0.5369\n",
      "Epoch 4336/5000\n",
      "85/85 [==============================] - 0s 762us/sample - loss: 0.6802 - p_acc: 0.7724 - val_loss: 1.1581 - val_p_acc: 0.4840\n",
      "Epoch 4337/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7090 - p_acc: 0.7011 - val_loss: 1.1604 - val_p_acc: 0.5369\n",
      "Epoch 4338/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.7873 - p_acc: 0.6891 - val_loss: 1.1610 - val_p_acc: 0.5016\n",
      "Epoch 4339/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.7168 - p_acc: 0.6907 - val_loss: 1.1622 - val_p_acc: 0.5369\n",
      "Epoch 4340/5000\n",
      "85/85 [==============================] - 0s 904us/sample - loss: 0.7521 - p_acc: 0.6659 - val_loss: 1.1608 - val_p_acc: 0.5016\n",
      "Epoch 4341/5000\n",
      "85/85 [==============================] - 0s 1ms/sample - loss: 0.7997 - p_acc: 0.6138 - val_loss: 1.1592 - val_p_acc: 0.4840\n",
      "Epoch 4342/5000\n",
      "85/85 [==============================] - 0s 962us/sample - loss: 0.7429 - p_acc: 0.7308 - val_loss: 1.1583 - val_p_acc: 0.5016\n",
      "Epoch 4343/5000\n",
      "85/85 [==============================] - 0s 928us/sample - loss: 0.7600 - p_acc: 0.6210 - val_loss: 1.1585 - val_p_acc: 0.4663\n",
      "Epoch 4344/5000\n",
      "85/85 [==============================] - 0s 892us/sample - loss: 0.8623 - p_acc: 0.6466 - val_loss: 1.1577 - val_p_acc: 0.5016\n",
      "Epoch 4345/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.7287 - p_acc: 0.6154 - val_loss: 1.1575 - val_p_acc: 0.5369\n",
      "Epoch 4346/5000\n",
      "85/85 [==============================] - 0s 974us/sample - loss: 0.6778 - p_acc: 0.7027 - val_loss: 1.1564 - val_p_acc: 0.5192\n",
      "Epoch 4347/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.7733 - p_acc: 0.6122 - val_loss: 1.1533 - val_p_acc: 0.4840\n",
      "Epoch 4348/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.7701 - p_acc: 0.6955 - val_loss: 1.1510 - val_p_acc: 0.5369\n",
      "Epoch 4349/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7705 - p_acc: 0.6330 - val_loss: 1.1535 - val_p_acc: 0.5016\n",
      "Epoch 4350/5000\n",
      "85/85 [==============================] - 0s 892us/sample - loss: 0.7602 - p_acc: 0.6138 - val_loss: 1.1567 - val_p_acc: 0.5897\n",
      "Epoch 4351/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.7251 - p_acc: 0.7027 - val_loss: 1.1575 - val_p_acc: 0.5545\n",
      "Epoch 4352/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7749 - p_acc: 0.6466 - val_loss: 1.1562 - val_p_acc: 0.5016\n",
      "Epoch 4353/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7294 - p_acc: 0.6819 - val_loss: 1.1522 - val_p_acc: 0.4631\n",
      "Epoch 4354/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8346 - p_acc: 0.6434 - val_loss: 1.1498 - val_p_acc: 0.4599\n",
      "Epoch 4355/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7446 - p_acc: 0.6715 - val_loss: 1.1502 - val_p_acc: 0.5160\n",
      "Epoch 4356/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8203 - p_acc: 0.5513 - val_loss: 1.1507 - val_p_acc: 0.5160\n",
      "Epoch 4357/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 0.7873 - p_acc: 0.7131 - val_loss: 1.1491 - val_p_acc: 0.5513\n",
      "Epoch 4358/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.8020 - p_acc: 0.7236 - val_loss: 1.1503 - val_p_acc: 0.4808\n",
      "Epoch 4359/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7866 - p_acc: 0.6122 - val_loss: 1.1527 - val_p_acc: 0.5192\n",
      "Epoch 4360/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7472 - p_acc: 0.6883 - val_loss: 1.1544 - val_p_acc: 0.5545\n",
      "Epoch 4361/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8672 - p_acc: 0.5841 - val_loss: 1.1579 - val_p_acc: 0.4840\n",
      "Epoch 4362/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7349 - p_acc: 0.7163 - val_loss: 1.1571 - val_p_acc: 0.5016\n",
      "Epoch 4363/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8472 - p_acc: 0.6402 - val_loss: 1.1561 - val_p_acc: 0.5016\n",
      "Epoch 4364/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7521 - p_acc: 0.6747 - val_loss: 1.1541 - val_p_acc: 0.5577\n",
      "Epoch 4365/5000\n",
      "85/85 [==============================] - 0s 845us/sample - loss: 0.8489 - p_acc: 0.6418 - val_loss: 1.1532 - val_p_acc: 0.4808\n",
      "Epoch 4366/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7557 - p_acc: 0.6939 - val_loss: 1.1512 - val_p_acc: 0.5401\n",
      "Epoch 4367/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7677 - p_acc: 0.6747 - val_loss: 1.1523 - val_p_acc: 0.4872\n",
      "Epoch 4368/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7553 - p_acc: 0.6643 - val_loss: 1.1551 - val_p_acc: 0.5224\n",
      "Epoch 4369/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7110 - p_acc: 0.7115 - val_loss: 1.1545 - val_p_acc: 0.5224\n",
      "Epoch 4370/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7978 - p_acc: 0.6330 - val_loss: 1.1569 - val_p_acc: 0.5224\n",
      "Epoch 4371/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8551 - p_acc: 0.5841 - val_loss: 1.1566 - val_p_acc: 0.5577\n",
      "Epoch 4372/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7268 - p_acc: 0.7220 - val_loss: 1.1600 - val_p_acc: 0.5401\n",
      "Epoch 4373/5000\n",
      "85/85 [==============================] - 0s 881us/sample - loss: 0.8132 - p_acc: 0.6122 - val_loss: 1.1590 - val_p_acc: 0.5401\n",
      "Epoch 4374/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 0.7887 - p_acc: 0.6675 - val_loss: 1.1567 - val_p_acc: 0.5401\n",
      "Epoch 4375/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7316 - p_acc: 0.6122 - val_loss: 1.1546 - val_p_acc: 0.5577\n",
      "Epoch 4376/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7000 - p_acc: 0.6803 - val_loss: 1.1540 - val_p_acc: 0.5401\n",
      "Epoch 4377/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7539 - p_acc: 0.6715 - val_loss: 1.1517 - val_p_acc: 0.5929\n",
      "Epoch 4378/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8134 - p_acc: 0.6971 - val_loss: 1.1518 - val_p_acc: 0.5401\n",
      "Epoch 4379/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7157 - p_acc: 0.7220 - val_loss: 1.1522 - val_p_acc: 0.5401\n",
      "Epoch 4380/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8561 - p_acc: 0.6923 - val_loss: 1.1541 - val_p_acc: 0.5048\n",
      "Epoch 4381/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7341 - p_acc: 0.6659 - val_loss: 1.1552 - val_p_acc: 0.5048\n",
      "Epoch 4382/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7489 - p_acc: 0.6851 - val_loss: 1.1559 - val_p_acc: 0.5753\n",
      "Epoch 4383/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8189 - p_acc: 0.6242 - val_loss: 1.1566 - val_p_acc: 0.5577\n",
      "Epoch 4384/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7517 - p_acc: 0.6939 - val_loss: 1.1630 - val_p_acc: 0.5401\n",
      "Epoch 4385/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7710 - p_acc: 0.6554 - val_loss: 1.1677 - val_p_acc: 0.5401\n",
      "Epoch 4386/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6980 - p_acc: 0.7131 - val_loss: 1.1727 - val_p_acc: 0.5369\n",
      "Epoch 4387/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7482 - p_acc: 0.7059 - val_loss: 1.1750 - val_p_acc: 0.5016\n",
      "Epoch 4388/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7737 - p_acc: 0.6659 - val_loss: 1.1776 - val_p_acc: 0.4663\n",
      "Epoch 4389/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7474 - p_acc: 0.6643 - val_loss: 1.1808 - val_p_acc: 0.5192\n",
      "Epoch 4390/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7101 - p_acc: 0.7516 - val_loss: 1.1843 - val_p_acc: 0.5016\n",
      "Epoch 4391/5000\n",
      "85/85 [==============================] - 0s 708us/sample - loss: 0.8274 - p_acc: 0.6002 - val_loss: 1.1898 - val_p_acc: 0.5192\n",
      "Epoch 4392/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7860 - p_acc: 0.6819 - val_loss: 1.1943 - val_p_acc: 0.4840\n",
      "Epoch 4393/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7602 - p_acc: 0.6522 - val_loss: 1.1972 - val_p_acc: 0.4840\n",
      "Epoch 4394/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7905 - p_acc: 0.7756 - val_loss: 1.1994 - val_p_acc: 0.5016\n",
      "Epoch 4395/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.6587 - p_acc: 0.7011 - val_loss: 1.1994 - val_p_acc: 0.5192\n",
      "Epoch 4396/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7785 - p_acc: 0.6955 - val_loss: 1.2013 - val_p_acc: 0.5192\n",
      "Epoch 4397/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7191 - p_acc: 0.6731 - val_loss: 1.2007 - val_p_acc: 0.5016\n",
      "Epoch 4398/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7376 - p_acc: 0.7220 - val_loss: 1.1983 - val_p_acc: 0.5369\n",
      "Epoch 4399/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8420 - p_acc: 0.6699 - val_loss: 1.1963 - val_p_acc: 0.5545\n",
      "Epoch 4400/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7860 - p_acc: 0.7236 - val_loss: 1.1945 - val_p_acc: 0.5192\n",
      "Epoch 4401/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7618 - p_acc: 0.7444 - val_loss: 1.1904 - val_p_acc: 0.5016\n",
      "Epoch 4402/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8285 - p_acc: 0.6851 - val_loss: 1.1896 - val_p_acc: 0.5369\n",
      "Epoch 4403/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7379 - p_acc: 0.6819 - val_loss: 1.1854 - val_p_acc: 0.4840\n",
      "Epoch 4404/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6921 - p_acc: 0.7460 - val_loss: 1.1847 - val_p_acc: 0.5016\n",
      "Epoch 4405/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6711 - p_acc: 0.7564 - val_loss: 1.1828 - val_p_acc: 0.5192\n",
      "Epoch 4406/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8478 - p_acc: 0.6066 - val_loss: 1.1842 - val_p_acc: 0.5016\n",
      "Epoch 4407/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7969 - p_acc: 0.6867 - val_loss: 1.1903 - val_p_acc: 0.5192\n",
      "Epoch 4408/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8088 - p_acc: 0.6643 - val_loss: 1.1940 - val_p_acc: 0.5192\n",
      "Epoch 4409/5000\n",
      "85/85 [==============================] - 0s 701us/sample - loss: 0.8356 - p_acc: 0.6466 - val_loss: 1.1949 - val_p_acc: 0.5016\n",
      "Epoch 4410/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7006 - p_acc: 0.6955 - val_loss: 1.1938 - val_p_acc: 0.5192\n",
      "Epoch 4411/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7026 - p_acc: 0.7340 - val_loss: 1.1911 - val_p_acc: 0.5192\n",
      "Epoch 4412/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7086 - p_acc: 0.7147 - val_loss: 1.1900 - val_p_acc: 0.5192\n",
      "Epoch 4413/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7350 - p_acc: 0.7220 - val_loss: 1.1897 - val_p_acc: 0.5369\n",
      "Epoch 4414/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7140 - p_acc: 0.6330 - val_loss: 1.1884 - val_p_acc: 0.5369\n",
      "Epoch 4415/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7386 - p_acc: 0.7147 - val_loss: 1.1871 - val_p_acc: 0.4840\n",
      "Epoch 4416/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7465 - p_acc: 0.7220 - val_loss: 1.1836 - val_p_acc: 0.5401\n",
      "Epoch 4417/5000\n",
      "85/85 [==============================] - 0s 710us/sample - loss: 0.6683 - p_acc: 0.6987 - val_loss: 1.1803 - val_p_acc: 0.5401\n",
      "Epoch 4418/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6769 - p_acc: 0.7147 - val_loss: 1.1822 - val_p_acc: 0.5369\n",
      "Epoch 4419/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8419 - p_acc: 0.7027 - val_loss: 1.1852 - val_p_acc: 0.5192\n",
      "Epoch 4420/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7567 - p_acc: 0.7236 - val_loss: 1.1887 - val_p_acc: 0.5016\n",
      "Epoch 4421/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7897 - p_acc: 0.6643 - val_loss: 1.1872 - val_p_acc: 0.4840\n",
      "Epoch 4422/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7239 - p_acc: 0.6779 - val_loss: 1.1865 - val_p_acc: 0.5016\n",
      "Epoch 4423/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6411 - p_acc: 0.7324 - val_loss: 1.1851 - val_p_acc: 0.5192\n",
      "Epoch 4424/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.8045 - p_acc: 0.6450 - val_loss: 1.1846 - val_p_acc: 0.5401\n",
      "Epoch 4425/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7195 - p_acc: 0.6554 - val_loss: 1.1820 - val_p_acc: 0.5224\n",
      "Epoch 4426/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8139 - p_acc: 0.7444 - val_loss: 1.1824 - val_p_acc: 0.5577\n",
      "Epoch 4427/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7152 - p_acc: 0.6210 - val_loss: 1.1826 - val_p_acc: 0.5016\n",
      "Epoch 4428/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8070 - p_acc: 0.6715 - val_loss: 1.1825 - val_p_acc: 0.5192\n",
      "Epoch 4429/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7555 - p_acc: 0.7564 - val_loss: 1.1808 - val_p_acc: 0.5016\n",
      "Epoch 4430/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7317 - p_acc: 0.7620 - val_loss: 1.1795 - val_p_acc: 0.4840\n",
      "Epoch 4431/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6217 - p_acc: 0.8157 - val_loss: 1.1788 - val_p_acc: 0.5369\n",
      "Epoch 4432/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5460 - p_acc: 0.833 - 0s 715us/sample - loss: 0.7965 - p_acc: 0.7059 - val_loss: 1.1785 - val_p_acc: 0.5929\n",
      "Epoch 4433/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.6777 - p_acc: 0.7043 - val_loss: 1.1775 - val_p_acc: 0.5048\n",
      "Epoch 4434/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8598 - p_acc: 0.6330 - val_loss: 1.1775 - val_p_acc: 0.5048\n",
      "Epoch 4435/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7487 - p_acc: 0.6362 - val_loss: 1.1785 - val_p_acc: 0.5048\n",
      "Epoch 4436/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6830 - p_acc: 0.7548 - val_loss: 1.1772 - val_p_acc: 0.5401\n",
      "Epoch 4437/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7390 - p_acc: 0.6747 - val_loss: 1.1758 - val_p_acc: 0.5048\n",
      "Epoch 4438/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 0.7945 - p_acc: 0.6675 - val_loss: 1.1734 - val_p_acc: 0.5048\n",
      "Epoch 4439/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6950 - p_acc: 0.7532 - val_loss: 1.1715 - val_p_acc: 0.5016\n",
      "Epoch 4440/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7565 - p_acc: 0.7220 - val_loss: 1.1681 - val_p_acc: 0.5192\n",
      "Epoch 4441/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7561 - p_acc: 0.6418 - val_loss: 1.1665 - val_p_acc: 0.5192\n",
      "Epoch 4442/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6769 - p_acc: 0.7636 - val_loss: 1.1662 - val_p_acc: 0.5369\n",
      "Epoch 4443/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7262 - p_acc: 0.7308 - val_loss: 1.1660 - val_p_acc: 0.5369\n",
      "Epoch 4444/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.6615 - p_acc: 0.6731 - val_loss: 1.1667 - val_p_acc: 0.5192\n",
      "Epoch 4445/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7678 - p_acc: 0.7652 - val_loss: 1.1655 - val_p_acc: 0.5016\n",
      "Epoch 4446/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7139 - p_acc: 0.7027 - val_loss: 1.1649 - val_p_acc: 0.5192\n",
      "Epoch 4447/5000\n",
      "85/85 [==============================] - 0s 707us/sample - loss: 0.7135 - p_acc: 0.7740 - val_loss: 1.1662 - val_p_acc: 0.4840\n",
      "Epoch 4448/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7714 - p_acc: 0.6835 - val_loss: 1.1666 - val_p_acc: 0.5545\n",
      "Epoch 4449/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8096 - p_acc: 0.6154 - val_loss: 1.1660 - val_p_acc: 0.4663\n",
      "Epoch 4450/5000\n",
      "85/85 [==============================] - 0s 700us/sample - loss: 0.7069 - p_acc: 0.7236 - val_loss: 1.1671 - val_p_acc: 0.5192\n",
      "Epoch 4451/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6601 - p_acc: 0.7564 - val_loss: 1.1673 - val_p_acc: 0.5401\n",
      "Epoch 4452/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7023 - p_acc: 0.6659 - val_loss: 1.1687 - val_p_acc: 0.5401\n",
      "Epoch 4453/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7497 - p_acc: 0.6835 - val_loss: 1.1688 - val_p_acc: 0.4696\n",
      "Epoch 4454/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.7563 - p_acc: 0.6835 - val_loss: 1.1682 - val_p_acc: 0.5224\n",
      "Epoch 4455/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8250 - p_acc: 0.6482 - val_loss: 1.1684 - val_p_acc: 0.5577\n",
      "Epoch 4456/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7898 - p_acc: 0.7043 - val_loss: 1.1692 - val_p_acc: 0.5224\n",
      "Epoch 4457/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7778 - p_acc: 0.7131 - val_loss: 1.1684 - val_p_acc: 0.5224\n",
      "Epoch 4458/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7709 - p_acc: 0.6378 - val_loss: 1.1683 - val_p_acc: 0.5753\n",
      "Epoch 4459/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7687 - p_acc: 0.7163 - val_loss: 1.1663 - val_p_acc: 0.5224\n",
      "Epoch 4460/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7872 - p_acc: 0.6226 - val_loss: 1.1659 - val_p_acc: 0.5224\n",
      "Epoch 4461/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7370 - p_acc: 0.6835 - val_loss: 1.1635 - val_p_acc: 0.5401\n",
      "Epoch 4462/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7621 - p_acc: 0.6643 - val_loss: 1.1623 - val_p_acc: 0.5577\n",
      "Epoch 4463/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8142 - p_acc: 0.6627 - val_loss: 1.1613 - val_p_acc: 0.5192\n",
      "Epoch 4464/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6799 - p_acc: 0.6643 - val_loss: 1.1592 - val_p_acc: 0.5016\n",
      "Epoch 4465/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8562 - p_acc: 0.6346 - val_loss: 1.1571 - val_p_acc: 0.5337\n",
      "Epoch 4466/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8034 - p_acc: 0.7075 - val_loss: 1.1559 - val_p_acc: 0.5337\n",
      "Epoch 4467/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7040 - p_acc: 0.6923 - val_loss: 1.1572 - val_p_acc: 0.5160\n",
      "Epoch 4468/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.6995 - p_acc: 0.6138 - val_loss: 1.1589 - val_p_acc: 0.4808\n",
      "Epoch 4469/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7860 - p_acc: 0.666 - 0s 692us/sample - loss: 0.8271 - p_acc: 0.6138 - val_loss: 1.1589 - val_p_acc: 0.4984\n",
      "Epoch 4470/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7796 - p_acc: 0.6995 - val_loss: 1.1589 - val_p_acc: 0.4808\n",
      "Epoch 4471/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7149 - p_acc: 0.6851 - val_loss: 1.1582 - val_p_acc: 0.4631\n",
      "Epoch 4472/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7545 - p_acc: 0.7324 - val_loss: 1.1578 - val_p_acc: 0.4984\n",
      "Epoch 4473/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.6939 - p_acc: 0.7460 - val_loss: 1.1557 - val_p_acc: 0.4984\n",
      "Epoch 4474/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6913 - p_acc: 0.6923 - val_loss: 1.1550 - val_p_acc: 0.5160\n",
      "Epoch 4475/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7030 - p_acc: 0.7115 - val_loss: 1.1547 - val_p_acc: 0.4808\n",
      "Epoch 4476/5000\n",
      "85/85 [==============================] - 0s 688us/sample - loss: 0.7077 - p_acc: 0.7043 - val_loss: 1.1548 - val_p_acc: 0.4455\n",
      "Epoch 4477/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8157 - p_acc: 0.6883 - val_loss: 1.1547 - val_p_acc: 0.4455\n",
      "Epoch 4478/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7301 - p_acc: 0.6394 - val_loss: 1.1556 - val_p_acc: 0.4808\n",
      "Epoch 4479/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7758 - p_acc: 0.6210 - val_loss: 1.1574 - val_p_acc: 0.4663\n",
      "Epoch 4480/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6997 - p_acc: 0.6170 - val_loss: 1.1592 - val_p_acc: 0.4840\n",
      "Epoch 4481/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7810 - p_acc: 0.7268 - val_loss: 1.1572 - val_p_acc: 0.5192\n",
      "Epoch 4482/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6541 - p_acc: 0.7845 - val_loss: 1.1555 - val_p_acc: 0.5192\n",
      "Epoch 4483/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6248 - p_acc: 0.7949 - val_loss: 1.1562 - val_p_acc: 0.5160\n",
      "Epoch 4484/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7896 - p_acc: 0.7043 - val_loss: 1.1567 - val_p_acc: 0.5369\n",
      "Epoch 4485/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7409 - p_acc: 0.6907 - val_loss: 1.1547 - val_p_acc: 0.4455\n",
      "Epoch 4486/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7496 - p_acc: 0.7652 - val_loss: 1.1552 - val_p_acc: 0.4808\n",
      "Epoch 4487/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7379 - p_acc: 0.6298 - val_loss: 1.1552 - val_p_acc: 0.5016\n",
      "Epoch 4488/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7571 - p_acc: 0.7340 - val_loss: 1.1548 - val_p_acc: 0.5545\n",
      "Epoch 4489/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7559 - p_acc: 0.6522 - val_loss: 1.1556 - val_p_acc: 0.5016\n",
      "Epoch 4490/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8473 - p_acc: 0.6643 - val_loss: 1.1561 - val_p_acc: 0.5545\n",
      "Epoch 4491/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7738 - p_acc: 0.7115 - val_loss: 1.1538 - val_p_acc: 0.5016\n",
      "Epoch 4492/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8209 - p_acc: 0.6258 - val_loss: 1.1529 - val_p_acc: 0.5016\n",
      "Epoch 4493/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7193 - p_acc: 0.7131 - val_loss: 1.1534 - val_p_acc: 0.5401\n",
      "Epoch 4494/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7629 - p_acc: 0.5841 - val_loss: 1.1539 - val_p_acc: 0.5160\n",
      "Epoch 4495/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7096 - p_acc: 0.7027 - val_loss: 1.1553 - val_p_acc: 0.5016\n",
      "Epoch 4496/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8009 - p_acc: 0.5946 - val_loss: 1.1574 - val_p_acc: 0.5016\n",
      "Epoch 4497/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7260 - p_acc: 0.7428 - val_loss: 1.1597 - val_p_acc: 0.5577\n",
      "Epoch 4498/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7795 - p_acc: 0.6659 - val_loss: 1.1633 - val_p_acc: 0.4872\n",
      "Epoch 4499/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7560 - p_acc: 0.6731 - val_loss: 1.1640 - val_p_acc: 0.5369\n",
      "Epoch 4500/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7431 - p_acc: 0.6747 - val_loss: 1.1645 - val_p_acc: 0.5192\n",
      "Epoch 4501/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7269 - p_acc: 0.6643 - val_loss: 1.1658 - val_p_acc: 0.5721\n",
      "Epoch 4502/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8413 - p_acc: 0.6538 - val_loss: 1.1673 - val_p_acc: 0.4840\n",
      "Epoch 4503/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7814 - p_acc: 0.6170 - val_loss: 1.1672 - val_p_acc: 0.5016\n",
      "Epoch 4504/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7044 - p_acc: 0.7115 - val_loss: 1.1684 - val_p_acc: 0.5192\n",
      "Epoch 4505/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7368 - p_acc: 0.6803 - val_loss: 1.1698 - val_p_acc: 0.5016\n",
      "Epoch 4506/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7650 - p_acc: 0.6611 - val_loss: 1.1690 - val_p_acc: 0.5016\n",
      "Epoch 4507/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7817 - p_acc: 0.6731 - val_loss: 1.1715 - val_p_acc: 0.5545\n",
      "Epoch 4508/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7590 - p_acc: 0.7027 - val_loss: 1.1717 - val_p_acc: 0.5192\n",
      "Epoch 4509/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8066 - p_acc: 0.6538 - val_loss: 1.1739 - val_p_acc: 0.5192\n",
      "Epoch 4510/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.6972 - p_acc: 0.6362 - val_loss: 1.1744 - val_p_acc: 0.5016\n",
      "Epoch 4511/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6706 - p_acc: 0.7356 - val_loss: 1.1745 - val_p_acc: 0.5545\n",
      "Epoch 4512/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7403 - p_acc: 0.7740 - val_loss: 1.1706 - val_p_acc: 0.5016\n",
      "Epoch 4513/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7005 - p_acc: 0.7428 - val_loss: 1.1697 - val_p_acc: 0.5721\n",
      "Epoch 4514/5000\n",
      "85/85 [==============================] - 0s 725us/sample - loss: 0.7210 - p_acc: 0.6779 - val_loss: 1.1694 - val_p_acc: 0.5192\n",
      "Epoch 4515/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8358 - p_acc: 0.7027 - val_loss: 1.1684 - val_p_acc: 0.4663\n",
      "Epoch 4516/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7140 - p_acc: 0.7099 - val_loss: 1.1661 - val_p_acc: 0.4808\n",
      "Epoch 4517/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7601 - p_acc: 0.6554 - val_loss: 1.1654 - val_p_acc: 0.4631\n",
      "Epoch 4518/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8868 - p_acc: 0.6434 - val_loss: 1.1670 - val_p_acc: 0.4663\n",
      "Epoch 4519/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7567 - p_acc: 0.6418 - val_loss: 1.1733 - val_p_acc: 0.5369\n",
      "Epoch 4520/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7298 - p_acc: 0.6643 - val_loss: 1.1792 - val_p_acc: 0.5016\n",
      "Epoch 4521/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8685 - p_acc: 0.6747 - val_loss: 1.1821 - val_p_acc: 0.5016\n",
      "Epoch 4522/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8246 - p_acc: 0.6450 - val_loss: 1.1797 - val_p_acc: 0.5369\n",
      "Epoch 4523/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7929 - p_acc: 0.6298 - val_loss: 1.1778 - val_p_acc: 0.5192\n",
      "Epoch 4524/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7437 - p_acc: 0.6939 - val_loss: 1.1763 - val_p_acc: 0.4840\n",
      "Epoch 4525/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7316 - p_acc: 0.6747 - val_loss: 1.1754 - val_p_acc: 0.4840\n",
      "Epoch 4526/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7915 - p_acc: 0.6763 - val_loss: 1.1749 - val_p_acc: 0.5016\n",
      "Epoch 4527/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7190 - p_acc: 0.6627 - val_loss: 1.1758 - val_p_acc: 0.5721\n",
      "Epoch 4528/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7088 - p_acc: 0.6450 - val_loss: 1.1768 - val_p_acc: 0.5545\n",
      "Epoch 4529/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7285 - p_acc: 0.7532 - val_loss: 1.1774 - val_p_acc: 0.5192\n",
      "Epoch 4530/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8062 - p_acc: 0.6434 - val_loss: 1.1780 - val_p_acc: 0.5192\n",
      "Epoch 4531/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7089 - p_acc: 0.7220 - val_loss: 1.1790 - val_p_acc: 0.4663\n",
      "Epoch 4532/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6853 - p_acc: 0.7131 - val_loss: 1.1775 - val_p_acc: 0.5192\n",
      "Epoch 4533/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6514 - p_acc: 0.7308 - val_loss: 1.1773 - val_p_acc: 0.5369\n",
      "Epoch 4534/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6641 - p_acc: 0.7388 - val_loss: 1.1761 - val_p_acc: 0.5721\n",
      "Epoch 4535/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6665 - p_acc: 0.7492 - val_loss: 1.1742 - val_p_acc: 0.5545\n",
      "Epoch 4536/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7325 - p_acc: 0.6538 - val_loss: 1.1719 - val_p_acc: 0.4487\n",
      "Epoch 4537/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8331 - p_acc: 0.6050 - val_loss: 1.1712 - val_p_acc: 0.4840\n",
      "Epoch 4538/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7029 - p_acc: 0.6851 - val_loss: 1.1718 - val_p_acc: 0.5192\n",
      "Epoch 4539/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6547 - p_acc: 0.6867 - val_loss: 1.1700 - val_p_acc: 0.4663\n",
      "Epoch 4540/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7559 - p_acc: 0.7829 - val_loss: 1.1692 - val_p_acc: 0.4663\n",
      "Epoch 4541/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.6842 - p_acc: 0.7043 - val_loss: 1.1676 - val_p_acc: 0.4840\n",
      "Epoch 4542/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8080 - p_acc: 0.6715 - val_loss: 1.1681 - val_p_acc: 0.5016\n",
      "Epoch 4543/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7159 - p_acc: 0.6522 - val_loss: 1.1670 - val_p_acc: 0.5192\n",
      "Epoch 4544/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7646 - p_acc: 0.7043 - val_loss: 1.1667 - val_p_acc: 0.5016\n",
      "Epoch 4545/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7632 - p_acc: 0.7324 - val_loss: 1.1650 - val_p_acc: 0.5369\n",
      "Epoch 4546/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7977 - p_acc: 0.6418 - val_loss: 1.1654 - val_p_acc: 0.4487\n",
      "Epoch 4547/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7283 - p_acc: 0.6242 - val_loss: 1.1650 - val_p_acc: 0.4840\n",
      "Epoch 4548/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7604 - p_acc: 0.6258 - val_loss: 1.1606 - val_p_acc: 0.4984\n",
      "Epoch 4549/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.6446 - p_acc: 0.7476 - val_loss: 1.1566 - val_p_acc: 0.4808\n",
      "Epoch 4550/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7841 - p_acc: 0.6450 - val_loss: 1.1549 - val_p_acc: 0.4984\n",
      "Epoch 4551/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6939 - p_acc: 0.6851 - val_loss: 1.1531 - val_p_acc: 0.4808\n",
      "Epoch 4552/5000\n",
      "85/85 [==============================] - 0s 719us/sample - loss: 0.7526 - p_acc: 0.6210 - val_loss: 1.1521 - val_p_acc: 0.4631\n",
      "Epoch 4553/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7769 - p_acc: 0.6210 - val_loss: 1.1536 - val_p_acc: 0.4631\n",
      "Epoch 4554/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7584 - p_acc: 0.7099 - val_loss: 1.1537 - val_p_acc: 0.5160\n",
      "Epoch 4555/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.7438 - p_acc: 0.6715 - val_loss: 1.1528 - val_p_acc: 0.4984\n",
      "Epoch 4556/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7032 - p_acc: 0.7917 - val_loss: 1.1530 - val_p_acc: 0.4984\n",
      "Epoch 4557/5000\n",
      "85/85 [==============================] - 0s 752us/sample - loss: 0.7262 - p_acc: 0.6346 - val_loss: 1.1506 - val_p_acc: 0.4631\n",
      "Epoch 4558/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7646 - p_acc: 0.7460 - val_loss: 1.1505 - val_p_acc: 0.4808\n",
      "Epoch 4559/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8030 - p_acc: 0.6450 - val_loss: 1.1523 - val_p_acc: 0.5160\n",
      "Epoch 4560/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7450 - p_acc: 0.7340 - val_loss: 1.1552 - val_p_acc: 0.5369\n",
      "Epoch 4561/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7594 - p_acc: 0.6923 - val_loss: 1.1580 - val_p_acc: 0.4663\n",
      "Epoch 4562/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6681 - p_acc: 0.7532 - val_loss: 1.1590 - val_p_acc: 0.5016\n",
      "Epoch 4563/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7438 - p_acc: 0.6330 - val_loss: 1.1594 - val_p_acc: 0.5192\n",
      "Epoch 4564/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7937 - p_acc: 0.6330 - val_loss: 1.1615 - val_p_acc: 0.5016\n",
      "Epoch 4565/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.6545 - p_acc: 0.6643 - val_loss: 1.1622 - val_p_acc: 0.4840\n",
      "Epoch 4566/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8005 - p_acc: 0.6450 - val_loss: 1.1592 - val_p_acc: 0.5016\n",
      "Epoch 4567/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7442 - p_acc: 0.6434 - val_loss: 1.1573 - val_p_acc: 0.5016\n",
      "Epoch 4568/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7765 - p_acc: 0.6851 - val_loss: 1.1552 - val_p_acc: 0.4455\n",
      "Epoch 4569/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7350 - p_acc: 0.6554 - val_loss: 1.1535 - val_p_acc: 0.4808\n",
      "Epoch 4570/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6951 - p_acc: 0.7131 - val_loss: 1.1511 - val_p_acc: 0.4631\n",
      "Epoch 4571/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6789 - p_acc: 0.6939 - val_loss: 1.1495 - val_p_acc: 0.4455\n",
      "Epoch 4572/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7143 - p_acc: 0.6611 - val_loss: 1.1505 - val_p_acc: 0.4279\n",
      "Epoch 4573/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7234 - p_acc: 0.7268 - val_loss: 1.1504 - val_p_acc: 0.4808\n",
      "Epoch 4574/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8227 - p_acc: 0.6330 - val_loss: 1.1506 - val_p_acc: 0.4808\n",
      "Epoch 4575/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7337 - p_acc: 0.6851 - val_loss: 1.1492 - val_p_acc: 0.4808\n",
      "Epoch 4576/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7054 - p_acc: 0.6506 - val_loss: 1.1476 - val_p_acc: 0.4808\n",
      "Epoch 4577/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7672 - p_acc: 0.6779 - val_loss: 1.1468 - val_p_acc: 0.4631\n",
      "Epoch 4578/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7035 - p_acc: 0.7548 - val_loss: 1.1481 - val_p_acc: 0.4279\n",
      "Epoch 4579/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7399 - p_acc: 0.7324 - val_loss: 1.1474 - val_p_acc: 0.4455\n",
      "Epoch 4580/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7335 - p_acc: 0.7043 - val_loss: 1.1479 - val_p_acc: 0.4808\n",
      "Epoch 4581/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8089 - p_acc: 0.7236 - val_loss: 1.1483 - val_p_acc: 0.4808\n",
      "Epoch 4582/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6128 - p_acc: 0.7620 - val_loss: 1.1464 - val_p_acc: 0.4808\n",
      "Epoch 4583/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7268 - p_acc: 0.7324 - val_loss: 1.1456 - val_p_acc: 0.5160\n",
      "Epoch 4584/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7885 - p_acc: 0.6538 - val_loss: 1.1476 - val_p_acc: 0.4631\n",
      "Epoch 4585/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7988 - p_acc: 0.6923 - val_loss: 1.1463 - val_p_acc: 0.4984\n",
      "Epoch 4586/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6907 - p_acc: 0.6835 - val_loss: 1.1437 - val_p_acc: 0.5160\n",
      "Epoch 4587/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7894 - p_acc: 0.6939 - val_loss: 1.1424 - val_p_acc: 0.4808\n",
      "Epoch 4588/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7981 - p_acc: 0.6611 - val_loss: 1.1416 - val_p_acc: 0.4984\n",
      "Epoch 4589/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6933 - p_acc: 0.7099 - val_loss: 1.1414 - val_p_acc: 0.5337\n",
      "Epoch 4590/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6507 - p_acc: 0.7636 - val_loss: 1.1403 - val_p_acc: 0.5513\n",
      "Epoch 4591/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7587 - p_acc: 0.6923 - val_loss: 1.1413 - val_p_acc: 0.4808\n",
      "Epoch 4592/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7935 - p_acc: 0.7011 - val_loss: 1.1417 - val_p_acc: 0.5337\n",
      "Epoch 4593/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.6824 - p_acc: 0.7147 - val_loss: 1.1424 - val_p_acc: 0.4984\n",
      "Epoch 4594/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7682 - p_acc: 0.6715 - val_loss: 1.1427 - val_p_acc: 0.4808\n",
      "Epoch 4595/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7007 - p_acc: 0.6835 - val_loss: 1.1423 - val_p_acc: 0.4631\n",
      "Epoch 4596/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7457 - p_acc: 0.6715 - val_loss: 1.1415 - val_p_acc: 0.4808\n",
      "Epoch 4597/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7520 - p_acc: 0.6330 - val_loss: 1.1410 - val_p_acc: 0.4808\n",
      "Epoch 4598/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7266 - p_acc: 0.6955 - val_loss: 1.1414 - val_p_acc: 0.4984\n",
      "Epoch 4599/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6680 - p_acc: 0.8069 - val_loss: 1.1441 - val_p_acc: 0.4808\n",
      "Epoch 4600/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7027 - p_acc: 0.6362 - val_loss: 1.1448 - val_p_acc: 0.5160\n",
      "Epoch 4601/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7089 - p_acc: 0.7564 - val_loss: 1.1434 - val_p_acc: 0.4984\n",
      "Epoch 4602/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8075 - p_acc: 0.6138 - val_loss: 1.1439 - val_p_acc: 0.4808\n",
      "Epoch 4603/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6944 - p_acc: 0.7163 - val_loss: 1.1436 - val_p_acc: 0.4279\n",
      "Epoch 4604/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7876 - p_acc: 0.6627 - val_loss: 1.1422 - val_p_acc: 0.4631\n",
      "Epoch 4605/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.6442 - p_acc: 0.7444 - val_loss: 1.1437 - val_p_acc: 0.4808\n",
      "Epoch 4606/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8372 - p_acc: 0.6627 - val_loss: 1.1451 - val_p_acc: 0.4631\n",
      "Epoch 4607/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.8009 - p_acc: 0.6819 - val_loss: 1.1472 - val_p_acc: 0.4984\n",
      "Epoch 4608/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7522 - p_acc: 0.7220 - val_loss: 1.1483 - val_p_acc: 0.4631\n",
      "Epoch 4609/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7081 - p_acc: 0.6122 - val_loss: 1.1503 - val_p_acc: 0.5160\n",
      "Epoch 4610/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8395 - p_acc: 0.6923 - val_loss: 1.1509 - val_p_acc: 0.4840\n",
      "Epoch 4611/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7398 - p_acc: 0.7059 - val_loss: 1.1528 - val_p_acc: 0.4663\n",
      "Epoch 4612/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7515 - p_acc: 0.6330 - val_loss: 1.1540 - val_p_acc: 0.5016\n",
      "Epoch 4613/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.7354 - p_acc: 0.7340 - val_loss: 1.1541 - val_p_acc: 0.5016\n",
      "Epoch 4614/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8387 - p_acc: 0.6242 - val_loss: 1.1547 - val_p_acc: 0.5192\n",
      "Epoch 4615/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7289 - p_acc: 0.7252 - val_loss: 1.1516 - val_p_acc: 0.4840\n",
      "Epoch 4616/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7136 - p_acc: 0.7147 - val_loss: 1.1535 - val_p_acc: 0.5369\n",
      "Epoch 4617/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8340 - p_acc: 0.6066 - val_loss: 1.1546 - val_p_acc: 0.5369\n",
      "Epoch 4618/5000\n",
      "85/85 [==============================] - 0s 721us/sample - loss: 0.7512 - p_acc: 0.7115 - val_loss: 1.1534 - val_p_acc: 0.5369\n",
      "Epoch 4619/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7981 - p_acc: 0.6611 - val_loss: 1.1532 - val_p_acc: 0.5369\n",
      "Epoch 4620/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7319 - p_acc: 0.6747 - val_loss: 1.1545 - val_p_acc: 0.5016\n",
      "Epoch 4621/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7462 - p_acc: 0.6867 - val_loss: 1.1566 - val_p_acc: 0.5048\n",
      "Epoch 4622/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7296 - p_acc: 0.6747 - val_loss: 1.1568 - val_p_acc: 0.5577\n",
      "Epoch 4623/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.9017 - p_acc: 0.6210 - val_loss: 1.1575 - val_p_acc: 0.5401\n",
      "Epoch 4624/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7607 - p_acc: 0.7059 - val_loss: 1.1601 - val_p_acc: 0.5224\n",
      "Epoch 4625/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7039 - p_acc: 0.7444 - val_loss: 1.1624 - val_p_acc: 0.5048\n",
      "Epoch 4626/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7156 - p_acc: 0.6611 - val_loss: 1.1638 - val_p_acc: 0.5224\n",
      "Epoch 4627/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7413 - p_acc: 0.7516 - val_loss: 1.1661 - val_p_acc: 0.5577\n",
      "Epoch 4628/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8162 - p_acc: 0.6554 - val_loss: 1.1676 - val_p_acc: 0.5401\n",
      "Epoch 4629/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6870 - p_acc: 0.6851 - val_loss: 1.1678 - val_p_acc: 0.5577\n",
      "Epoch 4630/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7319 - p_acc: 0.6867 - val_loss: 1.1676 - val_p_acc: 0.5401\n",
      "Epoch 4631/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7664 - p_acc: 0.6763 - val_loss: 1.1662 - val_p_acc: 0.5577\n",
      "Epoch 4632/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8111 - p_acc: 0.6346 - val_loss: 1.1668 - val_p_acc: 0.5401\n",
      "Epoch 4633/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7254 - p_acc: 0.6554 - val_loss: 1.1690 - val_p_acc: 0.4696\n",
      "Epoch 4634/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7007 - p_acc: 0.6538 - val_loss: 1.1679 - val_p_acc: 0.5401\n",
      "Epoch 4635/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7208 - p_acc: 0.6867 - val_loss: 1.1675 - val_p_acc: 0.5048\n",
      "Epoch 4636/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7281 - p_acc: 0.6939 - val_loss: 1.1665 - val_p_acc: 0.5016\n",
      "Epoch 4637/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6844 - p_acc: 0.6554 - val_loss: 1.1659 - val_p_acc: 0.5369\n",
      "Epoch 4638/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7071 - p_acc: 0.6450 - val_loss: 1.1666 - val_p_acc: 0.5192\n",
      "Epoch 4639/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7615 - p_acc: 0.6731 - val_loss: 1.1651 - val_p_acc: 0.5545\n",
      "Epoch 4640/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7567 - p_acc: 0.6659 - val_loss: 1.1630 - val_p_acc: 0.5016\n",
      "Epoch 4641/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7119 - p_acc: 0.6643 - val_loss: 1.1616 - val_p_acc: 0.5192\n",
      "Epoch 4642/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7588 - p_acc: 0.7027 - val_loss: 1.1643 - val_p_acc: 0.4840\n",
      "Epoch 4643/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.8164 - p_acc: 0.6522 - val_loss: 1.1680 - val_p_acc: 0.5545\n",
      "Epoch 4644/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8612 - p_acc: 0.6731 - val_loss: 1.1696 - val_p_acc: 0.5192\n",
      "Epoch 4645/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7496 - p_acc: 0.7236 - val_loss: 1.1729 - val_p_acc: 0.5401\n",
      "Epoch 4646/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.6467 - p_acc: 0.7949 - val_loss: 1.1711 - val_p_acc: 0.5016\n",
      "Epoch 4647/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7499 - p_acc: 0.6955 - val_loss: 1.1708 - val_p_acc: 0.5577\n",
      "Epoch 4648/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7178 - p_acc: 0.6971 - val_loss: 1.1739 - val_p_acc: 0.5401\n",
      "Epoch 4649/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7178 - p_acc: 0.6763 - val_loss: 1.1744 - val_p_acc: 0.5577\n",
      "Epoch 4650/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6785 - p_acc: 0.7147 - val_loss: 1.1739 - val_p_acc: 0.5224\n",
      "Epoch 4651/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7827 - p_acc: 0.6939 - val_loss: 1.1744 - val_p_acc: 0.4840\n",
      "Epoch 4652/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6789 - p_acc: 0.7636 - val_loss: 1.1762 - val_p_acc: 0.5192\n",
      "Epoch 4653/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8128 - p_acc: 0.6434 - val_loss: 1.1768 - val_p_acc: 0.5016\n",
      "Epoch 4654/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7312 - p_acc: 0.7027 - val_loss: 1.1770 - val_p_acc: 0.5192\n",
      "Epoch 4655/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8145 - p_acc: 0.6362 - val_loss: 1.1757 - val_p_acc: 0.5160\n",
      "Epoch 4656/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8165 - p_acc: 0.6643 - val_loss: 1.1723 - val_p_acc: 0.5192\n",
      "Epoch 4657/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7042 - p_acc: 0.7356 - val_loss: 1.1677 - val_p_acc: 0.5192\n",
      "Epoch 4658/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7239 - p_acc: 0.6538 - val_loss: 1.1643 - val_p_acc: 0.5369\n",
      "Epoch 4659/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7835 - p_acc: 0.5913 - val_loss: 1.1625 - val_p_acc: 0.5721\n",
      "Epoch 4660/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8606 - p_acc: 0.5753 - val_loss: 1.1613 - val_p_acc: 0.4663\n",
      "Epoch 4661/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7109 - p_acc: 0.7043 - val_loss: 1.1598 - val_p_acc: 0.5192\n",
      "Epoch 4662/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7930 - p_acc: 0.6819 - val_loss: 1.1617 - val_p_acc: 0.4840\n",
      "Epoch 4663/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7515 - p_acc: 0.6883 - val_loss: 1.1618 - val_p_acc: 0.5369\n",
      "Epoch 4664/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6674 - p_acc: 0.7252 - val_loss: 1.1614 - val_p_acc: 0.5369\n",
      "Epoch 4665/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7812 - p_acc: 0.6883 - val_loss: 1.1627 - val_p_acc: 0.5192\n",
      "Epoch 4666/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7322 - p_acc: 0.6835 - val_loss: 1.1658 - val_p_acc: 0.5545\n",
      "Epoch 4667/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6850 - p_acc: 0.7043 - val_loss: 1.1666 - val_p_acc: 0.4840\n",
      "Epoch 4668/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6791 - p_acc: 0.7933 - val_loss: 1.1672 - val_p_acc: 0.5192\n",
      "Epoch 4669/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7642 - p_acc: 0.6226 - val_loss: 1.1674 - val_p_acc: 0.5192\n",
      "Epoch 4670/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7750 - p_acc: 0.7027 - val_loss: 1.1695 - val_p_acc: 0.5369\n",
      "Epoch 4671/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8007 - p_acc: 0.6418 - val_loss: 1.1707 - val_p_acc: 0.5577\n",
      "Epoch 4672/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8472 - p_acc: 0.6939 - val_loss: 1.1707 - val_p_acc: 0.5577\n",
      "Epoch 4673/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7994 - p_acc: 0.7099 - val_loss: 1.1702 - val_p_acc: 0.5401\n",
      "Epoch 4674/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7499 - p_acc: 0.6346 - val_loss: 1.1692 - val_p_acc: 0.5753\n",
      "Epoch 4675/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7772 - p_acc: 0.6835 - val_loss: 1.1697 - val_p_acc: 0.5753\n",
      "Epoch 4676/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7794 - p_acc: 0.6731 - val_loss: 1.1710 - val_p_acc: 0.5401\n",
      "Epoch 4677/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7279 - p_acc: 0.6466 - val_loss: 1.1710 - val_p_acc: 0.5401\n",
      "Epoch 4678/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.6764 - p_acc: 0.7516 - val_loss: 1.1684 - val_p_acc: 0.5753\n",
      "Epoch 4679/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8100 - p_acc: 0.6611 - val_loss: 1.1650 - val_p_acc: 0.5369\n",
      "Epoch 4680/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7468 - p_acc: 0.6731 - val_loss: 1.1613 - val_p_acc: 0.5016\n",
      "Epoch 4681/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7180 - p_acc: 0.7131 - val_loss: 1.1570 - val_p_acc: 0.5369\n",
      "Epoch 4682/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8077 - p_acc: 0.6907 - val_loss: 1.1575 - val_p_acc: 0.5369\n",
      "Epoch 4683/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8452 - p_acc: 0.6955 - val_loss: 1.1563 - val_p_acc: 0.5369\n",
      "Epoch 4684/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7896 - p_acc: 0.6587 - val_loss: 1.1560 - val_p_acc: 0.5016\n",
      "Epoch 4685/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8168 - p_acc: 0.7027 - val_loss: 1.1555 - val_p_acc: 0.5192\n",
      "Epoch 4686/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8819 - p_acc: 0.6434 - val_loss: 1.1563 - val_p_acc: 0.5545\n",
      "Epoch 4687/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.5810 - p_acc: 0.7636 - val_loss: 1.1543 - val_p_acc: 0.5545\n",
      "Epoch 4688/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8298 - p_acc: 0.6210 - val_loss: 1.1540 - val_p_acc: 0.5192\n",
      "Epoch 4689/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7676 - p_acc: 0.6867 - val_loss: 1.1573 - val_p_acc: 0.5545\n",
      "Epoch 4690/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.6682 - p_acc: 0.7532 - val_loss: 1.1603 - val_p_acc: 0.4840\n",
      "Epoch 4691/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8060 - p_acc: 0.6763 - val_loss: 1.1624 - val_p_acc: 0.5016\n",
      "Epoch 4692/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6908 - p_acc: 0.7115 - val_loss: 1.1629 - val_p_acc: 0.5192\n",
      "Epoch 4693/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.7306 - p_acc: 0.6659 - val_loss: 1.1619 - val_p_acc: 0.5016\n",
      "Epoch 4694/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7311 - p_acc: 0.6402 - val_loss: 1.1624 - val_p_acc: 0.4487\n",
      "Epoch 4695/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6861 - p_acc: 0.7131 - val_loss: 1.1624 - val_p_acc: 0.5192\n",
      "Epoch 4696/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7061 - p_acc: 0.6554 - val_loss: 1.1643 - val_p_acc: 0.5192\n",
      "Epoch 4697/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7192 - p_acc: 0.7131 - val_loss: 1.1658 - val_p_acc: 0.5192\n",
      "Epoch 4698/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7292 - p_acc: 0.6715 - val_loss: 1.1694 - val_p_acc: 0.4840\n",
      "Epoch 4699/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.6567 - p_acc: 0.7620 - val_loss: 1.1708 - val_p_acc: 0.5192\n",
      "Epoch 4700/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7852 - p_acc: 0.6450 - val_loss: 1.1698 - val_p_acc: 0.5192\n",
      "Epoch 4701/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7608 - p_acc: 0.7268 - val_loss: 1.1690 - val_p_acc: 0.5192\n",
      "Epoch 4702/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7236 - p_acc: 0.6939 - val_loss: 1.1667 - val_p_acc: 0.5369\n",
      "Epoch 4703/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8648 - p_acc: 0.6731 - val_loss: 1.1647 - val_p_acc: 0.5016\n",
      "Epoch 4704/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6781 - p_acc: 0.6643 - val_loss: 1.1617 - val_p_acc: 0.4840\n",
      "Epoch 4705/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6523 - p_acc: 0.7356 - val_loss: 1.1566 - val_p_acc: 0.5016\n",
      "Epoch 4706/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8092 - p_acc: 0.7059 - val_loss: 1.1484 - val_p_acc: 0.5337\n",
      "Epoch 4707/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7624 - p_acc: 0.6450 - val_loss: 1.1444 - val_p_acc: 0.4808\n",
      "Epoch 4708/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7147 - p_acc: 0.6715 - val_loss: 1.1432 - val_p_acc: 0.4631\n",
      "Epoch 4709/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8202 - p_acc: 0.6538 - val_loss: 1.1435 - val_p_acc: 0.4984\n",
      "Epoch 4710/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7355 - p_acc: 0.7043 - val_loss: 1.1443 - val_p_acc: 0.4984\n",
      "Epoch 4711/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7498 - p_acc: 0.6907 - val_loss: 1.1463 - val_p_acc: 0.5160\n",
      "Epoch 4712/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8349 - p_acc: 0.6210 - val_loss: 1.1470 - val_p_acc: 0.4808\n",
      "Epoch 4713/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7323 - p_acc: 0.6571 - val_loss: 1.1482 - val_p_acc: 0.4455\n",
      "Epoch 4714/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6877 - p_acc: 0.7075 - val_loss: 1.1495 - val_p_acc: 0.4808\n",
      "Epoch 4715/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7474 - p_acc: 0.6627 - val_loss: 1.1485 - val_p_acc: 0.5513\n",
      "Epoch 4716/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.6746 - p_acc: 0.7236 - val_loss: 1.1462 - val_p_acc: 0.5160\n",
      "Epoch 4717/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7106 - p_acc: 0.6923 - val_loss: 1.1441 - val_p_acc: 0.4631\n",
      "Epoch 4718/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7570 - p_acc: 0.6522 - val_loss: 1.1423 - val_p_acc: 0.4455\n",
      "Epoch 4719/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8378 - p_acc: 0.6450 - val_loss: 1.1411 - val_p_acc: 0.5160\n",
      "Epoch 4720/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6497 - p_acc: 0.7812 - val_loss: 1.1404 - val_p_acc: 0.4808\n",
      "Epoch 4721/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7821 - p_acc: 0.6627 - val_loss: 1.1403 - val_p_acc: 0.4984\n",
      "Epoch 4722/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7879 - p_acc: 0.7147 - val_loss: 1.1408 - val_p_acc: 0.4808\n",
      "Epoch 4723/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.6740 - p_acc: 0.6923 - val_loss: 1.1405 - val_p_acc: 0.4808\n",
      "Epoch 4724/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8081 - p_acc: 0.5946 - val_loss: 1.1393 - val_p_acc: 0.5337\n",
      "Epoch 4725/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7151 - p_acc: 0.6731 - val_loss: 1.1383 - val_p_acc: 0.4455\n",
      "Epoch 4726/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7847 - p_acc: 0.5929 - val_loss: 1.1395 - val_p_acc: 0.5160\n",
      "Epoch 4727/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7030 - p_acc: 0.6835 - val_loss: 1.1405 - val_p_acc: 0.4808\n",
      "Epoch 4728/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.6594 - p_acc: 0.7059 - val_loss: 1.1398 - val_p_acc: 0.5160\n",
      "Epoch 4729/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.6783 - p_acc: 0.7428 - val_loss: 1.1397 - val_p_acc: 0.4808\n",
      "Epoch 4730/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8793 - p_acc: 0.6154 - val_loss: 1.1391 - val_p_acc: 0.4631\n",
      "Epoch 4731/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7855 - p_acc: 0.6643 - val_loss: 1.1364 - val_p_acc: 0.5513\n",
      "Epoch 4732/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7042 - p_acc: 0.6731 - val_loss: 1.1364 - val_p_acc: 0.5160\n",
      "Epoch 4733/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6663 - p_acc: 0.7845 - val_loss: 1.1343 - val_p_acc: 0.5160\n",
      "Epoch 4734/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7643 - p_acc: 0.7131 - val_loss: 1.1313 - val_p_acc: 0.4071\n",
      "Epoch 4735/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7072 - p_acc: 0.7845 - val_loss: 1.1293 - val_p_acc: 0.4776\n",
      "Epoch 4736/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6854 - p_acc: 0.7236 - val_loss: 1.1294 - val_p_acc: 0.4599\n",
      "Epoch 4737/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7530 - p_acc: 0.6330 - val_loss: 1.1309 - val_p_acc: 0.4776\n",
      "Epoch 4738/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7537 - p_acc: 0.7043 - val_loss: 1.1312 - val_p_acc: 0.5128\n",
      "Epoch 4739/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7077 - p_acc: 0.7236 - val_loss: 1.1308 - val_p_acc: 0.4423\n",
      "Epoch 4740/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7279 - p_acc: 0.6538 - val_loss: 1.1302 - val_p_acc: 0.4599\n",
      "Epoch 4741/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7444 - p_acc: 0.6835 - val_loss: 1.1306 - val_p_acc: 0.4247\n",
      "Epoch 4742/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7932 - p_acc: 0.6571 - val_loss: 1.1296 - val_p_acc: 0.4423\n",
      "Epoch 4743/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7431 - p_acc: 0.6731 - val_loss: 1.1311 - val_p_acc: 0.4423\n",
      "Epoch 4744/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7989 - p_acc: 0.6362 - val_loss: 1.1306 - val_p_acc: 0.4599\n",
      "Epoch 4745/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6760 - p_acc: 0.7268 - val_loss: 1.1307 - val_p_acc: 0.4247\n",
      "Epoch 4746/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7898 - p_acc: 0.6050 - val_loss: 1.1292 - val_p_acc: 0.4776\n",
      "Epoch 4747/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6613 - p_acc: 0.7284 - val_loss: 1.1291 - val_p_acc: 0.4599\n",
      "Epoch 4748/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7446 - p_acc: 0.6867 - val_loss: 1.1291 - val_p_acc: 0.4599\n",
      "Epoch 4749/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6774 - p_acc: 0.7428 - val_loss: 1.1301 - val_p_acc: 0.4247\n",
      "Epoch 4750/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.6465 - p_acc: 0.6643 - val_loss: 1.1313 - val_p_acc: 0.4599\n",
      "Epoch 4751/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7385 - p_acc: 0.6803 - val_loss: 1.1297 - val_p_acc: 0.4599\n",
      "Epoch 4752/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7653 - p_acc: 0.7548 - val_loss: 1.1302 - val_p_acc: 0.4776\n",
      "Epoch 4753/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7524 - p_acc: 0.7356 - val_loss: 1.1312 - val_p_acc: 0.4423\n",
      "Epoch 4754/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7866 - p_acc: 0.6731 - val_loss: 1.1310 - val_p_acc: 0.4776\n",
      "Epoch 4755/5000\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7237 - p_acc: 0.666 - 0s 692us/sample - loss: 0.6914 - p_acc: 0.7059 - val_loss: 1.1315 - val_p_acc: 0.4071\n",
      "Epoch 4756/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7719 - p_acc: 0.6835 - val_loss: 1.1322 - val_p_acc: 0.4776\n",
      "Epoch 4757/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.6564 - p_acc: 0.7388 - val_loss: 1.1333 - val_p_acc: 0.4599\n",
      "Epoch 4758/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7100 - p_acc: 0.7252 - val_loss: 1.1336 - val_p_acc: 0.4423\n",
      "Epoch 4759/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.6392 - p_acc: 0.7652 - val_loss: 1.1344 - val_p_acc: 0.4776\n",
      "Epoch 4760/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.8124 - p_acc: 0.6747 - val_loss: 1.1349 - val_p_acc: 0.4776\n",
      "Epoch 4761/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7751 - p_acc: 0.6731 - val_loss: 1.1367 - val_p_acc: 0.4952\n",
      "Epoch 4762/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7431 - p_acc: 0.7163 - val_loss: 1.1386 - val_p_acc: 0.4599\n",
      "Epoch 4763/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.6324 - p_acc: 0.7724 - val_loss: 1.1396 - val_p_acc: 0.4071\n",
      "Epoch 4764/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8377 - p_acc: 0.6522 - val_loss: 1.1422 - val_p_acc: 0.4776\n",
      "Epoch 4765/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7120 - p_acc: 0.7756 - val_loss: 1.1434 - val_p_acc: 0.4631\n",
      "Epoch 4766/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6955 - p_acc: 0.7949 - val_loss: 1.1453 - val_p_acc: 0.4984\n",
      "Epoch 4767/5000\n",
      "85/85 [==============================] - 0s 696us/sample - loss: 0.7348 - p_acc: 0.7220 - val_loss: 1.1457 - val_p_acc: 0.4631\n",
      "Epoch 4768/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7101 - p_acc: 0.7043 - val_loss: 1.1478 - val_p_acc: 0.4455\n",
      "Epoch 4769/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7475 - p_acc: 0.6731 - val_loss: 1.1493 - val_p_acc: 0.5160\n",
      "Epoch 4770/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8097 - p_acc: 0.6627 - val_loss: 1.1490 - val_p_acc: 0.4984\n",
      "Epoch 4771/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6731 - p_acc: 0.7548 - val_loss: 1.1495 - val_p_acc: 0.4984\n",
      "Epoch 4772/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.6871 - p_acc: 0.8125 - val_loss: 1.1533 - val_p_acc: 0.5160\n",
      "Epoch 4773/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7262 - p_acc: 0.6923 - val_loss: 1.1564 - val_p_acc: 0.4631\n",
      "Epoch 4774/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7329 - p_acc: 0.7532 - val_loss: 1.1559 - val_p_acc: 0.4808\n",
      "Epoch 4775/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7603 - p_acc: 0.6554 - val_loss: 1.1541 - val_p_acc: 0.4455\n",
      "Epoch 4776/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7069 - p_acc: 0.7428 - val_loss: 1.1540 - val_p_acc: 0.4631\n",
      "Epoch 4777/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6054 - p_acc: 0.7668 - val_loss: 1.1518 - val_p_acc: 0.5337\n",
      "Epoch 4778/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6569 - p_acc: 0.8101 - val_loss: 1.1515 - val_p_acc: 0.4808\n",
      "Epoch 4779/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7383 - p_acc: 0.6675 - val_loss: 1.1507 - val_p_acc: 0.4808\n",
      "Epoch 4780/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6542 - p_acc: 0.7965 - val_loss: 1.1506 - val_p_acc: 0.4808\n",
      "Epoch 4781/5000\n",
      "85/85 [==============================] - 0s 733us/sample - loss: 0.7851 - p_acc: 0.6715 - val_loss: 1.1479 - val_p_acc: 0.4631\n",
      "Epoch 4782/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6536 - p_acc: 0.7147 - val_loss: 1.1470 - val_p_acc: 0.4631\n",
      "Epoch 4783/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7593 - p_acc: 0.6939 - val_loss: 1.1458 - val_p_acc: 0.4984\n",
      "Epoch 4784/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7835 - p_acc: 0.6747 - val_loss: 1.1434 - val_p_acc: 0.5160\n",
      "Epoch 4785/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7481 - p_acc: 0.7043 - val_loss: 1.1416 - val_p_acc: 0.4808\n",
      "Epoch 4786/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7671 - p_acc: 0.6867 - val_loss: 1.1417 - val_p_acc: 0.5160\n",
      "Epoch 4787/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7871 - p_acc: 0.6643 - val_loss: 1.1432 - val_p_acc: 0.4631\n",
      "Epoch 4788/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7206 - p_acc: 0.7724 - val_loss: 1.1432 - val_p_acc: 0.4631\n",
      "Epoch 4789/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.6556 - p_acc: 0.7388 - val_loss: 1.1438 - val_p_acc: 0.4631\n",
      "Epoch 4790/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7441 - p_acc: 0.6611 - val_loss: 1.1409 - val_p_acc: 0.5160\n",
      "Epoch 4791/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.8074 - p_acc: 0.6715 - val_loss: 1.1406 - val_p_acc: 0.4984\n",
      "Epoch 4792/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7316 - p_acc: 0.6763 - val_loss: 1.1403 - val_p_acc: 0.4808\n",
      "Epoch 4793/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6902 - p_acc: 0.7428 - val_loss: 1.1436 - val_p_acc: 0.4631\n",
      "Epoch 4794/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7909 - p_acc: 0.7115 - val_loss: 1.1502 - val_p_acc: 0.5016\n",
      "Epoch 4795/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7579 - p_acc: 0.6226 - val_loss: 1.1550 - val_p_acc: 0.5369\n",
      "Epoch 4796/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7413 - p_acc: 0.6258 - val_loss: 1.1574 - val_p_acc: 0.5753\n",
      "Epoch 4797/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7369 - p_acc: 0.7099 - val_loss: 1.1577 - val_p_acc: 0.5577\n",
      "Epoch 4798/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6746 - p_acc: 0.7740 - val_loss: 1.1549 - val_p_acc: 0.5577\n",
      "Epoch 4799/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6780 - p_acc: 0.6939 - val_loss: 1.1506 - val_p_acc: 0.5369\n",
      "Epoch 4800/5000\n",
      "85/85 [==============================] - 0s 762us/sample - loss: 0.7438 - p_acc: 0.6851 - val_loss: 1.1478 - val_p_acc: 0.4663\n",
      "Epoch 4801/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7287 - p_acc: 0.7372 - val_loss: 1.1491 - val_p_acc: 0.4840\n",
      "Epoch 4802/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7479 - p_acc: 0.6554 - val_loss: 1.1490 - val_p_acc: 0.5369\n",
      "Epoch 4803/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7311 - p_acc: 0.6258 - val_loss: 1.1498 - val_p_acc: 0.5192\n",
      "Epoch 4804/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6188 - p_acc: 0.7444 - val_loss: 1.1493 - val_p_acc: 0.4840\n",
      "Epoch 4805/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7325 - p_acc: 0.6643 - val_loss: 1.1494 - val_p_acc: 0.4663\n",
      "Epoch 4806/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6816 - p_acc: 0.7131 - val_loss: 1.1455 - val_p_acc: 0.5545\n",
      "Epoch 4807/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8351 - p_acc: 0.6747 - val_loss: 1.1422 - val_p_acc: 0.4631\n",
      "Epoch 4808/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7283 - p_acc: 0.6138 - val_loss: 1.1413 - val_p_acc: 0.4455\n",
      "Epoch 4809/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7453 - p_acc: 0.6835 - val_loss: 1.1397 - val_p_acc: 0.5160\n",
      "Epoch 4810/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7153 - p_acc: 0.6691 - val_loss: 1.1404 - val_p_acc: 0.4631\n",
      "Epoch 4811/5000\n",
      "85/85 [==============================] - 0s 668us/sample - loss: 0.9031 - p_acc: 0.5946 - val_loss: 1.1421 - val_p_acc: 0.4808\n",
      "Epoch 4812/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7629 - p_acc: 0.7043 - val_loss: 1.1393 - val_p_acc: 0.4631\n",
      "Epoch 4813/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7276 - p_acc: 0.6258 - val_loss: 1.1361 - val_p_acc: 0.4631\n",
      "Epoch 4814/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6978 - p_acc: 0.7131 - val_loss: 1.1305 - val_p_acc: 0.4984\n",
      "Epoch 4815/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7717 - p_acc: 0.6699 - val_loss: 1.1295 - val_p_acc: 0.4776\n",
      "Epoch 4816/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7575 - p_acc: 0.6731 - val_loss: 1.1288 - val_p_acc: 0.4423\n",
      "Epoch 4817/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7457 - p_acc: 0.5946 - val_loss: 1.1296 - val_p_acc: 0.4952\n",
      "Epoch 4818/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7415 - p_acc: 0.7324 - val_loss: 1.1318 - val_p_acc: 0.4952\n",
      "Epoch 4819/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7669 - p_acc: 0.6242 - val_loss: 1.1334 - val_p_acc: 0.4423\n",
      "Epoch 4820/5000\n",
      "85/85 [==============================] - 0s 707us/sample - loss: 0.7646 - p_acc: 0.7115 - val_loss: 1.1326 - val_p_acc: 0.4599\n",
      "Epoch 4821/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7830 - p_acc: 0.6715 - val_loss: 1.1332 - val_p_acc: 0.5128\n",
      "Epoch 4822/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6564 - p_acc: 0.7356 - val_loss: 1.1334 - val_p_acc: 0.4952\n",
      "Epoch 4823/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7938 - p_acc: 0.6226 - val_loss: 1.1332 - val_p_acc: 0.4599\n",
      "Epoch 4824/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7123 - p_acc: 0.6506 - val_loss: 1.1347 - val_p_acc: 0.4423\n",
      "Epoch 4825/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7430 - p_acc: 0.6643 - val_loss: 1.1371 - val_p_acc: 0.4279\n",
      "Epoch 4826/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7488 - p_acc: 0.6955 - val_loss: 1.1367 - val_p_acc: 0.4984\n",
      "Epoch 4827/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7840 - p_acc: 0.7236 - val_loss: 1.1360 - val_p_acc: 0.4423\n",
      "Epoch 4828/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6647 - p_acc: 0.7548 - val_loss: 1.1338 - val_p_acc: 0.4423\n",
      "Epoch 4829/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7063 - p_acc: 0.7516 - val_loss: 1.1343 - val_p_acc: 0.5128\n",
      "Epoch 4830/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7112 - p_acc: 0.6731 - val_loss: 1.1363 - val_p_acc: 0.4808\n",
      "Epoch 4831/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7900 - p_acc: 0.6362 - val_loss: 1.1381 - val_p_acc: 0.4808\n",
      "Epoch 4832/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.8051 - p_acc: 0.6034 - val_loss: 1.1404 - val_p_acc: 0.4984\n",
      "Epoch 4833/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7599 - p_acc: 0.6715 - val_loss: 1.1392 - val_p_acc: 0.5337\n",
      "Epoch 4834/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6597 - p_acc: 0.6795 - val_loss: 1.1386 - val_p_acc: 0.4455\n",
      "Epoch 4835/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6562 - p_acc: 0.7740 - val_loss: 1.1388 - val_p_acc: 0.4984\n",
      "Epoch 4836/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7227 - p_acc: 0.7027 - val_loss: 1.1400 - val_p_acc: 0.4631\n",
      "Epoch 4837/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.6613 - p_acc: 0.7236 - val_loss: 1.1407 - val_p_acc: 0.4808\n",
      "Epoch 4838/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.6650 - p_acc: 0.7636 - val_loss: 1.1403 - val_p_acc: 0.5160\n",
      "Epoch 4839/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6450 - p_acc: 0.7043 - val_loss: 1.1409 - val_p_acc: 0.4984\n",
      "Epoch 4840/5000\n",
      "85/85 [==============================] - 0s 787us/sample - loss: 0.8127 - p_acc: 0.6466 - val_loss: 1.1403 - val_p_acc: 0.4984\n",
      "Epoch 4841/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7339 - p_acc: 0.6763 - val_loss: 1.1424 - val_p_acc: 0.4984\n",
      "Epoch 4842/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7506 - p_acc: 0.7620 - val_loss: 1.1405 - val_p_acc: 0.5160\n",
      "Epoch 4843/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6755 - p_acc: 0.6955 - val_loss: 1.1398 - val_p_acc: 0.4599\n",
      "Epoch 4844/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6304 - p_acc: 0.7356 - val_loss: 1.1388 - val_p_acc: 0.4808\n",
      "Epoch 4845/5000\n",
      "85/85 [==============================] - 0s 720us/sample - loss: 0.7010 - p_acc: 0.7236 - val_loss: 1.1422 - val_p_acc: 0.4808\n",
      "Epoch 4846/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.6770 - p_acc: 0.7460 - val_loss: 1.1444 - val_p_acc: 0.5513\n",
      "Epoch 4847/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.8345 - p_acc: 0.7107 - val_loss: 1.1473 - val_p_acc: 0.4808\n",
      "Epoch 4848/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6620 - p_acc: 0.7340 - val_loss: 1.1499 - val_p_acc: 0.4808\n",
      "Epoch 4849/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7549 - p_acc: 0.6763 - val_loss: 1.1537 - val_p_acc: 0.5337\n",
      "Epoch 4850/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7126 - p_acc: 0.6883 - val_loss: 1.1568 - val_p_acc: 0.4455\n",
      "Epoch 4851/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7323 - p_acc: 0.7059 - val_loss: 1.1580 - val_p_acc: 0.5160\n",
      "Epoch 4852/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.6957 - p_acc: 0.7147 - val_loss: 1.1567 - val_p_acc: 0.5160\n",
      "Epoch 4853/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.8609 - p_acc: 0.6434 - val_loss: 1.1560 - val_p_acc: 0.4631\n",
      "Epoch 4854/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7485 - p_acc: 0.6066 - val_loss: 1.1561 - val_p_acc: 0.4808\n",
      "Epoch 4855/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6252 - p_acc: 0.7372 - val_loss: 1.1566 - val_p_acc: 0.5160\n",
      "Epoch 4856/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7633 - p_acc: 0.7075 - val_loss: 1.1543 - val_p_acc: 0.4808\n",
      "Epoch 4857/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7947 - p_acc: 0.6170 - val_loss: 1.1522 - val_p_acc: 0.4808\n",
      "Epoch 4858/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6156 - p_acc: 0.7845 - val_loss: 1.1521 - val_p_acc: 0.4279\n",
      "Epoch 4859/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7444 - p_acc: 0.7147 - val_loss: 1.1491 - val_p_acc: 0.5160\n",
      "Epoch 4860/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6622 - p_acc: 0.6835 - val_loss: 1.1498 - val_p_acc: 0.4455\n",
      "Epoch 4861/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6853 - p_acc: 0.7949 - val_loss: 1.1481 - val_p_acc: 0.5160\n",
      "Epoch 4862/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7427 - p_acc: 0.5913 - val_loss: 1.1471 - val_p_acc: 0.4631\n",
      "Epoch 4863/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 715us/sample - loss: 0.6511 - p_acc: 0.7236 - val_loss: 1.1481 - val_p_acc: 0.4984\n",
      "Epoch 4864/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7525 - p_acc: 0.6731 - val_loss: 1.1494 - val_p_acc: 0.4631\n",
      "Epoch 4865/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6818 - p_acc: 0.7340 - val_loss: 1.1493 - val_p_acc: 0.4631\n",
      "Epoch 4866/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7143 - p_acc: 0.7268 - val_loss: 1.1509 - val_p_acc: 0.4808\n",
      "Epoch 4867/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7344 - p_acc: 0.6851 - val_loss: 1.1539 - val_p_acc: 0.4808\n",
      "Epoch 4868/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8318 - p_acc: 0.6018 - val_loss: 1.1559 - val_p_acc: 0.5192\n",
      "Epoch 4869/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7655 - p_acc: 0.7131 - val_loss: 1.1591 - val_p_acc: 0.5369\n",
      "Epoch 4870/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6639 - p_acc: 0.6955 - val_loss: 1.1606 - val_p_acc: 0.5753\n",
      "Epoch 4871/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8065 - p_acc: 0.6226 - val_loss: 1.1642 - val_p_acc: 0.5929\n",
      "Epoch 4872/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6173 - p_acc: 0.8053 - val_loss: 1.1646 - val_p_acc: 0.4872\n",
      "Epoch 4873/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7126 - p_acc: 0.6202 - val_loss: 1.1658 - val_p_acc: 0.5401\n",
      "Epoch 4874/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7501 - p_acc: 0.6538 - val_loss: 1.1632 - val_p_acc: 0.5401\n",
      "Epoch 4875/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 0.7348 - p_acc: 0.7356 - val_loss: 1.1636 - val_p_acc: 0.5577\n",
      "Epoch 4876/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.6524 - p_acc: 0.6763 - val_loss: 1.1609 - val_p_acc: 0.5401\n",
      "Epoch 4877/5000\n",
      "85/85 [==============================] - 0s 736us/sample - loss: 0.7216 - p_acc: 0.7444 - val_loss: 1.1582 - val_p_acc: 0.5401\n",
      "Epoch 4878/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.9319 - p_acc: 0.6907 - val_loss: 1.1558 - val_p_acc: 0.5369\n",
      "Epoch 4879/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7535 - p_acc: 0.7179 - val_loss: 1.1543 - val_p_acc: 0.4840\n",
      "Epoch 4880/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6914 - p_acc: 0.7147 - val_loss: 1.1553 - val_p_acc: 0.5016\n",
      "Epoch 4881/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7012 - p_acc: 0.6747 - val_loss: 1.1561 - val_p_acc: 0.5192\n",
      "Epoch 4882/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8342 - p_acc: 0.5825 - val_loss: 1.1552 - val_p_acc: 0.4808\n",
      "Epoch 4883/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7671 - p_acc: 0.6643 - val_loss: 1.1558 - val_p_acc: 0.4808\n",
      "Epoch 4884/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6445 - p_acc: 0.6538 - val_loss: 1.1580 - val_p_acc: 0.5369\n",
      "Epoch 4885/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6514 - p_acc: 0.7220 - val_loss: 1.1614 - val_p_acc: 0.4840\n",
      "Epoch 4886/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6363 - p_acc: 0.7636 - val_loss: 1.1645 - val_p_acc: 0.5401\n",
      "Epoch 4887/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7533 - p_acc: 0.7043 - val_loss: 1.1677 - val_p_acc: 0.5577\n",
      "Epoch 4888/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.6952 - p_acc: 0.6346 - val_loss: 1.1706 - val_p_acc: 0.5753\n",
      "Epoch 4889/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8043 - p_acc: 0.6506 - val_loss: 1.1737 - val_p_acc: 0.5224\n",
      "Epoch 4890/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.6667 - p_acc: 0.7652 - val_loss: 1.1763 - val_p_acc: 0.5401\n",
      "Epoch 4891/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6625 - p_acc: 0.7043 - val_loss: 1.1801 - val_p_acc: 0.5224\n",
      "Epoch 4892/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7599 - p_acc: 0.6955 - val_loss: 1.1848 - val_p_acc: 0.5224\n",
      "Epoch 4893/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7471 - p_acc: 0.7236 - val_loss: 1.1866 - val_p_acc: 0.5016\n",
      "Epoch 4894/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7754 - p_acc: 0.6851 - val_loss: 1.1873 - val_p_acc: 0.5369\n",
      "Epoch 4895/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.9167 - p_acc: 0.6923 - val_loss: 1.1867 - val_p_acc: 0.4840\n",
      "Epoch 4896/5000\n",
      "85/85 [==============================] - 0s 736us/sample - loss: 0.7449 - p_acc: 0.6923 - val_loss: 1.1857 - val_p_acc: 0.5369\n",
      "Epoch 4897/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7484 - p_acc: 0.7131 - val_loss: 1.1857 - val_p_acc: 0.4840\n",
      "Epoch 4898/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.7899 - p_acc: 0.6627 - val_loss: 1.1833 - val_p_acc: 0.5192\n",
      "Epoch 4899/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8495 - p_acc: 0.6122 - val_loss: 1.1828 - val_p_acc: 0.5401\n",
      "Epoch 4900/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.6958 - p_acc: 0.7147 - val_loss: 1.1825 - val_p_acc: 0.5048\n",
      "Epoch 4901/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7492 - p_acc: 0.7147 - val_loss: 1.1814 - val_p_acc: 0.5577\n",
      "Epoch 4902/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.8670 - p_acc: 0.5425 - val_loss: 1.1831 - val_p_acc: 0.5577\n",
      "Epoch 4903/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6911 - p_acc: 0.7147 - val_loss: 1.1833 - val_p_acc: 0.5577\n",
      "Epoch 4904/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7950 - p_acc: 0.6522 - val_loss: 1.1858 - val_p_acc: 0.5224\n",
      "Epoch 4905/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7426 - p_acc: 0.6955 - val_loss: 1.1841 - val_p_acc: 0.5753\n",
      "Epoch 4906/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7342 - p_acc: 0.7532 - val_loss: 1.1840 - val_p_acc: 0.5224\n",
      "Epoch 4907/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6813 - p_acc: 0.7829 - val_loss: 1.1820 - val_p_acc: 0.5753\n",
      "Epoch 4908/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7619 - p_acc: 0.7043 - val_loss: 1.1821 - val_p_acc: 0.5401\n",
      "Epoch 4909/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7128 - p_acc: 0.6883 - val_loss: 1.1842 - val_p_acc: 0.5577\n",
      "Epoch 4910/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7515 - p_acc: 0.7147 - val_loss: 1.1858 - val_p_acc: 0.5048\n",
      "Epoch 4911/5000\n",
      "85/85 [==============================] - 0s 703us/sample - loss: 0.7149 - p_acc: 0.7115 - val_loss: 1.1875 - val_p_acc: 0.5048\n",
      "Epoch 4912/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7694 - p_acc: 0.6851 - val_loss: 1.1874 - val_p_acc: 0.4840\n",
      "Epoch 4913/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8881 - p_acc: 0.6314 - val_loss: 1.1856 - val_p_acc: 0.5401\n",
      "Epoch 4914/5000\n",
      "85/85 [==============================] - 0s 786us/sample - loss: 0.7613 - p_acc: 0.6050 - val_loss: 1.1852 - val_p_acc: 0.5753\n",
      "Epoch 4915/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.6677 - p_acc: 0.7131 - val_loss: 1.1845 - val_p_acc: 0.5401\n",
      "Epoch 4916/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7226 - p_acc: 0.7236 - val_loss: 1.1838 - val_p_acc: 0.5577\n",
      "Epoch 4917/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7182 - p_acc: 0.6819 - val_loss: 1.1847 - val_p_acc: 0.5577\n",
      "Epoch 4918/5000\n",
      "85/85 [==============================] - 0s 821us/sample - loss: 0.8339 - p_acc: 0.6939 - val_loss: 1.1860 - val_p_acc: 0.5577\n",
      "Epoch 4919/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7365 - p_acc: 0.7059 - val_loss: 1.1901 - val_p_acc: 0.4663\n",
      "Epoch 4920/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7258 - p_acc: 0.6418 - val_loss: 1.1916 - val_p_acc: 0.4840\n",
      "Epoch 4921/5000\n",
      "85/85 [==============================] - 0s 728us/sample - loss: 0.7611 - p_acc: 0.6226 - val_loss: 1.1911 - val_p_acc: 0.4840\n",
      "Epoch 4922/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6388 - p_acc: 0.6747 - val_loss: 1.1875 - val_p_acc: 0.5048\n",
      "Epoch 4923/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6939 - p_acc: 0.7147 - val_loss: 1.1854 - val_p_acc: 0.5753\n",
      "Epoch 4924/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7124 - p_acc: 0.6522 - val_loss: 1.1864 - val_p_acc: 0.5224\n",
      "Epoch 4925/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7094 - p_acc: 0.7340 - val_loss: 1.1904 - val_p_acc: 0.5401\n",
      "Epoch 4926/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7684 - p_acc: 0.7147 - val_loss: 1.1930 - val_p_acc: 0.5401\n",
      "Epoch 4927/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7403 - p_acc: 0.7252 - val_loss: 1.1898 - val_p_acc: 0.5577\n",
      "Epoch 4928/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.7306 - p_acc: 0.6434 - val_loss: 1.1889 - val_p_acc: 0.5224\n",
      "Epoch 4929/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6212 - p_acc: 0.7372 - val_loss: 1.1873 - val_p_acc: 0.5577\n",
      "Epoch 4930/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.8221 - p_acc: 0.5946 - val_loss: 1.1841 - val_p_acc: 0.5401\n",
      "Epoch 4931/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.7289 - p_acc: 0.7099 - val_loss: 1.1801 - val_p_acc: 0.5401\n",
      "Epoch 4932/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7506 - p_acc: 0.6314 - val_loss: 1.1776 - val_p_acc: 0.5753\n",
      "Epoch 4933/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6445 - p_acc: 0.6939 - val_loss: 1.1748 - val_p_acc: 0.5048\n",
      "Epoch 4934/5000\n",
      "85/85 [==============================] - 0s 693us/sample - loss: 0.6897 - p_acc: 0.6659 - val_loss: 1.1745 - val_p_acc: 0.5401\n",
      "Epoch 4935/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6413 - p_acc: 0.7340 - val_loss: 1.1718 - val_p_acc: 0.5048\n",
      "Epoch 4936/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6966 - p_acc: 0.7043 - val_loss: 1.1720 - val_p_acc: 0.5577\n",
      "Epoch 4937/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.6715 - p_acc: 0.7756 - val_loss: 1.1700 - val_p_acc: 0.5048\n",
      "Epoch 4938/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7826 - p_acc: 0.6851 - val_loss: 1.1684 - val_p_acc: 0.5192\n",
      "Epoch 4939/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7542 - p_acc: 0.6346 - val_loss: 1.1667 - val_p_acc: 0.5369\n",
      "Epoch 4940/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.6141 - p_acc: 0.7252 - val_loss: 1.1648 - val_p_acc: 0.4840\n",
      "Epoch 4941/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7363 - p_acc: 0.6306 - val_loss: 1.1638 - val_p_acc: 0.5016\n",
      "Epoch 4942/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 0.7567 - p_acc: 0.6835 - val_loss: 1.1628 - val_p_acc: 0.5721\n",
      "Epoch 4943/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7228 - p_acc: 0.7131 - val_loss: 1.1602 - val_p_acc: 0.5016\n",
      "Epoch 4944/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7860 - p_acc: 0.6779 - val_loss: 1.1599 - val_p_acc: 0.5369\n",
      "Epoch 4945/5000\n",
      "85/85 [==============================] - 0s 715us/sample - loss: 0.7751 - p_acc: 0.6330 - val_loss: 1.1587 - val_p_acc: 0.5016\n",
      "Epoch 4946/5000\n",
      "85/85 [==============================] - 0s 750us/sample - loss: 0.7254 - p_acc: 0.6538 - val_loss: 1.1578 - val_p_acc: 0.5016\n",
      "Epoch 4947/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7563 - p_acc: 0.5962 - val_loss: 1.1570 - val_p_acc: 0.4840\n",
      "Epoch 4948/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7235 - p_acc: 0.6627 - val_loss: 1.1529 - val_p_acc: 0.5016\n",
      "Epoch 4949/5000\n",
      "85/85 [==============================] - 0s 775us/sample - loss: 0.7041 - p_acc: 0.7131 - val_loss: 1.1518 - val_p_acc: 0.5369\n",
      "Epoch 4950/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7823 - p_acc: 0.6763 - val_loss: 1.1534 - val_p_acc: 0.5016\n",
      "Epoch 4951/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7517 - p_acc: 0.7115 - val_loss: 1.1554 - val_p_acc: 0.5016\n",
      "Epoch 4952/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7778 - p_acc: 0.6835 - val_loss: 1.1562 - val_p_acc: 0.5192\n",
      "Epoch 4953/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.8414 - p_acc: 0.6226 - val_loss: 1.1542 - val_p_acc: 0.4840\n",
      "Epoch 4954/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6836 - p_acc: 0.7204 - val_loss: 1.1514 - val_p_acc: 0.4455\n",
      "Epoch 4955/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6767 - p_acc: 0.7268 - val_loss: 1.1487 - val_p_acc: 0.4631\n",
      "Epoch 4956/5000\n",
      "85/85 [==============================] - 0s 681us/sample - loss: 0.6896 - p_acc: 0.6747 - val_loss: 1.1476 - val_p_acc: 0.4631\n",
      "Epoch 4957/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7566 - p_acc: 0.7027 - val_loss: 1.1468 - val_p_acc: 0.4808\n",
      "Epoch 4958/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7295 - p_acc: 0.6434 - val_loss: 1.1478 - val_p_acc: 0.4984\n",
      "Epoch 4959/5000\n",
      "85/85 [==============================] - 0s 691us/sample - loss: 0.7345 - p_acc: 0.7252 - val_loss: 1.1477 - val_p_acc: 0.4808\n",
      "Epoch 4960/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7946 - p_acc: 0.6715 - val_loss: 1.1462 - val_p_acc: 0.4984\n",
      "Epoch 4961/5000\n",
      "85/85 [==============================] - 0s 705us/sample - loss: 0.7482 - p_acc: 0.7043 - val_loss: 1.1417 - val_p_acc: 0.4808\n",
      "Epoch 4962/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.8922 - p_acc: 0.6050 - val_loss: 1.1406 - val_p_acc: 0.4984\n",
      "Epoch 4963/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7482 - p_acc: 0.6611 - val_loss: 1.1391 - val_p_acc: 0.4808\n",
      "Epoch 4964/5000\n",
      "85/85 [==============================] - 0s 669us/sample - loss: 0.7634 - p_acc: 0.7163 - val_loss: 1.1345 - val_p_acc: 0.4984\n",
      "Epoch 4965/5000\n",
      "85/85 [==============================] - 0s 687us/sample - loss: 0.6465 - p_acc: 0.7548 - val_loss: 1.1340 - val_p_acc: 0.4455\n",
      "Epoch 4966/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7877 - p_acc: 0.7147 - val_loss: 1.1356 - val_p_acc: 0.4247\n",
      "Epoch 4967/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.7437 - p_acc: 0.7340 - val_loss: 1.1365 - val_p_acc: 0.4423\n",
      "Epoch 4968/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.7766 - p_acc: 0.6819 - val_loss: 1.1373 - val_p_acc: 0.4599\n",
      "Epoch 4969/5000\n",
      "85/85 [==============================] - 0s 708us/sample - loss: 0.7275 - p_acc: 0.7236 - val_loss: 1.1355 - val_p_acc: 0.4599\n",
      "Epoch 4970/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.6103 - p_acc: 0.8037 - val_loss: 1.1342 - val_p_acc: 0.4423\n",
      "Epoch 4971/5000\n",
      "85/85 [==============================] - 0s 892us/sample - loss: 0.6512 - p_acc: 0.7324 - val_loss: 1.1333 - val_p_acc: 0.4599\n",
      "Epoch 4972/5000\n",
      "85/85 [==============================] - 0s 903us/sample - loss: 0.8740 - p_acc: 0.6579 - val_loss: 1.1336 - val_p_acc: 0.4952\n",
      "Epoch 4973/5000\n",
      "85/85 [==============================] - 0s 916us/sample - loss: 0.7220 - p_acc: 0.6571 - val_loss: 1.1320 - val_p_acc: 0.4776\n",
      "Epoch 4974/5000\n",
      "85/85 [==============================] - 0s 950us/sample - loss: 0.7208 - p_acc: 0.6923 - val_loss: 1.1325 - val_p_acc: 0.4776\n",
      "Epoch 4975/5000\n",
      "85/85 [==============================] - 0s 927us/sample - loss: 0.7916 - p_acc: 0.6659 - val_loss: 1.1345 - val_p_acc: 0.5128\n",
      "Epoch 4976/5000\n",
      "85/85 [==============================] - 0s 810us/sample - loss: 0.7678 - p_acc: 0.7444 - val_loss: 1.1346 - val_p_acc: 0.4599\n",
      "Epoch 4977/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 774us/sample - loss: 0.7281 - p_acc: 0.6731 - val_loss: 1.1356 - val_p_acc: 0.4599\n",
      "Epoch 4978/5000\n",
      "85/85 [==============================] - 0s 774us/sample - loss: 0.5923 - p_acc: 0.7845 - val_loss: 1.1361 - val_p_acc: 0.4599\n",
      "Epoch 4979/5000\n",
      "85/85 [==============================] - 0s 740us/sample - loss: 0.7094 - p_acc: 0.7220 - val_loss: 1.1373 - val_p_acc: 0.4808\n",
      "Epoch 4980/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.6514 - p_acc: 0.7949 - val_loss: 1.1371 - val_p_acc: 0.4808\n",
      "Epoch 4981/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6863 - p_acc: 0.6955 - val_loss: 1.1371 - val_p_acc: 0.4423\n",
      "Epoch 4982/5000\n",
      "85/85 [==============================] - 0s 763us/sample - loss: 0.7807 - p_acc: 0.6907 - val_loss: 1.1368 - val_p_acc: 0.4599\n",
      "Epoch 4983/5000\n",
      "85/85 [==============================] - 0s 739us/sample - loss: 0.7630 - p_acc: 0.6955 - val_loss: 1.1358 - val_p_acc: 0.4952\n",
      "Epoch 4984/5000\n",
      "85/85 [==============================] - 0s 727us/sample - loss: 0.6909 - p_acc: 0.7236 - val_loss: 1.1340 - val_p_acc: 0.4247\n",
      "Epoch 4985/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7618 - p_acc: 0.6418 - val_loss: 1.1333 - val_p_acc: 0.4776\n",
      "Epoch 4986/5000\n",
      "85/85 [==============================] - 0s 692us/sample - loss: 0.6870 - p_acc: 0.6715 - val_loss: 1.1317 - val_p_acc: 0.4599\n",
      "Epoch 4987/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7070 - p_acc: 0.6779 - val_loss: 1.1306 - val_p_acc: 0.4776\n",
      "Epoch 4988/5000\n",
      "85/85 [==============================] - 0s 751us/sample - loss: 0.7913 - p_acc: 0.6747 - val_loss: 1.1304 - val_p_acc: 0.4776\n",
      "Epoch 4989/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6960 - p_acc: 0.7668 - val_loss: 1.1295 - val_p_acc: 0.4423\n",
      "Epoch 4990/5000\n",
      "85/85 [==============================] - 0s 704us/sample - loss: 0.7979 - p_acc: 0.5946 - val_loss: 1.1283 - val_p_acc: 0.4599\n",
      "Epoch 4991/5000\n",
      "85/85 [==============================] - 0s 716us/sample - loss: 0.6416 - p_acc: 0.7236 - val_loss: 1.1297 - val_p_acc: 0.4776\n",
      "Epoch 4992/5000\n",
      "85/85 [==============================] - 0s 798us/sample - loss: 0.6955 - p_acc: 0.6747 - val_loss: 1.1298 - val_p_acc: 0.4423\n",
      "Epoch 4993/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.7250 - p_acc: 0.6939 - val_loss: 1.1293 - val_p_acc: 0.5128\n",
      "Epoch 4994/5000\n",
      "85/85 [==============================] - 0s 868us/sample - loss: 0.7482 - p_acc: 0.7131 - val_loss: 1.1311 - val_p_acc: 0.4776\n",
      "Epoch 4995/5000\n",
      "85/85 [==============================] - 0s 833us/sample - loss: 0.6263 - p_acc: 0.7236 - val_loss: 1.1297 - val_p_acc: 0.4247\n",
      "Epoch 4996/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 0.7452 - p_acc: 0.6274 - val_loss: 1.1292 - val_p_acc: 0.4599\n",
      "Epoch 4997/5000\n",
      "85/85 [==============================] - 0s 880us/sample - loss: 0.6421 - p_acc: 0.7444 - val_loss: 1.1288 - val_p_acc: 0.4599\n",
      "Epoch 4998/5000\n",
      "85/85 [==============================] - 0s 857us/sample - loss: 0.6108 - p_acc: 0.7444 - val_loss: 1.1303 - val_p_acc: 0.4247\n",
      "Epoch 4999/5000\n",
      "85/85 [==============================] - 0s 892us/sample - loss: 0.7083 - p_acc: 0.7340 - val_loss: 1.1310 - val_p_acc: 0.4599\n",
      "Epoch 5000/5000\n",
      "85/85 [==============================] - 0s 892us/sample - loss: 0.7545 - p_acc: 0.7236 - val_loss: 1.1311 - val_p_acc: 0.4247\n"
     ]
    }
   ],
   "source": [
    "hist_m1 = m1.fit([ftr1[:, 0, :, :], ftr1[:, 1, :, :]], ltr1 , validation_data= [[ftt1[:, 0, :, :], ftt1[:, 1, :, :]], ltt1], epochs = 5000, shuffle = True, batch_size = 24, verbose = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
