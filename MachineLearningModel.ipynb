{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.svm import LinearSVR,SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import OneHotEncoder,LabelEncoder\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 13), (96, 11))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.read_csv('Csv/x_features.csv')\n",
    "y = pd.read_csv('Csv/y_features.csv')\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw=y[['id','N (Raw)','E (Raw)','O (Raw)','A (Raw)','C(Raw)']].copy()\n",
    "y_t=y[['id','N (T score)','E(T score)','O (T score)','A (T score)','C(T score)']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop('id',inplace=True,axis=1)\n",
    "y_raw.drop('id',inplace=True,axis=1)\n",
    "y_t.drop('id',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscaler1_=StandardScaler()\\nscaler2_=StandardScaler()\\nscaler3_=StandardScaler()\\nscaler4_=StandardScaler()\\nscaler5_=StandardScaler()\\nscaler6_=StandardScaler()\\nscaler7_=StandardScaler()\\nscaler8_=StandardScaler()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler1=MinMaxScaler()\n",
    "scaler2=MinMaxScaler()\n",
    "scaler3=MinMaxScaler()\n",
    "scaler4=MinMaxScaler()\n",
    "scaler5=MinMaxScaler()\n",
    "scaler6=MinMaxScaler()\n",
    "scaler7=MinMaxScaler()\n",
    "scaler8=MinMaxScaler()\n",
    "\n",
    "'''\n",
    "scaler1_=StandardScaler()\n",
    "scaler2_=StandardScaler()\n",
    "scaler3_=StandardScaler()\n",
    "scaler4_=StandardScaler()\n",
    "scaler5_=StandardScaler()\n",
    "scaler6_=StandardScaler()\n",
    "scaler7_=StandardScaler()\n",
    "scaler8_=StandardScaler()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(['Qualifiaction','Name ','Age ','Gender'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['baseline', 'pen_pressure', 'letter_size', 'word_spacing',\n",
       "       'line_spacing', 'width', 'height', 'bar-height'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['baseline']=scaler1.fit_transform(np.array(x['baseline']).reshape(-1,1))\n",
    "x['pen_pressure']=scaler2.fit_transform(np.array(x['pen_pressure']).reshape(-1,1))\n",
    "x['letter_size']=scaler3.fit_transform(np.array(x['letter_size']).reshape(-1,1))\n",
    "x['line_spacing']=scaler4.fit_transform(np.array(x['line_spacing']).reshape(-1,1))\n",
    "x['word_spacing']=scaler5.fit_transform(np.array(x['word_spacing']).reshape(-1,1))\n",
    "x['width']=scaler6.fit_transform(np.array(x['width']).reshape(-1,1))\n",
    "x['height']=scaler7.fit_transform(np.array(x['height']).reshape(-1,1))\n",
    "x['bar-height']=scaler8.fit_transform(np.array(x['bar-height']).reshape(-1,1))\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N (T score)</th>\n",
       "      <th>E(T score)</th>\n",
       "      <th>O (T score)</th>\n",
       "      <th>A (T score)</th>\n",
       "      <th>C(T score)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>34</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>67</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>64</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>68</td>\n",
       "      <td>66</td>\n",
       "      <td>60</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>74</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>58</td>\n",
       "      <td>73</td>\n",
       "      <td>53</td>\n",
       "      <td>67</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>58</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>63</td>\n",
       "      <td>68</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>68</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    N (T score)  E(T score)  O (T score)  A (T score)  C(T score)\n",
       "0            55          74           73           34          67\n",
       "1            66          67           66           63          55\n",
       "2            72          57           74           64          49\n",
       "3            73          74           74           67          48\n",
       "4            72          68           66           60          74\n",
       "..          ...         ...          ...          ...         ...\n",
       "91           69          66           74           61          74\n",
       "92           58          73           53           67          74\n",
       "93           65          65           58           74          74\n",
       "94           63          68           74           71          74\n",
       "95           62          57           74           68          63\n",
       "\n",
       "[96 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels y \n",
    "\n",
    "for i in range(len(y_t)):\n",
    "    if(y_t['N (T score)'][i]>=26 and y_t['N (T score)'][i]<=34):\n",
    "        y_t['N (T score)'][i]=0\n",
    "        \n",
    "    elif(y_t['N (T score)'][i]>=35 and y_t['N (T score)'][i]<=44):\n",
    "        y_t['N (T score)'][i]=1\n",
    "        \n",
    "    elif(y_t['N (T score)'][i]>=45 and y_t['N (T score)'][i]<=55):\n",
    "        y_t['N (T score)'][i]=2\n",
    "        \n",
    "    elif(y_t['N (T score)'][i]>=56 and y_t['N (T score)'][i]<=65):\n",
    "        y_t['N (T score)'][i]=3\n",
    "     \n",
    "    elif(y_t['N (T score)'][i]>=66 and y_t['N (T score)'][i]<=74):\n",
    "        y_t['N (T score)'][i]=4\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    if(y_t['E(T score)'][i]>=26 and y_t['E(T score)'][i]<=34):\n",
    "        y_t['E(T score)'][i]=0\n",
    "        \n",
    "    elif(y_t['E(T score)'][i]>=35 and y_t['E(T score)'][i]<=44):\n",
    "        y_t['E(T score)'][i]=1\n",
    "        \n",
    "    elif(y_t['E(T score)'][i]>=45 and y_t['E(T score)'][i]<=55):\n",
    "        y_t['E(T score)'][i]=2\n",
    "        \n",
    "    elif(y_t['E(T score)'][i]>=56 and y_t['E(T score)'][i]<=65):\n",
    "        y_t['E(T score)'][i]=3\n",
    "        \n",
    "    elif(y_t['E(T score)'][i]>=66 and y_t['E(T score)'][i]<=74):\n",
    "        y_t['E(T score)'][i]=4\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(y_t['O (T score)'][i]>=26 and y_t['O (T score)'][i]<=34):\n",
    "        y_t['O (T score)'][i]=0\n",
    "        \n",
    "    elif(y_t['O (T score)'][i]>=35 and y_t['O (T score)'][i]<=44):\n",
    "        y_t['O (T score)'][i]=1\n",
    "        \n",
    "    elif(y_t['O (T score)'][i]>=45 and y_t['O (T score)'][i]<=55):\n",
    "        y_t['O (T score)'][i]=2\n",
    "        \n",
    "    elif(y_t['O (T score)'][i]>=56 and y_t['O (T score)'][i]<=65):\n",
    "        y_t['O (T score)'][i]=3\n",
    "        \n",
    "    elif(y_t['O (T score)'][i]>=66 and y_t['O (T score)'][i]<=74):\n",
    "        y_t['O (T score)'][i]=4\n",
    "    \n",
    "        \n",
    "    \n",
    "    if(y_t['A (T score)'][i]>=26 and y_t['A (T score)'][i]<=34):\n",
    "        y_t['A (T score)'][i]=0\n",
    "        \n",
    "    elif(y_t['A (T score)'][i]>=35 and y_t['A (T score)'][i]<=44):\n",
    "        y_t['A (T score)'][i]=1\n",
    "        \n",
    "    elif(y_t['A (T score)'][i]>=45 and y_t['A (T score)'][i]<=55):\n",
    "        y_t['A (T score)'][i]=2\n",
    "        \n",
    "    elif(y_t['A (T score)'][i]>=56 and y_t['A (T score)'][i]<=65):\n",
    "        y_t['A (T score)'][i]=3\n",
    "        \n",
    "    elif(y_t['A (T score)'][i]>=66 and y_t['A (T score)'][i]<=74):\n",
    "        y_t['A (T score)'][i]=4\n",
    "        \n",
    "   \n",
    " \n",
    "    if(y_t['C(T score)'][i]>=26 and y_t['C(T score)'][i]<=34):\n",
    "        y_t['C(T score)'][i]=0\n",
    "        \n",
    "    elif(y_t['C(T score)'][i]>=35 and y_t['C(T score)'][i]<=44):\n",
    "        y_t['C(T score)'][i]=1\n",
    "        \n",
    "    elif(y_t['C(T score)'][i]>=45 and y_t['C(T score)'][i]<=55):\n",
    "        y_t['C(T score)'][i]=2\n",
    "        \n",
    "    elif(y_t['C(T score)'][i]>=56 and y_t['C(T score)'][i]<=65):\n",
    "        y_t['C(T score)'][i]=3\n",
    "        \n",
    "    elif(y_t['C(T score)'][i]>=66 and y_t['C(T score)'][i]<=74):\n",
    "        y_t['C(T score)'][i]=4\n",
    "    \n",
    "    else:\n",
    "        incorrect_ids.append(y_t['id'][i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N (T score)</th>\n",
       "      <th>E(T score)</th>\n",
       "      <th>O (T score)</th>\n",
       "      <th>A (T score)</th>\n",
       "      <th>C(T score)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    N (T score)  E(T score)  O (T score)  A (T score)  C(T score)\n",
       "0             2           4            4            0           4\n",
       "1             4           4            4            3           2\n",
       "2             4           3            4            3           2\n",
       "3             4           4            4            4           2\n",
       "4             4           4            4            3           4\n",
       "..          ...         ...          ...          ...         ...\n",
       "91            4           4            4            3           4\n",
       "92            3           4            2            4           4\n",
       "93            3           3            3            4           4\n",
       "94            3           4            4            4           4\n",
       "95            3           3            4            4           3\n",
       "\n",
       "[96 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    50\n",
       "3    32\n",
       "2    10\n",
       "1     4\n",
       "Name: C(T score), dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t['C(T score)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    58\n",
       "3    26\n",
       "2    11\n",
       "1     1\n",
       "Name: N (T score), dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t['N (T score)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    63\n",
       "3    29\n",
       "2     4\n",
       "Name: E(T score), dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t['E(T score)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    57\n",
       "3    30\n",
       "2     9\n",
       "Name: O (T score), dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t['O (T score)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    53\n",
       "3    21\n",
       "2    18\n",
       "1     3\n",
       "0     1\n",
       "Name: A (T score), dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t['A (T score)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t1=np.array(y_t['N (T score)'])\n",
    "y_t2=np.array(y_t['E(T score)'])\n",
    "y_t3=np.array(y_t['O (T score)'])\n",
    "y_t4=np.array(y_t['A (T score)'])\n",
    "y_t5=np.array(y_t['C(T score)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96,), (96,), (96,), (96,), (96,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t1.shape,y_t2.shape,y_t3.shape,y_t4.shape,y_t5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ohe1 = OneHotEncoder()\n",
    "ohe2 = OneHotEncoder()\n",
    "ohe3 = OneHotEncoder()\n",
    "ohe4 = OneHotEncoder()\n",
    "ohe5 = OneHotEncoder()\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "le3 = LabelEncoder()\n",
    "le4 = LabelEncoder()\n",
    "le5 = LabelEncoder()\n",
    "\n",
    "y_t1 = ohe1.fit_transform(y_t1.reshape((-1,1))).toarray()\n",
    "y_t2 = ohe2.fit_transform(y_t2.reshape((-1,1))).toarray()\n",
    "y_t3 = ohe3.fit_transform(y_t3.reshape((-1,1))).toarray()\n",
    "y_t4 = ohe4.fit_transform(y_t4.reshape((-1,1))).toarray()\n",
    "y_t5 = ohe5.fit_transform(y_t5.reshape((-1,1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t1.astype(float)\n",
    "y_t2.astype(float)\n",
    "y_t3.astype(float)\n",
    "y_t4.astype(float)\n",
    "y_t5.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 4), (96, 3), (96, 3), (96, 5), (96, 4))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t1.shape,y_t2.shape,y_t3.shape,y_t4.shape,y_t5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(x, y_t1,test_size=0.2, random_state=42)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(x, y_t2,test_size=0.2, random_state=42)\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(x, y_t3,test_size=0.2, random_state=42)\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(x, y_t4,test_size=0.2, random_state=42)\n",
    "X_train6, X_test6, y_train6, y_test6 = train_test_split(x, y_t5,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76, 8), (76, 8), (76, 8), (76, 8), (76, 8))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape,X_train3.shape,X_train4.shape,X_train5.shape,X_train6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76, 4), (76, 3), (76, 3), (76, 5), (76, 4))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2.shape,y_train3.shape,y_train4.shape,y_train5.shape,y_train6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\multiclass.py:75: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "log2=OneVsRestClassifier(LogisticRegression())\n",
    "log3=OneVsRestClassifier(LogisticRegression())\n",
    "log4=OneVsRestClassifier(LogisticRegression())\n",
    "log5=OneVsRestClassifier(LogisticRegression())\n",
    "log6=OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "\n",
    "log2.fit(X_train2,y_train2)\n",
    "log3.fit(X_train3,y_train3)\n",
    "log4.fit(X_train4,y_train4)\n",
    "log5.fit(X_train5,y_train5)\n",
    "log6.fit(X_train6,y_train6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred2=log2.predict(X_test2)\n",
    "y_pred3=log3.predict(X_test3)\n",
    "y_pred4=log4.predict(X_test4)\n",
    "y_pred5=log5.predict(X_test5)\n",
    "y_pred6=log6.predict(X_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision none: N [0.   0.   0.   0.75]\n",
      "Recall: none  N [0.         0.         0.         0.85714286]\n",
      "Precision: macro N  0.1875\n",
      "Recall: macro N  0.21428571428571427\n",
      "Precision:micro N 0.75\n",
      "Recall:micro N 0.6\n",
      "Precision none: E [0.   0.   0.85]\n",
      "Recall: none E [0. 0. 1.]\n",
      "Precision: macro E 0.2833333333333333\n",
      "Recall: macro  E 0.3333333333333333\n",
      "Precision:micro E 0.85\n",
      "Recall:micro E 0.85\n",
      "Precision none: O [0.         0.         0.64705882]\n",
      "Recall: none O [0.         0.         0.84615385]\n",
      "Precision: macro O 0.21568627450980393\n",
      "Recall: macro  O 0.28205128205128205\n",
      "Precision:micro O 0.6470588235294118\n",
      "Recall:micro O 0.55\n",
      "Precision none: A [0. 0. 0. 0. 0.]\n",
      "Recall: none A [0. 0. 0. 0. 0.]\n",
      "Precision: macro A 0.0\n",
      "Recall: macro A  0.0\n",
      "Precision:micro A 0.0\n",
      "Recall:micro A 0.0\n",
      "Precision none: C [0.  0.  0.  0.7]\n",
      "Recall: none C [0.         0.         0.         0.53846154]\n",
      "Precision: macro C 0.175\n",
      "Recall: macro C  0.1346153846153846\n",
      "Precision:micro 0.7\n",
      "Recall:micro C 0.35\n",
      "Acc N:  0.6\n",
      "Acc E:  0.85\n",
      "Acc O:  0.55\n",
      "Acc A:  0.0\n",
      "Acc C:  0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision none: N\",metrics.precision_score(y_test2, y_pred2,average=None))\n",
    "print(\"Recall: none  N\",metrics.recall_score(y_test2, y_pred2,average=None))\n",
    "print(\"Precision: macro N \",metrics.precision_score(y_test2, y_pred2,average='macro'))\n",
    "print(\"Recall: macro N \",metrics.recall_score(y_test2, y_pred2,average='macro'))\n",
    "print(\"Precision:micro N\",metrics.precision_score(y_test2, y_pred2,average='micro'))\n",
    "print(\"Recall:micro N\",metrics.recall_score(y_test2, y_pred2,average='micro'))\n",
    "\n",
    "print(\"Precision none: E\",metrics.precision_score(y_test3, y_pred3,average=None))\n",
    "print(\"Recall: none E\",metrics.recall_score(y_test3, y_pred3,average=None))\n",
    "print(\"Precision: macro E\",metrics.precision_score(y_test3, y_pred3,average='macro'))\n",
    "print(\"Recall: macro  E\",metrics.recall_score(y_test3, y_pred3,average='macro'))\n",
    "print(\"Precision:micro E\",metrics.precision_score(y_test3, y_pred3,average='micro'))\n",
    "print(\"Recall:micro E\",metrics.recall_score(y_test3, y_pred3,average='micro'))\n",
    "\n",
    "print(\"Precision none: O\",metrics.precision_score(y_test4, y_pred4,average=None))\n",
    "print(\"Recall: none O\",metrics.recall_score(y_test4, y_pred4,average=None))\n",
    "print(\"Precision: macro O\",metrics.precision_score(y_test4, y_pred4,average='macro'))\n",
    "print(\"Recall: macro  O\",metrics.recall_score(y_test4, y_pred4,average='macro'))\n",
    "print(\"Precision:micro O\",metrics.precision_score(y_test4, y_pred4,average='micro'))\n",
    "print(\"Recall:micro O\",metrics.recall_score(y_test4, y_pred4,average='micro'))\n",
    "\n",
    "print(\"Precision none: A\",metrics.precision_score(y_test5, y_pred5,average=None))\n",
    "print(\"Recall: none A\",metrics.recall_score(y_test5, y_pred5,average=None))\n",
    "print(\"Precision: macro A\",metrics.precision_score(y_test5, y_pred5,average='macro'))\n",
    "print(\"Recall: macro A \",metrics.recall_score(y_test5, y_pred5,average='macro'))\n",
    "print(\"Precision:micro A\",metrics.precision_score(y_test5, y_pred5,average='micro'))\n",
    "print(\"Recall:micro A\",metrics.recall_score(y_test5, y_pred5,average='micro'))\n",
    "\n",
    "print(\"Precision none: C\",metrics.precision_score(y_test6, y_pred6,average=None))\n",
    "print(\"Recall: none C\",metrics.recall_score(y_test6, y_pred6,average=None))\n",
    "print(\"Precision: macro C\",metrics.precision_score(y_test6, y_pred6,average='macro'))\n",
    "print(\"Recall: macro C \",metrics.recall_score(y_test6, y_pred6,average='macro'))\n",
    "print(\"Precision:micro\",metrics.precision_score(y_test6, y_pred6,average='micro'))\n",
    "print(\"Recall:micro C\",metrics.recall_score(y_test6, y_pred6,average='micro'))\n",
    "\n",
    "print(\"Acc N: \",accuracy_score(y_pred2,y_test2))\n",
    "print(\"Acc E: \",accuracy_score(y_pred3,y_test3))\n",
    "print(\"Acc O: \",accuracy_score(y_pred4,y_test4))\n",
    "print(\"Acc A: \",accuracy_score(y_pred5,y_test5))\n",
    "print(\"Acc C: \",accuracy_score(y_pred6,y_test6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\multiclass.py:75: UserWarning: Label not 0 is present in all training examples.\n",
      "  str(classes[c]))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "grid2 = OneVsRestClassifier(SVC(kernel='rbf'))\n",
    "grid3 = OneVsRestClassifier(SVC(kernel='rbf'))\n",
    "grid4 = OneVsRestClassifier(SVC(kernel='rbf'))\n",
    "grid5 = OneVsRestClassifier(SVC(kernel='rbf'))\n",
    "grid6 = OneVsRestClassifier(SVC(kernel='rbf'))\n",
    "\n",
    "grid2.fit(X_train2,y_train2)\n",
    "grid3.fit(X_train3,y_train3)\n",
    "grid4.fit(X_train4,y_train4)\n",
    "grid5.fit(X_train5,y_train5)\n",
    "grid6.fit(X_train6,y_train6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred2=grid2.predict(X_test2)\n",
    "y_pred3=grid3.predict(X_test3)\n",
    "y_pred4=grid4.predict(X_test4)\n",
    "y_pred5=grid5.predict(X_test5)\n",
    "y_pred6=grid6.predict(X_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: macro N  0.18333333333333332\n",
      "Recall: macro N  0.19642857142857142\n",
      "Precision:micro N 0.7333333333333333\n",
      "Recall:micro N 0.55\n",
      "Precision: macro E 0.2833333333333333\n",
      "Recall: macro  E 0.3333333333333333\n",
      "Precision:micro E 0.85\n",
      "Recall:micro E 0.85\n",
      "Precision: macro O 0.22916666666666666\n",
      "Recall: macro  O 0.28205128205128205\n",
      "Precision:micro O 0.6875\n",
      "Recall:micro O 0.55\n",
      "Precision: macro A 0.15\n",
      "Recall: macro A  0.04\n",
      "Precision:micro A 0.75\n",
      "Recall:micro A 0.15\n",
      "Precision: macro C 0.21875\n",
      "Recall: macro C  0.1346153846153846\n",
      "Precision:micro 0.875\n",
      "Recall:micro C 0.35\n",
      "Acc N:  0.55\n",
      "Acc E:  0.85\n",
      "Acc O:  0.55\n",
      "Acc A:  0.15\n",
      "Acc C:  0.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Precision: macro N \",metrics.precision_score(y_test2, y_pred2,average='macro'))\n",
    "print(\"Recall: macro N \",metrics.recall_score(y_test2, y_pred2,average='macro'))\n",
    "print(\"Precision:micro N\",metrics.precision_score(y_test2, y_pred2,average='micro'))\n",
    "print(\"Recall:micro N\",metrics.recall_score(y_test2, y_pred2,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro E\",metrics.precision_score(y_test3, y_pred3,average='macro'))\n",
    "print(\"Recall: macro  E\",metrics.recall_score(y_test3, y_pred3,average='macro'))\n",
    "print(\"Precision:micro E\",metrics.precision_score(y_test3, y_pred3,average='micro'))\n",
    "print(\"Recall:micro E\",metrics.recall_score(y_test3, y_pred3,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro O\",metrics.precision_score(y_test4, y_pred4,average='macro'))\n",
    "print(\"Recall: macro  O\",metrics.recall_score(y_test4, y_pred4,average='macro'))\n",
    "print(\"Precision:micro O\",metrics.precision_score(y_test4, y_pred4,average='micro'))\n",
    "print(\"Recall:micro O\",metrics.recall_score(y_test4, y_pred4,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro A\",metrics.precision_score(y_test5, y_pred5,average='macro'))\n",
    "print(\"Recall: macro A \",metrics.recall_score(y_test5, y_pred5,average='macro'))\n",
    "print(\"Precision:micro A\",metrics.precision_score(y_test5, y_pred5,average='micro'))\n",
    "print(\"Recall:micro A\",metrics.recall_score(y_test5, y_pred5,average='micro'))\n",
    "\n",
    "print(\"Precision: macro C\",metrics.precision_score(y_test6, y_pred6,average='macro'))\n",
    "print(\"Recall: macro C \",metrics.recall_score(y_test6, y_pred6,average='macro'))\n",
    "print(\"Precision:micro\",metrics.precision_score(y_test6, y_pred6,average='micro'))\n",
    "print(\"Recall:micro C\",metrics.recall_score(y_test6, y_pred6,average='micro'))\n",
    "\n",
    "print(\"Acc N: \",accuracy_score(y_pred2,y_test2))\n",
    "print(\"Acc E: \",accuracy_score(y_pred3,y_test3))\n",
    "print(\"Acc O: \",accuracy_score(y_pred4,y_test4))\n",
    "print(\"Acc A: \",accuracy_score(y_pred5,y_test5))\n",
    "print(\"Acc C: \",accuracy_score(y_pred6,y_test6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2352 candidates, totalling 11760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=8)]: Done 528 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done 5648 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=8)]: Done 11586 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=8)]: Done 11760 out of 11760 | elapsed:   10.7s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2352 candidates, totalling 11760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 2032 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=8)]: Done 11760 out of 11760 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2352 candidates, totalling 11760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1520 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=8)]: Done 6640 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=8)]: Done 11760 out of 11760 | elapsed:   11.0s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2352 candidates, totalling 11760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1520 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 6640 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=8)]: Done 11760 out of 11760 | elapsed:   11.6s finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2352 candidates, totalling 11760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 1520 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=8)]: Done 6640 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=8)]: Done 11760 out of 11760 | elapsed:   11.5s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "depths = np.arange(1, 21)\n",
    "num_leafs = [1, 5, 10, 20, 50, 100]\n",
    "param_grid_tree = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4],'max_depth':[3,4,5,6], 'criterion':['gini','entropy']}\n",
    "\n",
    "dt2 = GridSearchCV(DecisionTreeClassifier(), param_grid_tree, refit = True, verbose = 3,n_jobs=8)\n",
    "dt3 = GridSearchCV(DecisionTreeClassifier(), param_grid_tree, refit = True, verbose = 3,n_jobs=8)\n",
    "dt4 = GridSearchCV(DecisionTreeClassifier(), param_grid_tree, refit = True, verbose = 3,n_jobs=8)\n",
    "dt5 = GridSearchCV(DecisionTreeClassifier(), param_grid_tree, refit = True, verbose = 3,n_jobs=8)\n",
    "dt6 = GridSearchCV(DecisionTreeClassifier(), param_grid_tree, refit = True, verbose = 3,n_jobs=8)\n",
    "\n",
    "\n",
    "dt2.fit(X_train2,y_train2)\n",
    "dt3.fit(X_train3,y_train3)\n",
    "dt4.fit(X_train4,y_train4)\n",
    "dt5.fit(X_train5,y_train5)\n",
    "dt6.fit(X_train6,y_train6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred2=dt2.predict(X_test2)\n",
    "y_pred3=dt3.predict(X_test3)\n",
    "y_pred4=dt4.predict(X_test4)\n",
    "y_pred5=dt5.predict(X_test5)\n",
    "y_pred6=dt6.predict(X_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: macro N  0.2745098039215686\n",
      "Recall: macro N  0.29464285714285715\n",
      "Precision:micro N 0.7\n",
      "Recall:micro N 0.7\n",
      "Precision: macro E 0.30833333333333335\n",
      "Recall: macro  E 0.3235294117647059\n",
      "Precision:micro E 0.45\n",
      "Recall:micro E 0.45\n",
      "Precision: macro O 0.37777777777777777\n",
      "Recall: macro  O 0.44871794871794873\n",
      "Precision:micro O 0.65\n",
      "Recall:micro O 0.65\n",
      "Precision: macro A 0.16363636363636364\n",
      "Recall: macro A  0.12\n",
      "Precision:micro A 0.8181818181818182\n",
      "Recall:micro A 0.45\n",
      "Precision: macro C 0.36388888888888893\n",
      "Recall: macro C  0.3814102564102564\n",
      "Precision:micro 0.7\n",
      "Recall:micro C 0.7\n",
      "Acc N:  0.7\n",
      "Acc E:  0.45\n",
      "Acc O:  0.65\n",
      "Acc A:  0.45\n",
      "Acc C:  0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: macro N \",metrics.precision_score(y_test2, y_pred2,average='macro'))\n",
    "print(\"Recall: macro N \",metrics.recall_score(y_test2, y_pred2,average='macro'))\n",
    "print(\"Precision:micro N\",metrics.precision_score(y_test2, y_pred2,average='micro'))\n",
    "print(\"Recall:micro N\",metrics.recall_score(y_test2, y_pred2,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro E\",metrics.precision_score(y_test3, y_pred3,average='macro'))\n",
    "print(\"Recall: macro  E\",metrics.recall_score(y_test3, y_pred3,average='macro'))\n",
    "print(\"Precision:micro E\",metrics.precision_score(y_test3, y_pred3,average='micro'))\n",
    "print(\"Recall:micro E\",metrics.recall_score(y_test3, y_pred3,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro O\",metrics.precision_score(y_test4, y_pred4,average='macro'))\n",
    "print(\"Recall: macro  O\",metrics.recall_score(y_test4, y_pred4,average='macro'))\n",
    "print(\"Precision:micro O\",metrics.precision_score(y_test4, y_pred4,average='micro'))\n",
    "print(\"Recall:micro O\",metrics.recall_score(y_test4, y_pred4,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro A\",metrics.precision_score(y_test5, y_pred5,average='macro'))\n",
    "print(\"Recall: macro A \",metrics.recall_score(y_test5, y_pred5,average='macro'))\n",
    "print(\"Precision:micro A\",metrics.precision_score(y_test5, y_pred5,average='micro'))\n",
    "print(\"Recall:micro A\",metrics.recall_score(y_test5, y_pred5,average='micro'))\n",
    "\n",
    "print(\"Precision: macro C\",metrics.precision_score(y_test6, y_pred6,average='macro'))\n",
    "print(\"Recall: macro C \",metrics.recall_score(y_test6, y_pred6,average='macro'))\n",
    "print(\"Precision:micro\",metrics.precision_score(y_test6, y_pred6,average='micro'))\n",
    "print(\"Recall:micro C\",metrics.recall_score(y_test6, y_pred6,average='micro'))\n",
    "\n",
    "print(\"Acc N: \",accuracy_score(y_pred2,y_test2))\n",
    "print(\"Acc E: \",accuracy_score(y_pred3,y_test3))\n",
    "print(\"Acc O: \",accuracy_score(y_pred4,y_test4))\n",
    "print(\"Acc A: \",accuracy_score(y_pred5,y_test5))\n",
    "print(\"Acc C: \",accuracy_score(y_pred6,y_test6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed:   32.0s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=8)]: Done 1136 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 1440 out of 1440 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  18 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 208 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=8)]: Done 432 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=8)]: Done 656 tasks      | elapsed:   37.0s\n",
      "[Parallel(n_jobs=8)]: Done 944 tasks      | elapsed:   53.8s\n",
      "[Parallel(n_jobs=8)]: Done 1296 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 1440 out of 1440 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  17 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 152 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=8)]: Done 312 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=8)]: Done 536 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=8)]: Done 824 tasks      | elapsed:   47.8s\n",
      "[Parallel(n_jobs=8)]: Done 1176 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 1440 out of 1440 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=8)]: Done 272 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=8)]: Done 496 tasks      | elapsed:   28.4s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:   45.5s\n",
      "[Parallel(n_jobs=8)]: Done 1136 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done 1440 out of 1440 | elapsed:  1.4min finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  18 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=8)]: Done 168 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=8)]: Done 328 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=8)]: Done 552 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=8)]: Done 840 tasks      | elapsed:   50.6s\n",
      "[Parallel(n_jobs=8)]: Done 1192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=8)]: Done 1440 out of 1440 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "param_grid_rf = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100,110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 11],\n",
    "    'n_estimators': [100, 200, 300,100]\n",
    "}\n",
    "\n",
    "grid_rf2 = GridSearchCV(RandomForestClassifier(), param_grid_rf, refit = True, verbose = 3,n_jobs=8)\n",
    "grid_rf3 = GridSearchCV(RandomForestClassifier(), param_grid_rf, refit = True, verbose = 3,n_jobs=8)\n",
    "grid_rf4 = GridSearchCV(RandomForestClassifier(), param_grid_rf, refit = True, verbose = 3,n_jobs=8)\n",
    "grid_rf5 = GridSearchCV(RandomForestClassifier(), param_grid_rf, refit = True, verbose = 3,n_jobs=8)\n",
    "grid_rf6 = GridSearchCV(RandomForestClassifier(), param_grid_rf, refit = True, verbose = 3,n_jobs=8)\n",
    "\n",
    "\n",
    "grid_rf2.fit(X_train2,y_train2)\n",
    "grid_rf3.fit(X_train3,y_train3)\n",
    "grid_rf4.fit(X_train4,y_train4)\n",
    "grid_rf5.fit(X_train5,y_train5)\n",
    "grid_rf6.fit(X_train6,y_train6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred2=grid_rf2.predict(X_test2)\n",
    "y_pred3=grid_rf3.predict(X_test3)\n",
    "y_pred4=grid_rf4.predict(X_test4)\n",
    "y_pred5=grid_rf5.predict(X_test5)\n",
    "y_pred6=grid_rf6.predict(X_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: macro N  0.1875\n",
      "Recall: macro N  0.16071428571428573\n",
      "Precision:micro N 0.6428571428571429\n",
      "Recall:micro N 0.45\n",
      "Precision: macro E 0.40277777777777773\n",
      "Recall: macro  E 0.4411764705882353\n",
      "Precision:micro E 0.7894736842105263\n",
      "Recall:micro E 0.75\n",
      "Precision: macro O 0.23076923076923075\n",
      "Recall: macro  O 0.23076923076923075\n",
      "Precision:micro O 0.47368421052631576\n",
      "Recall:micro O 0.45\n",
      "Precision: macro A 0.175\n",
      "Recall: macro A  0.09333333333333334\n",
      "Precision:micro A 0.875\n",
      "Recall:micro A 0.35\n",
      "Precision: macro C 0.38541666666666663\n",
      "Recall: macro C  0.21794871794871795\n",
      "Precision:micro 0.8181818181818182\n",
      "Recall:micro C 0.45\n",
      "Acc N:  0.45\n",
      "Acc E:  0.75\n",
      "Acc O:  0.45\n",
      "Acc A:  0.35\n",
      "Acc C:  0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DivyanshuSharma\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: macro N \",metrics.precision_score(y_test2, y_pred2,average='macro'))\n",
    "print(\"Recall: macro N \",metrics.recall_score(y_test2, y_pred2,average='macro'))\n",
    "print(\"Precision:micro N\",metrics.precision_score(y_test2, y_pred2,average='micro'))\n",
    "print(\"Recall:micro N\",metrics.recall_score(y_test2, y_pred2,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro E\",metrics.precision_score(y_test3, y_pred3,average='macro'))\n",
    "print(\"Recall: macro  E\",metrics.recall_score(y_test3, y_pred3,average='macro'))\n",
    "print(\"Precision:micro E\",metrics.precision_score(y_test3, y_pred3,average='micro'))\n",
    "print(\"Recall:micro E\",metrics.recall_score(y_test3, y_pred3,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro O\",metrics.precision_score(y_test4, y_pred4,average='macro'))\n",
    "print(\"Recall: macro  O\",metrics.recall_score(y_test4, y_pred4,average='macro'))\n",
    "print(\"Precision:micro O\",metrics.precision_score(y_test4, y_pred4,average='micro'))\n",
    "print(\"Recall:micro O\",metrics.recall_score(y_test4, y_pred4,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro A\",metrics.precision_score(y_test5, y_pred5,average='macro'))\n",
    "print(\"Recall: macro A \",metrics.recall_score(y_test5, y_pred5,average='macro'))\n",
    "print(\"Precision:micro A\",metrics.precision_score(y_test5, y_pred5,average='micro'))\n",
    "print(\"Recall:micro A\",metrics.recall_score(y_test5, y_pred5,average='micro'))\n",
    "\n",
    "print(\"Precision: macro C\",metrics.precision_score(y_test6, y_pred6,average='macro'))\n",
    "print(\"Recall: macro C \",metrics.recall_score(y_test6, y_pred6,average='macro'))\n",
    "print(\"Precision:micro\",metrics.precision_score(y_test6, y_pred6,average='micro'))\n",
    "print(\"Recall:micro C\",metrics.recall_score(y_test6, y_pred6,average='micro'))\n",
    "\n",
    "print(\"Acc N: \",accuracy_score(y_pred2,y_test2))\n",
    "print(\"Acc E: \",accuracy_score(y_pred3,y_test3))\n",
    "print(\"Acc O: \",accuracy_score(y_pred4,y_test4))\n",
    "print(\"Acc A: \",accuracy_score(y_pred5,y_test5))\n",
    "print(\"Acc C: \",accuracy_score(y_pred6,y_test6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2352 candidates, totalling 11760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 208 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=8)]: Done 528 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=8)]: Done 976 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=8)]: Done 1552 tasks      | elapsed:   39.8s\n",
      "[Parallel(n_jobs=8)]: Done 2256 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=8)]: Done 3088 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=8)]: Done 4048 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=8)]: Done 5136 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=8)]: Done 6352 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=8)]: Done 7696 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=8)]: Done 9168 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=8)]: Done 10768 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=8)]: Done 11760 out of 11760 | elapsed:  5.2min finished\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2352 candidates, totalling 11760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 208 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=8)]: Done 528 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=8)]: Done 976 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=8)]: Done 1552 tasks      | elapsed:   38.7s\n",
      "[Parallel(n_jobs=8)]: Done 2256 tasks      | elapsed:   56.9s\n",
      "[Parallel(n_jobs=8)]: Done 3088 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=8)]: Done 4048 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=8)]: Done 5136 tasks      | elapsed:  2.2min\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "param_grid_tree = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4],'max_depth':[3,4,5,6], 'criterion':['gini','entropy']}\n",
    "\n",
    "dt2 = GridSearchCV(ExtraTreesClassifier(), param_grid_tree, refit = True, verbose = 3,n_jobs=8)\n",
    "dt3 = GridSearchCV(ExtraTreesClassifier(), param_grid_tree, refit = True, verbose = 3,n_jobs=8)\n",
    "dt4 = GridSearchCV(ExtraTreesClassifier(), param_grid_tree, refit = True, verbose = 3,n_jobs=8)\n",
    "dt5 = GridSearchCV(ExtraTreesClassifier(), param_grid_tree, refit = True, verbose = 3,n_jobs=8)\n",
    "dt6 = GridSearchCV(ExtraTreesClassifier(), param_grid_tree, refit = True, verbose = 3,n_jobs=8)\n",
    "\n",
    "\n",
    "dt2.fit(X_train2,y_train2)\n",
    "dt3.fit(X_train3,y_train3)\n",
    "dt4.fit(X_train4,y_train4)\n",
    "dt5.fit(X_train5,y_train5)\n",
    "dt6.fit(X_train6,y_train6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred2=dt2.predict(X_test2)\n",
    "y_pred3=dt3.predict(X_test3)\n",
    "y_pred4=dt4.predict(X_test4)\n",
    "y_pred5=dt5.predict(X_test5)\n",
    "y_pred6=dt6.predict(X_test6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: macro N \",metrics.precision_score(y_test2, y_pred2,average='macro'))\n",
    "print(\"Recall: macro N \",metrics.recall_score(y_test2, y_pred2,average='macro'))\n",
    "print(\"Precision:micro N\",metrics.precision_score(y_test2, y_pred2,average='micro'))\n",
    "print(\"Recall:micro N\",metrics.recall_score(y_test2, y_pred2,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro E\",metrics.precision_score(y_test3, y_pred3,average='macro'))\n",
    "print(\"Recall: macro  E\",metrics.recall_score(y_test3, y_pred3,average='macro'))\n",
    "print(\"Precision:micro E\",metrics.precision_score(y_test3, y_pred3,average='micro'))\n",
    "print(\"Recall:micro E\",metrics.recall_score(y_test3, y_pred3,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro O\",metrics.precision_score(y_test4, y_pred4,average='macro'))\n",
    "print(\"Recall: macro  O\",metrics.recall_score(y_test4, y_pred4,average='macro'))\n",
    "print(\"Precision:micro O\",metrics.precision_score(y_test4, y_pred4,average='micro'))\n",
    "print(\"Recall:micro O\",metrics.recall_score(y_test4, y_pred4,average='micro'))\n",
    "\n",
    "\n",
    "print(\"Precision: macro A\",metrics.precision_score(y_test5, y_pred5,average='macro'))\n",
    "print(\"Recall: macro A \",metrics.recall_score(y_test5, y_pred5,average='macro'))\n",
    "print(\"Precision:micro A\",metrics.precision_score(y_test5, y_pred5,average='micro'))\n",
    "print(\"Recall:micro A\",metrics.recall_score(y_test5, y_pred5,average='micro'))\n",
    "\n",
    "print(\"Precision: macro C\",metrics.precision_score(y_test6, y_pred6,average='macro'))\n",
    "print(\"Recall: macro C \",metrics.recall_score(y_test6, y_pred6,average='macro'))\n",
    "print(\"Precision:micro\",metrics.precision_score(y_test6, y_pred6,average='micro'))\n",
    "print(\"Recall:micro C\",metrics.recall_score(y_test6, y_pred6,average='micro'))\n",
    "\n",
    "print(\"Acc N: \",accuracy_score(y_pred2,y_test2))\n",
    "print(\"Acc E: \",accuracy_score(y_pred3,y_test3))\n",
    "print(\"Acc O: \",accuracy_score(y_pred4,y_test4))\n",
    "print(\"Acc A: \",accuracy_score(y_pred5,y_test5))\n",
    "print(\"Acc C: \",accuracy_score(y_pred6,y_test6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
